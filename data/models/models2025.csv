"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"FVCP2PGE","journalArticle","2023","Zhao, Haodong; He, Ruifang; Xiao, Mengnan; Xu, Jing","Infusing Hierarchical Guidance into Prompt Tuning: A Parameter-Efficient Framework for Multi-level Implicit Discourse Relation Recognition","","","","10.18653/v1/2023.acl-long.357","","Multi-level implicit discourse relation recognition (MIDRR) aims at identifying hierarchical discourse relations among arguments. Previous methods achieve the promotion through finetuning PLMs. However, due to the data scarcity and the task gap, the pre-trained feature space cannot be accurately tuned to the task-specific space, which even aggravates the collapse of the vanilla space. Besides, the comprehension of hierarchical semantics for MIDRR makes the conversion much harder. In this paper, we propose a prompt-based Parameter-Efficient Multilevel IDRR (PEMI) framework to solve the above problems. First, we leverage parameterefficient prompt tuning to drive the inputted arguments to match the pre-trained space and realize the approximation with few parameters. Furthermore, we propose a hierarchical label refining (HLR) method for the prompt verbalizer to deeply integrate hierarchical guidance into the prompt tuning. Finally, our model achieves comparable results on PDTB 2.0 and 3.0 using about 0.1% trainable parameters compared with baselines and the visualization demonstrates the effectiveness of our HLR method.","2023","2023-10-30 16:40:45","2025-03-22 16:54:22","","","","","","","","","","","","","","","en","","","https://paperswithcode.com/paper/infusing-hierarchical-guidance-into-prompt","","Zotero","[{""task"": ""Named Entity Recognition (NER)"", ""dataset"": ""JNLPBA"", ""res"": ""82.0"", ""metric"": ""F1""}, {""task"": ""Named Entity Recognition (NER)"", ""dataset"": ""BC2GM"", ""res"": ""85.1"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""GAD"", ""res"": ""84.3"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DDI"", ""res"": ""81.9"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ChemProt"", ""res"": ""77.5"", ""metric"": ""F1""}]","{'citing': [], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/55VCPRKE/Zhao et al. - 2023 - Infusing Hierarchical Guidance into Prompt Tuning A Parameter-Efficient Framework for Multi-level I.pdf","","DONE; PTM:Roberta; GRANULARITY:Sentences; LANG:English; DATATYPEPROP:String; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; LEARNINGMETHOD:Promptbased; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; ARCHI:Transformer; ARCHI:Embedding; LEARNINGMETHOD:PEFT; TASK:RelationClassif; ARCHI:MLM; DATASET:PDTB2; DATASET:PDTB3; LEARNINGMETHOD:HLR; TASK:IMPLICIT_Discourse; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2Y9IP8XX","conferencePaper","2021","Hu, Xuming; Zhang, Chenwei; Ma, Fukun; Liu, Chenyao; Wen, Lijie; Yu, Philip S.","Semi-supervised Relation Extraction via Incremental Meta Self-Training","Findings of the Association for Computational Linguistics: EMNLP 2021","","","10.18653/v1/2021.findings-emnlp.44","https://aclanthology.org/2021.findings-emnlp.44","To alleviate human efforts from obtaining large-scale annotations, Semi-Supervised Relation Extraction methods aim to leverage unlabeled data in addition to learning from limited samples. Existing self-training methods suffer from the gradual drift problem, where noisy pseudo labels on unlabeled data are incorporated during training. To alleviate the noise in pseudo labels, we propose a method called MetaSRE, where a Relation Label Generation Network generates quality assessment on pseudo labels by (meta) learning from the successful and failed attempts on Relation Classiﬁcation Network as an additional metaobjective. To reduce the inﬂuence of noisy pseudo labels, MetaSRE adopts a pseudo label selection and exploitation scheme which assesses pseudo label quality on unlabeled samples and only exploits high-quality pseudo labels in a self-training fashion to incrementally augment labeled samples for both robustness and accuracy. Experimental results on two public datasets demonstrate the effectiveness of the proposed approach. Source code is available1. lots of manually labeled data for model training.","2021","2023-10-30 16:40:45","2025-03-22 16:53:52","2023-06-01 14:39:39","487-496","","","","","","MetaSRE","","","","","ACL","Punta Cana, Dominican Republic","en","","","https://paperswithcode.com/paper/semi-supervised-relation-extraction-via","","DOI.org (Crossref)","","{'citing': ['10.1109/taslp.2023.3270771', '10.1145/3539618.3592072', '10.1007/978-981-99-6207-5_12', '10.1109/access.2023.3252608', '10.1017/s1471068423000297', '10.1109/icassp43922.2022.9746499', '10.1109/trustcom56396.2022.00225', '10.1145/3534678.3539294', '10.1007/s10489-024-05327-y', '10.1145/3539618.3592058', '10.1109/bibm55620.2022.9995416', '10.1007/s11227-022-04875-9'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/9S2ALKWL/Hu et al. - 2021 - Semi-supervised Relation Extraction via Incremental Meta Self-Training.pdf","","DONE; GRANULARITY:Sentences; LANG:English; DATATYPEPROP:String; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; LEARNINGMETHOD:Self-Training; DATASET:TACRED; DATASET:Semeval2010; INPUT:NER; PTM:BERT; INPUT:TEXT; ARCHI:RelEmbedding; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP","","","","","","","","","","","","","","",""
"UU8PLL3E","journalArticle","2021","Hu, Yanfeng; Shen, Hong; Liu, Wuling; Min, Fei; Qiao, Xue; Jin, Kangrong","A Graph Convolutional Network With Multiple Dependency Representations for Relation Extraction","IEEE Access","","2169-3536","10.1109/ACCESS.2021.3086480","","Dependency analysis can assist neural networks to capture semantic features within a sentence for entity relation extraction (RE). Both hard and soft strategies of encoding dependency tree structure have been developed to balance the beneficial extra information against the unfavorable interference in the task of RE. A wide application of graph convolutional network (GCN) in the field of natural language processing (NLP) has demonstrated its effectiveness in encoding the input sentence with the dependency tree structure, as well as its efficiency in parallel computation. This study proposes a novel GCN-based model using multiple representations to depict the dependency tree from various perspectives, and combines those dependency representations afterward to obtain a better sentence representation for relation classification. This model can maximally draw from the sentence the semantic features relevant to the relationship between entities. Results show that our model achieves state-of-the-art performance in terms of the F1 score (68.0) on the Text Analysis Conference relation extraction dataset (TACRED). In addition, we verify that the renormalization parameter in the GCN operation should be carefully chosen to help GCN-based models achieve its best performance.","2021","2023-10-30 16:40:45","2025-03-22 16:53:51","","81575-81587","","","9","","","","","","","","","","","","","","","IEEE Xplore","","{'citing': ['10.1109/access.2023.3240898', '10.1155/2022/6221413', '10.3390/math10081344', '10.1007/s10462-022-10239-9', '10.1007/s11390-022-2420-2', '10.1007/s12065-023-00845-z', '10.1155/2023/8342104', '10.1145/3460210.3493547'], 'cited': ['10.18653/v1/p17-1053', '10.3115/1220575.1220666', '10.1016/j.procs.2017.05.045', '10.18653/v1/d18-1244', '10.18653/v1/p18-1192', '10.18653/v1/d18-1246', '10.1007/978-3-662-53622-3', '10.1109/msp.2012.2235192', '10.18653/v1/p16-1105', '10.18653/v1/p16-1072', '10.1017/cbo9781139030687', '10.18653/v1/p19-1282', '10.18653/v1/p19-1423', '10.3115/1218955.1219009', '10.1109/taslp.2016.2573050', '10.18653/v1/p19-1024', '10.18653/v1/p19-1131', '10.1016/j.knosys.2014.05.005', '10.1162/tacl_a_00049', '10.3115/1621969.1621986', '10.1109/icassp.2013.6638947', '10.18653/v1/d17-1004', '10.1109/tsipn.2018.2824239', '10.3115/v1/d14-1162', '10.1145/945645.945658', '10.18653/v1/n19-1298', '10.1016/0364-0213(90)90002-e', '10.1109/icccbda49378.2020.9095628', '10.18653/v1/d15-1206', '10.18653/v1/w15-4007', '10.1109/jproc.2018.2820126', '10.18653/v1/d15-1062', '10.3115/v1/p15-1150', '10.1007/s11222-007-9033-z', '10.1109/access.2020.2980859']}","","/root/snap/zotero-snap/common/Zotero/storage/SCPXMMYJ/Hu et al. - 2021 - A Graph Convolutional Network With Multiple Dependency Representations for Relation Extraction.pdf; /root/snap/zotero-snap/common/Zotero/storage/KHICSI3G/9446853.html","","DONE; GRANULARITY:Sentences; LANG:English; DATATYPEPROP:String; INPUT:Text; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:10^0; DATASET:TACRED; DATASET:Semeval2010; OBJECTPROPERTIES_BIN:NSP; INPUT:NER; ARCHI:classifLayer; PTM:Glove; ARCHI:GCN; ARCHI:BILSTM; ARCHI:FFN; ARCHI:Embedding; ARCHI:ENtityEmbedding; TASK:RelationClassif; ARCHI:POSEmbed; LEARNINGMETHOD:Training; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QI6X7548","journalArticle","2021","Christou, Despina; Tsoumakas, Grigorios","Improving Distantly-Supervised Relation Extraction Through BERT-Based Label and Instance Embeddings","IEEE Access","","2169-3536","10.1109/ACCESS.2021.3073428","https://ieeexplore.ieee.org/abstract/document/9405641","Distantly-supervised relation extraction (RE) is an effective method to scale RE to large corpora but suffers from noisy labels. Existing approaches try to alleviate noise through multi-instance learning and by providing additional information but manage to recognize mainly the top frequent relations, neglecting those in the long-tail. We propose REDSandT (Relation Extraction with Distant Supervision and Transformers), a novel distantly-supervised transformer-based RE method that manages to capture a wider set of relations through highly informative instance and label embeddings for RE by exploiting BERT's pre-trained model, and the relationship between labels and entities, respectively. We guide REDSandT to focus solely on relational tokens by fine-tuning BERT on a structured input, including the sub-tree connecting an entity pair and the entities' types. Using the extracted informative vectors, we shape label embeddings, which we also use as an attention mechanism over instances to further reduce noise. Finally, we represent sentences by concatenating relation and instance embeddings. Experiments in the two benchmark datasets for distantly-supervised RE, NYT-10 and GDS, show that REDSandT captures a broader set of relations with higher confidence, achieving a state-of-the-art AUC (0.424) in NYT-10 and an excellent AUC (0.862) in GDS.","2021","2023-10-30 16:40:45","2025-03-22 16:52:49","","62574-62582","","","9","","","REDSandT","","","","","","","","","","https://paperswithcode.com/paper/improving-distantly-supervised-relation-3","","IEEE Xplore","","{'citing': ['10.1016/j.neunet.2022.10.008', '10.1007/978-981-99-6207-5_10', '10.3233/idt-200094', '10.3390/su13169391', '10.3390/app12031532', '10.1155/2022/1912750', '10.1109/access.2023.3240898', '10.1145/3477495.3531876', '10.1109/cscwd54268.2022.9776118', '10.1109/taslp.2022.3199655', '10.3390/sym15091788', '10.1016/j.eswa.2023.119727', '10.1007/s11280-021-00979-z', '10.1016/j.aei.2023.101900', '10.1109/ijcnn54540.2023.10191666', '10.1007/s40747-023-01226-w'], 'cited': ['10.18653/v1/d18-1243', '10.18653/v1/d18-1157', '10.18653/v1/p18-1031', '10.18653/v1/p18-1046', '10.18653/v1/p18-1216', '10.18653/v1/p16-1200', '10.18653/v1/p16-1162', '10.1109/ijcnn.2018.8489631', '10.1007/978-3-642-15939-8_10', '10.18653/v1/d19-1395', '10.18653/v1/p19-1134', '10.18653/v1/d17-1189', '10.3115/1690219.1690287', '10.18653/v1/d17-1187', '10.18653/v1/n19-1288', '10.1109/access.2020.2996642', '10.18653/v1/d15-1206', '10.18653/v1/d15-1203']}","","/root/snap/zotero-snap/common/Zotero/storage/9JPEWPE3/Christou and Tsoumakas - 2021 - Improving Distantly-Supervised Relation Extraction Through BERT-Based Label and Instance Embeddings.pdf; /root/snap/zotero-snap/common/Zotero/storage/L7329ZPC/9405641.html","","DONE; GRANULARITY:Sentences; PTM:Bert; LANG:English; COSTEVAL_BIN:1; DATATYPEPROP:String; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; LEARNINGMETHOD:Distant; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:NSP; TO_EXCLUDE?; OBJECTPROPERTIES_BIN:NSP; INPUT:NER; ARCHI:PositionnalEMbed; PTM:TransE; ARCHI:RelEmbedding; DATASET:NYT10; TASK:RelationClassif; ARCHI:LabelEMbed; DATASET:GDS; TOCKECH; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YI5W6FIJ","conferencePaper","2022",", Qipeng Guo; , Yuqing Yang; , Hang Yan; , Xipeng Qiu; , Zheng Zhang","DORE: Document Ordered Relation Extraction based on Generative Framework","Findings of the Association for Computational Linguistics: EMNLP 2022","","","10.18653/v1/2022.findings-emnlp.253","https://arxiv.org/abs/2210.16064v2","In recent years, there is a surge of generation-based information extraction work, which allows a more direct use of pre-trained language models and efficiently captures output dependencies. However, previous generative methods using lexical representation do not naturally fit document-level relation extraction (DocRE) where there are multiple entities and relational facts. In this paper, we investigate the root cause of the underwhelming performance of the existing generative DocRE models and discover that the culprit is the inadequacy of the training paradigm, instead of the capacities of the models. We propose to generate a symbolic and ordered sequence from the relation matrix which is deterministic and easier for model to learn. Moreover, we design a parallel row generation method to process overlong target sequences. Besides, we introduce several negative sampling strategies to improve the performance with balanced signals. Experimental results on four datasets show that our proposed method can improve the performance of the generative DocRE models. We have released our code at https://github.com/ayyyq/DORE.","2022-10-28","2023-10-30 16:40:45","2025-03-22 16:53:20","","","","","","","","DORE","","","","","ACL","","","NA","","https://paperswithcode.com/paper/dore-document-ordered-relation-extraction","https://github.com/ayyyq/dore","","","{'citing': ['10.1109/tkde.2023.3292974'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/BLY32V37/et al. - 2022 - DORE Document Ordered Relation Extraction based on Generative Framework.pdf","","star; DONE; PTM:T5; PTM:Longformer; GRANULARITY:Document; ARCHI:Encoder-Decoder; LANG:English; PTM:Bart; DATATYPEPROP:String; DECODINGMETHOD_BIN:1; INPUT:Text; LEARNINGMETHOD:Finetuning; LINEARIZEDGRAPH_BIN:1; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:NSP; OBJECTPROPERTIES_BIN:0; NBDATASET:4; DATASET:GDA; INPUT:NER; DATASET:CDR; DATASET:DocRED; TASK:RelationClassif; DATASET:SciREx; PTM:BioBart; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP","","","","","","","","","","","","","","",""
"CAQKI226","conferencePaper","2022",", Dmitriy Dligach; , Steven Bethard; , Timothy Miller; , Guergana Savova","Exploring Text Representations for Generative Temporal Relation Extraction","","","","10.18653/v1/2022.clinicalnlp-1.12","https://aclanthology.org/2022.clinicalnlp-1.12","Sequence-to-sequence models are appealing because they allow both encoder and decoder to be shared across many tasks by formulating those tasks as text-to-text problems. Despite recently reported successes of such models, we find that engineering input/output representations for such text-to-text models is challenging. On the Clinical TempEval 2016 relation extraction task, the most natural choice of output representations, where relations are spelled out in simple predicate logic statements, did not lead to good performance. We explore a variety of input/output representations, with the most successful prompting one event at a time, and achieving results competitive with standard pairwise temporal relation extraction systems.","2022-07-01","2023-10-30 16:40:45","2025-02-04 17:58:32","","NA","","","NA","","","","","","","","ACL","","","NA","","https://paperswithcode.com/paper/exploring-text-representations-for-generative","na","","","{'citing': ['10.3389/fncom.2022.992296'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/PPAWCIYE/et al. - 2022 - Exploring Text Representations for Generative Temporal Relation Extraction.pdf","","DONE; PTM:T5; GRANULARITY:Sentences; PTM:Bert; ARCHI:Encoder-Decoder; LANG:English; PTM:Bart; DATATYPEPROP:String; INPUT:Text; LINEARIZEDGRAPH_BIN:1; LEARNINGMETHOD:Promptbased; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; PTM:Biobert; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; NBDATASET:2; OBJECTPROPERTIES_BIN:0; NBTYPEREL:10^0; INPUT:NER; TASK:RelationClassif; DATASET:Semeval2016; TOCKECH; DATASET:ClinicalTempEval; PTM:SciFive; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL (ClinicalNLP) 2022 7","","","","","","","","","","","","","","",""
"5GX9LVM2","conferencePaper","2022",", Chenguang Wang; , Xiao Liu; , Zui Chen; , Haoyun Hong; , Jie Tang; , Dawn Song","DeepStruct: Pretraining of Language Models for Structure Prediction","ACL 2022","","","10.18653/v1/2022.findings-acl.67","https://arxiv.org/abs/2205.10475v2","We introduce a method for improving the structural understanding abilities of language models. Unlike previous approaches that finetune the models with task-specific augmentation, we pretrain language models on a collection of task-agnostic corpora to generate structures from text. Our structure pretraining enables zero-shot transfer of the learned knowledge that models have about the structure tasks. We study the performance of this approach on 28 datasets, spanning 10 structure prediction tasks including open information extraction, joint entity and relation extraction, named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, factual probe, intent detection, and dialogue state tracking. We further enhance the pretraining with the task-specific training sets. We show that a 10B parameter language model transfers non-trivially to most tasks and obtains state-of-the-art performance on 21 of 28 datasets that we evaluate.","2022-05-21","2023-10-30 16:40:45","2025-03-22 16:52:59","","NA","","","NA","","","DeepStruct","","","","","ACL","","","NA","","https://paperswithcode.com/paper/deepstruct-pretraining-of-language-models-for-1","https://github.com/cgraywang/deepstruct","","[{""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""60.7"", ""metric"": ""Entity F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""83.8"", ""metric"": ""Relation F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""10.6"", ""metric"": ""Relation F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""83.6"", ""metric"": ""Relation F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""90.5"", ""metric"": ""Entity F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""91.1"", ""metric"": ""Entity F1""}, {""task"": ""Intent Detection"", ""dataset"": ""ATIS"", ""res"": ""97.3"", ""metric"": ""F1""}, {""task"": ""Intent Detection"", ""dataset"": ""SNIPS"", ""res"": ""97.3"", ""metric"": ""F1""}, {""task"": ""Intent Detection"", ""dataset"": ""ATIS"", ""res"": ""97.8"", ""metric"": ""F1""}, {""task"": ""Intent Detection"", ""dataset"": ""SNIPS"", ""res"": ""97.4"", ""metric"": ""F1""}, {""task"": ""Named Entity Recognition (NER)"", ""dataset"": ""GENIA"", ""res"": ""80.2"", ""metric"": ""F1""}, {""task"": ""Named Entity Recognition (NER)"", ""dataset"": ""GENIA"", ""res"": ""80.8"", ""metric"": ""F1""}, {""task"": ""Named Entity Recognition (NER)"", ""dataset"": ""GENIA"", ""res"": ""47.2"", ""metric"": ""F1""}, {""task"": ""Open Information Extraction"", ""dataset"": ""Penn Treebank"", ""res"": ""51"", ""metric"": ""F1""}, {""task"": ""Open Information Extraction"", ""dataset"": ""OIE2016"", ""res"": ""71.2"", ""metric"": ""F1""}, {""task"": ""Open Information Extraction"", ""dataset"": ""Penn Treebank"", ""res"": ""54.5"", ""metric"": ""F1""}, {""task"": ""Open Information Extraction"", ""dataset"": ""OIE2016"", ""res"": ""71.3"", ""metric"": ""F1""}, {""task"": ""Open Information Extraction"", ""dataset"": ""OIE2016"", ""res"": ""28.1"", ""metric"": ""F1""}, {""task"": ""Open Information Extraction"", ""dataset"": ""Penn Treebank"", ""res"": ""45,1"", ""metric"": ""F1""}, {""task"": ""Relation Classification"", ""dataset"": ""FewRel"", ""res"": ""72.4"", ""metric"": ""F1 (5-way 1-shot)""}, {""task"": ""Relation Classification"", ""dataset"": ""FewRel"", ""res"": ""97.8"", ""metric"": ""F1 (10-way 1-shot)""}, {""task"": ""Relation Classification"", ""dataset"": ""FewRel"", ""res"": ""66.4"", ""metric"": ""F1 (10-way 5-shot)""}, {""task"": ""Relation Classification"", ""dataset"": ""FewRel"", ""res"": ""99.8"", ""metric"": ""F1 (10-way 5-shot)""}, {""task"": ""Relation Classification"", ""dataset"": ""TACRED"", ""res"": ""76.8"", ""metric"": ""F1""}, {""task"": ""Relation Classification"", ""dataset"": ""TACRED"", ""res"": ""74.9"", ""metric"": ""F1""}, {""task"": ""Relation Classification"", ""dataset"": ""TACRED"", ""res"": ""36.1"", ""metric"": ""F1""}, {""task"": ""Relation Classification"", ""dataset"": ""FewRel"", ""res"": ""92.2"", ""metric"": ""F1 (10-way 1-shot)""}, {""task"": ""Relation Classification"", ""dataset"": ""FewRel"", ""res"": ""93.6"", ""metric"": ""F1 (5-way 1-shot)""}, {""task"": ""Relation Classification"", ""dataset"": ""FewRel"", ""res"": ""96.4"", ""metric"": ""F1 (5-way 5-shot""}, {""task"": ""Relation Classification"", ""dataset"": ""FewRel"", ""res"": ""98.4"", ""metric"": ""F1 (5-way 1-shot)""}, {""task"": ""Relation Classification"", ""dataset"": ""FewRel"", ""res"": ""67.6"", ""metric"": ""F1 (10-way 1-shot)""}, {""task"": ""Relation Classification"", ""dataset"": ""FewRel"", ""res"": ""70.8"", ""metric"": ""F1 (5-way 5-shot""}, {""task"": ""Relation Classification"", ""dataset"": ""FewRel"", ""res"": ""94.6"", ""metric"": ""F1 (10-way 5-shot)""}, {""task"": ""Relation Classification"", ""dataset"": ""FewRel"", ""res"": ""100"", ""metric"": ""F1 (5-way 5-shot""}, {""task"": ""Relation Extraction"", ""dataset"": ""TACRED"", ""res"": ""76.8"", ""metric"": ""F1""}]","{'citing': ['10.1007/978-3-031-40286-9_34', '10.1109/icccworkshops57813.2023.10233741', '10.1109/access.2024.3349952'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/WZY5FIMP/et al. - 2022 - DeepStruct Pretraining of Language Models for Structure Prediction.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Encoder-Decoder; TASK:Endtoendre; LANG:English; DATASET:Ace2005; PTM:Glm; TASK:Coref; DATASET:Fewrel; COSTEVAL_BIN:1; DATASET:Ade; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LINEARIZEDGRAPH_BIN:1; USENEGATIVEEXAMPLE_BIN:0; ARCHI:Decoder; DATASET:Atis; DATASET:Genia; DATASET:Snips; LEARNINGMETHOD:Pretraining; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; DATASET:ConceptNet; TASK:NER; NBTYPEREL:NSP; TO_EXCLUDE?; DATASET:NYT; OBJECTPROPERTIES_BIN:NSP; DATASET:GoogleRE; DATASET:Conll04; TASK:RelationClassif; DATASET:TEKGEN; DATASET:TREX; TOCKECH; DATASET:Ontonotes; DATASET:KELM; DATASET:OPIEC; DATASET:PENN; NBDATASET:15; TASK:RelationIdentification; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings (ACL) 2022 5","","","","","","","","","","","","","","",""
"CZG5WI4U","conferencePaper","2022",", Yew Ken Chia; , Lidong Bing; , Soujanya Poria; , Luo Si","RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction","","","","10.18653/v1/2022.findings-acl.5","https://arxiv.org/abs/2203.09101v1","Despite the importance of relation extraction in building and representing knowledge, less research is focused on generalizing to unseen relations types. We introduce the task setting of Zero-Shot Relation Triplet Extraction (ZeroRTE) to encourage further research in low-resource relation extraction methods. Given an input sentence, each extracted triplet consists of the head entity, relation label, and tail entity where the relation label is not seen at the training stage. To solve ZeroRTE, we propose to synthesize relation examples by prompting language models to generate structured texts. Concretely, we unify language model prompts and structured text approaches to design a structured prompt template for generating synthetic relation samples when conditioning on relation label prompts (RelationPrompt). To overcome the limitation for extracting multiple relation triplets in a sentence, we design a novel Triplet Search Decoding method. Experiments on FewRel and Wiki-ZSL datasets show the efficacy of RelationPrompt for the ZeroRTE task and zero-shot relation classification. Our code and data are available at github.com/declare-lab/RelationPrompt.","2022-03-17","2023-10-30 16:40:45","2025-03-22 16:52:51","","NA","","","NA","","","RelationPrompt","","","","","ACL","","","NA","","https://paperswithcode.com/paper/relationprompt-leveraging-prompts-to-generate","https://github.com/declare-lab/relationprompt","","[{""task"": ""Zero-shot Relation Triplet Extraction"", ""dataset"": ""FewRel"", ""res"": ""24.61"", ""metric"": ""Avg. F1""}, {""task"": ""Zero-shot Relation Triplet Extraction"", ""dataset"": ""Wiki-ZSL"", ""res"": ""31.19"", ""metric"": ""Avg. F1""}]","{'citing': ['10.1109/ijcnn54540.2023.10191459', '10.1145/3564281', '10.1109/taslp.2023.3304481', '10.3390/app13074636', '10.1145/3539618.3591763', '10.1109/bibm58861.2023.10385919', '10.1007/s12559-023-10110-1', '10.1109/bigdata59044.2023.10386190', '10.4018/ijitsa.328681', '10.1109/bibm58861.2023.10385666'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/U4TQ3FW4/et al. - 2022 - RelationPrompt Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extract.pdf","","DONE; GRANULARITY:Sentences; PTM:Bert; ARCHI:Encoder-Decoder; LANG:English; PTM:Bart; DATASET:Fewrel; DATATYPEPROP:String; DECODINGMETHOD_BIN:1; INPUT:Text; LINEARIZEDGRAPH_BIN:1; NBTYPEREL:10²; SYNTHGENERATION_BIN:1; USENEGATIVEEXAMPLE_BIN:0; LEARNINGMETHOD:Promptbased; ARCHI:Encoder; LEARNINGMETHOD:Zeroshot; DATASET:Wiki-Zsl; COSTEVAL_BIN:0; LOSSUPDATE_BIN:0; NBTYPEREL:10^1; NBDATASET:2; OBJECTPROPERTIES_BIN:0; TO_EXCLUDE?; TASK:RelationClassif; TOCKECH; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings (ACL) 2022 5","","","","","","","","","","","","","","",""
"WXEYZDFB","conferencePaper","2021",", Haoyang Wen; , Heng Ji","Utilizing Relative Event Time to Enhance Event-Event Temporal Relation Extraction","","","","10.18653/v1/2021.emnlp-main.815","https://aclanthology.org/2021.emnlp-main.815","Event time is one of the most important features for event-event temporal relation extraction. However, explicit event time information in text is sparse. For example, only about 20% of event mentions in TimeBank-Dense have event-time links. In this paper, we propose a joint model for event-event temporal relation classification and an auxiliary task, relative event time prediction, which predicts the event time as real numbers. We adopt the Stack-Propagation framework to incorporate predicted relative event time for temporal relation classification and keep the differentiability. Our experiments on MATRES dataset show that our model can significantly improve the RoBERTa-based baseline and achieve state-of-the-art performance.","2021-11-01","2023-10-30 16:40:45","2025-03-22 16:53:54","","NA","","","NA","","","","","","","","ACL","","","NA","","https://paperswithcode.com/paper/utilizing-relative-event-time-to-enhance","https://github.com/wenhycs/emnlp2021-utilizing-relative-event-time-to-enhance-event-event-temporal-relation-extraction","","","{'citing': ['10.1155/2022/5680971', '10.1007/978-3-031-17120-8_15', '10.1007/978-3-031-17120-8_20', '10.1007/978-3-031-30678-5_1', '10.1007/978-3-031-10983-6_27', '10.1016/j.inffus.2023.101919', '10.3934/mbe.2023312', '10.1016/j.ipm.2023.103469', '10.5715/jnlp.30.557', '10.2139/ssrn.4482481', '10.1109/inc457730.2023.10263169'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/PVGBG49L/and - 2021 - Utilizing Relative Event Time to Enhance Event-Event Temporal Relation Extraction.pdf","","DONE; Granularity:Document; PTM:Roberta; LANG:English; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; DATASET:TempEval; DATASET:TimeBank; DATASET:AQUAINT; OBJECTPROPERTIES_BIN:NSP; ARCHI:PositionnalEMbed; ARCHI:FFN; ARCHI:Embedding; TASK:RelationClassif; DATASET:MATRES; DATASET:TempEval3; NBTYPEREL:4; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2021 11","","","","","","","","","","","","","","",""
"8B7N8WXL","conferencePaper","2021",", Yuanhe Tian; , Guimin Chen; , Yan Song; , Xiang Wan","Dependency-driven Relation Extraction with Attentive Graph Convolutional Networks","","","","10.18653/v1/2021.acl-long.344","https://aclanthology.org/2021.acl-long.344","Syntactic information, especially dependency trees, has been widely used by existing studies to improve relation extraction with better semantic guidance for analyzing the context information associated with the given entities. However, most existing studies suffer from the noise in the dependency trees, especially when they are automatically generated, so that intensively leveraging dependency information may introduce confusions to relation classification and necessary pruning is of great importance in this task. In this paper, we propose a dependency-driven approach for relation extraction with attentive graph convolutional networks (A-GCN). In this approach, an attention mechanism upon graph convolutional networks is applied to different contextual words in the dependency tree obtained from an off-the-shelf dependency parser, to distinguish the importance of different word dependencies. Consider that dependency types among words also contain important contextual guidance, which is potentially helpful for relation extraction, we also include the type information in A-GCN modeling. Experimental results on two English benchmark datasets demonstrate the effectiveness of our A-GCN, which outperforms previous studies and achieves state-of-the-art performance on both datasets.","2021-08-01","2023-10-30 16:40:45","2025-03-22 16:53:13","","NA","","","NA","","","A-GCN + BERT","","","","","ACL","","","NA","","https://paperswithcode.com/paper/dependency-driven-relation-extraction-with","https://github.com/cuhksz-nlp/re-agcn","","{""SemEval-2010 Task 8"": {""F1"": ""89.85""}}","{'citing': ['10.1016/j.knosys.2022.109800', '10.1016/j.knosys.2022.109703', '10.1017/s135132492200033x', '10.3390/app13063993', '10.1007/s11063-022-11115-x', '10.1007/s11063-023-11412-z', '10.1109/globecom48099.2022.10001525', '10.1109/itaic54216.2022.9836511', '10.1007/s11280-023-01142-6', '10.1016/j.jss.2022.111324', '10.1109/icaice54393.2021.00054', '10.1016/j.knosys.2023.110428', '10.1007/978-981-99-9319-2_16', '10.1007/s00521-022-07223-3', '10.1007/s10489-023-04964-z', '10.1109/icsai61474.2023.10423340', '10.1117/12.3014256', '10.1186/s40537-023-00814-4', '10.5715/jnlp.30.304', '10.1109/ijcnn54540.2023.10191893', '10.3390/s23104812', '10.1109/icaiic57133.2023.10067083', '10.1145/3539618.3592050', '10.1016/j.eswa.2022.117678', '10.1109/ijcnn54540.2023.10191909', '10.1109/bibm58861.2023.10385893', '10.1007/s40747-023-01226-w', '10.1007/s40747-023-01075-7'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/47KKQT2H/et al. - 2021 - Dependency-driven Relation Extraction with Attentive Graph Convolutional Networks.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Gcn; PTM:Bert; COSTEVAL_BIN:1; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; NBTYPEREL:10^0; DATASET:Semeval2010; TASK:EndToEndRE; ARCHI:Attention; INPUT:DependencyParsing; ARCHI:Embedding; TASK:RelationClassif; ARCHI:POSEmbed; LANG:english; DATASET:ACE2005; ARCHI:TypeEmbed; TOCKECH; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2021 5","","","","","","","","","","","","","","",""
"EGFGCCPN","conferencePaper","2021",", Xingwei Tan; , Gabriele Pergola; , Yulan He","Extracting Event Temporal Relations via Hyperbolic Geometry","","","","10.18653/v1/2021.emnlp-main.636","https://arxiv.org/abs/2109.05527v1","Detecting events and their evolution through time is a crucial task in natural language understanding. Recent neural approaches to event temporal relation extraction typically map events to embeddings in the Euclidean space and train a classifier to detect temporal relations between event pairs. However, embeddings in the Euclidean space cannot capture richer asymmetric relations such as event temporal relations. We thus propose to embed events into hyperbolic spaces, which are intrinsically oriented at modeling hierarchical structures. We introduce two approaches to encode events and their temporal relations in hyperbolic spaces. One approach leverages hyperbolic embeddings to directly infer event relations through simple geometrical operations. In the second one, we devise an end-to-end architecture composed of hyperbolic neural units tailored for the temporal relation extraction task. Thorough experimental assessments on widely used datasets have shown the benefits of revisiting the tasks on a different geometrical space, resulting in state-of-the-art performance on several standard metrics. Finally, the ablation study and several qualitative analyses highlighted the rich event semantics implicitly encoded into hyperbolic spaces.","2021-09-12","2023-10-30 16:40:45","2025-03-22 16:53:34","","NA","","","NA","","","","","","","","ACL","","","NA","","https://paperswithcode.com/paper/extracting-event-temporal-relations-via","https://github.com/xingwei-warwick/hyper-event-temprel","","","{'citing': ['10.1155/2022/5680971', '10.1007/978-3-031-17120-8_15', '10.1007/978-3-031-17120-8_20', '10.1007/978-3-031-30678-5_1', '10.1007/978-3-031-10983-6_27', '10.1016/j.inffus.2023.101919', '10.1016/j.ipm.2023.103469', '10.1007/978-981-99-9864-7_12', '10.1007/978-3-031-18315-7_12'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/RRQ5RUYF/et al. - 2021 - Extracting Event Temporal Relations via Hyperbolic Geometry.pdf","","DONE; Granularity:Document; PTM:Roberta; TASK:Nlu; LANG:English; COSTEVAL_BIN:1; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; PTM:ELMO; OBJECTPROPERTIES_BIN:0; NBTYPEREL:10^0; ARCHI:SiameseNetwork; ARCHI:RelEmbedding; TASK:RelationClassif; DATASET:MATRES; ARCHI:CommonSenseKG; ARCHI:HyperbolicClassif; ARCHI:HyperbolicGRU; DATASET:TCR; DatasetSplit:OfficialSplit","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2021 11","","","","","","","","","","","","","","",""
"2FK7U2BU","conferencePaper","2021",", Zhiheng Yan; , Chong Zhang; , Jinlan Fu; , Qi Zhang; , Zhongyu Wei","A Partition Filter Network for Joint Entity and Relation Extraction","","","","10.18653/v1/2021.emnlp-main.17","https://arxiv.org/abs/2108.12202v8","In joint entity and relation extraction, existing work either sequentially encode task-specific features, leading to an imbalance in inter-task feature interaction where features extracted later have no direct contact with those that come first. Or they encode entity features and relation features in a parallel manner, meaning that feature representation learning for each task is largely independent of each other except for input sharing. We propose a partition filter network to model two-way interaction between tasks properly, where feature encoding is decomposed into two steps: partition and filter. In our encoder, we leverage two gates: entity and relation gate, to segment neurons into two task partitions and one shared partition. The shared partition represents inter-task information valuable to both tasks and is evenly shared across two tasks to ensure proper two-way interaction. The task partitions represent intra-task information and are formed through concerted efforts of both gates, making sure that encoding of task-specific features is dependent upon each other. Experiment results on six public datasets show that our model performs significantly better than previous approaches. In addition, contrary to what previous work has claimed, our auxiliary experiments suggest that relation prediction is contributory to named entity prediction in a non-negligible way. The source code can be found at https://github.com/Coopercoppers/PFN.","2021-08-27","2023-10-30 16:40:45","2025-03-22 16:52:46","","NA","","","NA","","","PFN","","","","","ACL","","","NA","","https://paperswithcode.com/paper/a-partition-filter-network-for-joint-entity","https://github.com/Coopercoppers/PFN","","[{""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""SciERC"", ""res"": ""38.4"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""SciERC"", ""res"": ""66.8"", ""metric"": ""Entity F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""SciERC"", ""res"": ""No"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""SciERC"", ""res"": ""38.4"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""No"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""WebNLG"", ""res"": ""93.6"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""91.3"", ""metric"": ""NER Macro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""83.2"", ""metric"": ""RE+ Macro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""89.0"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""No"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""62.5"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""66.8"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""ALBERT"", ""metric"": ""Sentence Encoder""}, {""task"": ""Relation Extraction"", ""dataset"": ""WebNLG"", ""res"": ""98.0"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""SciERC"", ""res"": ""66.8"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""89.3"", ""metric"": ""NER Micro F1""}]","{'citing': ['10.1109/ijcnn54540.2023.10191693', '10.1016/j.jksuci.2023.101748', '10.1007/978-3-031-39965-7_49', '10.32604/iasc.2022.028352', '10.1109/taslp.2022.3228129', '10.1109/taslp.2023.3254166', '10.1007/978-981-99-6207-5_15', '10.1007/978-3-031-17120-8_21', '10.1145/3511808.3557323', '10.3390/app131810538', '10.3390/e26020162', '10.1007/s10994-023-06477-9', '10.1109/ijcnn54540.2023.10191826', '10.1093/bib/bbac342', '10.1109/ijcnn54540.2023.10191216', '10.3390/app12126231', '10.1007/978-981-99-4826-0_10', '10.1007/978-981-99-4826-0_2', '10.1007/978-981-99-4826-0_9', '10.1007/978-981-99-4826-0_8', '10.1049/itr2.12398', '10.1007/978-3-031-34560-9_28', '10.1007/978-3-031-14771-5_26', '10.1109/icme55011.2023.00101', '10.1515/jisys-2022-2014', '10.1007/978-3-031-18315-7_11', '10.1016/j.eswa.2023.120435', '10.1109/prai59366.2023.10331957', '10.1109/iros55552.2023.10342509', '10.1016/j.eswa.2023.122007', '10.1145/3543507.3583504', '10.1007/978-981-19-6142-7_10', '10.1007/s10489-023-05170-7', '10.1016/j.neunet.2023.03.001', '10.1007/978-3-031-19433-7_37', '10.1109/bibm55620.2022.9995158', '10.1007/s12559-023-10163-2', '10.3390/app13137585', '10.1109/access.2023.3335623', '10.3390/app131910643'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/X7WGMQ4R/et al. - 2021 - A Partition Filter Network for Joint Entity and Relation Extraction.pdf","","DONE; GRANULARITY:Document; TASK:Endtoendre; LANG:Arabic; LANG:Chinese; LANG:English; PTM:Albert; DATASET:Scierc; PTM:Scibert; DATASET:Webnlg; OBJECTPROPERTIES_BIN:?; DATASET:Ade; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; NBTYPEREL:10^2; TASK:NER; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:10^0; TASK:EndToEndRE; TO_EXCLUDE?; DATASET:NYT; PTM:BERT; NBDATASET:6; DATASET:ACE2004; ARCHI:Embedding; DATASET:ACE2005; TOCKECH; DatasetSplit:CrossValidation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2021 11","","","","","","","","","","","","","","",""
"FYJVKLAT","conferencePaper","2021",", Yijun Wang; , Changzhi Sun; , Yuanbin Wu; , Hao Zhou; , Lei LI; , Junchi Yan","UniRE: A Unified Label Space for Entity Relation Extraction","","","","10.18653/v1/2021.acl-long.19","https://arxiv.org/abs/2107.04292v1","Many joint entity relation extraction models setup two separated label spaces for the two sub-tasks (i.e., entity detection and relation classification). We argue that this setting may hinder the information interaction between entities and relations. In this work, we propose to eliminate the different treatment on the two sub-tasks' label spaces. The input of our model is a table containing all word pairs from a sentence. Entities and relations are represented by squares and rectangles in the table. We apply a unified classifier to predict each cell's label, which unifies the learning of two sub-tasks. For testing, an effective (yet fast) approximate decoder is proposed for finding squares and rectangles from tables. Experiments on three benchmarks (ACE04, ACE05, SciERC) show that, using only half the number of parameters, our model achieves competitive accuracy with the best extractor, and is faster.","2021-07-09","2023-10-30 16:40:45","2025-03-22 16:52:54","","NA","","","NA","","","UNIRE","","","","","ACL","","","NA","","https://paperswithcode.com/paper/unire-a-unified-label-space-for-entity","https://github.com/Receiling/UniRE","","","{'citing': ['10.3390/app122110824', '10.1007/978-3-031-40286-9_30', '10.1007/978-3-031-44201-8_20', '10.1007/s11063-023-11412-z', '10.1109/taslp.2024.3350905', '10.1080/09540091.2022.2026295', '10.1109/ijcnn55064.2022.9892310', '10.3390/app13074636', '10.1109/cscwd54268.2022.9776159', '10.1007/978-3-031-17120-8_21', '10.3390/app13158700', '10.3390/e26020162', '10.2478/cait-2023-0014', '10.1007/s00521-022-07747-8', '10.1109/access.2023.3281845', '10.1007/978-981-99-9864-7_12', '10.1016/j.eswa.2023.120435', '10.1007/s40747-023-01321-y', '10.1049/cim2.12073', '10.3390/electronics12010121', '10.3390/app14041334', '10.1016/j.eswa.2023.122007', '10.1016/j.jmsy.2023.08.006', '10.1007/978-3-031-30108-7_18', '10.1007/978-3-031-23190-2_5', '10.1109/cscloud-edgecom58631.2023.00070', '10.1145/3569581', '10.1016/j.jksuci.2022.08.038', '10.3390/app13137585', '10.1109/medai59581.2023.00039', '10.1007/s40747-023-01004-8', '10.1007/s40747-023-01075-7'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/TRSZFC5H/et al. - 2021 - UniRE A Unified Label Space for Entity Relation Extraction.pdf","","DONE; GRANULARITY:Sentences; LANG:English; DATASET:Scierc; DATATYPEPROP:String; DECODINGMETHOD_BIN:1; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; SYNTHGENERATION_BIN:0; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; NBTYPEREL:10^0; NBDATASET:3; TASK:EndToEndRE; TO_EXCLUDE?; ARCHI:PositionnalEMbed; ARCHI:MLP; PTM:BERT; DATASET:ACE2004; INPUT:text; TASK:RelationClassif; DATASET:ACE2005; TOCKECH; TASK:RelationIdentification; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2021 5","","","","","","","","","","","","","","",""
"KSHD6LMS","conferencePaper","2021",", Shuang Zeng; , Yuting Wu; , Baobao Chang","SIRE: Separate Intra- and Inter-sentential Reasoning for Document-level Relation Extraction","","","","10.18653/v1/2021.findings-acl.47","https://arxiv.org/abs/2106.01709v1","Document-level relation extraction has attracted much attention in recent years. It is usually formulated as a classification problem that predicts relations for all entity pairs in the document. However, previous works indiscriminately represent intra- and inter-sentential relations in the same way, confounding the different patterns for predicting them. Besides, they create a document graph and use paths between entities on the graph as clues for logical reasoning. However, not all entity pairs can be connected with a path and have the correct logical reasoning paths in their graph. Thus many cases of logical reasoning cannot be covered. This paper proposes an effective architecture, SIRE, to represent intra- and inter-sentential relations in different ways. We design a new and straightforward form of logical reasoning module that can cover more logical reasoning chains. Experiments on the public datasets show SIRE outperforms the previous state-of-the-art methods. Further analysis shows that our predictions are reliable and explainable. Our code is available at https://github.com/DreamInvoker/SIRE.","2021-06-03","2023-10-30 16:40:45","2025-03-22 16:53:17","","NA","","","NA","","","SIRE","","","","","ACL","","","NA","","https://paperswithcode.com/paper/sire-separate-intra-and-inter-sentential","https://github.com/DreamInvoker/SIRE","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""55.96"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""62.05"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""54.04"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""60.18"", ""metric"": ""Ign F1""}]","{'citing': ['10.1007/978-3-031-17120-8_13', '10.1145/3511808.3557313', '10.1145/3511808.3557615', '10.1109/bibm58861.2023.10385582', '10.3390/e26030210', '10.1007/s00521-022-07223-3', '10.1145/3572898', '10.1109/jas.2023.123540', '10.1007/s40747-023-01084-6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/64VIMVL4/et al. - 2021 - SIRE Separate Intra- and Inter-sentential Reasoning for Document-level Relation Extraction.pdf","","DONE; GRANULARITY:Document; GRANULARITY:Sentences; LANG:English; COSTEVAL_BIN:1; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; PTM:Biobert; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:NSP; DATASET:GDA; NBDATASET:3; TASK:EvidenceExtraction; INPUT:NER; PTM:Glove; ARCHI:LSTM; PTM:BERT; LOSSUPDATE_BIN:NSP; DATASET:CDR; DATASET:DocRED; ARCHI:RelEmbedding; ARCHI:ENtityEmbedding; TASK:RelationClassif; TOCKECH; ARCHI:RGCN; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings (ACL) 2021 8","","","","","","","","","","","","","","",""
"TVMAVA62","conferencePaper","2021",", Peng Su; , Yifan Peng; , K. Vijay-Shanker","Improving BERT Model Using Contrastive Learning for Biomedical Relation Extraction","","","","10.18653/v1/2021.bionlp-1.1","https://arxiv.org/abs/2104.13913v1","Contrastive learning has been used to learn a high-quality representation of the image in computer vision. However, contrastive learning is not widely utilized in natural language processing due to the lack of a general method of data augmentation for text data. In this work, we explore the method of employing contrastive learning to improve the text representation from the BERT model for relation extraction. The key knob of our framework is a unique contrastive pre-training step tailored for the relation extraction tasks by seamlessly integrating linguistic knowledge into the data augmentation. Furthermore, we investigate how large-scale data constructed from the external knowledge bases can enhance the generality of contrastive pre-training of BERT. The experimental results on three relation extraction benchmark datasets demonstrate that our method can improve the BERT model representation and achieve state-of-the-art performance. In addition, we explore the interpretability of models by showing that BERT with contrastive pre-training relies more on rationales for prediction. Our code and data are publicly available at: https://github.com/udel-biotm-lab/BERT-CLRE.","2021-04-28","2023-10-30 16:40:45","2025-03-22 16:53:37","","NA","","","NA","","","BERT-CLRE","","","","","ACL","","","NA","","https://paperswithcode.com/paper/improving-bert-model-using-contrastive","https://github.com/udel-biotm-lab/BERT-CLRE","","","{'citing': ['10.1109/icbda57405.2023.10105090', '10.1016/j.jbi.2023.104415', '10.1145/3511808.3557318', '10.3390/app122010199', '10.1007/978-981-19-3679-1_47', '10.1007/s10462-023-10580-7', '10.1007/978-981-19-7596-7_4', '10.1109/access.2022.3154820'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/HKBBXBUD/et al. - 2021 - Improving BERT Model Using Contrastive Learning for Biomedical Relation Extraction.pdf","","DONE; GRANULARITY:Sentences; LANG:English; LEARNINGMETHOD:Contrastive; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; PTM:Biobert; LEARNINGMETHOD:Pretraining; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; DATATYPEPROP:NSP; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:10^0; NBDATASET:3; DATASET:ChemProt; ARCHI:MLP; INPUT:NERType; INPUT:TExt; TASK:RelationClassif; DATASET:AIMed; DATASET:DDI; PTM:PubMedBERT; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL (BioNLP) 2021 6","","","","","","","","","","","","","","",""
"JLIVENBF","conferencePaper","2021",", Benfeng Xu; , Quan Wang; , Yajuan Lyu; , Yong Zhu; , Zhendong Mao","Entity Structure Within and Throughout: Modeling Mention Dependencies for Document-Level Relation Extraction","AAAI Technical Track on Speech and Natural Language Processing III","","","10.1609/aaai.v35i16.17665","https://arxiv.org/abs/2102.10249v1","Entities, as the essential elements in relation extraction tasks, exhibit certain structure. In this work, we formulate such structure as distinctive dependencies between mention pairs. We then propose SSAN, which incorporates these structural dependencies within the standard self-attention mechanism and throughout the overall encoding stage. Specifically, we design two alternative transformation modules inside each self-attention building block to produce attentive biases so as to adaptively regularize its attention flow. Our experiments demonstrate the usefulness of the proposed entity structure and the effectiveness of SSAN. It significantly outperforms competitive baselines, achieving new state-of-the-art results on three popular document-level relation extraction datasets. We further provide ablation and visualization to show how the entity structure guides the model for better relation extraction. Our code is publicly available.","2021-02-20","2023-10-30 16:40:45","2025-03-22 16:52:57","","","","","","","","SSAN","","","","","AAAI","","","NA","","https://paperswithcode.com/paper/entity-structure-within-and-throughout","https://github.com/PaddlePaddle/Research","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""58.16"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""61.42"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""57.71"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""CDR"", ""res"": ""68.7"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""59.47"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""59.94"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""65.92"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""63.78"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""55.84"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""GDA"", ""res"": ""83.9"", ""metric"": ""F1""}]","{'citing': ['10.1109/icpr56361.2022.9956191', '10.1007/978-981-16-6471-7_6', '10.1016/j.engappai.2023.106212', '10.1145/3485447.3512032', '10.1007/978-3-031-17120-8_13', '10.1007/978-3-031-17189-5_21', '10.1145/3511808.3557313', '10.1145/3511808.3557615', '10.1109/ijcnn55064.2022.9892647', '10.1109/bibm58861.2023.10385582', '10.1007/978-3-031-33374-3_25', '10.1007/978-3-031-28244-7_38', '10.3390/e26030210', '10.1007/s42524-023-0273-1', '10.1109/iscai58869.2022.00015', '10.1016/j.knosys.2023.110428', '10.1016/j.knosys.2023.110873', '10.1007/978-3-031-44213-1_42', '10.3390/electronics13030648', '10.1007/978-3-030-91560-5_25', '10.1109/icmla55696.2022.00254', '10.1007/978-981-19-9865-2_3', '10.1109/isctis58954.2023.10213156', '10.1109/icassp49357.2023.10096263', '10.1109/icassp49357.2023.10095786', '10.1007/978-981-99-9864-7_11', '10.1007/978-981-99-9864-7_10', '10.1007/s44196-023-00305-7', '10.1016/j.array.2023.100331', '10.1109/ijcnn54540.2023.10191414', '10.1109/ialp61005.2023.10337090', '10.3233/jifs-234202', '10.26599/bdma.2022.9020051', '10.1007/978-3-031-40292-0_34', '10.1007/978-3-031-44198-1_2', '10.1007/978-3-031-23190-2_5', '10.1109/ijcnn54540.2023.10191391', '10.1007/978-3-031-19433-7_3', '10.1109/icpr56361.2022.9956376', '10.3233/jifs-237167', '10.1038/s41746-022-00742-2', '10.1016/j.eswa.2022.117678', '10.1007/s11227-022-04875-9', '10.1007/s10489-022-03731-w', '10.1007/s40747-023-01084-6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/KHWHHD7Z/et al. - 2021 - Entity Structure Within and Throughout Modeling Mention Dependencies for Document-Level Relation Ex.pdf","","DONE; PTM:Roberta; GRANULARITY:Document; LANG:English; TASK:Coref; DATASET:Docred; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LINEARIZEDGRAPH_BIN:1; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; DATASET:Cdr; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; NBTYPEREL:10^0; DATASET:GDA; NBDATASET:3; TO_EXCLUDE?; OBJECTPROPERTIES_BIN:NSP; ARCHI:Attention; ARCHI:PositionnalEMbed; PTM:BERT; PTM:SciBERT; ARCHI:Embedding; TASK:RelationClassif; TOCKECH; ARCHI:SSAN; TASK:RelationIdentification; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"GYJZ5JS7","conferencePaper","2021",", Yongliang Shen; , Xinyin Ma; , Yechun Tang; , Weiming Lu","A Trigger-Sense Memory Flow Framework for Joint Entity and Relation Extraction","WWW '21: Proceedings of the Web Conference 2021","","","10.1145/3442381.3449895","https://arxiv.org/abs/2101.10213v3","Joint entity and relation extraction framework constructs a unified model to perform entity recognition and relation extraction simultaneously, which can exploit the dependency between the two tasks to mitigate the error propagation problem suffered by the pipeline model. Current efforts on joint entity and relation extraction focus on enhancing the interaction between entity recognition and relation extraction through parameter sharing, joint decoding, or other ad-hoc tricks (e.g., modeled as a semi-Markov decision process, cast as a multi-round reading comprehension task). However, there are still two issues on the table. First, the interaction utilized by most methods is still weak and uni-directional, which is unable to model the mutual dependency between the two tasks. Second, relation triggers are ignored by most methods, which can help explain why humans would extract a relation in the sentence. They're essential for relation extraction but overlooked. To this end, we present a Trigger-Sense Memory Flow Framework (TriMF) for joint entity and relation extraction. We build a memory module to remember category representations learned in entity recognition and relation extraction tasks. And based on it, we design a multi-level memory flow attention mechanism to enhance the bi-directional interaction between entity recognition and relation extraction. Moreover, without any human annotations, our model can enhance relation trigger information in a sentence through a trigger sensor module, which improves the model performance and makes model predictions with better interpretation. Experiment results show that our proposed framework achieves state-of-the-art results by improves the relation F1 to 52.44% (+3.2%) on SciERC, 66.49% (+4.9%) on ACE05, 72.35% (+0.6%) on CoNLL04 and 80.66% (+2.3%) on ADE.","2021-01-25","2023-10-30 16:40:45","2025-03-22 16:53:33","","","","","","","","TriMF","","","","","ACM","","","NA","","https://paperswithcode.com/paper/a-trigger-sense-memory-flow-framework-for","https://github.com/tricktreat/trimf","","[{""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""62.77"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""87.61"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""66.49"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""Yes"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""66.49"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""BERT base"", ""metric"": ""Sentence Encoder""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""62.77"", ""metric"": ""RE Micro F1""}]","{'citing': ['10.1109/icpr56361.2022.9956191', '10.1145/3474085.3475317', '10.1145/3485447.3511998', '10.1109/taslp.2023.3304481', '10.1080/09540091.2022.2026295', '10.1109/ijcnn55064.2022.9892140', '10.3390/e26020162', '10.1109/cisp-bmei60920.2023.10373243', '10.1093/bib/bbac342', '10.1109/bigdata55660.2022.10020308', '10.1109/icmla55696.2022.00254', '10.1007/978-3-031-37717-4_48', '10.1016/j.eswa.2023.120182', '10.1016/j.eswa.2023.120435', '10.1186/s12859-023-05172-9', '10.1016/j.eswa.2023.122007', '10.3390/s23094250', '10.1007/978-3-031-36021-3_29', '10.1007/s12559-023-10163-2', '10.1109/aiiot54504.2022.9817231', '10.1016/j.jksuci.2022.08.038', '10.1109/access.2023.3335623'], 'cited': ['10.3115/1220575.1220666', '10.18653/v1/p18-1047', '10.18653/v1/d18-1360', '10.1016/j.eswa.2018.07.032', '10.18653/v1/d18-1307', '10.1145/336597.336644', '10.18653/v1/p16-1087', '10.18653/v1/p16-1105', '10.18653/v1/p16-1200', '10.1093/bioinformatics/btq620', '10.1093/bioinformatics/btl616', '10.1016/j.jbi.2012.04.008', '10.1145/3366423.3380282', '10.1007/978-3-319-93417-4_38', '10.18653/v1/d19-1371', '10.18653/v1/d19-1585', '10.18653/v1/p19-1136', '10.24963/ijcai.2018/620', '10.24963/ijcai.2020/561', '10.3115/1219044.1219066', '10.18653/v1/n19-1308', '10.3115/v1/p14-1038', '10.3115/992133.992154', '10.18653/v1/p17-1113', '10.3115/1220835.1220872', '10.18653/v1/2020.acl-main.136', '10.24963/ijcai.2020/546', '10.18653/v1/d15-1056', '10.1609/aaai.v33i01.33017072']}","","/root/snap/zotero-snap/common/Zotero/storage/LGHGLLMP/et al. - 2021 - A Trigger-Sense Memory Flow Framework for Joint Entity and Relation Extraction.pdf","","DONE; GRANULARITY:Document; TASK:Nlu; LANG:Arabic; LANG:Chinese; LANG:English; DATASET:Scierc; DATASET:Ace2005; DATATYPEPROP:String; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; TASK:NER; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; NBDATASET:4; NBTYPEREL:10^0; DATASET:ADE; PTM:BERT; ARCHI:ATtention; DATASET:Conll04; TASK:RelationClassif; LEARNINGMETHOD:Training; ARCHI:Memory; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WWW","","","","","","","","","","","","","","",""
"QBRZUU3C","journalArticle","2021",", Po-Ting Lai; , Zhiyong Lu","BERT-GT: Cross-sentence n-ary relation extraction with BERT and Graph Transformer","Ofxord Academic","","","10.1093/bioinformatics/btaa1087","https://arxiv.org/abs/2101.04158v1","A biomedical relation statement is commonly expressed in multiple sentences and consists of many concepts, including gene, disease, chemical, and mutation. To automatically extract information from biomedical literature, existing biomedical text-mining approaches typically formulate the problem as a cross-sentence n-ary relation-extraction task that detects relations among n entities across multiple sentences, and use either a graph neural network (GNN) with long short-term memory (LSTM) or an attention mechanism. Recently, Transformer has been shown to outperform LSTM on many natural language processing (NLP) tasks. In this work, we propose a novel architecture that combines Bidirectional Encoder Representations from Transformers with Graph Transformer (BERT-GT), through integrating a neighbor-attention mechanism into the BERT architecture. Unlike the original Transformer architecture, which utilizes the whole sentence(s) to calculate the attention of the current token, the neighbor-attention mechanism in our method calculates its attention utilizing only its neighbor tokens. Thus, each token can pay attention to its neighbor information with little noise. We show that this is critically important when the text is very long, as in cross-sentence or abstract-level relation-extraction tasks. Our benchmarking results show improvements of 5.44% and 3.89% in accuracy and F1-measure over the state-of-the-art on n-ary and chemical-protein relation datasets, suggesting BERT-GT is a robust approach that is applicable to other biomedical relation extraction tasks or datasets.","2021-01-11","2023-10-30 16:40:45","2025-03-22 16:52:03","","","","","","","Bioinformatics","BERT-GT","","","","","","","","NA","","https://paperswithcode.com/paper/bert-gt-cross-sentence-n-ary-relation","https://github.com/ncbi/bert_gt","","[{""task"": ""Relation Extraction"", ""dataset"": ""BioRED"", ""res"": ""56.5"", ""metric"": ""F1""}, {""task"": ""Binary Relation Extraction"", ""dataset"": ""BioRED"", ""res"": ""72.1"", ""metric"": ""F1""}]","{'citing': ['10.1016/j.jbi.2023.104445', '10.1016/j.jbi.2023.104459', '10.1016/j.jbi.2021.103874', '10.3390/pr10020350', '10.1093/database/baac036', '10.1093/bib/bbac282', '10.1002/pmic.202300011', '10.1093/database/baac058', '10.1016/j.compbiolchem.2022.107732', '10.1109/taslp.2022.3199655', '10.1016/j.cmpb.2023.107789', '10.1016/j.ijbiomac.2023.123180', '10.1016/j.patrec.2022.03.021', '10.3390/math11061439', '10.1186/s12864-023-09561-5', '10.1093/gigascience/giad036', '10.1093/database/baad054'], 'cited': ['10.1016/j.clinph.2009.12.033', '10.1093/database/bay073', '10.1093/database/bax024', '10.1093/database/baw032', '10.1093/database/baw068', '10.1093/database/baw048', '10.1093/database/baw036', '10.1186/s12911-018-0629-3', '10.18653/v1/w19-5034', '10.1038/nbt.4267', '10.1093/bib/bbaa142', '10.1186/2041-1480-3-s3-s5', '10.1093/bioinformatics/btz682']}","","/root/snap/zotero-snap/common/Zotero/storage/3ZYZ9DAZ/and - 2021 - BERT-GT Cross-sentence n-ary relation extraction with BERT and Graph Transformer.pdf","","DONE; GRANULARITY:Document; GRANULARITY:Sentences; ARCHI:Lstm; PTM:Bert; ARCHI:Encoder-Decoder; INPUT:Graph; COSTEVAL_BIN:1; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Graphtransformer; NBTYPEREL:10³; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; NBDATASET:2; DATATYPEPROP:NSP; LINEARIZEDGRAPH_BIN:0; INPUT:NER; DECODINGMETHOD_BIN:NSP; DATASET:CDR; TASK:RelationClassif; LANG:english; DATASET:N-ary; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4KGFZ2AG","conferencePaper","2020",", Yujia Qin; , Yankai Lin; , Ryuichi Takanobu; , Zhiyuan Liu; , Peng Li; , Heng Ji; , Minlie Huang; , Maosong Sun; , Jie zhou","ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning","","","","10.18653/v1/2021.acl-long.260","https://arxiv.org/abs/2012.15022v2","Pre-trained Language Models (PLMs) have shown superior performance on various downstream Natural Language Processing (NLP) tasks. However, conventional pre-training objectives do not explicitly model relational facts in text, which are crucial for textual understanding. To address this issue, we propose a novel contrastive learning framework ERICA to obtain a deep understanding of the entities and their relations in text. Specifically, we define two novel pre-training tasks to better understand entities and relations: (1) the entity discrimination task to distinguish which tail entity can be inferred by the given head entity and relation; (2) the relation discrimination task to distinguish whether two relations are close or not semantically, which involves complex relational reasoning. Experimental results demonstrate that ERICA can improve typical PLMs (BERT and RoBERTa) on several language understanding tasks, including relation extraction, entity typing and question answering, especially under low-resource settings.","2020-12-30","2023-10-30 16:40:45","2025-03-22 16:53:42","","NA","","","NA","","","ERICA","","","","","ACL","","","NA","","https://paperswithcode.com/paper/erica-improving-entity-and-relation","https://github.com/thunlp/ERICA","","","{'citing': ['10.1145/3477495.3531954', '10.1145/3551637', '10.1145/3485447.3511994', '10.1007/978-3-031-10983-6_39', '10.1007/s10109-023-00433-w', '10.1007/978-981-99-1600-9_5', '10.1007/978-981-99-1600-9_9', '10.2991/978-94-6463-230-9_128', '10.1007/s11633-023-1416-x', '10.1007/s10462-023-10580-7', '10.1016/j.aiopen.2021.08.002', '10.1145/3543507.3583504', '10.1145/3580305.3599795', '10.1101/2023.01.26.525795', '10.1007/978-981-19-8991-9_26', '10.3390/math11122780', '10.1109/tkde.2023.3292974', '10.1109/icassp49357.2023.10096551', '10.1109/cisp-bmei60920.2023.10373223'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/BYC8D5R4/et al. - 2020 - ERICA Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive L.pdf","","DONE; Granularity:Document; PTM:Roberta; GRANULARITY:Sentences; TASK:Nlu; LANG:English; TASK:Entitytyping; LEARNINGMETHOD:Contrastive; DATATYPEPROP:String; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; SOURCE:Wikidata; SOURCE:Wikipedia; LEARNINGMETHOD:Pretraining; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; LINEARIZEDGRAPH_BIN:0; DATASET:TACRED; DATASET:Semeval2010; ARCHI:Transformer; OBJECTPROPERTIES_BIN:NSP; PTM:BERT; DATASET:DocRED; DATASET:NaturalQA; DATASET:SQUAD; Dataset:TriviaQA; TASK:QA; DATASET:WikiHop; Dataset:FIGER; NBDATASET:8; NBTYPEREL:10^3; TASK:RelationClassif; DatasetSplit:NewDataset","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2021 5","","","","","","","","","","","","","","",""
"XTJKS445","conferencePaper","2020",", Wang Xu; , Kehai Chen; , Tiejun Zhao","Document-Level Relation Extraction with Reconstruction","The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)","","","10.1609/aaai.v35i16.17667","https://arxiv.org/abs/2012.11384v1","In document-level relation extraction (DocRE), graph structure is generally used to encode relation information in the input document to classify the relation category between each entity pair, and has greatly advanced the DocRE task over the past several years. However, the learned graph representation universally models relation information between all entity pairs regardless of whether there are relationships between these entity pairs. Thus, those entity pairs without relationships disperse the attention of the encoder-classifier DocRE for ones with relationships, which may further hind the improvement of DocRE. To alleviate this issue, we propose a novel encoder-classifier-reconstructor model for DocRE. The reconstructor manages to reconstruct the ground-truth path dependencies from the graph representation, to ensure that the proposed DocRE model pays more attention to encode entity pairs with relationships in the training. Furthermore, the reconstructor is regarded as a relationship indicator to assist relation classification in the inference, which can further improve the performance of DocRE model. Experimental results on a large-scale DocRE dataset show that the proposed model can significantly improve the accuracy of relation extraction on a strong heterogeneous graph-based baseline.","2020-12-21","2023-10-30 16:40:45","2025-03-22 16:54:00","","","","","","","","HeterGSAN","","","","","AAAI","","","NA","","https://paperswithcode.com/paper/document-level-relation-extraction-with-1","https://github.com/xwjim/DocRE-Rec","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""57.12"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""53.27"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""59.45"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""55.23"", ""metric"": ""F1""}]","{'citing': ['10.1016/j.jksuci.2023.101643', '10.1016/j.engappai.2023.106212', '10.1145/3485447.3512032', '10.1007/978-3-031-17120-8_13', '10.1145/3511808.3557313', '10.1109/ijcnn55064.2022.9892647', '10.1109/taslp.2021.3138714', '10.1016/j.knosys.2023.110873', '10.3390/app12031599', '10.1145/3508546.3508633', '10.2991/978-94-6463-230-9_128', '10.1007/978-3-031-44213-1_42', '10.1007/978-981-19-9865-2_3', '10.1016/j.array.2023.100331', '10.1109/ialp61005.2023.10337090', '10.1007/978-3-031-44198-1_2', '10.1109/ijcnn54540.2023.10191391', '10.1007/978-3-031-19433-7_3', '10.1145/3572898', '10.1109/icpr56361.2022.9956376', '10.3233/jifs-237167', '10.1109/jas.2023.123540', '10.1109/tkde.2023.3292974', '10.1007/s11227-022-04875-9', '10.1007/s10489-022-03731-w', '10.1007/978-3-031-00126-0_9', '10.1145/3502223.3502245', '10.1007/s40747-023-01084-6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/3IJBSTZW/et al. - 2020 - Document-Level Relation Extraction with Reconstruction.pdf","","DONE; GRANULARITY:Document; ARCHI:Bilstm; LANG:English; DATASET:Docred; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; ARCHI:Encoder; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; DATATYPEPROP:NSP; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; PTM:Glove; ARCHI:LSTM; ARCHI:MLP; PTM:BERT; ARCHI:HeterogeneousGraph; TASK:RelationClassif; ARCHI:NodeEmbed; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"JJNFUJM3","conferencePaper","2020",", Zexuan Zhong; , Danqi Chen","A Frustratingly Easy Approach for Entity and Relation Extraction","","","","10.18653/v1/2021.naacl-main.5","https://arxiv.org/abs/2010.12812v2","End-to-end relation extraction aims to identify named entities and extract relations between them. Most recent work models these two subtasks jointly, either by casting them in one structured prediction framework, or performing multi-task learning through shared representations. In this work, we present a simple pipelined approach for entity and relation extraction, and establish the new state-of-the-art on standard benchmarks (ACE04, ACE05 and SciERC), obtaining a 1.7%-2.8% absolute improvement in relation F1 over previous joint models with the same pre-trained encoders. Our approach essentially builds on two independent encoders and merely uses the entity model to construct the input for the relation model. Through a series of careful examinations, we validate the importance of learning distinct contextual representations for entities and relations, fusing entity information early in the relation model, and incorporating global context. Finally, we also present an efficient approximation to our approach which requires only one pass of both entity and relation encoders at inference time, achieving an 8-16$\times$ speedup with a slight reduction in accuracy.","2020-10-24","2023-10-30 16:40:45","2025-03-22 16:54:14","","NA","","","NA","","","PURE","","","","","ACL","","","NA","","https://paperswithcode.com/paper/a-frustratingly-easy-approach-for-joint","https://github.com/YaoXinZhi/BERT-for-BioNLP-OST2019-AGAC-Task2","","[{""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""SciERC"", ""res"": ""68.9"", ""metric"": ""Entity F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""62.2"", ""metric"": ""Relation F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""SciERC"", ""res"": ""50.1"", ""metric"": ""Relation F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""SciERC"", ""res"": ""36.7"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""SciERC"", ""res"": ""Yes"", ""metric"": ""Cross Sentence""}, {""task"": ""Named Entity Recognition (NER)"", ""dataset"": ""ACE 2005"", ""res"": ""90.9"", ""metric"": ""F1""}, {""task"": ""Named Entity Recognition (NER)"", ""dataset"": ""ACE 2004"", ""res"": ""90.3"", ""metric"": ""F1""}, {""task"": ""Named Entity Recognition (NER)"", ""dataset"": ""SciERC"", ""res"": ""68.2"", ""metric"": ""F1""}, {""task"": ""Named Entity Recognition (NER)"", ""dataset"": ""ACE 2004"", ""res"": ""y"", ""metric"": ""Multi-Task Supervision""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""62.2"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""Yes"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""90.9"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""69.4"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""62.2"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""ALBERT"", ""metric"": ""Sentence Encoder""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""90.3"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""66.1"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""Yes"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""66.1"", ""metric"": ""RE Micro F1""}]","{'citing': ['10.1109/icpr56361.2022.9956191', '10.1109/ijcnn54540.2023.10191604', '10.1109/ijcnn54540.2023.10191251', '10.1109/ijcnn54540.2023.10191693', '10.1007/978-3-031-37890-4_9', '10.1007/s13278-023-01095-8', '10.1007/s10489-022-03817-5', '10.3934/mbe.2022240', '10.1016/j.ins.2021.09.028', '10.3390/app13158609', '10.3390/info15020091', '10.1016/j.artmed.2023.102573', '10.32604/iasc.2022.028352', '10.1007/s10994-022-06151-6', '10.1016/j.eswa.2022.119240', '10.1038/s41598-023-29454-7', '10.1007/s11063-022-10907-5', '10.1109/tai.2022.3205567', '10.1109/taslp.2023.3293047', '10.1016/j.engappai.2023.106723', '10.1109/taslp.2024.3350905', '10.1016/j.cogr.2022.11.001', '10.1109/ijcnn55064.2022.9891960', '10.1109/ijcnn55064.2022.9892140', '10.1109/ijcnn55064.2022.9892310', '10.1007/978-981-99-6207-5_15', '10.3390/en16124654', '10.1016/j.jbi.2023.104415', '10.1016/j.jbi.2023.104456', '10.1016/j.knosys.2022.109129', '10.1007/978-3-031-17120-8_45', '10.1007/978-3-031-17120-8_21', '10.1145/3511808.3557313', '10.1145/3511808.3557422', '10.1109/icdh60066.2023.00047', '10.3390/app131810538', '10.5715/jnlp.29.187', '10.3390/app13158700', '10.1007/s13042-021-01491-6', '10.1007/978-3-031-10983-6_31', '10.1038/s41598-022-26116-y', '10.1109/access.2023.3279288', '10.3390/e25081217', '10.3390/e26020162', '10.1109/cisp-bmei60920.2023.10373243', '10.1007/978-981-19-8300-9_2', '10.3390/math11143165', '10.1109/ijcnn54540.2023.10191921', '10.1016/j.compbiomed.2024.108189', '10.1016/j.knosys.2023.110471', '10.1016/j.knosys.2022.109184', '10.1109/bigdata55660.2022.10020308', '10.1007/s00521-022-07747-8', '10.1109/icassp49357.2023.10094905', '10.2196/preprints.48072', '10.1049/ell2.12411', '10.1109/bibm52615.2021.9669736', '10.1016/j.aei.2022.101780', '10.1109/icmla55696.2022.00254', '10.1007/978-981-19-9865-2_2', '10.1007/s11192-023-04694-6', '10.1007/978-3-031-37717-4_48', '10.1109/access.2023.3299880', '10.1109/icme55011.2023.00101', '10.1186/s12911-023-02127-1', '10.1109/icassp49357.2023.10095786', '10.1007/978-3-031-24755-2_8', '10.1080/10095020.2022.2076619', '10.1007/978-3-031-18315-7_11', '10.1007/978-3-031-18315-7_21', '10.3390/electronics12112483', '10.1007/978-981-99-6222-8_20', '10.1007/s40747-023-01321-y', '10.1117/12.3014256', '10.1109/iros55552.2023.10342509', '10.3390/electronics12010121', '10.1109/icbaie56435.2022.9985876', '10.3390/app14051717', '10.1186/s12859-022-05096-w', '10.1145/3543507.3583504', '10.1145/3580305.3599791', '10.1007/978-981-19-6142-7_10', '10.1038/s41524-023-01003-w', '10.3390/drones7060360', '10.2991/978-94-6463-046-6_42', '10.1145/3604811', '10.1007/978-3-031-44198-1_2', '10.1109/ijcnn54540.2023.10191391', '10.1145/3534678.3539386', '10.1145/3569581', '10.4018/ijitsa.328681', '10.1007/s00500-024-09629-8', '10.1007/s12559-023-10163-2', '10.1145/3539618.3591912', '10.1093/bib/bbab451', '10.1007/978-3-030-88480-2_41', '10.1007/978-3-030-88483-3_40', '10.1109/bigdata52589.2021.9671529', '10.1016/j.jksuci.2022.08.038', '10.1007/s00521-024-09454-y', '10.1109/tkde.2023.3292974', '10.1007/978-981-16-5188-5_2', '10.1109/tkde.2022.3177226', '10.3390/app13137585', '10.3390/app13106178', '10.1109/iccc54389.2021.9674535', '10.1016/j.cogsys.2023.101153', '10.1109/access.2023.3335623', '10.1145/3502223.3502245', '10.1155/2022/9947098', '10.1007/s10278-022-00717-5', '10.3390/app131910643', '10.1007/s40747-023-01004-8'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/KKMT5R7V/and - 2020 - A Frustratingly Easy Approach for Entity and Relation Extraction.pdf","","DONE; GRANULARITY:Document; TASK:Endtoendre; LANG:Arabic; LANG:Chinese; LANG:English; PTM:Albert; DATASET:Scierc; DATASET:Ace2005; USENEGATIVEEXAMPLE_BIN:?; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; INPUT:Embedding; ARCHI:Encoder; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; DATATYPEPROP:NSP; TASK:NER; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:10^0; NBDATASET:3; INPUT:NER; ARCHI:PositionnalEMbed; PTM:BERT; DATASET:ACE2004; PTM:SciBERT; INPUT:TypeEntity; ARCHI:ENtityTypeEmbed; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL 2021 4","","","","","","","","","","","","","","",""
"X38Y4WNS","conferencePaper","2020",", Wenxuan Zhou; , Kevin Huang; , Tengyu Ma; , Jing Huang","Document-Level Relation Extraction with Adaptive Thresholding and Localized Context Pooling","AAAI","","","10.1609/aaai.v35i16.17717","https://arxiv.org/abs/2010.11304v3","Document-level relation extraction (RE) poses new challenges compared to its sentence-level counterpart. One document commonly contains multiple entity pairs, and one entity pair occurs multiple times in the document associated with multiple possible relations. In this paper, we propose two novel techniques, adaptive thresholding and localized context pooling, to solve the multi-label and multi-entity problems. The adaptive thresholding replaces the global threshold for multi-label classification in the prior work with a learnable entities-dependent threshold. The localized context pooling directly transfers attention from pre-trained language models to locate relevant context that is useful to decide the relation. We experiment on three document-level RE benchmark datasets: DocRED, a recently released large-scale RE dataset, and two datasets CDRand GDA in the biomedical domain. Our ATLOP (Adaptive Thresholding and Localized cOntext Pooling) model achieves an F1 score of 63.4, and also significantly outperforms existing models on both CDR and GDA.","2020-10-21","2023-10-30 16:40:45","2025-03-22 16:54:24","","","","","","","","ATLOP","","","","","AAAI","","","NA","","https://paperswithcode.com/paper/document-level-relation-extraction-with","https://github.com/wzhouad/ATLOP","","[{""task"": ""Relation Extraction"", ""dataset"": ""GDA"", ""res"": ""83.9"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""63.40"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""61.30"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""61.39"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""59.31"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""CDR"", ""res"": ""69.4"", ""metric"": ""F1""}]","{'citing': ['10.1109/slaai-icai59257.2023.10365022', '10.1016/j.jksuci.2023.101643', '10.1007/978-981-99-9955-2_62', '10.1007/978-3-031-44201-8_5', '10.1016/j.jbi.2023.104487', '10.1016/j.engappai.2023.106212', '10.1016/j.knosys.2022.109146', '10.1007/978-3-031-17120-8_13', '10.1145/3511808.3557313', '10.1145/3511808.3557615', '10.1109/ijcnn55064.2022.9892647', '10.3390/info14070365', '10.1109/bibm58861.2023.10385582', '10.1007/978-3-031-33374-3_25', '10.1007/978-3-031-28244-7_38', '10.3390/e26030210', '10.1007/s42524-023-0273-1', '10.1016/j.knosys.2023.110428', '10.1016/j.knosys.2023.110873', '10.3390/app12031599', '10.1145/3508546.3508633', '10.1007/978-3-031-25198-6_9', '10.1109/icassp49357.2023.10096263', '10.1109/icassp49357.2023.10095437', '10.1109/iccwamtip60502.2023.10387128', '10.1007/978-981-99-9864-7_10', '10.1007/978-981-19-5391-0_6', '10.1016/j.array.2023.100331', '10.1109/tkde.2023.3266495', '10.1145/3534678.3539304', '10.26599/bdma.2022.9020051', '10.5715/jnlp.30.557', '10.1007/978-3-031-44198-1_2', '10.1109/ijcnn54540.2023.10191391', '10.1007/978-3-031-20309-1_11', '10.1088/1742-6596/2504/1/012004', '10.1109/access.2022.3160201', '10.1007/978-3-031-19433-7_3', '10.1007/978-981-19-7596-7_4', '10.1145/3572898', '10.3233/jifs-237167', '10.1007/s00500-024-09629-8', '10.1145/3539618.3591984', '10.1145/3539618.3591912', '10.1109/jas.2023.123540', '10.1016/j.eswa.2022.117678', '10.1007/s00521-023-09336-9', '10.1109/tkde.2023.3292974', '10.1007/s11227-022-04875-9', '10.1145/3597610', '10.1007/s10489-022-03731-w', '10.1109/access.2023.3335196', '10.1145/3502223.3502245', '10.1109/bibm52615.2021.9669319', '10.1007/s40747-023-01084-6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/PVN3YJEM/ et al. - 2020 - Document-Level Relation Extraction with Adaptive T.pdf","","DONE; GRANULARITY:Document; GRANULARITY:Sentences; LANG:English; PTM:Scibert; DATASET:Docred; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; NBTYPEREL:10²; USENEGATIVEEXAMPLE_BIN:1; DATASET:Cdr; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:10^0; DATASET:GDA; NBDATASET:3; PTM:BERT; ARCHI:BinaryClassif; ARCHI:AdaptiveThreshold; ARCHI:Pooling; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"QUCVVH5D","conferencePaper","2020",", Shan Zhao; , Minghao Hu; , Zhiping Cai; , Fang Liu","Modeling Dense Cross-Modal Interactions for Joint Entity-Relation Extraction","IJCAI","","","10.24963/ijcai.2020/558","https://www.ijcai.org/Proceedings/2020/558","Joint extraction of entities and their relations benefits from the close interaction between named entities and their relation information. Therefore, how to effectively model such cross-modal interactions is critical for the final performance. Previous works have used simple methods such as label-feature concatenation to perform coarse-grained semantic fusion among cross-modal instances, but fail to capture fine-grained correlations over token and label spaces, resulting in insufficient interactions. In this paper, we propose a deep Cross-Modal Attention Network (CMAN) for joint entity and relation extraction. The network is carefully constructed by stacking multiple attention units in depth to fully model dense interactions over token-label spaces, in which two basic attention units are proposed to explicitly capture fine-grained correlations across different modalities (e.g., token-to-token and labelto-token). Experiment results on CoNLL04 dataset show that our model obtains state-of-the-art results by achieving 90.62% F1 on entity recognition and 72.97% F1 on relation classification. In ADE dataset, our model surpasses existing approaches by more than 1.9% F1 on relation classification. Extensive analyses further confirm the effectiveness of our approach.","2020-07-01","2023-10-30 16:40:45","2025-03-22 16:54:11","","NA","","","NA","","","CMAN","","","","","IJCAI","","","NA","","https://paperswithcode.com/paper/modeling-dense-cross-modal-interactions-for","na","","[{""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""89.40"", ""metric"": ""NER Macro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""81.14"", ""metric"": ""RE+ Macro F1""}]","{'citing': ['10.1145/3539618.3591711', '10.1007/s10115-022-01665-w', '10.1007/978-3-031-39965-7_49', '10.1080/09540091.2022.2026295', '10.1038/s41598-023-35482-0', '10.3390/app131810538', '10.1109/tnnls.2021.3104971', '10.1145/3530190.3534850', '10.1109/bigdata55660.2022.10020994', '10.1016/j.knosys.2022.110228', '10.1186/s12911-023-02117-3', '10.1007/978-981-19-2500-9_29', '10.1016/j.eswa.2023.120182', '10.1007/s11042-024-18472-w', '10.1371/journal.pone.0281055', '10.1016/j.eswa.2023.122007', '10.1109/tcbb.2022.3205113', '10.1109/isctis58954.2023.10213028', '10.1007/978-3-030-92307-5_5', '10.1007/978-981-16-5188-5_2', '10.1007/s40747-023-01004-8'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/DTI2AGKD/et al. - 2020 - Modeling Dense Cross-Modal Interactions for Joint Entity-Relation Extraction.pdf","","DONE; PTM:Word2Vec; GRANULARITY:Sentences; ARCHI:Bilstm; TASK:Endtoendre; PTM:Elmo; ARCHI:Crf; LANG:English; DATATYPEPROP:String; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; INPUT:Embedding; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBDATASET:2; TASK:NER; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:10^0; DATASET:ADE; OBJECTPROPERTIES_BIN:NSP; DATASET:Conll04; TASK:RelationClassif; LEARNINGMETHOD:Training; ARCHI:CMAN; ARCHI:LabelEMbed; LEARNINGMETHOD:AdversarialTraining; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IJCAI","","","","","","","","","","","","","","",""
"DXT4LIWY","conferencePaper","2020",", Ikuya Yamada; , Akari Asai; , Hiroyuki Shindo; , Hideaki Takeda; , Yuji Matsumoto","LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention","","","","10.18653/v1/2020.emnlp-main.523","https://arxiv.org/abs/2010.01057v1","Entity representations are useful in natural language tasks involving entities. In this paper, we propose new pretrained contextualized representations of words and entities based on the bidirectional transformer. The proposed model treats words and entities in a given text as independent tokens, and outputs contextualized representations of them. Our model is trained using a new pretraining task based on the masked language model of BERT. The task involves predicting randomly masked words and entities in a large entity-annotated corpus retrieved from Wikipedia. We also propose an entity-aware self-attention mechanism that is an extension of the self-attention mechanism of the transformer, and considers the types of tokens (words or entities) when computing attention scores. The proposed model achieves impressive empirical performance on a wide range of entity-related tasks. In particular, it obtains state-of-the-art results on five well-known datasets: Open Entity (entity typing), TACRED (relation classification), CoNLL-2003 (named entity recognition), ReCoRD (cloze-style question answering), and SQuAD 1.1 (extractive question answering). Our source code and pretrained representations are available at https://github.com/studio-ousia/luke.","2020-10-02","2023-10-30 16:40:45","2025-03-22 16:54:19","","NA","","","NA","","","LUKE","","","","","ACL","","","NA","","https://paperswithcode.com/paper/luke-deep-contextualized-entity","https://github.com/JiachengLi1995/UCTopic","","[{""task"": ""Question Answering"", ""dataset"": ""TACRED"", ""res"": ""72.7"", ""metric"": ""Relation F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""TACRED"", ""res"": ""60.6"", ""metric"": ""F1 (10% Few-Shot)""}, {""task"": ""Relation Extraction"", ""dataset"": ""TACRED"", ""res"": ""72.7"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""TACRED"", ""res"": ""51.6"", ""metric"": ""F1 (5% Few-Shot)""}, {""task"": ""Relation Extraction"", ""dataset"": ""TACRED"", ""res"": ""17.0"", ""metric"": ""F1 (1% Few-Shot)""}]","{'citing': ['10.1007/978-3-030-83527-9_29', '10.7717/peerj-cs.384', '10.3233/sw-222986', '10.1016/j.knosys.2022.109828', '10.1016/j.knosys.2022.109471', '10.3390/math11071624', '10.3390/math11081815', '10.1109/compsac57700.2023.00038', '10.1007/s10489-022-03817-5', '10.1145/3539618.3591911', '10.1007/s10115-022-01687-4', '10.3390/info13030151', '10.1017/s1351324922000304', '10.1017/s1351324921000322', '10.1101/2024.02.19.581094', '10.1016/j.neucom.2022.05.049', '10.1007/978-3-031-01333-1_2', '10.1109/icmcis52405.2021.9486422', '10.1016/j.eswa.2022.119369', '10.1007/s11063-023-11201-8', '10.1007/s11063-023-11168-6', '10.3390/ijgi11020079', '10.1145/3477495.3531971', '10.1145/3477495.3531746', '10.1145/3485447.3511998', '10.1007/978-3-031-16270-1_12', '10.14778/3551793.3551812', '10.1109/taslp.2022.3221009', '10.3390/sym16020136', '10.1109/asru57964.2023.10389706', '10.1007/978-3-030-86523-8_34', '10.1007/978-3-030-85899-5_9', '10.1145/3561299', '10.1145/3554734', '10.1109/ijcnn55064.2022.9892196', '10.3390/app13021159', '10.1016/j.engappai.2023.106212', '10.1109/icsecs52883.2021.00123', '10.1109/cscwd54268.2022.9776127', '10.1145/3485447.3512012', '10.1007/978-3-031-17189-5_12', '10.1007/978-3-031-17189-5_19', '10.1007/978-3-031-17189-5_24', '10.1007/978-3-031-17601-2_28', '10.5715/jnlp.29.294', '10.1007/978-3-031-10983-6_54', '10.1016/j.inffus.2022.11.025', '10.1007/s11280-023-01166-y', '10.1007/978-3-031-28244-7_24', '10.1162/tacl_a_00557', '10.32604/cmc.2021.015636', '10.1007/978-3-030-77867-5_10', '10.1109/icsc56153.2023.00035', '10.1109/access.2023.3339610', '10.1109/icsa56044.2023.00021', '10.1007/978-3-030-93758-4_22', '10.1093/bib/bbac409', '10.1109/icde53745.2022.00060', '10.1007/978-3-031-35320-8_19', '10.1007/s41060-021-00285-x', '10.1016/j.knosys.2023.110471', '10.1016/j.knosys.2022.109184', '10.1109/bigdata55660.2022.10020308', '10.1007/s10109-023-00433-w', '10.1007/978-3-030-80418-3_19', '10.1162/tacl_a_00429', '10.1162/tacl_a_00416', '10.1145/3477495.3531742', '10.1007/978-981-99-1600-9_9', '10.1109/access.2023.3234605', '10.3390/a16020102', '10.3390/s22134911', '10.1016/j.csl.2022.101412', '10.3390/electronics13030648', '10.1109/taslp.2022.3153256', '10.1007/978-3-031-44216-2_33', '10.1007/s11633-023-1416-x', '10.1145/3404835.3463113', '10.1177/1748006x221131128', '10.1007/s11192-023-04806-2', '10.1109/tse.2023.3333265', '10.1109/isai-nlp60301.2023.10355001', '10.1109/wi-iat59888.2023.00051', '10.1007/978-981-19-8388-7_176', '10.1007/978-3-031-39059-3_13', '10.1145/3508230.3508252', '10.1016/j.aiopen.2021.06.004', '10.1109/icme52920.2022.9859972', '10.1007/978-3-031-47715-7_57', '10.1007/s40747-024-01373-8', '10.1109/jbhi.2023.3271580', '10.1007/s10115-022-01783-5', '10.1007/978-3-031-23198-8_5', '10.1145/3591106.3592227', '10.1007/978-981-99-0601-7_42', '10.1109/qrs60937.2023.00077', '10.1016/j.eswa.2024.123478', '10.4218/etrij.2023-0321', '10.1145/3543507.3583504', '10.2196/41100', '10.1007/978-3-031-30675-4_43', '10.1109/iccns58795.2023.10193182', '10.1145/3576840.3578334', '10.1101/2022.02.27.22271257', '10.1109/access.2022.3205719', '10.1109/access.2022.3202889', '10.4018/ijdai.311063', '10.5715/jnlp.30.857', '10.1007/978-981-16-8800-3_176-2', '10.1007/978-3-031-23190-2_5', '10.1007/978-3-031-23190-2_3', '10.1016/j.neucom.2023.126511', '10.1162/coli_a_00463', '10.1145/3503161.3548172', '10.2139/ssrn.4186504', '10.1038/s41746-022-00742-2', '10.1145/3531478', '10.1145/3511098', '10.1109/cvpr52729.2023.00667', '10.1109/ijcnn54540.2023.10191841', '10.1109/ijcnn54540.2023.10191909', '10.1007/s00521-023-09285-3', '10.1080/1331677x.2022.2097108', '10.1007/978-3-031-20059-5_37', '10.3390/app13106178', '10.1109/access.2021.3128178', '10.5715/jnlp.29.997', '10.1145/3534678.3539349', '10.1016/j.eswa.2021.115049', '10.1007/978-3-031-00129-1_24', '10.1007/978-3-031-03948-5_11', '10.1007/s10489-021-02269-7', '10.1145/3497842', '10.1007/978-3-031-21648-0_18', '10.1145/3592854', '10.1145/3593023', '10.1145/3605550', '10.1109/tcsii.2022.3196055', '10.1016/j.asoc.2022.108604'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/PMZNP7JV/et al. - 2020 - LUKE Deep Contextualized Entity Representations with Entity-aware Self-attention.pdf","","DONE; GRANULARITY:Sentences; PTM:Bert; LANG:English; TASK:Entitytyping; DATATYPEPROP:?; SYNTHGENERATION_BIN:?; COSTEVAL_BIN:1; INPUT:Text; ARCHI:Encoder; DATASET:Conll; LEARNINGMETHOD:Pretraining; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; TASK:NER; LINEARIZEDGRAPH_BIN:0; NBDATASET:4; USENEGATIVEEXAMPLE_BIN:NSP; DATASET:TACRED; ARCHI:PositionnalEMbed; DATASET:SQUAD; TASK:QA; ARCHI:ENtityEmbedding; TASK:RelationClassif; ARCHI:TokenEmbed; DATASET:OpenEntity; DATASET:RECORD; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2020 11","","","","","","","","","","","","","","",""
"YBIDV7BA","conferencePaper","2020",", Shuang Zeng; , Runxin Xu; , Baobao Chang; , Lei LI","Double Graph Based Reasoning for Document-level Relation Extraction","","","","10.18653/v1/2020.emnlp-main.127","https://arxiv.org/abs/2009.13752v1","Document-level relation extraction aims to extract relations among entities within a document. Different from sentence-level relation extraction, it requires reasoning over multiple sentences across a document. In this paper, we propose Graph Aggregation-and-Inference Network (GAIN) featuring double graphs. GAIN first constructs a heterogeneous mention-level graph (hMG) to model complex interaction among different mentions across the document. It also constructs an entity-level graph (EG), based on which we propose a novel path reasoning mechanism to infer relations between entities. Experiments on the public dataset, DocRED, show GAIN achieves a significant performance improvement (2.85 on F1) over the previous state-of-the-art. Our code is available at https://github.com/DreamInvoker/GAIN .","2020-09-29","2023-10-30 16:40:45","2025-03-22 16:53:19","","NA","","","NA","","","GAIN-BERT, GAIN-GloVe, GAIN-BERT-large","","","","","ACL","","","NA","","https://paperswithcode.com/paper/double-graph-based-reasoning-for-document","https://github.com/DreamInvoker/GAIN","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""52.66"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""59.00"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""61.24"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""60.31"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""62.76"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""55.08"", ""metric"": ""F1""}]","{'citing': ['10.1109/icpr56361.2022.9956191', '10.1145/3404835.3463070', '10.1007/s10115-022-01665-w', '10.3390/electronics11223715', '10.1007/978-981-99-9955-2_62', '10.1007/978-3-030-85899-5_36', '10.1109/ijcnn55064.2022.9892310', '10.1016/j.engappai.2023.106212', '10.1007/s12559-021-09917-7', '10.1007/978-3-031-17120-8_13', '10.1145/3511808.3557313', '10.1145/3511808.3557615', '10.1109/ijcnn55064.2022.9892647', '10.3390/info14070365', '10.1016/j.knosys.2021.107274', '10.1109/itaic54216.2022.9836511', '10.1186/s12911-022-01862-1', '10.1007/978-3-031-33374-3_25', '10.1007/978-3-031-28244-7_38', '10.3390/e26030210', '10.1007/s42524-023-0273-1', '10.1145/3459637.3482236', '10.1016/j.knosys.2023.110428', '10.3390/app12031599', '10.1007/978-981-99-1600-9_9', '10.1145/3508546.3508633', '10.1007/978-3-031-44213-1_42', '10.1007/978-3-030-91560-5_25', '10.1145/3477495.3531758', '10.1109/icmla55696.2022.00254', '10.1007/978-981-19-9865-2_3', '10.1007/s00521-022-07223-3', '10.1109/icassp49357.2023.10096263', '10.1109/icassp49357.2023.10095786', '10.1007/978-981-99-9864-7_11', '10.1007/978-981-99-9864-7_10', '10.1109/icme52920.2022.9859653', '10.1145/3534678.3539304', '10.1109/iccsnt56096.2022.9972949', '10.26599/bdma.2022.9020051', '10.1007/978-3-031-44198-1_2', '10.1109/ijcnn54540.2023.10191391', '10.1038/s42256-023-00624-6', '10.1007/978-3-031-19433-7_3', '10.1145/3572898', '10.3233/jifs-237167', '10.1007/s12559-022-10105-4', '10.1145/3539618.3591984', '10.1145/3539618.3591912', '10.1109/jas.2023.123540', '10.1007/978-3-030-88480-2_26', '10.1007/978-3-030-88480-2_21', '10.1016/j.eswa.2022.117678', '10.1007/s00521-023-09336-9', '10.1109/tkde.2023.3292974', '10.1007/s11227-022-04875-9', '10.1145/3597610', '10.1007/978-3-030-75765-6_22', '10.1145/3502223.3502245', '10.1007/s40747-023-01084-6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/PLXQCXUV/et al. - 2020 - Double Graph Based Reasoning for Document-level Relation Extraction.pdf","","DONE; GRANULARITY:Document; GRANULARITY:Sentences; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; DATATYPEPROP:NSP; LINEARIZEDGRAPH_BIN:0; ARCHi:MLP; NBDATASET:1; INPUT:NER; PTM:Glove; ARCHI:GCN; PTM:BERT; DATASET:DOCRED; LANG:ENglish; ARCHI:BILSTM; ARCHI:Embedding; TASK:RelationClassif; ARCHI:CorefEmbed; ARCHI:TypeEmbed; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2020 11","","","","","","","","","","","","","","",""
"EU8CQVC9","conferencePaper","2020",", Difeng Wang; , Wei Hu; , Ermei Cao; , Weijian Sun","Global-to-Local Neural Networks for Document-Level Relation Extraction","","","","10.18653/v1/2020.emnlp-main.303","https://arxiv.org/abs/2009.10359v1","Relation extraction (RE) aims to identify the semantic relations between named entities in text. Recent years have witnessed it raised to the document level, which requires complex reasoning with entities and mentions throughout an entire document. In this paper, we propose a novel model to document-level RE, by encoding the document information in terms of entity global and local representations as well as context relation representations. Entity global representations model the semantic information of all entities in the document, entity local representations aggregate the contextual information of multiple mentions of specific entities, and context relation representations encode the topic information of other relations. Experimental results demonstrate that our model achieves superior performance on two public datasets for document-level RE. It is particularly effective in extracting relations between entities of long distance and having multiple mentions.","2020-09-22","2023-10-30 16:40:45","2025-03-22 16:54:31","","NA","","","NA","","","GLRE","","","","","ACL","","","NA","","https://paperswithcode.com/paper/global-to-local-neural-networks-for-document","https://github.com/nju-websoft/GLRE","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""59.0"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""56.8"", ""metric"": ""Ign F1""}]","{'citing': ['10.1007/s10115-022-01665-w', '10.3390/electronics11223715', '10.1007/978-981-99-9955-2_62', '10.1007/978-3-030-86523-8_35', '10.1109/phm-yantai55411.2022.9941768', '10.1016/j.engappai.2023.106212', '10.1007/s12559-021-09917-7', '10.1145/3511808.3557313', '10.1109/ijcnn55064.2022.9892647', '10.1109/bibm58861.2023.10385582', '10.1109/itaic54216.2022.9836511', '10.1007/978-3-031-33374-3_25', '10.1007/978-3-031-28244-7_38', '10.3390/e26030210', '10.1093/bib/bbac409', '10.1016/j.knosys.2023.110428', '10.3390/app12031599', '10.1145/3508546.3508633', '10.1109/tcbb.2021.3135844', '10.1145/3477495.3531758', '10.1007/s00521-022-07223-3', '10.1109/phm2022-london52454.2022.00049', '10.1007/978-3-031-25198-6_9', '10.1016/j.jmsy.2023.08.006', '10.1109/ialp61005.2023.10337090', '10.26599/bdma.2022.9020051', '10.1007/978-3-031-19433-7_3', '10.1109/icpr56361.2022.9956376', '10.3233/jifs-237167', '10.1007/978-3-030-88480-2_26', '10.1016/j.eswa.2022.117678', '10.1007/s00521-023-09336-9', '10.1109/tkde.2023.3292974', '10.1007/s11227-022-04875-9', '10.1145/3597610', '10.1007/978-3-030-75768-7_30', '10.1007/s10489-022-03731-w', '10.1007/s40747-023-01084-6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/DPXAXCVQ/ et al. - 2020 - Global-to-Local Neural Networks for Document-Level.pdf","","DONE; GRANULARITY:Document; LANG:English; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; NBTYPEREL:10¹; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:10^0; ARCHI:classifLayer; ARCHI:MultiAtttention; ARCHI:GCN; PTM:BERT; ARCHI:FNN; DATASET:CDR; DATASET:DocRED; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2020 11","","","","","","","","","","","","","","",""
"A7RLWETG","conferencePaper","2020",", Anson Bastos; , Abhishek Nadgeri; , Kuldeep Singh; , Isaiah Onando Mulang'; , Saeedeh Shekarpour; , Johannes Hoffart; , Manohar Kaul","RECON: Relation Extraction using Knowledge Graph Context in a Graph Neural Network","WWW '21: Proceedings of the Web Conference 2021","","","10.1145/3442381.3449917","https://arxiv.org/pdf/2009.08694v2","In this paper, we present a novel method named RECON, that automatically identifies relations in a sentence (sentential relation extraction) and aligns to a knowledge graph (KG). RECON uses a graph neural network to learn representations of both the sentence as well as facts stored in a KG, improving the overall extraction quality. These facts, including entity attributes (label, alias, description, instance-of) and factual triples, have not been collectively used in the state of the art methods. We evaluate the effect of various forms of representing the KG context on the performance of RECON. The empirical evaluation on two standard relation extraction datasets shows that RECON significantly outperforms all state of the art methods on NYT Freebase and Wikidata datasets. RECON reports 87.23 F1 score (Vs 82.29 baseline) on Wikidata dataset whereas on NYT Freebase, reported values are 87.5(P@10) and 74.1(P@30) compared to the previous baseline scores of 81.3(P@10) and 63.1(P@30).","2020-09-18","2023-10-30 16:40:45","2025-03-22 16:53:46","","","","","","","","RECON","","","","","ACM","","","NA","","https://paperswithcode.com/paper/recon-relation-extraction-using-knowledge","https://github.com/ansonb/RECON","","{""NYT Corpus"": {""P@10%"": ""87.5"", ""P@30%"": ""74.1""}}","{'citing': ['10.3233/sw-212865', '10.3233/sw-222925', '10.1016/j.knosys.2022.109800', '10.1109/ijcnn54540.2023.10191797', '10.1007/978-3-030-74296-6_19', '10.1145/3485447.3511998', '10.34133/2022/9841548', '10.1007/978-3-030-86523-8_34', '10.1145/3554734', '10.1145/3485447.3511986', '10.1007/978-3-031-17120-8_33', '10.1145/3511808.3557267', '10.3390/info14030186', '10.1109/itaic54216.2022.9836511', '10.1145/3459637.3482263', '10.1109/smc53992.2023.10394538', '10.1109/wi-iat59888.2023.00024', '10.1109/ictai56018.2022.00072', '10.3390/jrfm17010038', '10.1007/s10115-022-01826-x', '10.1016/j.eswa.2023.121725', '10.1145/3543507.3583549', '10.1016/j.eswa.2023.120479', '10.1007/s11280-021-00982-4', '10.1007/978-3-031-43421-1_14', '10.1007/978-3-031-19433-7_37', '10.1007/978-3-031-19433-7_3', '10.1007/978-3-031-19496-2_8', '10.1155/2022/5934071'], 'cited': ['10.18653/v1/d17-1188', '10.1007/978-3-030-37439-6', '10.18653/v1/p16-1200', '10.18653/v1/p19-1128', '10.1145/3227609.3227670', '10.18653/v1/d17-1189', '10.3115/1690219.1690287', '10.1162/089976698300017197', '10.1145/3241741', '10.1145/2187980.2188242', '10.18653/v1/n19-1323', '10.18653/v1/n19-1288', '10.1609/aaai.v28i1.8870', '10.1007/978-3-540-76298-0_52', '10.1109/78.650093', '10.1145/3340531.3412159']}","","/root/snap/zotero-snap/common/Zotero/storage/YDTV7ALW/et al. - 2020 - RECON Relation Extraction using Knowledge Graph Context in a Graph Neural Network.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Bilstm; LANG:English; COSTEVAL_BIN:1; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; SOURCE:Wikidata; SOURCE:Freebase; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBDATASET:2; NBTYPEREL:10^2; LINEARIZEDGRAPH_BIN:0; INPUT:NER; PTM:Glove; ARCHI:PositionnalEMbed; ARCHI:GNN; ARCHI:CNN; MANUALANNOTATION:1; TASK:RelationClassif; DATASET:NYT-FB; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WWW","","","","","","","","","","","","","","",""
"CL353TTH","conferencePaper","2020",", Ranran Haoran Zhang; , Qianying Liu; , Aysa Xuemo Fan; , Heng Ji; , Daojian Zeng; , Fei Cheng; , Daisuke Kawahara; , Sadao Kurohashi","Minimize Exposure Bias of Seq2Seq Models in Joint Entity and Relation Extraction","","","","10.18653/v1/2020.findings-emnlp.23","https://arxiv.org/abs/2009.07503v2","Joint entity and relation extraction aims to extract relation triplets from plain text directly. Prior work leverages Sequence-to-Sequence (Seq2Seq) models for triplet sequence generation. However, Seq2Seq enforces an unnecessary order on the unordered triplets and involves a large decoding length associated with error accumulation. These introduce exposure bias, which may cause the models overfit to the frequent label combination, thus deteriorating the generalization. We propose a novel Sequence-to-Unordered-Multi-Tree (Seq2UMTree) model to minimize the effects of exposure bias by limiting the decoding length to three within a triplet and removing the order among triplets. We evaluate our model on two datasets, DuIE and NYT, and systematically study how exposure bias alters the performance of Seq2Seq models. Experiments show that the state-of-the-art Seq2Seq model overfits to both datasets while Seq2UMTree shows significantly better generalization. Our code is available at https://github.com/WindChimeRan/OpenJERE .","2020-09-16","2023-10-30 16:40:45","2025-03-22 16:53:24","","NA","","","NA","","","OpenJERE","","","","","ACL","","","NA","","https://paperswithcode.com/paper/minimize-exposure-bias-of-seq2seq-models-in","https://github.com/WindChimeRan/OpenJERE","","","{'citing': ['10.1093/bib/bbac409', '10.1109/icde55515.2023.00187', '10.1109/iaecst54258.2021.9695906', '10.1007/s13042-023-01923-5', '10.1371/journal.pone.0281055', '10.1007/978-981-19-6142-7_10', '10.1109/iscipt53667.2021.00160', '10.1007/978-981-16-5188-5_2', '10.1007/978-981-99-7393-4_54'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/PBV2RGQI/et al. - 2020 - Minimize Exposure Bias of Seq2Seq Models in Joint Entity and Relation Extraction.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Lstm; TASK:Endtoendre; LANG:Chinese; LANG:English; USENEGATIVEEXAMPLE_BIN:?; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; ARCHI:Encoder; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; NBDATASET:2; PTM:None; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; DATASET:NYT; ARCHI:RelEmbedding; ARCHI:ENtityEmbedding; ARCHI:UMtreeDecoder; DATASET:DUIE; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings of the Association for Computational Linguistics 2020","","","","","","","","","","","","","","",""
"AU5XBUR6","conferencePaper","2020",", Thy Thy Tran; , Phong Le; , Sophia Ananiadou","Revisiting Unsupervised Relation Extraction","","","","10.18653/v1/2020.acl-main.669","https://arxiv.org/abs/2005.00087v1","Unsupervised relation extraction (URE) extracts relations between named entities from raw text without manually-labelled data and existing knowledge bases (KBs). URE methods can be categorised into generative and discriminative approaches, which rely either on hand-crafted features or surface form. However, we demonstrate that by using only named entities to induce relation types, we can outperform existing methods on two popular datasets. We conduct a comparison and evaluation of our findings with other URE techniques, to ascertain the important features in URE. We conclude that entity types provide a strong inductive bias for URE.","2020-04-30","2023-10-30 16:40:45","2025-03-22 16:53:49","","NA","","","NA","","","EType","","","","","ACL","","","NA","","https://paperswithcode.com/paper/revisiting-unsupervised-relation-extraction","https://github.com/ttthy/ure","","","{'citing': ['10.1080/13658816.2022.2087224', '10.1007/978-981-99-9640-7_25', '10.1109/taslp.2022.3226680', '10.1007/978-3-031-33455-9_20', '10.1145/3511808.3557422', '10.1109/icsc56153.2023.00053', '10.1007/978-3-030-80418-3_25', '10.1109/taslp.2022.3199655', '10.1007/s11633-022-1323-6', '10.1007/978-3-031-19433-7_37', '10.1007/978-3-030-88480-2_23', '10.1007/s10489-022-03596-z', '10.1007/978-3-031-33377-4_31'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/FDWYN627/et al. - 2020 - Revisiting Unsupervised Relation Extraction.pdf","","DONE; GRANULARITY:Sentences; LANG:English; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:0; SOURCE:Freebase; COSTEVAL_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBDATASET:2; PTM:None; LINEARIZEDGRAPH_BIN:0; DATASET:TACRED; ARCHI:PCNN; DECODINGMETHOD_BIN:NSP; ARCHI:FFN; TASK:RelationClassif; DATASET:NYT-FB; DatasetSplit:Random; DatasetSplit:AnnotatedData; DatasetSplit:OneRel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2020 6","","","","","","","","","","","","","","",""
"TPI6MWBE","conferencePaper","2020",", Kai Sun; , Richong Zhang; , Samuel Mensah; , Yongyi Mao; , Xudong Liu","Recurrent Interaction Network for Jointly Extracting Entities and Classifying Relations","","","","10.18653/v1/2020.emnlp-main.304","https://arxiv.org/abs/2005.00162v2","The idea of using multi-task learning approaches to address the joint extraction of entity and relation is motivated by the relatedness between the entity recognition task and the relation classification task. Existing methods using multi-task learning techniques to address the problem learn interactions among the two tasks through a shared network, where the shared information is passed into the task-specific networks for prediction. However, such an approach hinders the model from learning explicit interactions between the two tasks to improve the performance on the individual tasks. As a solution, we design a multi-task learning model which we refer to as recurrent interaction network which allows the learning of interactions dynamically, to effectively model task-specific features for classification. Empirical studies on two real-world datasets confirm the superiority of the proposed model.","2020-05-01","2023-10-30 16:40:45","2025-03-22 16:52:08","","NA","","","NA","","","RIN","","","","","ACL","","","NA","","https://paperswithcode.com/paper/recurrent-interaction-network-for-jointly","https://github.com/BDBC-KG-NLP/Recurrent_Interaction_Network_EMNLP2020","","{""NYT"": {""F1"": ""87.8""}, ""WebNLG"": {""F1"": ""90.1""}}","{'citing': ['10.1145/3488560.3498409', '10.1007/s12559-021-09917-7', '10.1145/3511808.3557323', '10.1109/access.2022.3232493', '10.1145/3459637.3482045', '10.1007/978-981-19-6142-7_10', '10.4018/ijswis.329965', '10.1007/978-3-031-19433-7_37', '10.1007/978-3-031-20865-2_13', '10.1007/s40747-023-01004-8'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/QCFB7SSI/et al. - 2020 - Recurrent Interaction Network for Jointly Extracting Entities and Classifying Relations.pdf","","DONE; GRANULARITY:Sentences; LANG:English; DATASET:Webnlg; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; NBTYPEENTITY:10²; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; TASK:NER; LINEARIZEDGRAPH_BIN:0; USENEGATIVEEXAMPLE_BIN:NSP; NBDATASET:3; ARCHI:GRU; DATASET:NYT; PTM:Glove; INPUT:POSTAG; ARCHI:BILSTM; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2020 11","","","","","","","","","","","","","","",""
"PDCR39EE","conferencePaper","2020",", Christoph Alt; , Aleksandra Gabryszak; , Leonhard Hennig","TACRED Revisited: A Thorough Evaluation of the TACRED Relation Extraction Task","","","","10.18653/v1/2020.acl-main.142","https://arxiv.org/abs/2004.14855v1","TACRED (Zhang et al., 2017) is one of the largest, most widely used crowdsourced datasets in Relation Extraction (RE). But, even with recent advances in unsupervised pre-training and knowledge enhanced neural RE, models still show a high error rate. In this paper, we investigate the questions: Have we reached a performance ceiling or is there still room for improvement? And how do crowd annotations, dataset, and models contribute to this error rate? To answer these questions, we first validate the most challenging 5K examples in the development and test sets using trained annotators. We find that label errors account for 8% absolute F1 test error, and that more than 50% of the examples need to be relabeled. On the relabeled test set the average F1 score of a large baseline model set improves from 62.1 to 70.1. After validation, we analyze misclassifications on the challenging instances, categorize them into linguistically motivated error groups, and verify the resulting error hypotheses on three state-of-the-art RE models. We show that two groups of ambiguous relations are responsible for most of the remaining errors and that models may adopt shallow heuristics on the dataset when entities are not masked.","2020-04-30","2023-10-30 16:40:45","2025-03-22 16:54:32","","NA","","","NA","","","Tacrev","","","","","ACL","","","NA","","https://paperswithcode.com/paper/tacred-revisited-a-thorough-evaluation-of-the","https://github.com/DFKI-NLP/tacrev","","","{'citing': ['10.1016/j.knosys.2022.109471', '10.1007/978-981-16-6471-7_4', '10.1145/3477495.3531746', '10.1145/3485447.3511998', '10.3390/app13021159', '10.1145/3539618.3592072', '10.1007/978-981-99-6207-5_20', '10.1145/3485447.3511921', '10.1145/3570991.3571055', '10.1016/j.knosys.2023.110471', '10.3390/a16020102', '10.1007/978-3-031-08473-7_29', '10.1145/3580305.3599318', '10.3390/s22134911', '10.1016/j.eswa.2024.123478', '10.1145/3539618.3591748', '10.1007/978-3-031-43421-1_2', '10.1162/coli_a_00464', '10.1007/978-3-030-75015-2_15', '10.1145/3555776.3578592', '10.1109/tkde.2023.3289879'], 'cited': []}","","","","DONE; DATASET:Tacred; GRANULARITY:Sentences; PTM:Spanbert; LANG:English; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; INPUT:NER; ARCHI:CNN; DATASET_CREATED:TACREV; PTM:KnowBERT; PTM:TRE; MANUALANNOTATION:1; TASK:RelationClassif; DatasetSplit:Random; DatasetSplit:ChallengingCriteria","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2020 6","","","","","","","","","","","","","","",""
"T9N3D7NB","conferencePaper","2020",", Deming Ye; , Yankai Lin; , Jiaju Du; , Zheng-Hao Liu; , Peng Li; , Maosong Sun; , Zhiyuan Liu","Coreferential Reasoning Learning for Language Representation","","","","10.18653/v1/2020.emnlp-main.582","https://arxiv.org/abs/2004.06870v2","Language representation models such as BERT could effectively capture contextual semantic information from plain text, and have been proved to achieve promising results in lots of downstream NLP tasks with appropriate fine-tuning. However, most existing language representation models cannot explicitly handle coreference, which is essential to the coherent understanding of the whole discourse. To address this issue, we present CorefBERT, a novel language representation model that can capture the coreferential relations in context. The experimental results show that, compared with existing baseline models, CorefBERT can achieve significant improvements consistently on various downstream NLP tasks that require coreferential reasoning, while maintaining comparable performance to previous models on other common NLP tasks. The source code and experiment details of this paper can be obtained from https://github.com/thunlp/CorefBERT.","2020-04-15","2023-10-30 16:40:45","2025-03-22 16:54:02","","NA","","","NA","","","CorefBERT","","","","","ACL","","","NA","","https://paperswithcode.com/paper/coreferential-reasoning-learning-for-language","https://github.com/thunlp/CorefBERT","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""56.40"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""60.25"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""54.54"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""56.96"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""58.83"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""57.90"", ""metric"": ""Ign F1""}]","{'citing': ['10.1162/tacl_a_00503', '10.1007/978-981-99-9955-2_62', '10.1007/978-3-030-86523-8_35', '10.1109/icdm54844.2022.00043', '10.1016/j.knosys.2022.109146', '10.1007/978-3-031-17120-8_13', '10.1145/3511808.3557615', '10.3390/info14070365', '10.1007/978-3-031-33374-3_25', '10.1007/978-3-031-28244-7_38', '10.3390/e26030210', '10.1016/j.knosys.2023.110471', '10.3390/app12031599', '10.1145/3487553.3524622', '10.1145/3508546.3508633', '10.1007/978-3-030-91560-5_25', '10.1145/3485127', '10.1109/taslp.2022.3193222', '10.1007/978-981-19-9865-2_3', '10.1007/s10462-023-10506-3', '10.1109/icassp49357.2023.10096263', '10.1109/access.2023.3327271', '10.1145/3534678.3539304', '10.1109/ialp61005.2023.10337090', '10.3233/jifs-234202', '10.26599/bdma.2022.9020051', '10.1007/978-3-031-44198-1_2', '10.1109/ijcnn54540.2023.10191391', '10.1109/icpr56361.2022.9956376', '10.3233/jifs-237167', '10.1109/jas.2023.123540', '10.1007/978-3-030-88480-2_26', '10.1145/3597610', '10.1145/3502223.3502245', '10.1007/s40747-023-01084-6', '10.1109/tpami.2023.3280178', '10.1007/978-3-031-25538-0_6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/N6TW6BZ3/et al. - 2020 - Coreferential Reasoning Learning for Language Representation.pdf","","DONE; PTM:Roberta; GRANULARITY:Document; PTM:Bert; LANG:English; TASK:Coref; COSTEVAL_BIN:1; DATASET:Docred; DATATYPEPROP:String; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; ARCHI:Encoder; SOURCE:Wikipedia; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; INPUT:POSTAG; DATASET:FEVER; DATASET:GLUE; DATASET:MRQA; DATASET:NaturalQA; DATASET:QUOREF; DATASET:SQUAD; Dataset:TriviaQA; INPUT:TExt; NBDATASET:6; TASK:NLU; TASK:QA; ARCHI:Embedding; TASK:RelationClassif; ARCHI:POSEmbed; DATASET:SearchQA; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2020 11","","","","","","","","","","","","","","",""
"IKP9WLM3","conferencePaper","2019",", Daojian Zeng; , Ranran Haoran Zhang; , Qianying Liu","CopyMTL: Copy Mechanism for Joint Extraction of Entities and Relations with Multi-Task Learning","AAAI Technical Track: Natural Language Processing","","","10.1609/aaai.v34i05.6495","https://arxiv.org/abs/1911.10438v2","Joint extraction of entities and relations has received significant attention due to its potential of providing higher performance for both tasks. Among existing methods, CopyRE is effective and novel, which uses a sequence-to-sequence framework and copy mechanism to directly generate the relation triplets. However, it suffers from two fatal problems. The model is extremely weak at differing the head and tail entity, resulting in inaccurate entity extraction. It also cannot predict multi-token entities (e.g. \textit{Steven Jobs}). To address these problems, we give a detailed analysis of the reasons behind the inaccurate entity extraction problem, and then propose a simple but extremely effective model structure to solve this problem. In addition, we propose a multi-task learning framework equipped with copy mechanism, called CopyMTL, to allow the model to predict multi-token entities. Experiments reveal the problems of CopyRE and show that our model achieves significant improvement over the current state-of-the-art method by 9% in NYT and 16% in WebNLG (F1 score). Our code is available at https://github.com/WindChimeRan/CopyMTL","2019-11-24","2023-10-30 16:40:45","2025-03-22 16:52:38","","","","","","","","CopyMTL","","","","","AAAI","","","NA","","https://paperswithcode.com/paper/copymtl-copy-mechanism-for-joint-extraction","https://github.com/WindChimeRan/OpenJERE","","{""NYT"": {""F1"": ""72.2""}, ""WebNLG"": {""F1"": ""60.5""}}","{'citing': ['10.1145/3533020', '10.1145/3488560.3498409', '10.1109/ijcnn54540.2023.10191604', '10.1109/ijcnn54540.2023.10191251', '10.1007/978-981-16-6471-7_4', '10.1007/978-3-030-71590-8_5', '10.32604/iasc.2022.028352', '10.3390/electronics11101535', '10.1038/s41598-023-29454-7', '10.1007/s11227-023-05442-6', '10.1109/taslp.2024.3353574', '10.1109/ijcnn55064.2022.9892140', '10.1007/s12559-021-09917-7', '10.3233/jifs-210281', '10.1109/taslp.2021.3110126', '10.1186/s12911-021-01614-7', '10.1007/s13042-021-01491-6', '10.1038/s41598-022-26116-y', '10.3390/app13074447', '10.3390/e25081217', '10.1007/978-3-031-35415-1_16', '10.1109/ijcnn54540.2023.10191826', '10.1007/978-981-99-4749-2_10', '10.1145/3459637.3482045', '10.2478/cait-2023-0014', '10.3390/app12126231', '10.1109/ijcnn52387.2021.9533902', '10.1109/ijcnn52387.2021.9533951', '10.1007/978-3-031-34560-9_28', '10.1109/taslp.2022.3198802', '10.1145/3639479.3639484', '10.1109/imcec51613.2021.9482001', '10.1109/wi-iat59888.2023.00023', '10.1007/978-3-031-07472-1_16', '10.1007/s40747-023-01321-y', '10.1016/j.array.2023.100331', '10.1007/s13042-023-01923-5', '10.1109/tkde.2022.3161584', '10.1371/journal.pone.0281055', '10.1186/s12859-022-05096-w', '10.1016/j.eswa.2023.122007', '10.1016/j.jmsy.2023.08.006', '10.1109/dsc50466.2020.00021', '10.1109/icbaie56435.2022.9985852', '10.1109/icebe55470.2022.00046', '10.1109/iccsnt56096.2022.9972949', '10.1017/s1351324923000050', '10.1016/j.eswa.2023.119905', '10.1109/itnec56291.2023.10082180', '10.1007/978-3-030-88483-3_37', '10.3389/fnbot.2022.914705', '10.1016/j.eswa.2022.116538', '10.1007/978-3-031-10986-7_7', '10.1007/s10489-021-02699-3', '10.1109/ijcnn52387.2021.9533950', '10.3390/app13020842', '10.1109/prai59366.2023.10331969', '10.1109/icassp43922.2022.9746958', '10.1007/s40747-023-01004-8'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/EYTH59F3/et al. - 2019 - CopyMTL Copy Mechanism for Joint Extraction of Entities and Relations with Multi-Task Learning.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Bilstm; LANG:English; ARCHI:Pointernet; PTM:Characterbert; DATATYPEPROP:Date; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; ARCHI:Gan; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; NBDATASET:2; NBTYPEREL:10^2; TASK:NER; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; TASK:EndToEndRE; TO_EXCLUDE?; DATASET:NYT; DATASET:WebNLG; TOCKECH; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"T6VLQQYE","conferencePaper","2019",", Dai Dai; , Xinyan Xiao; , Yajuan Lyu; , Shan Dou; , Qiaoqiao She; , Haifeng Wang","Joint extraction of entities and overlapping relations using position-attentive sequence labeling","","","","10.1609/aaai.v33i01.33016300","https://www.aaai.org/ojs/index.php/AAAI/article/view/4591","Joint entity and relation extraction is to detect entity and relation using a single model. In this paper, we present a novel unified joint extraction model which directly tags entity and relation labels according to a query word position p, i.e., detecting entity at p, and identifying entities at other positions that have relationship with the former. To this end, we first design a tagging scheme to generate n tag sequences for an n-word sentence. Then a position-attention mechanism is introduced to produce different sentence representations for every query position to model these n tag sequences. In this way, our method can simultaneously extract all entities and their type, as well as all overlapping relations. Experiment results show that our framework performances significantly better on extracting overlapping relations as well as detecting long-range relation, and thus we achieve state-of-the-art performance on two public datasets.","2019-07-17","2023-10-30 16:40:45","2025-03-22 16:53:09","","NA","","","NA","","","PA","","","","","AAAI","","","NA","","https://paperswithcode.com/paper/joint-extraction-of-entities-and-overlapping","na","","{""NYT-single"": {""F1"": ""53.8""}, ""NYT"": {""F1"": ""53.8""}}","{'citing': ['10.1109/ipccc51483.2021.9679404', '10.1109/ijcnn54540.2023.10191604', '10.1109/ijcnn54540.2023.10191251', '10.1007/978-3-030-71590-8_5', '10.1109/ihmsc49165.2020.10119', '10.1007/978-3-031-40286-9_30', '10.1016/j.neucom.2022.04.064', '10.1080/0951192x.2021.1891572', '10.1007/978-3-030-32236-6_72', '10.1109/ispds56360.2022.9874122', '10.32604/iasc.2022.028352', '10.3390/electronics11101535', '10.1109/tbdata.2022.3144151', '10.1109/iccc54389.2021.9674630', '10.12677/csa.2022.121018', '10.34133/2021/9819851', '10.1109/ijcnn55064.2022.9892140', '10.1016/j.jbi.2023.104456', '10.1109/icceai55464.2022.00011', '10.5715/jnlp.28.965', '10.1109/access.2021.3062231', '10.1109/taslp.2021.3110126', '10.1007/s13042-021-01491-6', '10.1038/s41598-022-26116-y', '10.1007/978-3-030-86890-1_25', '10.1145/3442381.3450029', '10.1007/978-981-19-8300-9_14', '10.1109/ijcnn54540.2023.10191826', '10.1109/tnnls.2021.3070843', '10.3390/app12189027', '10.1109/access.2022.3232493', '10.1007/978-981-19-2456-9_66', '10.1162/coli_a_00415', '10.3390/app12136361', '10.1142/s0218001421590424', '10.1117/12.3004580', '10.1007/s00521-021-06685-1', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00090', '10.3934/mbe.2023494', '10.1007/978-3-031-07472-1_16', '10.1007/s11831-021-09576-9', '10.1016/j.array.2023.100331', '10.1007/s13042-023-01923-5', '10.1371/journal.pone.0281055', '10.1109/dsc50466.2020.00021', '10.1145/3383972.3384052', '10.2196/18417', '10.1007/s00500-024-09629-8', '10.1109/aiiot54504.2022.9817231', '10.2196/preprints.18417', '10.1007/978-981-16-5188-5_2', '10.1007/s10489-021-03002-0', '10.1109/hpcc-dss-smartcity-dependsys53884.2021.00167', '10.1007/978-3-031-20891-1_30', '10.1371/journal.pone.0298974', '10.1007/s10489-021-02667-x', '10.1109/icassp43922.2022.9746958', '10.1109/ccis57298.2022.10016347'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/75QLBHHV/et al. - 2019 - Joint extraction of entities and overlapping relations using position-attentive sequence labeling.pdf","","DONE; PTM:?; GRANULARITY:Sentences; TASK:Endtoendre; LANG:English; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; ARCHI:CRF; TO_EXCLUDE?; DATASET:NYT; ARCHI:LSTM; ARCHI:PositionnalEMbed; DATASET:Wiki-KBP; TOCKECH; TASK:RelationIdentification; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI-2019 2019 7","","","","","","","","","","","","","","",""
"KNDYQZYI","conferencePaper","2019",", Bowen Yu; , Zhen-Yu Zhang; , Tingwen Liu; , Bin Wang; , Sujian Li; , Quangang Li","Beyond Word Attention: Using Segment Attention in Neural Relation Extraction","","","","10.24963/ijcai.2019/750","https://www.ijcai.org/proceedings/2019/0750.pdf","Relation extraction studies the issue of predicting semantic relations between pairs of entities in sentences. Attention mechanisms are often used in this task to alleviate the inner-sentence noise by performing soft selections of words independently. Based on the observation that information pertinent to relations is usually contained within segments (continuous words in a sentence), it is possible to make use of this phenomenon for better extraction. In this paper, we aim to incorporate such segment information into neural relation extractor. Our approach views the attention mechanism as linear-chain conditional random fields over a set of latent variables whose edges encode the desired structure, and regards attention weight as the marginal distribution of each word being selected as a part of the relational expression. Experimental results show that our method can attend to continuous relational expressions without explicit annotations, and achieve the state-of-the-art performance on the large-scale TACRED dataset.","2019-08-10","2023-10-30 16:40:45","2025-01-01 15:35:17","","NA","","","NA","","","SA-LSTM+D","","","","","ACL","","","NA","","https://paperswithcode.com/paper/beyond-word-attention-using-segment-attention","https://github.com/yubowen-ph/segment","","{""TACRED"": {""F1"": ""67.6""}}","{'citing': ['10.1007/978-3-030-47426-3_16', '10.1145/3395046', '10.1145/3395046', '10.1145/3395046', '10.1145/3395046', '10.1145/3442381.3450029', '10.1007/978-3-030-75762-5_33', '10.1007/978-3-030-84529-2_39', '10.1007/978-3-030-92435-5_27', '10.1007/978-981-16-6963-7_85', '10.1109/ijcnn48605.2020.9207021', '10.1109/ijcnn48605.2020.9207132', '10.1109/dsc53577.2021.00017', '10.1109/cscwd54268.2022.9776127', '10.1109/tetci.2021.3136598', '10.1109/access.2020.2995447', '10.1109/aiea53260.2021.00059', '10.1109/tetci.2020.3040444', '10.1109/icassp39728.2021.9414755', '10.1016/j.eswa.2022.118385'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/CUZ7WU5V/et al. - 2019 - Beyond Word Attention Using Segment Attention in Neural Relation Extraction.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Bilstm; LANG:English; DATATYPEPROP:Date; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; PTM:None; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; DATASET:TACRED; ARCHI:CRF; ARCHI:Atttention; INPUT:NER; ARCHI:classifLayer; NBTYPEREL:42; INPUT:POSTAG; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IJCAI-19 2019 8","","","","","","","","","","","","","","",""
"QKYG7TU7","conferencePaper","2019",", Tianyu Gao; , Xu Han; , Ruobing Xie; , Zhiyuan Liu; , Fen Lin; , Leyu Lin; , Maosong Sun","Neural Snowball for Few-Shot Relation Learning","AAAI","","","10.1609/aaai.v34i05.6281","https://arxiv.org/abs/1908.11007v2","Knowledge graphs typically undergo open-ended growth of new relations. This cannot be well handled by relation extraction that focuses on pre-defined relations with sufficient training data. To address new relations with few-shot instances, we propose a novel bootstrapping approach, Neural Snowball, to learn new relations by transferring semantic knowledge about existing relations. More specifically, we use Relational Siamese Networks (RSN) to learn the metric of relational similarities between instances based on existing relations and their labeled data. Afterwards, given a new relation and its few-shot instances, we use RSN to accumulate reliable instances from unlabeled corpora; these instances are used to train a relation classifier, which can further identify new facts of the new relation. The process is conducted iteratively like a snowball. Experiments show that our model can gather high-quality instances for better few-shot relation learning and achieves significant improvement compared to baselines. Codes and datasets are released on https://github.com/thunlp/Neural-Snowball.","2019-08-29","2023-10-30 16:40:45","2025-01-06 08:39:44","","","","","","","","NeuralSnowball","","","","","AAAI","","","NA","","https://paperswithcode.com/paper/neural-snowball-for-few-shot-relation","https://github.com/thunlp/Neural-Snowball","","","{'citing': ['10.1145/3442381.3449870', '10.1145/3447548.3467438', '10.1007/978-3-030-84186-7_21', '10.1145/3459637.3482268', '10.1016/j.jii.2021.100301', '10.1145/3510030', '10.1145/3485447.3511998', '10.1007/s10489-022-03596-z', '10.1109/mlke55170.2022.00057', '10.1109/icassp39728.2021.9413437', '10.1007/s10489-022-03677-z', '10.1109/tcss.2022.3178416'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/2AE6GCFG/et al. - 2019 - Neural Snowball for Few-Shot Relation Learning.pdf","","DONE; GRANULARITY:?; LANG:English; DATASET:Fewrel; LEARNINGMETHOD:Fewshot; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; NBTYPEREL:10¹; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; SOURCE:Wikipedia; LEARNINGMETHOD:Pretraining; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; INPUT:NER; ARCHI:classifLayer; DATATYPEPROP:0; ARCHI:CNN; ARCHI:DistanceFct; ARCHI:SiameseNetwork; PTM:BERT; LEARNINGMETHOD:Snowball; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"CM7CF6JD","conferencePaper","2019",", Abiola Obamuyide; , Andreas Vlachos","Meta-Learning Improves Lifelong Relation Extraction","","","","10.18653/v1/w19-4326","https://aclanthology.org/W19-4326","Most existing relation extraction models assume a fixed set of relations and are unable to adapt to exploit newly available supervision data to extract new relations. In order to alleviate such problems, there is the need to develop approaches that make relation extraction models capable of continuous adaptation and learning. We investigate and present results for such an approach, based on a combination of ideas from lifelong learning and optimization-based meta-learning. We evaluate the proposed approach on two recent lifelong relation extraction benchmarks, and demonstrate that it markedly outperforms current state-of-the-art approaches.","2019-08-01","2023-10-30 16:40:45","2025-03-22 16:52:10","","NA","","","NA","","","","","","","","ACL","","","NA","","https://paperswithcode.com/paper/meta-learning-improves-lifelong-relation","https://github.com/Nithin-Holla/MetaLifelongLanguage","","","{'citing': ['10.1007/978-3-031-33380-4_11', '10.1016/j.neucom.2022.07.079', '10.1007/978-981-16-1964-9_13', '10.1109/taslp.2022.3199655', '10.1145/3510030', '10.1145/3543507.3583548', '10.1007/978-3-030-87571-8_29', '10.1016/j.eswa.2022.117113'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/S4M9FP3A/and - 2019 - Meta-Learning Improves Lifelong Relation Extraction.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Bilstm; LANG:English; DATASET:Fewrel; LOSSUPDATE_BIN:1; INPUT:Embedding; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; PTM:Glove; DATATYPEPROP:0; DATAset:LifelongSimpleQuestions; LEARNINGMETHOD:Metalearning; ARCHI:HierarchicalBilstm; DATASET_CREATED:LifelongFewRel; TASK:RelationClassif; DatasetSplit:Clustering; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WS 2019 8","","","","","","","","","","","","","","",""
"ATQ7XRBI","conferencePaper","2019",", Tsu-Jui Fu; , Peng-Hsuan Li; , Wei-Yun Ma","GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction","","","","10.18653/v1/p19-1136","https://aclanthology.org/P19-1136","In this paper, we present GraphRel, an end-to-end relation extraction model which uses graph convolutional networks (GCNs) to jointly learn named entities and relations. In contrast to previous baselines, we consider the interaction between named entities and relations via a 2nd-phase relation-weighted GCN to better extract relations. Linear and dependency structures are both used to extract both sequential and regional features of the text, and a complete word graph is further utilized to extract implicit features among all word pairs of the text. With the graph-based approach, the prediction for overlapping relations is substantially improved over previous sequential approaches. We evaluate GraphRel on two public datasets: NYT and WebNLG. Results show that GraphRel maintains high precision while increasing recall substantially. Also, GraphRel outperforms previous work by 3.2{\%} and 5.8{\%} (F1 score), achieving a new state-of-the-art for relation extraction.","2019-07-01","2023-10-30 16:40:45","2025-03-22 16:53:01","","NA","","","NA","","","GraphRel","","","","","ACL","","","NA","","https://paperswithcode.com/paper/graphrel-modeling-text-as-relational-graphs","https://github.com/tsujuifu/pytorch_graph-rel","","","{'citing': ['10.1007/978-3-030-82147-0_13', '10.1145/3488560.3498409', '10.1109/ijcnn54540.2023.10191251', '10.1016/j.eswa.2023.122723', '10.1007/978-3-030-71590-8_5', '10.1007/978-3-030-60450-9_22', '10.1007/s00500-022-07370-8', '10.1109/prml59573.2023.10348196', '10.1016/j.asoc.2021.107080', '10.1007/978-981-16-9492-9_302', '10.1145/3508546.3508639', '10.1017/s135132492200033x', '10.1109/tnnls.2021.3126046', '10.1109/mlbdbi58171.2022.00008', '10.1007/978-3-031-40286-9_30', '10.3390/s24010231', '10.3390/electronics11152287', '10.3390/electronics11142161', '10.1109/taai51410.2020.00024', '10.1109/tbdata.2022.3144151', '10.1007/s11227-022-04476-6', '10.1038/s41598-023-29454-7', '10.1109/globecom48099.2022.10001220', '10.1007/978-3-031-44201-8_20', '10.1007/s11063-023-11412-z', '10.1017/9781108924184', '10.1109/cbd54617.2021.00026', '10.1145/3457682.3457765', '10.1109/icaica54878.2022.9844508', '10.1007/s11227-023-05442-6', '10.1109/taslp.2023.3304481', '10.1109/ijcnn55064.2022.9892310', '10.1109/bibm55620.2022.9994978', '10.1007/978-981-99-4752-2_56', '10.1007/s12559-021-09917-7', '10.1007/978-981-19-1742-4_40', '10.1007/978-3-030-89363-7_6', '10.1007/978-981-16-5943-0_10', '10.1049/cit2.12086', '10.1109/icceai55464.2022.00011', '10.3389/fnins.2023.1266771', '10.5715/jnlp.28.965', '10.1109/access.2021.3062231', '10.1155/2021/6631768', '10.1145/3451471.3451506', '10.1109/itaic54216.2022.9836511', '10.1109/iiai-aai59060.2023.00072', '10.3233/jifs-210281', '10.1007/s13042-021-01491-6', '10.1007/s00521-020-05087-z', '10.1007/978-3-030-86890-1_25', '10.1145/3442381.3449895', '10.1109/bigdata50022.2020.9378317', '10.1007/978-981-19-8300-9_14', '10.1007/978-3-031-35415-1_16', '10.1109/ijcnn54540.2023.10191826', '10.1007/s10515-022-00325-1', '10.3390/app12199691', '10.1007/978-3-030-63031-7_14', '10.1145/3459637.3482045', '10.1109/icsp54964.2022.9778528', '10.3390/app12178493', '10.1109/ijcnn54540.2023.10191216', '10.1145/3477495.3531831', '10.3390/app12136361', '10.1017/9781108924184.018', '10.1017/9781108924184.002', '10.1017/9781108924184.004', '10.1017/9781108924184.016', '10.1017/9781108924184.009', '10.1017/9781108924184.013', '10.1017/9781108924184.021', '10.1017/9781108924184.011', '10.1017/9781108924184.017', '10.1017/9781108924184.012', '10.1017/9781108924184.023', '10.1109/access.2020.3034907', '10.1007/978-3-030-72113-8_47', '10.1109/ijcnn52387.2021.9533951', '10.1109/access.2023.3281845', '10.1049/itr2.12398', '10.1117/12.3021506', '10.1162/dint_a_00108', '10.2196/preprints.37804', '10.1109/iccc51575.2020.9344883', '10.1109/taslp.2022.3199655', '10.1109/taslp.2022.3198802', '10.1007/s12650-021-00800-z', '10.1109/ijcnn52387.2021.9534434', '10.1109/imcec51613.2021.9482001', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00090', '10.1109/icpr48806.2021.9413232', '10.1109/access.2023.3299824', '10.1007/s10462-023-10465-9', '10.3934/mbe.2023312', '10.3934/mbe.2023494', '10.1109/wi-iat59888.2023.00023', '10.1007/978-3-031-07472-1_16', '10.1109/iciscae59047.2023.10393780', '10.1007/978-3-031-40289-0_2', '10.1007/s10489-023-04970-1', '10.1007/978-3-031-24755-2_8', '10.1007/978-3-031-18315-7_11', '10.1007/978-3-031-18315-7_5', '10.1007/978-981-19-5391-0_6', '10.1016/j.eswa.2023.121488', '10.1016/j.ipm.2021.102563', '10.1007/s40747-023-01321-y', '10.3390/electronics12163430', '10.1038/s41598-024-51559-w', '10.1109/tkde.2022.3161584', '10.3390/electronics12041013', '10.1371/journal.pone.0281055', '10.1186/s12859-022-05096-w', '10.1145/3639631.3639665', '10.1016/j.eswa.2023.122850', '10.1007/978-3-031-30108-7_18', '10.1109/tcbb.2022.3205113', '10.1109/dsc50466.2020.00021', '10.1007/978-981-19-6142-7_10', '10.1109/icbaie56435.2022.9985852', '10.1117/12.2685546', '10.1007/s11633-022-1323-6', '10.1186/s40494-023-01042-y', '10.1109/iccsnt56096.2022.9972933', '10.5715/jnlp.30.557', '10.1017/s1351324923000050', '10.1007/978-981-99-0105-0_19', '10.1109/icnlp58431.2023.00060', '10.1007/978-3-031-43418-1_17', '10.1109/tnnls.2022.3188569', '10.1109/cscloud-edgecom58631.2023.00070', '10.1109/tcyb.2022.3179020', '10.1109/iaecst57965.2022.10061961', '10.2196/37804', '10.1109/icaice54393.2021.00074', '10.1109/access.2022.3150409', '10.1016/j.eswa.2023.119905', '10.1007/s00500-024-09629-8', '10.1007/s12559-023-10163-2', '10.1145/3539618.3591662', '10.1145/3594409.3594422', '10.1109/itnec56291.2023.10082180', '10.1109/icarcv57592.2022.10004260', '10.1371/journal.pone.0260426', '10.1007/978-3-030-84186-7_29', '10.1007/978-3-030-88480-2_24', '10.1109/aiiot54504.2022.9817231', '10.1007/s00521-023-09336-9', '10.1109/tkde.2023.3289879', '10.3389/fnbot.2022.914705', '10.3389/fnbot.2021.635492', '10.1109/ijcnn48605.2020.9207706', '10.1145/3578741.3578769', '10.1007/s12553-021-00607-w', '10.1016/j.eswa.2022.116538', '10.1007/978-3-031-09076-9_31', '10.1007/978-3-030-75762-5_64', '10.1145/3397271.3401442', '10.1109/iccc54389.2021.9674535', '10.1007/s10489-021-03002-0', '10.1007/s10489-021-02699-3', '10.1109/ijcnn52387.2021.9533950', '10.1007/978-3-031-20865-2_13', '10.1109/prai59366.2023.10331969', '10.1109/tnnls.2021.3138956', '10.1109/bigdata59044.2023.10386115', '10.1371/journal.pone.0298974', '10.1109/access.2020.2980859', '10.1007/978-3-030-53980-1_119', '10.1016/j.neunet.2021.04.010', '10.1016/j.neunet.2021.03.030', '10.1007/s10489-021-02667-x', '10.1007/s10489-021-02596-9', '10.1007/s10489-021-02600-2', '10.1017/9781108924184.006', '10.1017/9781108924184.003', '10.1017/9781108924184.022', '10.1017/9781108924184.005', '10.1017/9781108924184.008', '10.1017/9781108924184.007', '10.1017/9781108924184.015', '10.1017/9781108924184.014', '10.1017/9781108924184.001', '10.1017/9781108924184.019', '10.1017/9781108924184.010', '10.1017/9781108924184.020', '10.1007/978-3-031-22064-7_7', '10.1007/s40747-023-01004-8'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/DJKHCX8W/et al. - 2019 - GraphRel Modeling Text as Relational Graphs for Joint Entity and Relation Extraction.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Bilstm; TASK:Endtoendre; LANG:English; NBTYPEREL:?; USENEGATIVEEXAMPLE_BIN:?; INPUT:Graph; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; INPUT:Embedding; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; TO_EXCLUDE?; DATASET:NYT; PTM:Glove; INPUT:POSTAG; DATASET:WebNLG; ARCHI:GCN; DATATYPEPROP:0; ARCHI:Embedding; ARCHI:POSEmbed; TOCKECH; TASK:RelationIdentification; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2019 7","","","","","","","","","","","","","","",""
"NZ7CIN6S","conferencePaper","2019",", Changzhi Sun; , Yeyun Gong; , Yuanbin Wu; , Ming Gong; , Daxin Jiang; , Man Lan; , Shiliang Sun; , Nan Duan","Joint Type Inference on Entities and Relations via Graph Convolutional Networks","","","","10.18653/v1/p19-1131","https://aclanthology.org/P19-1131","We develop a new paradigm for the task of joint entity relation extraction. It first identifies entity spans, then performs a joint inference on entity types and relation types. To tackle the joint type inference task, we propose a novel graph convolutional network (GCN) running on an entity-relation bipartite graph. By introducing a binary relation classification task, we are able to utilize the structure of entity-relation bipartite graph in a more efficient and interpretable way. Experiments on ACE05 show that our model outperforms existing joint models in entity performance and is competitive with the state-of-the-art in relation performance.","2019-07-01","2023-10-30 16:40:45","2025-01-03 11:14:57","","NA","","","NA","","","GCN","","","","","ACL","","","NA","","https://paperswithcode.com/paper/joint-type-inference-on-entities-and","https://github.com/changzhisun/AntNRE","","[{""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""84.2"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""No"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""biLSTM"", ""metric"": ""Sentence Encoder""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""59.1"", ""metric"": ""RE+ Micro F1""}]","{'citing': ['10.1007/s00500-020-04742-w', '10.1007/978-3-030-63031-7_14', '10.2196/25670', '10.1016/j.neunet.2021.03.030', '10.3389/fnbot.2021.635492', '10.1145/3457682.3457765', '10.2196/preprints.25670', '10.1017/9781108924184.003', '10.1017/9781108924184.005', '10.1017/9781108924184.017', '10.1017/9781108924184.008', '10.1017/9781108924184.009', '10.1017/9781108924184.001', '10.1017/9781108924184.004', '10.1017/9781108924184.011', '10.1017/9781108924184.015', '10.1017/9781108924184.018', '10.1017/9781108924184.023', '10.1017/9781108924184.007', '10.1017/9781108924184.021', '10.1007/978-3-030-82147-0_13', '10.1017/9781108924184.010', '10.1017/9781108924184.019', '10.1017/9781108924184', '10.1017/9781108924184.002', '10.1017/9781108924184.014', '10.1017/9781108924184.020', '10.1017/9781108924184.006', '10.1017/9781108924184.012', '10.1017/9781108924184.016', '10.1017/9781108924184.013', '10.1017/9781108924184.022', '10.1016/j.jbi.2021.103931', '10.1109/access.2021.3140175', '10.1109/access.2020.2980859', '10.1109/access.2021.3086480', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00090', '10.1109/aiiot54504.2022.9817231', '10.1109/bibm47256.2019.8983370', '10.1016/j.knosys.2022.109129', '10.1109/icassp39728.2021.9413673', '10.1109/ijcnn52387.2021.9533402', '10.1109/bigdata52589.2021.9671514', '10.3390/app12178493', '10.1109/itaic54216.2022.9836511', '10.1093/bib/bbac409', '10.1007/978-3-031-20891-1_30'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/HBD864JR/ et al. - 2019 - Joint Type Inference on Entities and Relations via.pdf","","DONE; GRANULARITY:Document; ARCHI:Gcn; ARCHI:Bilstm; LANG:Arabic; LANG:Chinese; LANG:English; DATASET:Ace2005; INPUT:Graph; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; TASK:EndToEndRE; NBTYPEREL:6; ARCHI:classifLayer; PTM:Glove; ARCHI:MLP; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2019 7","","","","","","","","","","","","","","",""
"NRSWMQHJ","conferencePaper","2019",", Christoph Alt; , Marc Hübner; , Leonhard Hennig","Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction","","","","10.18653/v1/p19-1134","https://arxiv.org/abs/1906.08646v1","Distantly supervised relation extraction is widely used to extract relational facts from text, but suffers from noisy labels. Current relation extraction methods try to alleviate the noise by multi-instance learning and by providing supporting linguistic and contextual information to more efficiently guide the relation classification. While achieving state-of-the-art results, we observed these models to be biased towards recognizing a limited set of relations with high precision, while ignoring those in the long tail. To address this gap, we utilize a pre-trained language model, the OpenAI Generative Pre-trained Transformer (GPT) [Radford et al., 2018]. The GPT and similar models have been shown to capture semantic and syntactic features, and also a notable amount of ""common-sense"" knowledge, which we hypothesize are important features for recognizing a more diverse set of relations. By extending the GPT to the distantly supervised setting, and fine-tuning it on the NYT10 dataset, we show that it predicts a larger set of distinct relation types with high confidence. Manual and automated evaluation of our model shows that it achieves a state-of-the-art AUC score of 0.422 on the NYT10 dataset, and performs especially well at higher recall levels.","2019-06-19","2023-10-30 16:40:45","2025-03-22 16:53:07","","NA","","","NA","","","DISTRE","","","","","ACL","","","NA","","https://paperswithcode.com/paper/fine-tuning-pre-trained-transformer-language-1","https://github.com/DFKI-NLP/DISTRE","","","{'citing': ['10.1007/978-3-030-82147-0_3', '10.1145/3503917', '10.1007/978-3-658-31938-0_6', '10.1007/978-981-16-6471-7_4', '10.1007/978-3-030-55130-8_13', '10.1109/icde51399.2021.00280', '10.1142/s0218001423500106', '10.1016/j.neucom.2020.06.070', '10.1109/access.2021.3073428', '10.1007/978-981-99-6207-5_10', '10.1109/icsess47205.2019.9040807', '10.1007/s11431-020-1673-6', '10.1109/taslp.2022.3145320', '10.3390/su13169391', '10.1016/j.knosys.2020.105912', '10.3390/app12178821', '10.1109/mlbdbi51377.2020.00008', '10.1145/3477495.3531876', '10.1109/iccv48922.2021.00334', '10.3390/app12062891', '10.1145/3404835.3463103', '10.1038/s41597-022-01350-1', '10.1007/s10489-023-04964-z', '10.1109/iwcmc48107.2020.9148384', '10.3390/sym15091788', '10.1109/icccs57501.2023.10150972', '10.1007/978-3-030-96623-2_13', '10.1109/dasa54658.2022.9765232', '10.1016/j.eswa.2023.119727', '10.1007/s11280-021-00979-z', '10.5715/jnlp.29.1138', '10.1109/ijcnn54540.2023.10191666', '10.1109/ictai.2019.00040', '10.1007/s00521-023-08795-4', '10.1016/j.eswa.2022.117113', '10.1109/tkde.2022.3177226', '10.1007/s10489-022-03547-8', '10.1109/icse48619.2023.00161', '10.1007/s40747-023-01226-w'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/DUZ464QE/et al. - 2019 - Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction.pdf","","DONE; GRANULARITY:Sentences; PTM:Gpt; LANG:English; SYNTHGENERATION_BIN:?; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Decoder; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; NBTYPEREL:10^1; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; OBJECTPROPERTIES_BIN:0; TO_EXCLUDE?; ARCHI:Transformer; ARCHI:SelectedAttention; DATASET:NYT10; TASK:RelationClassif; TOCKECH; TASK:RelationIdentification; DatasetSplit:TimeSelection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2019 7","","","","","","","","","","","","","","",""
"ER5XSEA9","conferencePaper","2019",", Zhijiang Guo; , Yan Zhang; , Wei Lu","Attention Guided Graph Convolutional Networks for Relation Extraction","","","","10.18653/v1/p19-1024","https://arxiv.org/abs/1906.07510v8","Dependency trees convey rich structural information that is proven useful for extracting relations among entities in text. However, how to effectively make use of relevant information while ignoring irrelevant information from the dependency trees remains a challenging research question. Existing approaches employing rule based hard-pruning strategies for selecting relevant partial dependency structures may not always yield optimal results. In this work, we propose Attention Guided Graph Convolutional Networks (AGGCNs), a novel model which directly takes full dependency trees as inputs. Our model can be understood as a soft-pruning approach that automatically learns how to selectively attend to the relevant sub-structures useful for the relation extraction task. Extensive results on various tasks including cross-sentence n-ary relation extraction and large-scale sentence-level relation extraction show that our model is able to better leverage the structural information of the full dependency trees, giving significantly better results than previous approaches.","2019-06-18","2023-10-30 16:40:49","2025-03-22 16:54:09","","NA","","","NA","","","AGGCN","","","","","ACL","","","NA","","https://paperswithcode.com/paper/attention-guided-graph-convolutional-networks","https://github.com/Cartus/AGGCN_TACRED","","[{""task"": ""Relation Extraction"", ""dataset"": ""TACRED"", ""res"": ""65.1"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""TACRED"", ""res"": ""68.2"", ""metric"": ""F1""}]","{'citing': ['10.1007/978-3-030-82136-4_35', '10.1145/3503917', '10.1145/3340531.3412072', '10.1109/icist49303.2020.9202183', '10.2196/preprints.37817', '10.1016/j.knosys.2022.109471', '10.1016/j.knosys.2022.110107', '10.7717/peerj-cs.1470', '10.1007/978-981-16-6471-7_11', '10.1145/3578741.3578781', '10.1007/s10115-022-01665-w', '10.1007/978-3-030-55130-8_11', '10.1109/ijcnn52387.2021.9534473', '10.1017/s135132492200033x', '10.1186/s13638-021-01936-0', '10.1109/tits.2020.3043250', '10.1007/s10489-022-03677-z', '10.1145/3638762', '10.1016/j.neucom.2021.10.037', '10.1016/j.neucom.2021.10.002', '10.1016/j.neucom.2021.02.098', '10.1109/access.2021.3086480', '10.1007/s11063-022-11101-3', '10.1007/s11063-023-11412-z', '10.1017/9781108924184', '10.1145/3474085.3476968', '10.1145/3485447.3511998', '10.1109/taslp.2023.3254166', '10.1007/s11227-023-05224-0', '10.1109/taslp.2024.3350905', '10.1007/978-3-030-86523-8_35', '10.1007/978-3-030-85896-4_23', '10.2196/preprints.17643', '10.1016/j.jbi.2023.104445', '10.1016/j.jbi.2023.104459', '10.1016/j.jbi.2023.104456', '10.1007/s12559-021-09917-7', '10.1049/cit2.12086', '10.1145/3485447.3512024', '10.1007/978-3-031-17189-5_3', '10.1145/3511808.3557543', '10.3390/info14070365', '10.1109/smc53992.2023.10394492', '10.1007/s40747-022-00742-5', '10.1109/access.2021.3062231', '10.1007/s11431-020-1673-6', '10.1145/3459637.3482440', '10.1109/atc52653.2021.9598337', '10.1109/itaic54216.2022.9836511', '10.1007/978-3-031-30678-5_1', '10.1049/cit2.12166', '10.1016/j.jbi.2021.103968', '10.1016/j.jbi.2021.103874', '10.1109/taslp.2021.3082295', '10.1007/978-3-031-10983-6_9', '10.1007/s11280-023-01142-6', '10.1007/978-3-031-28244-7_38', '10.1007/s42524-023-0273-1', '10.1109/dsc59305.2023.00034', '10.1007/s00521-020-05464-8', '10.1007/s00521-020-05087-z', '10.1109/bigdata50022.2020.9378317', '10.1109/ictai50040.2020.00072', '10.1016/j.mlwa.2022.100444', '10.1109/tnnls.2021.3114378', '10.1109/tnnls.2021.3104971', '10.1109/tnnls.2021.3070843', '10.1093/database/baac070', '10.1109/bigdata55660.2022.10020399', '10.3390/en16083405', '10.1109/tetci.2021.3136598', '10.1109/tetci.2020.3040444', '10.1186/s12859-020-03629-9', '10.1371/journal.pone.0248299', '10.1016/j.jii.2021.100301', '10.1145/3459637.3482268', '10.1016/j.knosys.2023.110428', '10.1109/mlbdbi54094.2021.00140', '10.3390/app12136361', '10.1017/9781108924184.018', '10.1017/9781108924184.002', '10.1017/9781108924184.004', '10.1017/9781108924184.016', '10.1017/9781108924184.009', '10.1017/9781108924184.013', '10.1017/9781108924184.021', '10.1017/9781108924184.011', '10.1109/aiea53260.2021.00059', '10.1017/9781108924184.017', '10.1017/9781108924184.012', '10.1017/9781108924184.023', '10.1007/s12559-023-10110-1', '10.1109/tifs.2023.3301414', '10.1109/tmm.2022.3167309', '10.1109/access.2020.3034907', '10.1007/s12652-022-03791-3', '10.1109/ijcnn52387.2021.9533932', '10.1007/s11356-022-22769-4', '10.1007/978-3-030-88189-4_15', '10.1007/978-3-030-91560-5_25', '10.1145/3529755', '10.2196/preprints.37804', '10.1109/ickg52313.2021.00048', '10.1109/trustcom50675.2020.00083', '10.1109/taslp.2022.3153256', '10.7717/peerj-cs.1856', '10.3390/s22082852', '10.1109/access.2020.3024872', '10.1007/s00521-022-07312-3', '10.1007/s00521-022-07223-3', '10.1007/s00521-021-06667-3', '10.1109/ijcnn52387.2021.9534434', '10.1145/3404835.3463061', '10.2196/preprints.27527', '10.1016/j.ipm.2023.103508', '10.1109/iccwamtip60502.2023.10387128', '10.1007/978-3-031-24755-2_8', '10.1109/tcss.2023.3263056', '10.1007/978-981-99-9864-7_7', '10.1109/dsc53577.2021.00017', '10.1109/icassp43922.2022.9747542', '10.1109/icassp43922.2022.9747486', '10.1007/978-981-19-5391-0_6', '10.1016/j.ipm.2021.102563', '10.3390/electronics12112429', '10.1109/icsai61474.2023.10423340', '10.1109/ieeeconf52377.2022.10013099', '10.1117/12.3014256', '10.1007/978-3-031-16101-8_88', '10.1016/j.datak.2023.102265', '10.1080/17538947.2023.2220610', '10.1007/s11390-022-2420-2', '10.1145/3543507.3583504', '10.1007/s11042-023-15496-6', '10.1007/s00521-022-08051-1', '10.1109/icra48891.2023.10160640', '10.1109/tpami.2021.3083269', '10.1007/s11761-022-00337-5', '10.1109/icme52920.2022.9860020', '10.1145/3534678.3539304', '10.3233/jifs-234202', '10.26599/bdma.2022.9020051', '10.5604/01.3001.0015.2733', '10.1016/j.neunet.2023.03.001', '10.4018/ijdwm.319803', '10.21203/rs.3.rs-2592963/v1', '10.3934/era.2023213', '10.1109/icaiic57133.2023.10067083', '10.1038/s42256-023-00624-6', '10.2196/37817', '10.2196/37804', '10.2196/27527', '10.2196/17643', '10.1109/access.2020.2996642', '10.1109/icebe52470.2021.00028', '10.1007/978-981-19-7596-7_4', '10.1145/3572898', '10.1109/icpr56361.2022.9956376', '10.3233/jifs-237167', '10.1007/s00500-024-09629-8', '10.1109/icicn56848.2022.10006513', '10.1007/978-3-030-88480-2_26', '10.1109/icccbda49378.2020.9095628', '10.1145/3502198', '10.1145/3387633', '10.1109/ijcnn54540.2023.10191841', '10.1109/ijcnn54540.2023.10191909', '10.1109/tkde.2023.3289879', '10.1109/bibm58861.2023.10385642', '10.1145/3340531.3412011', '10.1109/ijcnn48605.2020.9207706', '10.1109/icassp39728.2021.9414755', '10.1007/978-3-031-33054-4_6', '10.1145/3597610', '10.1007/978-3-030-75768-7_30', '10.1109/ijcnn52387.2021.9533296', '10.1007/s10489-022-03573-6', '10.1007/978-3-031-20891-1_30', '10.3390/info13080364', '10.1109/smc53654.2022.9945398', '10.1109/iip57348.2022.00022', '10.1109/tnnls.2021.3138956', '10.1145/3502223.3502245', '10.1109/bibm52615.2021.9669319', '10.1007/s10489-021-02667-x', '10.1017/9781108924184.006', '10.1017/9781108924184.003', '10.1017/9781108924184.022', '10.1017/9781108924184.005', '10.1017/9781108924184.008', '10.1017/9781108924184.007', '10.1017/9781108924184.015', '10.1017/9781108924184.014', '10.1017/9781108924184.001', '10.1017/9781108924184.019', '10.1017/9781108924184.010', '10.1017/9781108924184.020', '10.1007/978-3-030-69023-6_88-1', '10.1371/journal.pone.0297296'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/K5CDKEUW/et al. - 2019 - Attention Guided Graph Convolutional Networks for Relation Extraction.pdf","","EXAMPLE; DONE; GRANULARITY:Document; GRANULARITY:Sentences; ARCHI:Gcn; LANG:English; USENEGATIVEEXAMPLE_BIN:?; DATATYPEPROP:Date; LEARNINGMETHOD:Finetuning; INPUT:Embedding; COSTEVAL_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; DATASET:TACRED; TASK:EndToEndRE; DATASET:SemEval2018; ARCHI:Atttention; ARCHi:DenselyConnectedLayer; ARCHI:linearCombinationLayer; ARCHI:classifLayer; DECODINGMETHOD_BIN:NSP; NBTYPEREL:42; PTM:Glove; TASK:RelationClassif; ARCHI:NodeEmbed; DATASET:N-ARY; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2019 7","","","","","","","","","","","","","","",""
"2V4U5AGM","conferencePaper","2019",", Qiang Ning; , Zhili Feng; , Dan Roth","A Structured Learning Approach to Temporal Relation Extraction","","","","10.18653/v1/d17-1108","https://arxiv.org/abs/1906.04943v1","Identifying temporal relations between events is an essential step towards natural language understanding. However, the temporal relation between two events in a story depends on, and is often dictated by, relations among other events. Consequently, effectively identifying temporal relations between events is a challenging problem even for human annotators. This paper suggests that it is important to take these dependencies into account while learning to identify these relations and proposes a structured learning approach to address this challenge. As a byproduct, this provides a new perspective on handling missing relations, a known issue that hurts existing methods. As we show, the proposed approach results in significant improvements on the two commonly used data sets for this problem.","2019-06-12","2023-10-30 16:40:49","2025-03-22 16:52:05","","NA","","","NA","","","CoDL","","","","","ACL","","","NA","","https://paperswithcode.com/paper/a-structured-learning-approach-to-temporal-1","https://github.com/qiangning/StructTempRel-EMNLP17","","","{'citing': ['10.1109/tkde.2022.3180362', '10.1155/2022/5680971', '10.1007/978-3-031-17120-8_15', '10.1109/ijcnn55064.2022.9892554', '10.1109/taslp.2020.3027201', '10.1007/978-3-031-10983-6_27', '10.1007/978-981-16-1964-9_14', '10.1109/cvpr52729.2023.00247', '10.1007/978-3-031-53468-3_14', '10.1007/s10462-022-10338-7', '10.1145/3543507.3583295', '10.1007/978-3-031-19433-7_37', '10.1109/access.2021.3140175', '10.1007/978-3-030-60259-8_51'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/6QNYZL6J/ et al. - 2019 - A Structured Learning Approach to Temporal Relatio.pdf","","DONE; Granularity:Document; LANG:English; DATATYPEPROP:String; INPUT:Text; LOSSUPDATE_BIN:1; SYNTHGENERATION_BIN:1; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; PTM:None; TASK:NER; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; DATASET:TempEval; DATASET:TimeBank; DATASET:AQUAINT; ARCHI:ILP; ARCHI:StructuredPerceptron; LEARNINGMETHOD:Contraint-drivenLearning; NBTYPEREL:7; DATASET:Workshop; NBDATASET:5; TASK:RelationClassif; DATASET:TempEval3; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2017 9","","","","","","","","","","","","","","",""
"H9HHG4U3","conferencePaper","2019",", Livio Baldini Soares; , Nicholas FitzGerald; , Jeffrey Ling; , Tom Kwiatkowski","Matching the Blanks: Distributional Similarity for Relation Learning","","","","10.18653/v1/p19-1279","https://arxiv.org/abs/1906.03158v1","General purpose relation extractors, which can model arbitrary relations, are a core aspiration in information extraction. Efforts have been made to build general purpose extractors that represent relations with their surface forms, or which jointly embed surface forms with relations from an existing knowledge graph. However, both of these approaches are limited in their ability to generalize. In this paper, we build on extensions of Harris' distributional hypothesis to relations, as well as recent advances in learning text representations (specifically, BERT), to build task agnostic relation representations solely from entity-linked text. We show that these representations significantly outperform previous work on exemplar based relation extraction (FewRel) even without using any of that task's training data. We also show that models initialized with our task agnostic representations, and then tuned on supervised relation extraction datasets, significantly outperform the previous methods on SemEval 2010 Task 8, KBP37, and TACRED.","2019-06-07","2023-10-30 16:40:49","2025-03-22 16:53:11","","NA","","","NA","","","BERTEM+MTB","","","","","ACL","","","NA","","https://paperswithcode.com/paper/matching-the-blanks-distributional-similarity","https://github.com/Soikonomou/bert_new","","[{""task"": ""Relation Extraction"", ""dataset"": ""TACRED"", ""res"": ""64.8"", ""metric"": ""F1 (10% Few-Shot)""}, {""task"": ""Relation Extraction"", ""dataset"": ""TACRED"", ""res"": ""71.5"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""TACRED"", ""res"": ""43.4"", ""metric"": ""F1 (1% Few-Shot)""}, {""task"": ""Relation Extraction"", ""dataset"": ""SemEval-2010 Task 8"", ""res"": ""89.5"", ""metric"": ""F1""}]","{'citing': ['10.1007/978-3-030-82136-4_9', '10.1145/3503917', '10.1109/icist49303.2020.9202183', '10.1109/tcss.2022.3178416', '10.1109/jbhi.2021.3062322', '10.1109/ijcnn54540.2023.10191604', '10.1109/s.a.i.ence50533.2020.9303192', '10.1145/3539618.3591911', '10.1016/j.jksuci.2023.101643', '10.1109/prml59573.2023.10348317', '10.1109/prml59573.2023.10348324', '10.3934/mbe.2022240', '10.1109/icme51207.2021.9428274', '10.1016/j.neucom.2021.12.044', '10.1007/978-3-030-99736-6_5', '10.1109/tbdata.2022.3144151', '10.1142/s0218001423500106', '10.1007/s11063-024-11437-y', '10.1038/s41524-022-00784-w', '10.1145/3474085.3476968', '10.1145/3485447.3511998', '10.1109/taslp.2022.3226680', '10.1109/taslp.2023.3345146', '10.1109/jiot.2021.3093065', '10.1145/3554734', '10.4000/books.aaccademia.11097', '10.1007/978-981-99-6207-5_10', '10.1007/s12559-021-09917-7', '10.1007/s00799-021-00310-1', '10.1145/3453483.3454047', '10.1145/3511808.3557313', '10.1145/3511808.3557251', '10.1109/smc53992.2023.10394492', '10.5715/jnlp.27.211', '10.1109/ictai52525.2021.00191', '10.3390/math10203831', '10.1145/3458754', '10.1016/j.jbi.2021.103931', '10.1016/j.knosys.2020.105912', '10.1007/s11280-023-01142-6', '10.1145/3442442.3451384', '10.1145/3582768.3582794', '10.1109/iccc56324.2022.10065877', '10.1061/jmenea.meeng-5827', '10.1109/tkde.2022.3147455', '10.1109/tkde.2021.3096200', '10.1109/tkde.2019.2953839', '10.1007/978-3-030-93733-1_23', '10.1109/tnnls.2021.3105377', '10.1109/tnnls.2021.3070843', '10.1109/bigdata55660.2022.10021099', '10.1109/tetci.2021.3136598', '10.1109/tetci.2020.3040444', '10.1109/access.2020.3044308', '10.2200/s01078ed2v01y202002hlt049', '10.2200/s01057ed1v01y202009hlt047', '10.1145/3459637.3482280', '10.1145/3514094.3534178', '10.1162/tacl_a_00456', '10.1162/tacl_a_00392', '10.1162/tacl_a_00324', '10.1007/978-981-99-1600-9_9', '10.2139/ssrn.4131177', '10.1109/access.2020.3034907', '10.1016/j.csl.2021.101265', '10.1109/icbk50248.2020.00049', '10.1145/3565291.3565325', '10.1109/bibm52615.2021.9669869', '10.1109/taslp.2022.3199655', '10.1109/taslp.2022.3153256', '10.1145/3583788.3583804', '10.1007/s11633-023-1416-x', '10.2196/preprints.27527', '10.1007/s10462-022-10338-7', '10.1016/j.ins.2023.02.018', '10.1145/3510030', '10.1016/j.aiopen.2021.06.004', '10.2196/preprints.22982', '10.1109/tcad.2021.3121264', '10.1007/978-3-031-18315-7_7', '10.1016/j.ipm.2021.102563', '10.1109/tkde.2023.3240851', '10.1145/3578741.3578755', '10.1007/s00521-023-08704-9', '10.1109/access.2022.3197648', '10.1007/s10489-024-05327-y', '10.1007/s11633-022-1323-6', '10.5715/jnlp.30.304', '10.5715/jnlp.30.557', '10.1016/j.neunet.2023.03.001', '10.1016/j.neucom.2023.126796', '10.2196/27527', '10.1109/access.2022.3159338', '10.1145/3394486.3403244', '10.1007/978-3-031-19433-7_37', '10.1145/3572898', '10.1109/icpr56361.2022.9956376', '10.4018/ijitsa.328681', '10.1134/s1995080223010456', '10.1109/bibm55620.2022.9995416', '10.1109/bibm55620.2022.9995320', '10.1109/itnec56291.2023.10082634', '10.1145/3539618.3591984', '10.1007/978-3-030-84186-7_22', '10.1007/978-3-030-84186-7_13', '10.1145/3447548.3467438', '10.1016/j.jksuci.2022.08.038', '10.1109/ijcnn54540.2023.10191841', '10.1145/3555776.3578592', '10.1109/tkde.2023.3292974', '10.1007/978-981-15-5573-2_4', '10.1007/978-981-15-5573-2_7', '10.1145/3502223.3502237', '10.1007/s11227-022-04875-9', '10.1109/tcsvt.2022.3231437', '10.1109/tcsvt.2023.3284474', '10.1088/1742-6596/1601/3/032029', '10.1007/978-3-030-75768-7_26', '10.1007/s10489-022-03731-w', '10.1007/s10489-022-03596-z', '10.1007/s10489-022-03210-2', '10.1109/icassp49357.2023.10096551', '10.1109/cisp-bmei60920.2023.10373223', '10.1109/tnnls.2021.3138956', '10.1109/smc52423.2021.9658784', '10.1007/s10489-021-02596-9', '10.1109/tits.2021.3113661', '10.1145/3592601'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/N8Q2669M/et al. - 2019 - Matching the Blanks Distributional Similarity for Relation Learning.pdf","","DONE; DATASET:Tacred; GRANULARITY:Sentences; PTM:Bert; LANG:English; DATASET:Fewrel; LEARNINGMETHOD:Fewshot; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; INPUT:Embedding; NBTYPEREL:10¹; ARCHI:Encoder; NBTYPEENTITY:10²; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBDATASET:4; DATASET:TACRED; DATASET:Semeval2010; ARCHI:PositionnalEMbed; INput:NER; TASK:RelationClassif; TOCKECH; DatasetSplit:AnnotatedData","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2019 7","","","","","","","","","","","","","","",""
"92AYPYA8","conferencePaper","2019",", Sijia Liu; , Li-Wei Wang; , Vipin Chaudhary; , Hongfang Liu","Attention Neural Model for Temporal Relation Extraction","","","","10.18653/v1/w19-1917","https://aclanthology.org/W19-1917","Neural network models have shown promise in the temporal relation extraction task. In this paper, we present the attention based neural network model to extract the containment relations within sentences from clinical narratives. The attention mechanism used on top of GRU model outperforms the existing state-of-the-art neural network models on THYME corpus in intra-sentence temporal relation extraction.","2019-06-01","2023-10-30 16:40:49","2025-03-22 16:52:06","","NA","","","NA","","","","","","","","ACL","","","NA","","https://paperswithcode.com/paper/attention-neural-model-for-temporal-relation","https://github.com/onehaitao/Attention-CNN-relation-extraction","","","{'citing': ['10.1016/j.jbi.2023.104403', '10.1007/s00799-021-00310-1', '10.2196/preprints.18287', '10.1016/j.jbi.2022.104052', '10.1016/j.jbi.2021.103915', '10.1109/taslp.2020.3027201', '10.1145/3462475', '10.2196/18287', '10.2139/ssrn.4482481', '10.1007/978-3-031-35176-1_7'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/7ARJB22K/et al. - 2019 - Attention Neural Model for Temporal Relation Extraction.pdf","","DONE; Granularity:Document; LANG:English; ARCHI:Gru; DATATYPEPROP:Date; DATATYPEPROP:String; USENEGATIVEEXAMPLE_BIN:0; INPUT:Embedding; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:NSP; TO_EXCLUDE?; DATASET:TempEval; PTM:Glove; TASK:TemporalRE; DATASET:THYME; ARCHI:LSTM; LEARNINGMETHOD:Fine; ARCHI:PositionnalEMbed; ARCHI:CharacterEmbed; TASK:RelationClassif; TOCKECH; DatasetSplit:AnnotatedData","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WS 2019 6","","","","","","","","","","","","","","",""
"N9TVXVQL","conferencePaper","2019",", Robin Jia; , Cliff Wong; , Hoifung Poon","Document-Level N-ary Relation Extraction with Multiscale Representation Learning","","","","10.18653/v1/n19-1370","https://aclanthology.org/N19-1370","Most information extraction methods focus on binary relations expressed within single sentences. In high-value domains, however, n-ary relations are of great demand (e.g., drug-gene-mutation interactions in precision oncology). Such relations often involve entity mentions that are far apart in the document, yet existing work on cross-sentence relation extraction is generally confined to small text spans (e.g., three consecutive sentences), which severely limits recall. In this paper, we propose a novel multiscale neural architecture for document-level n-ary relation extraction. Our system combines representations learned over various text spans throughout the document and across the subrelation hierarchy. Widening the system{'}s purview to the entire document maximizes potential recall. Moreover, by integrating weak signals across the document, multiscale modeling increases precision, even in the presence of noisy labels from distant supervision. Experiments on biomedical machine reading show that our approach substantially outperforms previous n-ary relation extraction methods.","2019-06-01","2023-10-30 16:40:49","2025-03-22 16:52:56","","NA","","","NA","","","","","","","","ACL","","","NA","","https://paperswithcode.com/paper/document-level-n-ary-relation-extraction-with-1","na","","","{'citing': ['10.1109/ijcnn54540.2023.10191693', '10.1016/j.jksuci.2023.101643', '10.1007/978-3-030-86523-8_35', '10.1007/s00799-021-00306-x', '10.1109/ijcnn55064.2022.9892647', '10.1007/978-3-030-82322-1_5', '10.1007/s00799-023-00392-z', '10.1007/s10032-022-00399-3', '10.1007/978-3-031-33374-3_25', '10.3390/e26030210', '10.1016/j.knosys.2023.110428', '10.3390/app12031599', '10.1007/978-981-99-1600-9_12', '10.1109/access.2020.3034907', '10.1101/2021.07.14.21260440', '10.1007/s00521-022-07223-3', '10.1007/978-3-031-25198-6_9', '10.1109/iccwamtip60502.2023.10387128', '10.1186/s13063-021-05489-x', '10.1109/ialp61005.2023.10337090', '10.26599/bdma.2022.9020051', '10.1007/978-3-031-44198-1_2', '10.1162/coli_a_00462', '10.1109/icpr56361.2022.9956376', '10.1007/s12559-022-10105-4', '10.1016/j.eswa.2022.117678', '10.1038/s41598-019-48391-y', '10.1109/icassp39728.2021.9414755', '10.1145/3597610', '10.1007/978-3-030-75768-7_30', '10.1007/s10489-022-03731-w', '10.1145/3529372.3530922', '10.1145/3502223.3502245'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/GC9PU75T/et al. - 2019 - Document-Level N-ary Relation Extraction with Multiscale Representation Learning.pdf","","DONE; PTM:Word2Vec; GRANULARITY:Document; GRANULARITY:Sentences; ARCHI:Bilstm; TASK:Nlu; LANG:English; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; NBTYPEREL:NSP; TO_EXCLUDE?; INPUT:NER; SOURCE:CKB; SOURCE:GDKD; SOURCE:PMCOA; SOURCE:CIVIC; SOURCE:OncoKB; ARCHI:NER; DATASET_CREATED:CKB; TASK:RelationClassif; TOCKECH; DatasetSplit:BalanceSampling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL 2019 6","","","","","","","","","","","","","","",""
"FBYC5JSX","conferencePaper","2019",", Peng Xu; , Denilson Barbosa","Connecting Language and Knowledge with Heterogeneous Representations for Neural Relation Extraction","","","","10.18653/v1/n19-1323","https://arxiv.org/abs/1903.10126v3","Knowledge Bases (KBs) require constant up-dating to reflect changes to the world they represent. For general purpose KBs, this is often done through Relation Extraction (RE), the task of predicting KB relations expressed in text mentioning entities known to the KB. One way to improve RE is to use KB Embeddings (KBE) for link prediction. However, despite clear connections between RE and KBE, little has been done toward properly unifying these models systematically. We help close the gap with a framework that unifies the learning of RE and KBE models leading to significant improvements over the state-of-the-art in RE. The code is available at https://github.com/billy-inn/HRERE.","2019-03-25","2023-10-30 16:40:49","2025-01-02 09:56:17","","NA","","","NA","","","HRERE","","","","","ACL","","","NA","","https://paperswithcode.com/paper/connecting-language-and-knowledge-with","https://github.com/billy-inn/HRERE","","{""NYT Corpus"": {""P@10%"": ""84.9"", ""P@30%"": ""72.8""}}","{'citing': ['10.1016/j.neunet.2021.03.030', '10.1145/3442381.3449917', '10.1145/3442381.3450040', '10.1145/3404835.3463103', '10.1016/j.jbi.2021.103880', '10.3233/sw-222925', '10.1145/3486622.3494010', '10.1109/bigdata50022.2020.9378317', '10.1145/3477495.3531876'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/3GSDYTY9/and - 2019 - Connecting Language and Knowledge with Heterogeneous Representations for Neural Relation Extraction.pdf","","DONE; DATASET:Nyt; GRANULARITY:Sentences; ARCHI:Bilstm; LANG:English; INPUT:Graph; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; SOURCE:Freebase; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; DATATYPEPROP:NSP; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; NBTYPEREL:NSP; PTM:Glove; ARCHI:Attention; PTM:Complex; TASK:RelationClassif; DatasetSplit:TimeSelection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL 2019 6","","","","","","","","","","","","","","",""
"GY6UA9D3","conferencePaper","2019",", Hong Wang; , Wenhan Xiong; , Mo Yu; , Xiaoxiao Guo; , Shiyu Chang; , William Yang Wang","Sentence Embedding Alignment for Lifelong Relation Extraction","","","","10.18653/v1/n19-1086","http://arxiv.org/abs/1903.02588v3","Conventional approaches to relation extraction usually require a fixed set of pre-defined relations. Such requirement is hard to meet in many real applications, especially when new data and relations are emerging incessantly and it is computationally expensive to store all data and re-train the whole model every time new data and relations come in. We formulate such a challenging problem as lifelong relation extraction and investigate memory-efficient incremental learning methods without catastrophically forgetting knowledge learned from previous tasks. We first investigate a modified version of the stochastic gradient methods with a replay memory, which surprisingly outperforms recent state-of-the-art lifelong learning methods. We further propose to improve this approach to alleviate the forgetting problem by anchoring the sentence embedding space. Specifically, we utilize an explicit alignment model to mitigate the sentence embedding distortion of the learned model when training on new data and new relations. Experiment results on multiple benchmarks show that our proposed method significantly outperforms the state-of-the-art lifelong learning approaches.","2019-03-06","2023-10-30 16:40:49","2025-03-22 16:54:36","","NA","","","NA","","","","","","","","ACL","","","NA","","https://paperswithcode.com/paper/sentence-embedding-alignment-for-lifelong","https://github.com/hongwang600/Lifelong_Relation_Detection","","","{'citing': ['10.1007/978-3-030-60457-8_15', '10.1109/idsta53674.2021.9660801', '10.1109/cvprw56347.2022.00426', '10.1109/iccwamtip60502.2023.10387017', '10.1109/iccwamtip60502.2023.10387141', '10.1109/icse48619.2023.00015', '10.1016/j.knosys.2023.110288', '10.1007/978-981-99-1600-9_9', '10.1109/taslp.2022.3199655', '10.1109/icdm58522.2023.00116', '10.1109/icassp43922.2022.9747708', '10.1002/widm.1526', '10.1007/s10115-023-01889-4', '10.1109/tkde.2023.3267496', '10.1016/j.neunet.2022.08.033', '10.1007/s10489-024-05327-y', '10.1007/s11280-021-00984-2', '10.1109/access.2022.3152842', '10.1007/978-3-030-87571-8_29', '10.1007/978-3-031-30105-6_10', '10.1007/978-3-030-75762-5_18'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/VUQ3G2CW/ et al. - 2019 - Sentence Embedding Alignment for Lifelong Relation.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Bilstm; LANG:English; DATASET:Fewrel; INPUT:Text; LEARNINGMETHOD:Continual; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; PTM:Glove; DATATYPEPROP:0; DATAset:LifelongSimpleQuestions; INPUT:Relation; ARCHI:EpisodicMemoryReplay; TASK:RelationClassif; DatasetSplit:Clustering; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL 2019 6","","","","","","","","","","","","","","",""
"G8PKH7DG","conferencePaper","2019",", Hongtao Lin; , Jun Yan; , Meng Qu; , Xiang Ren","Learning Dual Retrieval Module for Semi-supervised Relation Extraction","WWW '19: The World Wide Web Conference","","","10.1145/3308558.3313573","http://arxiv.org/abs/1902.07814v2","Relation extraction is an important task in structuring content of text data, and becomes especially challenging when learning with weak supervision---where only a limited number of labeled sentences are given and a large number of unlabeled sentences are available. Most existing work exploits unlabeled data based on the ideas of self-training (i.e., bootstrapping a model) and multi-view learning (e.g., ensembling multiple model variants). However, these methods either suffer from the issue of semantic drift, or do not fully capture the problem characteristics of relation extraction. In this paper, we leverage a key insight that retrieving sentences expressing a relation is a dual task of predicting relation label for a given sentence---two tasks are complementary to each other and can be optimized jointly for mutual enhancement. To model this intuition, we propose DualRE, a principled framework that introduces a retrieval module which is jointly trained with the original relation prediction module. In this way, high-quality samples selected by retrieval module from unlabeled data can be used to improve prediction module, and vice versa. Experimental results\footnote{\small Code and data can be found at \url{https://github.com/INK-USC/DualRE}.} on two public datasets as well as case studies demonstrate the effectiveness of the DualRE approach.","2019-02-20","2023-10-30 16:40:49","2025-01-03 14:42:53","","","","","","","","DualRE","","","","","ACM","","","NA","","https://paperswithcode.com/paper/learning-dual-retrieval-module-for-semi","https://github.com/INK-USC/DualRE","","","{'citing': ['10.1145/3395046', '10.1145/3395046', '10.1007/s11431-020-1673-6', '10.1007/978-981-15-8884-6_12', '10.1007/978-3-030-87571-8_29', '10.1109/ijcnn52387.2021.9534434', '10.1109/icde53745.2022.00057', '10.1007/s13278-022-00924-6'], 'cited': ['10.1109/acvmot.2005.107', '10.1109/tpami.2018.2858821', '10.1145/2623330.2623677', '10.1145/279943.279962', '10.1145/3038912.3052708', '10.1145/336597.336644', '10.18653/v1/d15-1174', '10.18653/v1/d15-1203', '10.18653/v1/d17-1004', '10.18653/v1/d17-1186', '10.3115/1220575.1220666', '10.3115/1690219.1690287', '10.3115/v1/p14-5010']}","","/root/snap/zotero-snap/common/Zotero/storage/VXNBMJP5/ et al. - 2019 - Learning Dual Retrieval Module for Semi-supervised.pdf","","DONE; GRANULARITY:Sentences; LANG:English; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; NBDATASET:2; PTM:None; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; DATASET:TACRED; DATASET:Semeval2010; ARCHI:RNN; INPUT:NER; ARCHI:classifLayer; INPUT:POSTAG; ARCHI:CNN; ARCHI:Ranker; ARCHI:LookUp; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WWW","","","","","","","","","","","","","","",""
"QULXPX4A","conferencePaper","2019",", Fenia Christopoulou; , Makoto Miwa; , Sophia Ananiadou","A Walk-based Model on Entity Graphs for Relation Extraction","Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)","","","10.18653/v1/p18-2014","https://arxiv.org/abs/1902.07023v2","We present a novel graph-based neural network model for relation extraction. Our model treats multiple pairs in a sentence simultaneously and considers interactions among them. All the entities in a sentence are placed as nodes in a fully-connected graph structure. The edges are represented with position-aware contexts around the entity pairs. In order to consider different relation paths between two entities, we construct up to l-length walks between each pair. The resulting walks are merged and iteratively used to update the edge representations into longer walks representations. We show that the model achieves performance comparable to the state-of-the-art systems on the ACE 2005 dataset without using any external tools.","2019-02-19","2023-10-30 16:40:49","2024-12-29 12:29:23","","NA","","","NA","","","Walk-based","","","","","ACL","","","NA","","https://paperswithcode.com/paper/a-walk-based-model-on-entity-graphs-for","https://github.com/fenchri/walk-based-re","","[{""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""64.2"", ""metric"": ""Relation classification F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""No"", ""metric"": ""Cross Sentence""}]","{'citing': ['10.1007/s13042-019-00985-8', '10.1093/jamia/ocz101', '10.1007/978-981-15-0118-0_27', '10.1007/978-3-030-22744-9_23', '10.1007/978-3-030-43887-6_6', '10.1145/3331184.3331263', '10.1007/978-3-030-46140-9_26', '10.1007/978-3-030-60239-0_35', '10.1007/978-3-030-63031-7_18', '10.1016/j.neucom.2020.06.070', '10.1007/978-3-030-75765-6_22', '10.3389/fgene.2021.624307', '10.1007/s11704-020-9420-6', '10.2200/s01078ed2v01y202002hlt049', '10.1007/978-3-030-87571-8_28', '10.1007/978-3-030-86523-8_35', '10.1186/s12911-021-01733-1', '10.1186/s12911-021-01733-1', '10.1007/s10115-022-01665-w', '10.1109/icde48307.2020.00093', '10.1109/ijcnn52387.2021.9534434', '10.1109/icmla.2019.00297', '10.1109/cbd54617.2021.00026', '10.1186/s12859-022-04746-3', '10.1109/bibm.2018.8621136', '10.1016/j.knosys.2022.109471', '10.1007/s10115-022-01781-7'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/7QRI5KI8/ et al. - 2019 - A Walk-based Model on Entity Graphs for Relation E.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Bilstm; LANG:Arabic; LANG:Chinese; LANG:English; DATASET:Ace2005; LINEARIZEDGRAPH_BIN:?; LOSSUPDATE_BIN:?; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; OBJECTPROPERTIES_BIN:1; PTM:None; NBDATASET:1; ARCHI:BiLinearClassif; ARCHI:Atttention; NBTYPEREL:6; ARCHI:WalkLayer; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL","","","","","","","","","","","","","","",""
"4YFUNX6J","conferencePaper","2019",", Hao Zhu; , Yankai Lin; , Zhiyuan Liu; , Jie Fu; , Tat-Seng Chua; , Maosong Sun","Graph Neural Networks with Generated Parameters for Relation Extraction","","","","10.18653/v1/p19-1128","http://arxiv.org/abs/1902.00756v1","Recently, progress has been made towards improving relational reasoning in machine learning field. Among existing models, graph neural networks (GNNs) is one of the most effective approaches for multi-hop relational reasoning. In fact, multi-hop relational reasoning is indispensable in many natural language processing tasks such as relation extraction. In this paper, we propose to generate the parameters of graph neural networks (GP-GNNs) according to natural language sentences, which enables GNNs to process relational reasoning on unstructured text inputs. We verify GP-GNNs in relation extraction from text. Experimental results on a human-annotated dataset and two distantly supervised datasets show that our model achieves significant improvements compared to baselines. We also perform a qualitative analysis to demonstrate that our model could discover more accurate relations by multi-hop relational reasoning.","2019-02-02","2023-10-30 16:40:49","2025-03-22 16:54:07","","NA","","","NA","","","GP-GNN","","","","","ACL","","","NA","","https://paperswithcode.com/paper/graph-neural-networks-with-generated","https://github.com/thunlp/gp-gnn","","","{'citing': ['10.1007/s00521-021-05815-z', '10.3390/app122211833', '10.1109/ijcnn54540.2023.10191797', '10.1109/ijcnn54540.2023.10191251', '10.1007/s13278-023-01095-8', '10.1007/s00500-022-07370-8', '10.1186/s13638-021-01936-0', '10.1145/3474198.3478487', '10.1007/s10489-022-03677-z', '10.1109/tbdata.2022.3144151', '10.1017/9781108924184', '10.1145/3442381.3449953', '10.1145/3442381.3449917', '10.1016/j.knosys.2022.109146', '10.1109/ijcnn55064.2022.9892647', '10.3233/jifs-210795', '10.1007/s11431-020-1673-6', '10.1145/3459637.3482403', '10.1109/itaic54216.2022.9836511', '10.1007/s00500-020-04742-w', '10.1007/s00521-020-05087-z', '10.1145/3487553.3524702', '10.1007/978-3-031-35320-8_25', '10.1109/bigdata52589.2021.9671781', '10.3390/app12178493', '10.1109/mlbdbi54094.2021.00140', '10.1017/9781108924184.018', '10.1017/9781108924184.002', '10.1017/9781108924184.004', '10.1017/9781108924184.016', '10.1017/9781108924184.009', '10.1017/9781108924184.013', '10.1017/9781108924184.021', '10.1017/9781108924184.011', '10.1017/9781108924184.017', '10.1017/9781108924184.012', '10.1017/9781108924184.023', '10.1007/978-981-99-1600-9_6', '10.1007/978-981-99-1600-9_9', '10.1007/978-3-030-86549-8_33', '10.1145/3429889.3429900', '10.1109/taslp.2022.3199655', '10.1109/aiiip61647.2023.00026', '10.1145/3404835.3463061', '10.1145/3451964.3451970', '10.3390/electronics12132912', '10.1109/tkde.2021.3101237', '10.1016/j.eswa.2023.121725', '10.1016/j.eswa.2023.122366', '10.1109/access.2022.3169423', '10.1007/s11280-021-00982-4', '10.1007/978-3-031-43421-1_14', '10.1038/s42256-023-00624-6', '10.1109/icassp39728.2021.9413673', '10.1007/978-3-031-19433-7_37', '10.1109/ijcnn54540.2023.10191841', '10.1007/s00521-023-09336-9', '10.1109/access.2021.3140175', '10.1109/ijcnn48605.2020.9207706', '10.1109/itoec49072.2020.9141655', '10.1109/jsen.2022.3176016', '10.1109/access.2020.2980859', '10.1017/9781108924184.006', '10.1017/9781108924184.003', '10.1017/9781108924184.022', '10.1017/9781108924184.005', '10.1017/9781108924184.008', '10.1017/9781108924184.007', '10.1017/9781108924184.015', '10.1017/9781108924184.014', '10.1017/9781108924184.001', '10.1017/9781108924184.019', '10.1017/9781108924184.010', '10.1017/9781108924184.020'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/HFDD8KB6/et al. - 2019 - Graph Neural Networks with Generated Parameters for Relation Extraction.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Bilstm; TASK:Endtoendre; LANG:English; NBTYPEREL:?; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; SOURCE:Wikidata; SOURCE:Wikipedia; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; ARCHI:BiLinearClassif; NBDATASET:3; PTM:Glove; ARCHI:PositionnalEMbed; ARCHI:GNN; ARCHI:MLP; DATASET_CREATED:DistantLabel; DATASET_CREATED:DistantLabelDense; DATASET_CREATED:HumanAnnot; MANUALANNOTATION:1; ARCHI:POSEmbed; ARCHI:NodeEmbed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2019 7","","","","","","","","","","","","","","",""
"74FY7YIR","conferencePaper","2019",", Haoyu Wang; , Ming Tan; , Mo Yu; , Shiyu Chang; , Dakuo Wang; , Kun Xu; , Xiaoxiao Guo; , Saloni Potdar","Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers","","","","10.18653/v1/p19-1132","https://arxiv.org/abs/1902.01030v2","Most approaches to extraction multiple relations from a paragraph require multiple passes over the paragraph. In practice, multiple passes are computationally expensive and this makes difficult to scale to longer paragraphs and larger text corpora. In this work, we focus on the task of multiple relation extraction by encoding the paragraph only once (one-pass). We build our solution on the pre-trained self-attentive (Transformer) models, where we first add a structured prediction layer to handle extraction between multiple entity pairs, then enhance the paragraph embedding to capture multiple relational information associated with each entity with an entity-aware attention technique. We show that our approach is not only scalable but can also perform state-of-the-art on the standard benchmark ACE 2005.","2019-02-04","2023-10-30 16:40:49","2025-03-22 16:52:39","","NA","","","NA","","","Entity-Aware BERT","","","","","ACL","","","NA","","https://paperswithcode.com/paper/extracting-multiple-relations-in-one-pass","https://github.com/helloeve/mre-in-one-pass","","{""SemEval-2010 Task 8"": {""F1"": ""89.0""}}","{'citing': ['10.1007/978-981-16-6471-7_4', '10.1007/s10115-022-01665-w', '10.1016/j.neucom.2021.10.002', '10.1142/s0218001423500106', '10.1007/978-3-031-44201-8_5', '10.1016/j.neucom.2020.06.070', '10.1007/978-3-030-47426-3_52', '10.1109/inista55318.2022.9894216', '10.1007/s00799-021-00313-y', '10.1007/s11431-020-1673-6', '10.1016/j.jbi.2021.103761', '10.1016/j.knosys.2020.106321', '10.1109/ithings-greencom-cpscom-smartdata-cybermatics50389.2020.00094', '10.1016/j.mlwa.2022.100444', '10.1007/978-3-030-93733-1_23', '10.1109/tnnls.2021.3069230', '10.1109/tetci.2021.3136598', '10.1109/tetci.2020.3040444', '10.1371/journal.pone.0248299', '10.1007/978-3-030-63031-7_14', '10.1007/978-3-030-64452-9_1', '10.1007/978-981-99-9864-7_10', '10.1109/access.2022.3186760', '10.1007/s11280-021-00982-4', '10.4018/978-1-6684-6234-8.ch011', '10.1109/ieir56323.2022.10050065', '10.1109/access.2020.2996642', '10.1145/3536220.3558038', '10.1109/bibm55620.2022.9995210', '10.1109/ijcnn54540.2023.10191909', '10.1162/dint_a_00147', '10.1109/ijcnn52387.2021.9533807', '10.1007/978-3-030-65384-2_8', '10.1007/s40747-023-01084-6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/KEETAJPW/et al. - 2019 - Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers.pdf","","DONE; NBDATASET:?; GRANULARITY:Sentences; PTM:Bert; LANG:English; DATASET:Ace2005; DATATYPEPROP:?; NBTYPEREL:?; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; DATASET:Semeval2010; TO_EXCLUDE?; DATASET:SemEval2018; ARCHI:Attention; ARCHI:PositionnalEMbed; TASK:RelationClassif; TOCKECH; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2019 7","","","","","","","","","","","","","","",""
"Y2AJMSR9","conferencePaper","2021",", Chih-Yao Chen; , Cheng-Te Li","ZS-BERT: Towards Zero-Shot Relation Extraction with Attribute Representation Learning","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2021.naacl-main.272","https://arxiv.org/abs/2104.04697v1","While relation extraction is an essential task in knowledge acquisition and representation, and new-generated relations are common in the real world, less effort is made to predict unseen relations that cannot be observed at the training stage. In this paper, we formulate the zero-shot relation extraction problem by incorporating the text description of seen and unseen relations. We propose a novel multi-task learning model, zero-shot BERT (ZS-BERT), to directly predict unseen relations without hand-crafted attribute labeling and multiple pairwise classifications. Given training instances consisting of input sentences and the descriptions of their relations, ZS-BERT learns two functions that project sentences and relation descriptions into an embedding space by jointly minimizing the distances between them and classifying seen relations. By generating the embeddings of unseen relations and new-coming sentences based on such two functions, we use nearest neighbor search to obtain the prediction of unseen relations. Experiments conducted on two well-known datasets exhibit that ZS-BERT can outperform existing methods by at least 13.54\% improvement on F1 score.","2021-04-10","2023-10-30 16:40:49","2025-01-20 10:36:50","","","","","","","","ZS-BERT","","","","","ACL","","","NA","","https://paperswithcode.com/paper/zs-bert-towards-zero-shot-relation-extraction","NA","","","{'citing': ['10.1007/s10489-022-03596-z', '10.1016/j.websem.2022.100757', '10.1016/j.websem.2022.100757', '10.1016/j.websem.2022.100757', '10.1016/j.websem.2022.100757', '10.1007/978-3-031-18315-7_6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/33PMAPSM/and - 2021 - ZS-BERT Towards Zero-Shot Relation Extraction with Attribute Representation Learning.pdf","","DONE; GRANULARITY:Sentences; PTM:Bert; LANG:English; DATASET:Fewrel; DATATYPEPROP:String; INPUT:Text; SYNTHGENERATION_BIN:1; USENEGATIVEEXAMPLE_BIN:0; ARCHI:Encoder; LEARNINGMETHOD:Zeroshot; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; NBTYPEREL:10^1; NBTYPEREL:10^2; LINEARIZEDGRAPH_BIN:0; NBDATASET:3; LEARNINGMETHOD:few-shot learning; OBJECTPROPERTIES_BIN:NSP; INPUT:NER; PTM:SentenceBERT; TASK:RelationClassif; ARCHI:SentenceEmbed; DATASET_CREATED:WIkiKB; DATASET:Wiki-ZSL; INPUT:RelationDescription; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7LH7665P","conferencePaper","2020","Geng, Xiaoqing; Chen, Xiwen; Zhu, Kenny Q.; Shen, Libin; Zhao, Yinggong","MICK: A Meta-Learning Framework for Few-shot Relation Classification with Small Training Data","Proceedings of the 29th ACM International Conference on Information & Knowledge Management","","","10.1145/3340531.3411858","http://arxiv.org/abs/2004.14164","Few-shot relation classification seeks to classify incoming query instances after meeting only few support instances. This ability is gained by training with large amount of in-domain annotated data. In this paper, we tackle an even harder problem by further limiting the amount of data available at training time. We propose a few-shot learning framework for relation classification, which is particularly powerful when the training data is very small. In this framework, models not only strive to classify query instances, but also seek underlying knowledge about the support instances to obtain better instance representations. The framework also includes a method for aggregating cross-domain knowledge into models by open-source task enrichment. Additionally, we construct a brand new dataset: the TinyRel-CM dataset, a few-shot relation classification dataset in health domain with purposely small training data and challenging relation classes. Experimental results demonstrate that our framework brings performance gains for most underlying classification models, outperforms the state-of-the-art results given small training data, and achieves competitive results with sufficiently large training data.","2020-10-19","2023-10-30 16:40:49","2025-03-22 16:54:27","2023-03-06 19:34:20","415-424","","","","","","MICK","","","","","","","","","","https://paperswithcode.com/paper/mick-a-meta-learning-framework-for-few-shot","na","arXiv.org","","{'citing': ['10.1109/access.2021.3066609', '10.1109/taslp.2022.3153254', '10.1007/s11280-023-01184-w', '10.1007/978-3-031-30675-4_54', '10.1016/j.eswa.2022.117113', '10.1007/s10489-022-03210-2'], 'cited': ['10.18653/v1/d18-1223', '10.18653/v1/d18-1514', '10.1007/978-3-642-15939-8_10', '10.18653/v1/d19-1649', '10.18653/v1/p19-1277', '10.3115/1621969.1621986', '10.18653/v1/d17-1189', '10.18653/v1/n16-1065', '10.18653/v1/d15-1206', '10.18653/v1/d15-1203', '10.1109/cvpr.2019.00888', '10.1145/1376616.1376746']}","","/root/snap/zotero-snap/common/Zotero/storage/XG4UKEF8/Geng et al. - 2020 - MICK A Meta-Learning Framework for Few-shot Relat.pdf; /root/snap/zotero-snap/common/Zotero/storage/D6EJAL4T/2004.html","","DONE; GRANULARITY:Sentences; LANG:Chinese; LANG:English; DOMAIN:Medical; DATASET:Fewrel; LEARNINGMETHOD:Fewshot; INPUT:Text; LOSSUPDATE_BIN:1; NBTYPEREL:10¹; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; OBJECTPROPERTIES_BIN:1; NBDATASET:2; NBTYPEREL:10^2; LINEARIZEDGRAPH_BIN:0; INPUT:NER; ARCHI:GNN; LEARNINGMETHOD:Metalearning; PTM:BERT; ARCHI:DataAugmentation; DATASET_CREATED:TinyREL-CM; MANUALANNOTATION:1; TASK:RelationClassif; DatasetSplit:Clustering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQ2Y346N","conferencePaper","2019","Trisedya, Bayu Distiawan; Weikum, Gerhard; Qi, Jianzhong; Zhang, Rui","Neural Relation Extraction for Knowledge Base Enrichment","Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/p19-1023","https://aclanthology.org/P19-1023","We study relation extraction for knowledge base (KB) enrichment. Specifically, we aim to extract entities and their relationships from sentences in the form of triples and map the elements of the extracted triples to an existing KB in an end-to-end manner. Previous studies focus on the extraction itself and rely on Named Entity Disambiguation (NED) to map triples into the KB space. This way, NED errors may cause extraction errors that affect the overall precision and recall.To address this problem, we propose an end-to-end relation extraction model for KB enrichment based on a neural encoder-decoder model. We collect high-quality training data by distant supervision with co-reference resolution and paraphrase detection. We propose an n-gram based attention model that captures multi-word entity names in a sentence. Our model employs jointly learned word and entity embeddings to support named entity disambiguation. Finally, our model uses a modified beam search and a triple classifier to help generate high-quality triples. Our model outperforms state-of-the-art baselines by 15.51% and 8.38% in terms of F1 score on two real-world datasets.","2019-07","2023-10-30 16:40:49","2025-03-22 16:54:04","2023-02-28 16:25:00","229–240","","","","","","","","","","","Association for Computational Linguistics","Florence, Italy","","","","https://paperswithcode.com/paper/neural-relation-extraction-for-knowledge-base","","ACLWeb","","{'citing': ['10.6339/21-jds1012', '10.3233/sw-212838', '10.1109/ijcnn54540.2023.10191459', '10.4218/etrij.2020-0460', '10.1109/tpami.2021.3118703', '10.1109/icccs52626.2021.9449230', '10.1007/s12559-021-09917-7', '10.1007/s00778-022-00747-z', '10.1007/978-3-030-62419-4_17', '10.1109/icde48307.2020.00106', '10.1109/tetci.2021.3136598', '10.1145/3459637.3482268', '10.1007/978-981-33-6981-8_48', '10.54097/ehss.v8i.4287', '10.1109/tkde.2023.3240851', '10.1007/978-981-99-0105-0_19', '10.1109/jas.2023.123540', '10.1109/tkde.2023.3289949', '10.1109/tkde.2023.3271971', '10.1007/978-3-031-11609-4_35', '10.1109/ijcnn52387.2021.9533807', '10.1007/s10489-022-03596-z', '10.1109/jcdl52503.2021.00014', '10.1007/s13748-021-00263-1', '10.1007/s13748-021-00230-w'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/IP7AW9CU/Trisedya et al. - 2019 - Neural Relation Extraction for Knowledge Base Enrichment.pdf","","DONE; GRANULARITY:Sentences; TASK:Endtoendre; LANG:English; INPUT:Graph; DECODINGMETHOD_BIN:1; LEARNINGMETHOD:Finetuning; LINEARIZEDGRAPH_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; ARCHI:Decoder; SOURCE:Wikidata; SOURCE:Wikipedia; NBTYPEENTITY:10¹; COSTEVAL_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; OBJECTPROPERTIES_BIN:1; NBDATASET:2; NBTYPEREL:10^2; ARCHI:LSTM; ARCHI:NgramAttention; PTM:TransE; DATASET_CREATED:GEO; DATASET_CREATED:WikiCIE_Code; ARCHI:ENtityEmbedding; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2019","","","","","","","","","","","","","","",""
"RTB72N8D","conferencePaper","2019","Yao, Yuan; Ye, Deming; Li, Peng; Han, Xu; Lin, Yankai; Liu, Zhenghao; Liu, Zhiyuan; Huang, Lixin; Zhou, Jie; Sun, Maosong","DocRED: A Large-Scale Document-Level Relation Extraction Dataset","Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/P19-1074","https://www.aclweb.org/anthology/P19-1074","Multiple entities in a document generally exhibit complex inter-sentence relations, and cannot be well handled by existing relation extraction (RE) methods that typically focus on extracting intra-sentence relations for single entity pairs. In order to accelerate the research on document-level RE, we introduce DocRED, a new dataset constructed from Wikipedia and Wikidata with three features: (1) DocRED annotates both named entities and relations, and is the largest humanannotated dataset for document-level RE from plain text; (2) DocRED requires reading multiple sentences in a document to extract entities and infer their relations by synthesizing all information of the document; (3) along with the human-annotated data, we also offer large-scale distantly supervised data, which enables DocRED to be adopted for both supervised and weakly supervised scenarios. In order to verify the challenges of documentlevel RE, we implement recent state-of-the-art methods for RE and conduct a thorough evaluation of these methods on DocRED. Empirical results show that DocRED is challenging for existing RE methods, which indicates that document-level RE remains an open problem and requires further efforts. Based on the detailed analysis on the experiments, we discuss multiple promising directions for future research. We make DocRED and the code for our baselines publicly available at https: //github.com/thunlp/DocRED.","2019","2023-10-30 16:40:49","2025-03-22 16:54:34","2023-02-28 16:17:12","764-777","","","","","","DocRED","","","","","ACL","Florence, Italy","en","","","https://paperswithcode.com/paper/docred-a-large-scale-document-level-relation","https://github.com/xwjim/DocRE-Rec","DOI.org (Crossref)","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""44.73"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""36.44"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""50.64"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""51.06"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""43.93"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""43.60"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""50.12"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""42.33"", ""metric"": ""F1""}]","{'citing': ['10.1038/s41467-024-45563-x', '10.1145/3404835.3463070', '10.1016/j.jksuci.2023.101643', '10.1007/s10115-022-01665-w', '10.1109/icme51207.2021.9428274', '10.1109/jsac.2022.3191112', '10.1016/j.neucom.2022.11.064', '10.32604/cmes.2022.020084', '10.1007/978-981-99-9955-2_62', '10.1016/j.eswa.2022.119369', '10.1007/978-3-031-44201-8_5', '10.1109/tai.2022.3205567', '10.1007/978-3-030-47426-3_16', '10.14778/3551793.3551859', '10.1007/978-3-030-86523-8_35', '10.1109/ijcnn55064.2022.9892914', '10.1007/978-3-031-33455-9_20', '10.1016/j.jbi.2023.104487', '10.1016/j.engappai.2023.106212', '10.1007/s12559-021-09917-7', '10.1007/978-3-031-17120-8_13', '10.1007/s10115-022-01781-7', '10.1145/3511808.3557313', '10.1145/3511808.3557615', '10.1109/ijcnn55064.2022.9892647', '10.3390/info14070365', '10.3390/info14030186', '10.1109/bibm58861.2023.10385582', '10.1007/978-3-030-82322-1_5', '10.1007/s11431-020-1673-6', '10.1109/itaic54216.2022.9836511', '10.1007/978-981-99-4402-6_23', '10.1016/j.jbi.2021.103893', '10.1109/taslp.2021.3082295', '10.1007/978-3-031-33374-3_25', '10.1007/978-3-031-28244-7_38', '10.3390/e26030210', '10.1007/s42524-023-0273-1', '10.1145/3340531.3412133', '10.1016/j.jii.2021.100301', '10.1016/j.knosys.2023.110428', '10.1162/tacl_a_00456', '10.1162/tacl_a_00392', '10.3390/app12031599', '10.1007/s12559-023-10110-1', '10.1007/978-981-99-1600-9_9', '10.1007/978-981-99-1600-9_7', '10.1007/978-3-030-86549-8_33', '10.1145/3508546.3508633', '10.2991/978-94-6463-230-9_128', '10.1007/978-3-030-91560-5_25', '10.1162/dint_a_00108', '10.1109/icicta51737.2020.00077', '10.1007/978-981-19-9865-2_3', '10.1007/s00521-022-07223-3', '10.9728/dcs.2023.24.12.3131', '10.1109/icassp49357.2023.10096263', '10.1109/icassp49357.2023.10095437', '10.1109/icassp49357.2023.10095786', '10.1109/iccwamtip60502.2023.10387128', '10.1109/icbk50248.2020.00051', '10.1109/icme52920.2022.9859653', '10.1007/978-981-19-5391-0_6', '10.1016/j.ipm.2021.102563', '10.1109/cscwd57460.2023.10152766', '10.2196/48115', '10.1016/j.jmsy.2023.08.006', '10.1007/s10579-023-09674-z', '10.1109/trustcom56396.2022.00225', '10.1145/3534678.3539304', '10.1145/3534678.3539233', '10.1117/12.2641047', '10.1109/ialp61005.2023.10337090', '10.3233/jifs-234202', '10.1109/iccsnt56096.2022.9972949', '10.26599/bdma.2022.9020051', '10.5715/jnlp.29.1198', '10.5715/jnlp.30.557', '10.1007/978-3-031-40292-0_15', '10.1145/3593013.3593982', '10.1007/978-3-031-41682-8_13', '10.2196/preprints.48115', '10.1007/978-3-031-23190-2_5', '10.1109/ijcnn54540.2023.10191391', '10.1109/vtc2022-fall57202.2022.10012845', '10.1109/access.2020.2996642', '10.1007/978-3-031-19433-7_37', '10.1007/978-3-031-19433-7_3', '10.1145/3572898', '10.1109/icpr56361.2022.9956376', '10.1145/3503161.3548765', '10.3233/jifs-237167', '10.1007/978-3-031-36021-3_29', '10.1145/3539618.3591984', '10.1145/3539618.3591912', '10.1109/jas.2023.123540', '10.1007/978-3-030-88480-2_26', '10.1007/978-3-030-88480-2_6', '10.1016/j.eswa.2022.117678', '10.1007/s00521-023-09336-9', '10.1109/tkde.2023.3292974', '10.1007/978-3-030-79463-7_21', '10.1145/3340531.3412011', '10.1007/978-981-15-5573-2_4', '10.1109/icassp39728.2021.9414755', '10.1007/s11227-022-04875-9', '10.1145/3597610', '10.1007/978-3-030-75765-6_22', '10.1007/978-3-030-75768-7_30', '10.1145/3340531.3412878', '10.1007/s10489-022-03731-w', '10.1109/ictai56018.2022.00188', '10.1109/icse48619.2023.00161', '10.1109/tnnls.2021.3138956', '10.1016/j.neunet.2021.03.030', '10.1145/3502223.3502245', '10.1109/bibm52615.2021.9669319', '10.1007/s10489-021-02596-9', '10.1007/s40747-023-01084-6', '10.1145/3592601'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/E24V9Q4A/Yao et al. - 2019 - DocRED A Large-Scale Document-Level Relation Extr.pdf","","DONE; ARCHI:Cnn; GRANULARITY:Document; ARCHI:Lstm; PTM:Bert; ARCHI:Bilstm; TASK:Endtoendre; LANG:English; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:96; DATASET_CREATED:Docred; DatasetSplit:AnnotatedData","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","","","","","","","","","","","","","","",""
"7TBK3R62","conferencePaper","2019","Zeng, Xiangrong; He, Shizhu; Zeng, Daojian; Liu, Kang; Liu, Shengping; Zhao, Jun","Learning the Extraction Order of Multiple Relational Facts in a Sentence with Reinforcement Learning","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","10.18653/v1/D19-1035","https://aclanthology.org/D19-1035","The multiple relation extraction task tries to extract all relational facts from a sentence. Existing works didn't consider the extraction order of relational facts in a sentence. In this paper we argue that the extraction order is important in this task. To take the extraction order into consideration, we apply the reinforcement learning into a sequence-to-sequence model. The proposed model could generate relational facts freely. Widely conducted experiments on two public datasets demonstrate the efficacy of the proposed method.","2019-11","2023-10-30 16:40:49","2025-01-03 14:48:52","2023-02-28 16:16:28","367–377","","","","","","CopyRRL","","","","","ACL","Hong Kong, China","","","","https://paperswithcode.com/paper/learning-the-extraction-order-of-multiple","na","ACLWeb","","{'citing': ['10.1007/s11431-020-1673-6', '10.1016/j.asoc.2021.107080', '10.1007/978-3-030-73197-7_32', '10.1007/978-3-030-75762-5_64', '10.3233/jifs-210281', '10.1016/j.knosys.2021.106888', '10.1007/s10489-021-02600-2', '10.1145/3459637.3482045', '10.5715/jnlp.28.965', '10.1016/j.asoc.2022.108604', '10.1007/s10489-021-02699-3', '10.1371/journal.pone.0260426', '10.1007/s13042-021-01491-6', '10.1145/3488560.3498409', '10.1007/s10489-021-03002-0', '10.1109/imcec51613.2021.9482001', '10.1007/978-3-031-07472-1_16', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00090', '10.1109/iccc51575.2020.9344883', '10.1109/cscwd54268.2022.9776159', '10.3390/electronics11142161', '10.1109/icsp54964.2022.9778528', '10.1145/3477495.3531831', '10.3390/app12136361', '10.1007/978-3-031-20865-2_13', '10.1109/tbdata.2022.3144151', '10.1109/ijcnn55064.2022.9892140', '10.1109/ijcnn55064.2022.9892310', '10.1007/978-981-19-6142-7_10'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/ETTRG46P/Zeng et al. - 2019 - Learning the Extraction Order of Multiple Relational Facts in a Sentence with Reinforcement Learning.pdf","","DONE; GRANULARITY:Sentences; LANG:English; DATASET:Webnlg; ARCHI:Birnn; ARCHI:Pointernet; LEARNINGMETHOD:Reinforcement; PTM:Characterbert; DATATYPEPROP:String; INPUT:Text; LINEARIZEDGRAPH_BIN:1; LOSSUPDATE_BIN:1; NBTYPEREL:10²; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; NBDATASET:2; OBJECTPROPERTIES_BIN:0; TASK:EndToEndRE; DATASET:NYT; ARCHI:LSTM; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP-IJCNLP 2019","","","","","","","","","","","","","","",""
"LPYM45TZ","conferencePaper","2019","Bosselut, Antoine; Rashkin, Hannah; Sap, Maarten; Malaviya, Chaitanya; Celikyilmaz, Asli; Choi, Yejin","COMET: Commonsense Transformers for Automatic Knowledge Graph Construction","Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/P19-1470","https://www.aclweb.org/anthology/P19-1470","We present the ﬁrst comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET ) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our ﬁndings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.","2019","2023-10-30 16:40:49","2025-03-22 16:52:36","2023-02-28 16:16:13","4762-4779","","","","","","COMET","","","","","ACL","Florence, Italy","en","","","https://paperswithcode.com/paper/comet-commonsense-transformers-for-automatic","https://github.com/atcbosselut/comet-commonsense","DOI.org (Crossref)","","{'citing': ['10.1101/2020.06.26.174482', '10.1016/j.knosys.2022.109861', '10.1016/j.knosys.2022.109488', '10.3389/frai.2022.900943', '10.1109/ijcnn54540.2023.10191699', '10.1109/iccvw60793.2023.00327', '10.1038/s41467-022-29993-z', '10.1007/978-3-030-58558-7_30', '10.1007/s00500-022-07370-8', '10.1016/j.eswa.2019.112965', '10.1109/asiancon51346.2021.9544806', '10.1109/ijcnn52387.2021.9534299', '10.1007/s10115-022-01744-y', '10.1017/s1351324922000407', '10.2139/ssrn.4690824', '10.1146/annurev-linguistics-031120-122924', '10.2196/28858', '10.2196/preprints.28858', '10.1109/cvprw59228.2023.00522', '10.1145/3638760', '10.1007/s11063-022-10831-8', '10.1007/s11063-021-10586-8', '10.1155/2021/5557184', '10.1007/978-3-031-15931-2_3', '10.1145/3477495.3532080', '10.1109/wacv56688.2023.00401', '10.1109/taslp.2023.3254166', '10.1109/taslp.2021.3138721', '10.1016/j.engappai.2023.106723', '10.1007/978-3-031-39847-6_3', '10.1007/978-3-030-86523-8_39', '10.1109/ialp54817.2021.9675160', '10.1109/tdsc.2023.3238408', '10.1007/978-981-99-6207-5_25', '10.1073/pnas.2105646118', '10.1145/3485447.3511937', '10.1145/3511808.3557564', '10.1109/iscc58397.2023.10218135', '10.1111/cgf.14195', '10.1109/taslp.2021.3120601', '10.1109/taslp.2021.3058616', '10.1007/978-3-030-62419-4_26', '10.1007/978-3-031-10983-6_23', '10.1016/j.inffus.2022.11.025', '10.1007/s11280-023-01169-9', '10.1007/978-3-031-28244-7_28', '10.1162/tacl_a_00478', '10.1007/978-3-030-95481-9_3', '10.1145/3479566', '10.1145/3442381.3450141', '10.1109/taffc.2022.3223517', '10.1109/taffc.2022.3232166', '10.1109/ijcnn54540.2023.10191512', '10.1109/iccc56324.2022.10065877', '10.1109/cvpr52729.2023.01044', '10.3389/fpsyt.2023.1148534', '10.1109/access.2023.3339552', '10.1109/access.2024.3365533', '10.48175/ijarsct-15389', '10.1109/tkde.2020.3014166', '10.1080/0952813x.2021.1971777', '10.1109/tnnls.2020.3045034', '10.7210/jrsj.39.391', '10.1007/978-3-030-63031-7_18', '10.1109/access.2023.3298877', '10.1145/3544549.3585699', '10.1109/eki61071.2023.00023', '10.1007/978-3-030-82681-9_15', '10.1007/978-3-030-58592-1_36', '10.1162/tacl_a_00426', '10.1162/tacl_a_00407', '10.1162/tacl_a_00302', '10.1007/978-3-030-50146-4_31', '10.1109/taffc.2020.3038167', '10.4018/978-1-7998-6772-2.ch010', '10.1007/s10462-022-10248-8', '10.1016/j.aei.2022.101680', '10.1007/978-3-030-91669-5_12', '10.1145/3449049', '10.1109/taslp.2022.3202123', '10.1109/taslp.2022.3153256', '10.1109/access.2022.3227714', '10.1109/icdm58522.2023.00094', '10.1007/s11633-023-1416-x', '10.1007/s00521-022-07366-3', '10.1007/s10462-023-10564-7', '10.1007/978-3-031-25198-6_18', '10.1145/3527546.3527568', '10.1109/bigdata59044.2023.10386570', '10.1109/icassp49357.2023.10094672', '10.1016/j.aiopen.2021.08.002', '10.1109/ijcnn52387.2021.9534355', '10.1109/icassp43922.2022.9746464', '10.1007/978-3-031-26390-3_41', '10.1007/s10579-022-09584-6', '10.1016/j.cogsys.2023.101188', '10.1007/978-3-031-33023-0_13', '10.1109/tkde.2022.3206505', '10.1007/978-3-031-36819-6_36', '10.1109/jproc.2023.3279374', '10.1109/codit58514.2023.10284171', '10.29109/gujsc.1145516', '10.1109/icra48891.2023.10161345', '10.1016/j.eswa.2023.122039', '10.1007/978-3-031-30675-4_46', '10.1007/978-3-031-43415-0_29', '10.1007/978-3-031-30108-7_17', '10.1109/bigcomp57234.2023.00061', '10.1109/icmla55696.2022.00166', '10.1007/978-981-16-0479-9_5', '10.1038/s41597-023-01960-3', '10.1109/icme52920.2022.9859679', '10.1155/2022/6257658', '10.1007/s10489-024-05282-8', '10.3233/jifs-232260', '10.1360/ssi-2023-0113', '10.1007/978-3-031-24349-3_6', '10.1145/3543507.3583548', '10.1371/journal.pone.0286049', '10.1016/j.neunet.2023.06.028', '10.1007/978-3-031-40292-0_26', '10.1007/978-3-031-40292-0_31', '10.1007/978-3-031-20503-3_25', '10.1007/978-3-031-20309-1_4', '10.1007/978-3-030-42699-6_1', '10.1145/3603171', '10.1007/s12559-022-10105-4', '10.1007/978-981-99-4761-4_63', '10.1145/3539618.3591973', '10.1109/wacv56688.2023.00121', '10.3389/fpsyg.2023.1124369', '10.1145/3593078.3593933', '10.1007/978-3-031-31414-8_6', '10.1007/978-3-030-88483-3_32', '10.1109/bigdata52589.2021.9672080', '10.1007/978-3-031-19842-7_21', '10.21203/rs.3.rs-2220808/v1', '10.1109/tkde.2023.3289879', '10.1109/acii59096.2023.10388123', '10.1145/3340531.3412011', '10.1007/s13042-023-02066-3', '10.1016/j.eswa.2021.115708', '10.1109/access.2021.3128277', '10.1007/978-3-031-11609-4_38', '10.1145/3360901.3364451', '10.36680/j.itcon.2021.025', '10.1109/ictai56018.2022.00049', '10.1109/tmm.2023.3267295', '10.1016/j.cosrev.2023.100548', '10.1109/medai59581.2023.00011', '10.1007/s10514-023-10099-4'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/WVUUIEUD/Bosselut et al. - 2019 - COMET Commonsense Transformers for Automatic Knowledge Graph Construction.pdf","","DONE; GRANULARITY:Sentences; PTM:Gpt; LANG:English; DATASET:Atomic; USENEGATIVEEXAMPLE_BIN:?; INPUT:Graph; DATATYPEPROP:String; DECODINGMETHOD_BIN:1; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; COSTEVAL_BIN:0; SYNTHGENERATION_BIN:0; NBDATASET:2; DATASET:ConceptNet; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; TASK:EndToEndRE; TO_EXCLUDE?; ARCHI:Transformer; ARCHI:MultiAtttention; NBTYPEREL:34; DATASET_CREATED:COMET; TOCKECH; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","","","","","","","","","","","","","","",""
"Y9QR65F9","conferencePaper","2020","Wei, Zhepei; Su, Jianlin; Wang, Yue; Tian, Yuan; Chang, Yi","A Novel Cascade Binary Tagging Framework for Relational Triple Extraction","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/2020.acl-main.136","https://aclanthology.org/2020.acl-main.136","Extracting relational triples from unstructured text is crucial for large-scale knowledge graph construction. However, few existing works excel in solving the overlapping triple problem where multiple relational triples in the same sentence share the same entities. In this work, we introduce a fresh perspective to revisit the relational triple extraction task and propose a novel cascade binary tagging framework (CasRel) derived from a principled problem formulation. Instead of treating relations as discrete labels as in previous works, our new framework models relations as functions that map subjects to objects in a sentence, which naturally handles the overlapping problem. Experiments show that the CasRel framework already outperforms state-of-the-art methods even when its encoder module uses a randomly initialized BERT encoder, showing the power of the new tagging framework. It enjoys further performance boost when employing a pre-trained BERT encoder, outperforming the strongest baseline by 17.5 and 30.2 absolute gain in F1-score on two public datasets NYT and WebNLG, respectively. In-depth analysis on different scenarios of overlapping triples shows that the method delivers consistent performance gain across all these scenarios. The source code and data are released online.","2020-07","2023-10-30 16:40:49","2025-03-22 16:53:59","2023-02-28 16:15:51","1476–1488","","","","","","CasRel","","","","","ACL","Online","","","","https://paperswithcode.com/paper/a-novel-hierarchical-binary-tagging-framework","https://github.com/prasad4fun/casrel-torch","ACLWeb","[{""task"": ""Relation Extraction"", ""dataset"": ""NYT11-HRL"", ""res"": ""53.9"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""NYT11-HRL"", ""res"": ""51.25"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""WebNLG"", ""res"": ""91.8"", ""metric"": ""F1""}]","{'citing': ['10.1007/978-3-030-82147-0_13', '10.1145/3488560.3498409', '10.4018/ijswis.307908', '10.1007/978-981-99-1428-9_3', '10.1109/ijcnn54540.2023.10191604', '10.1109/ijcnn54540.2023.10191251', '10.1109/ijcnn54540.2023.10191693', '10.1007/978-3-030-60450-9_22', '10.1007/978-3-031-14054-9_17', '10.1109/mlccim55934.2022.00021', '10.1145/3578741.3578781', '10.1109/prml59573.2023.10348196', '10.1016/j.asoc.2021.107080', '10.1007/978-981-16-9492-9_302', '10.3390/electronics11233913', '10.1155/2022/1879483', '10.3389/fdata.2023.1278153', '10.3390/s24010231', '10.3390/electronics11142161', '10.3390/electronics11121810', '10.1007/978-3-031-15931-2_13', '10.1155/2022/2074035', '10.1109/tbdata.2022.3144151', '10.1038/s41598-023-29454-7', '10.3390/app122412736', '10.1007/978-3-031-44201-8_20', '10.1145/3477495.3531784', '10.1007/s11227-023-05442-6', '10.1109/ecnlpir57021.2022.00031', '10.12677/csa.2022.121018', '10.1109/ijcnn55064.2022.9892140', '10.1109/ijcnn55064.2022.9892310', '10.3390/app13074636', '10.1007/978-981-99-6207-5_15', '10.1007/978-981-99-6207-5_11', '10.1016/j.jbi.2023.104456', '10.1007/s12559-021-09917-7', '10.1007/978-981-19-1742-4_40', '10.1007/978-3-030-89363-7_6', '10.1016/j.knosys.2022.109129', '10.1007/978-3-031-17120-8_21', '10.1145/3511808.3557323', '10.1145/3511808.3557189', '10.1109/iccwamtip60502.2023.10387023', '10.1007/s11431-020-1673-6', '10.1016/j.knosys.2021.106888', '10.1007/978-3-031-30678-5_55', '10.1007/978-3-031-54321-0_1', '10.1109/taslp.2021.3110126', '10.1186/s12911-021-01614-7', '10.1007/s13042-021-01491-6', '10.1038/s41598-022-26116-y', '10.1109/access.2023.3279288', '10.1109/bigdata55660.2022.10020362', '10.3390/app13052962', '10.3390/e25081217', '10.1016/j.procs.2021.02.087', '10.1007/978-3-030-86890-1_25', '10.1145/3442381.3450029', '10.1145/3442381.3449895', '10.3390/app122010655', '10.1007/978-3-031-35415-1_16', '10.1109/ijcnn54540.2023.10191826', '10.1007/978-981-99-4749-2_11', '10.1007/978-981-99-4749-2_10', '10.1109/tnnls.2021.3070843', '10.1093/bib/bbac409', '10.1093/bib/bbac342', '10.1109/access.2022.3232493', '10.1145/3459637.3482045', '10.1145/3459637.3482491', '10.1145/3514094.3534178', '10.1016/j.knosys.2023.110550', '10.2478/cait-2023-0014', '10.1109/ijcnn54540.2023.10191216', '10.1145/3477495.3531831', '10.3390/app12136543', '10.3390/app12136361', '10.3390/app12126231', '10.1145/3487553.3524637', '10.1007/978-981-99-4826-0_2', '10.1007/978-981-99-4826-0_8', '10.1007/978-981-99-4826-0_3', '10.1007/978-3-031-06767-9_8', '10.1007/978-3-030-90885-0_9', '10.1109/ahpcai57455.2022.10087617', '10.1049/itr2.12398', '10.1007/978-3-031-34560-9_28', '10.1007/978-3-031-25198-6_18', '10.1007/978-3-031-07472-1_16', '10.1109/iciscae59047.2023.10393780', '10.1038/s41598-023-30355-y', '10.1007/978-3-031-40289-0_2', '10.1007/978-981-99-9864-7_6', '10.1007/978-981-99-9864-7_11', '10.1007/978-981-99-9864-7_12', '10.1007/978-3-030-88361-4_6', '10.1080/10095020.2022.2076619', '10.3390/math11183843', '10.1007/978-981-99-6222-8_20', '10.1007/978-981-99-6222-8_22', '10.1007/s40747-023-01321-y', '10.3390/electronics12163430', '10.3390/electronics12194037', '10.1007/s13042-022-01760-y', '10.1109/iros55552.2023.10342509', '10.3390/electronics12183939', '10.3390/electronics12041013', '10.1109/icbaie56435.2022.9985876', '10.3390/app14051717', '10.1371/journal.pone.0281055', '10.1145/3640912.3640993', '10.3390/app14041334', '10.1016/j.eswa.2023.122007', '10.1016/j.jmsy.2023.08.006', '10.1007/978-3-031-30108-7_18', '10.1109/ialp54817.2021.9675228', '10.1007/978-981-19-6142-7_10', '10.1109/icbaie56435.2022.9985852', '10.1117/12.2685546', '10.1109/ictai56018.2022.00047', '10.4018/ijswis.329965', '10.1186/s40494-023-01042-y', '10.3390/drones7060360', '10.1109/iccsnt56096.2022.9972933', '10.1017/s1351324923000050', '10.1007/978-981-99-0105-0_19', '10.1109/ijcnn54540.2023.10191225', '10.1145/3588911', '10.3390/s23104812', '10.1007/978-3-031-44198-1_20', '10.1007/s12204-022-2474-x', '10.1109/ijcnn54540.2023.10191391', '10.1109/cscloud-edgecom58631.2023.00070', '10.1109/iaecst57965.2022.10061961', '10.1109/aict55583.2022.10013614', '10.1109/icaice54393.2021.00074', '10.1007/978-3-031-19433-7_37', '10.1145/3572898', '10.1016/j.eswa.2023.119905', '10.4018/ijitsa.328681', '10.1109/icsai57119.2022.10005391', '10.1109/bibm55620.2022.9995210', '10.1007/s00500-024-09629-8', '10.1007/s12559-023-10163-2', '10.1145/3579654.3579741', '10.1371/journal.pone.0260426', '10.1007/978-3-030-84186-7_22', '10.1007/978-3-030-88480-2_21', '10.1007/978-3-030-88480-2_24', '10.1007/978-3-030-88483-3_40', '10.1007/978-3-030-88483-3_37', '10.1007/978-3-030-88483-3_28', '10.1109/tkde.2023.3289879', '10.1109/bibm58861.2023.10385477', '10.1109/bibm58861.2023.10385642', '10.3390/app13137585', '10.3390/machines11020271', '10.1109/icassp49357.2023.10096232', '10.1007/978-3-031-09076-9_31', '10.1007/978-3-031-10986-7_7', '10.1007/978-3-030-75762-5_64', '10.1007/978-3-030-75765-6_59', '10.1145/3501409.3501580', '10.1109/tocs53301.2021.9688944', '10.1007/s10489-021-03002-0', '10.1007/s10489-021-02699-3', '10.1109/ijcnn52387.2021.9533950', '10.1007/978-3-031-20865-2_13', '10.3390/info13080364', '10.3390/app13020842', '10.1109/prai59366.2023.10331969', '10.1109/access.2023.3335623', '10.1371/journal.pone.0298974', '10.1145/3502223.3502245', '10.1109/icassp43922.2022.9746958', '10.1007/978-3-031-22064-7_7', '10.1109/ccis57298.2022.10016347', '10.3390/app131910643', '10.1007/s40747-023-01004-8', '10.1007/s40747-023-01084-6', '10.1145/3592601', '10.1016/j.asoc.2022.108604'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/SN95TJR8/Wei et al. - 2020 - A Novel Cascade Binary Tagging Framework for Relational Triple Extraction.pdf","","DONE; GRANULARITY:Document; PTM:Bert; TASK:Endtoendre; LANG:English; DATASET:Webnlg; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; ARCHI:Encoder; ARCHI:Decoder; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBTYPEREL:10^2; LINEARIZEDGRAPH_BIN:0; NBDATASET:3; DATASET:NYT; PTM:Glove; ARCHI:LSTM; ARCHI:PositionnalEMbed; DATASET:Wiki-KBP; ARCHI:CascadeDecoder; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2020","","","","","","","","","","","","","","",""
"MT55IE6L","conferencePaper","2020","Nayak, Tapas; Ng, Hwee Tou","Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction","Proceedings of the AAAI Conference on Artificial Intelligence","","","10.1609/aaai.v34i05.6374","https://ojs.aaai.org/index.php/AAAI/article/view/6374","A relation tuple consists of two entities and the relation between them, and often such tuples are found in unstructured text. There may be multiple relation tuples present in a text and they may share one or both entities among them. Extracting such relation tuples from a sentence is a difficult task and sharing of entities or overlapping entities among the tuples makes it more challenging. Most prior work adopted a pipeline approach where entities were identified first followed by finding the relations among them, thus missing the interaction among the relation tuples in a sentence. In this paper, we propose two approaches to use encoder-decoder architecture for jointly extracting entities and relations. In the first approach, we propose a representation scheme for relation tuples which enables the decoder to generate one word at a time like machine translation models and still finds all the tuples present in a sentence with full entity names of different length and with overlapping entities. Next, we propose a pointer network-based decoding approach where an entire tuple is generated at every time step. Experiments on the publicly available New York Times corpus show that our proposed approaches outperform previous work and achieve significantly higher F1 scores.","2020-04-03","2023-10-30 16:40:49","2025-03-22 16:53:47","2023-02-28 16:12:49","8528-8535","","","34","","","PNDec","","","","","AAAI","","en","Copyright (c) 2020 Association for the Advancement of Artificial Intelligence","","https://paperswithcode.com/paper/effective-modeling-of-encoder-decoder","https://github.com/nusnlp/PtrNetDecoding4JERE","ojs.aaai.org","{""NYT29"": {""F1"": ""67.3""}, ""NYT24"": {""F1"": ""84.4""}}","{'citing': ['10.1145/3503917', '10.1145/3488560.3498409', '10.1109/ijcnn54540.2023.10191604', '10.1007/978-3-031-40286-9_30', '10.32604/iasc.2022.028352', '10.3390/electronics11101535', '10.1038/s41598-023-29454-7', '10.1109/tai.2022.3205567', '10.1016/j.commatsci.2023.112659', '10.1080/09540091.2022.2026295', '10.1007/978-981-99-6207-5_15', '10.1016/j.jbi.2023.104456', '10.1007/s12559-021-09917-7', '10.1016/j.knosys.2022.109129', '10.1109/iccwamtip60502.2023.10387023', '10.1016/j.knosys.2021.107472', '10.1109/tim.2022.3200429', '10.1016/j.jbi.2021.103956', '10.3233/jifs-210281', '10.1109/taslp.2021.3110126', '10.1186/s12911-021-01614-7', '10.1007/s13042-021-01491-6', '10.1038/s41598-022-26116-y', '10.3390/e25081217', '10.1007/978-3-031-35415-1_16', '10.1109/ijcnn54540.2023.10191826', '10.1007/978-3-030-93733-1_23', '10.1109/tnnls.2021.3105377', '10.1145/3487553.3524633', '10.1145/3459637.3482045', '10.3390/app12178493', '10.2478/cait-2023-0014', '10.1145/3477495.3531742', '10.3390/app12136361', '10.1145/3487553.3524637', '10.1162/tacl_a_00515', '10.1109/iceca52323.2021.9675961', '10.1109/access.2023.3281845', '10.3390/electronics13030648', '10.1145/3505243', '10.1109/taslp.2022.3198802', '10.1109/imcec51613.2021.9482001', '10.2139/ssrn.3990659', '10.1080/10095020.2022.2076619', '10.1007/s40747-023-01321-y', '10.1007/s13042-023-01923-5', '10.1109/tkde.2022.3161584', '10.32604/cmc.2022.024819', '10.1109/iccci56745.2023.10128290', '10.1016/j.eswa.2023.122007', '10.1016/j.eswa.2023.122850', '10.1007/978-981-19-6142-7_10', '10.1109/icebe55470.2022.00046', '10.4018/ijswis.329965', '10.1017/s1351324923000050', '10.1016/j.eswa.2023.119905', '10.1109/icsai57119.2022.10005391', '10.1109/bibm55620.2022.9995210', '10.1007/s00500-024-09629-8', '10.1109/aiiot54504.2022.9817231', '10.1109/tkde.2023.3289879', '10.1007/978-981-16-5188-5_2', '10.1007/s10489-021-03002-0', '10.1007/s10489-021-02699-3', '10.1109/ijcnn52387.2021.9533950', '10.1109/prai59366.2023.10331969', '10.1007/s10489-021-02600-2', '10.1109/icassp43922.2022.9746958', '10.1007/s00190-023-01745-x', '10.1007/s40747-023-01004-8'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/TW4YK37X/Nayak and Ng - 2020 - Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction.pdf","","DONE; PTM:Word2Vec; GRANULARITY:Sentences; ARCHI:Bilstm; ARCHI:Encoder-Decoder; LANG:English; ARCHI:Pointernet; USENEGATIVEEXAMPLE_BIN:?; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; INPUT:Embedding; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBDATASET:2; DATATYPEPROP:NSP; LINEARIZEDGRAPH_BIN:0; TASK:EndToEndRE; DATASET:NYT; ARCHI:LSTM; ARCHI:CharacterEmbed; ARCHI:FFN; ARCHI:ATtention; ARCHI:Embedding; ARCHI:RelEmbedding; DATASET:NYT10; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"LY64CWG5","conferencePaper","2020","Zhao, Tianyang; Yan, Zhao; Cao, Yunbo; Li, Zhoujun","Asking Effective and Diverse Questions: A Machine Reading Comprehension based Framework for Joint Entity-Relation Extraction","Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence","978-0-9992411-6-5","","10.24963/ijcai.2020/546","https://www.ijcai.org/proceedings/2020/546","Recent advances cast the entity-relation extraction to a multi-turn question answering (QA) task and provide an effective solution based on the machine reading comprehension (MRC) models. However, they use a single question to characterize the meaning of entities and relations, which is intuitively not enough because of the variety of context semantics. Meanwhile, existing models enumerate all relation types to generate questions, which is inefﬁcient and easily leads to confusing questions. In this paper, we improve the existing MRCbased entity-relation extraction model through diverse question answering. First, a diversity question answering mechanism is introduced to detect entity spans and two answering selection strategies are designed to integrate different answers. Then, we propose to predict a subset of potential relations and ﬁlter out irrelevant ones to generate questions effectively. Finally, entity and relation extractions are integrated in an end-to-end way and optimized through joint learning. Experiment results show that the proposed method signiﬁcantly outperforms baseline models, which improves the relation F1 to 62.1% (+1.9%) on ACE05 and 71.9% (+3.0%) on CoNLL04. Our implementation is available at https://github.com/TanyaZhao/MRC4ERE.","2020-07","2023-10-30 16:40:49","2025-03-22 16:52:41","2023-02-28 16:12:13","3948-3954","","","","","","MRC4ERE++","","","","","IJCAI","Yokohama, Japan","en","","","https://paperswithcode.com/paper/asking-effective-and-diverse-questions-a","https://github.com/TanyaZhao/MRC4ERE","DOI.org (Crossref)","[{""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""85.5"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""62.1"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""BERT base"", ""metric"": ""Sentence Encoder""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""No"", ""metric"": ""Cross Sentence""}]","{'citing': ['10.1145/3508546.3508639', '10.1155/2021/6645871', '10.1145/3469213.3470294', '10.1016/j.eswa.2022.119274', '10.3390/app13063993', '10.1109/taslp.2022.3221009', '10.1109/ijcnn55064.2022.9892140', '10.3390/app13021159', '10.5715/jnlp.28.965', '10.1109/taslp.2021.3138670', '10.3390/e26020162', '10.1145/3442381.3449895', '10.1007/978-3-030-63031-7_14', '10.1145/3459637.3482491', '10.1007/978-981-99-1645-0_19', '10.1016/j.knosys.2022.110228', '10.1007/978-3-031-37717-4_48', '10.1109/icme55011.2023.00101', '10.9728/dcs.2023.24.12.3131', '10.1016/j.eswa.2023.122007', '10.1007/s11633-022-1331-6', '10.1007/s41870-023-01479-1', '10.3390/s23094250', '10.1007/s12559-023-10163-2', '10.1007/978-3-030-86340-1_43', '10.1016/j.asoc.2022.108604'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/5S7C62KV/Zhao et al. - 2020 - Asking Effective and Diverse Questions A Machine Reading Comprehension based Framework for Joint En.pdf","","DONE; GRANULARITY:Document; LANG:Arabic; LANG:Chinese; LANG:English; DATASET:Ace2005; SYNTHGENERATION_BIN:?; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; ARCHI:Encoder; DATASET:Conll; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; OBJECTPROPERTIES_BIN:1; NBDATASET:2; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:10^0; USENEGATIVEEXAMPLE_BIN:NSP; TASK:EndToEndRE; TO_EXCLUDE?; DATATYPEPROP:0; PTM:BERT; TASK:QA; TASK:MRC; INPUT:Questions; Input:Text; ARCHI:ENtityEmbedding; TOCKECH; DatasetSplit:?","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IJCAI","","","","","","","","","","","","","","",""
"S443NCEC","conferencePaper","2021","Dognin, Pierre; Padhi, Inkit; Melnyk, Igor; Das, Payel","ReGen: Reinforcement Learning for Text and Knowledge Base Generation using Pretrained Language Models","Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2021.emnlp-main.83","https://aclanthology.org/2021.emnlp-main.83","Automatic construction of relevant Knowledge Bases (KBs) from text, and generation of semantically meaningful text from KBs are both long-standing goals in Machine Learning. In this paper, we present ReGen, a bidirectional generation of text and graph leveraging Reinforcement Learning (RL) to improve performance. Graph linearization enables us to re-frame both tasks as a sequence to sequence generation problem regardless of the generative direction, which in turn allows the use of Reinforcement Learning for sequence training where the model itself is employed as its own critic leading to Self-Critical Sequence Training (SCST). We present an extensive investigation demonstrating that the use of RL via SCST benefits graph and text generation on WebNLG+ 2020 and TekGen datasets. Our system provides state-of-the-art results on WebNLG+ 2020 by significantly improving upon published results from the WebNLG 2020+ Challenge for both text-to-graph and graph-to-text generation tasks.","2021","2023-10-30 16:40:49","2025-03-22 16:53:55","2023-02-28 16:10:02","1084-1099","","","","","","ReGen","","","","","ACL","Online and Punta Cana, Dominican Republic","en","","","https://paperswithcode.com/paper/regen-reinforcement-learning-for-text-and","","DOI.org (Crossref)","","{'citing': ['10.1007/978-3-031-02447-4_49', '10.1145/3580305.3599502', '10.1109/ijcnn54540.2023.10192007', '10.1145/3639479.3639496', '10.1007/s10844-023-00814-z'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/QKN6VA6F/Dognin et al. - 2021 - ReGen Reinforcement Learning for Text and Knowledge Base Generation using Pretrained Language Model.pdf","","DONE; PTM:T5; GRANULARITY:Sentences; ARCHI:Encoder-Decoder; LANG:English; LEARNINGMETHOD:Reinforcement; INPUT:Graph; DATATYPEPROP:String; LEARNINGMETHOD:Finetuning; LINEARIZEDGRAPH_BIN:1; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; NBDATASET:2; NBTYPEREL:NSP; TASK:EndToEndRE; DATASET:WebNLG; DATASET:TEKGEN; TASK:Graph-To-Text; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing","","","","","","","","","","","","","","",""
"GKYAPMDR","conferencePaper","2021","Huguet Cabot, Pere-Lluís; Navigli, Roberto","REBEL: Relation Extraction By End-to-end Language generation","Findings of the Association for Computational Linguistics: EMNLP 2021","","","10.18653/v1/2021.findings-emnlp.204","https://aclanthology.org/2021.findings-emnlp.204","Extracting relation triplets from raw text is a crucial task in Information Extraction, enabling multiple applications such as populating or validating knowledge bases, factchecking, and other downstream tasks. However, it usually involves multiple-step pipelines that propagate errors or are limited to a small number of relation types. To overcome these issues, we propose the use of autoregressive seq2seq models. Such models have previously been shown to perform well not only in language generation, but also in NLU tasks such as Entity Linking, thanks to their framing as seq2seq tasks. In this paper, we show how Relation Extraction can be simplified by expressing triplets as a sequence of text and we present REBEL, a seq2seq model based on BART that performs end-to-end relation extraction for more than 200 different relation types. We show our model's flexibility by fine-tuning it on an array of Relation Extraction and Relation Classification benchmarks, with it attaining state-of-the-art performance in most of them.","2021-11","2023-10-30 16:40:49","2025-02-05 13:28:42","2023-02-28 16:09:49","2370–2381","","","","","","REBEL","","","","","ACL","Punta Cana, Dominican Republic","","","","https://paperswithcode.com/paper/rebel-relation-extraction-by-end-to-end","https://github.com/Babelscape/rebel","ACLWeb","[{""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""47.1"", ""metric"": ""Relation F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""41.8"", ""metric"": ""Relation F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""Re-TACRED"", ""res"": ""90.4"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""82.2"", ""metric"": ""RE+ Macro F1""}]","{'citing': ['10.1145/3511808.3557323', '10.1007/978-3-031-19433-7_37', '10.1016/j.jksuci.2022.08.038', '10.1093/bib/bbac409'], 'cited': ['10.18653/v1/2021.findings-emnlp.204']}","","/root/snap/zotero-snap/common/Zotero/storage/IZNT6PN3/Huguet Cabot and Navigli - 2021 - REBEL Relation Extraction By End-to-end Language generation.pdf","","DONE; PTM:Roberta; GRANULARITY:Document; GRANULARITY:Sentences; ARCHI:Encoder-Decoder; TASK:Endtoendre; TASK:Nlu; LANG:English; DATASET:Retacred; PTM:Bart; COSTEVAL_BIN:1; DATASET:Ade; DATASET:Docred; DATATYPEPROP:Date; DATATYPEPROP:String; DECODINGMETHOD_BIN:1; INPUT:Text; LEARNINGMETHOD:Finetuning; LINEARIZEDGRAPH_BIN:1; LOSSUPDATE_BIN:1; NBTYPEREL:10²; SYNTHGENERATION_BIN:1; USENEGATIVEEXAMPLE_BIN:0; LEARNINGMETHOD:Pretraining; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; TASK:NER; TASK:EndToEndRE; TO_EXCLUDE?; NBDATASET:5; TOCKECH; DATASET_CREATED:Rebel; DATASET:Nyt-Multi; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings 2021","","","","","","","","","","","","","","",""
"6H97DPTL","conferencePaper","2021","Eberts, Markus; Ulges, Adrian","An End-to-end Model for Entity-level Relation Extraction using Multi-instance Learning","Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume","","","10.18653/v1/2021.eacl-main.319","https://aclanthology.org/2021.eacl-main.319","We present a joint model for entity-level relation extraction from documents. In contrast to other approaches - which focus on local intra-sentence mention pairs and thus require annotations on mention level - our model operates on entity level. To do so, a multi-task approach is followed that builds upon coreference resolution and gathers relevant signals via multi-instance learning with multi-level representations combining global entity and local mention information. We achieve state-of-the-art relation extraction results on the DocRED dataset and report the first entity-level end-to-end relation extraction results for future reference. Finally, our experimental results suggest that a joint approach is on par with task-specific learning, though more efficient due to shared parameters and training steps.","2021-04","2023-10-30 16:40:49","2025-03-22 16:54:16","2023-02-28 16:09:28","3650–3660","","","","","","JEREX","","","","","ACL","Online","","","","https://paperswithcode.com/paper/an-end-to-end-model-for-entity-level-relation","https://github.com/lavis-nlp/jerex","ACLWeb","[{""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""40.38"", ""metric"": ""Relation F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""60.40"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""58.44"", ""metric"": ""Ign F1""}]","{'citing': ['10.1007/s42524-022-0226-0', '10.1016/j.cmpbup.2021.100042', '10.1016/j.knosys.2021.107274', '10.1007/978-3-031-35415-1_16', '10.1016/j.knosys.2023.110428', '10.1007/978-3-031-34560-9_28', '10.1007/s00521-022-07223-3', '10.1109/icassp49357.2023.10095786', '10.1016/j.eswa.2023.120964', '10.26599/bdma.2022.9020051', '10.3390/ai4030039', '10.3233/jifs-237167', '10.1007/978-3-031-36021-3_29', '10.1016/j.eswa.2022.117678', '10.1007/s40747-023-01084-6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/U3HLWDYF/Eberts and Ulges - 2021 - An End-to-end Model for Entity-level Relation Extraction using Multi-instance Learning.pdf","","DONE; Granularity:Document; PTM:Bert; TASK:Coref; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; TASK:NER; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; ARCHI:classifLayer; DATASET:DocRED; ARCHI:FFN; TASK:TypeExtract; TASK:RelationClassif; LANG:english; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EACL 2021","","","","","","","","","","","","","","",""
"5MCP6GCV","conferencePaper","2021","Li, Sha; Ji, Heng; Han, Jiawei","Document-Level Event Argument Extraction by Conditional Generation","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2021.naacl-main.69","https://aclanthology.org/2021.naacl-main.69","","2021","2023-10-30 16:40:49","2025-01-20 15:52:11","2023-02-28 16:08:25","894-908","","","","","","","","","","","ACL","Online","en","","","https://paperswithcode.com/paper/document-level-event-argument-extraction-by","","DOI.org (Crossref)","","{'citing': ['10.1145/3528668', '10.1145/3477495.3531784', '10.1007/978-3-031-17120-8_13', '10.1007/978-3-031-17120-8_25', '10.1007/978-3-031-17120-8_14', '10.1109/taslp.2022.3210442', '10.1109/icist55546.2022.9926951'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/4R46AA5C/Li et al. - 2021 - Document-Level Event Argument Extraction by Conditional Generation.pdf","","DONE; GRANULARITY:Document; ARCHI:Encoder-Decoder; LANG:English; PTM:Bart; TASK:Coref; TASK:Entitytyping; DATATYPEPROP:String; DECODINGMETHOD_BIN:1; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; SYNTHGENERATION_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; LEARNINGMETHOD:Zeroshot; COSTEVAL_BIN:0; NBDATASET:2; NBTYPEREL:NSP; OBJECTPROPERTIES_BIN:0; ARCHI:CRF; PTM:BERT; ARCHI:Embedding; TASK:EventExtraction; DATASET:ACE2005; ARCHI:BRAT; DATASET_CREATED:WIKIEVENTS; DATASET:RAMS; LINEARIZEDGRAPH_BIN:TemplateBased; TASK:AnnotationText; DatasetSplit:AnnotatedData","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","","","","","","","","","","","","",""
"8G5NXZIE","conferencePaper","2022","Lu, Yaojie; Liu, Qing; Dai, Dai; Xiao, Xinyan; Lin, Hongyu; Han, Xianpei; Sun, Le; Wu, Hua","Unified Structure Generation for Universal Information Extraction","Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2022.acl-long.395","https://aclanthology.org/2022.acl-long.395","Information extraction suffers from its varying targets, heterogeneous structures, and demandspeciﬁc schemas. In this paper, we propose a uniﬁed text-to-structure generation framework, namely UIE, which can universally model different IE tasks, adaptively generate targeted structures, and collaboratively learn general IE abilities from different knowledge sources. Speciﬁcally, UIE uniformly encodes different extraction structures via a structured extraction language, adaptively generates target extractions via a schema-based prompt mechanism – structural schema instructor, and captures the common IE abilities via a large-scale pretrained text-to-structure model. Experiments show that UIE achieved the state-of-the-art performance on 4 IE tasks, 13 datasets, and on all supervised, low-resource, and few-shot settings for a wide range of entity, relation, event and sentiment extraction tasks and their uniﬁcation. These results veriﬁed the effectiveness, universality, and transferability of UIE1.","2022","2023-10-30 16:40:49","2025-03-22 16:53:29","2023-02-28 16:07:10","5755-5772","","","","","","UIE","","","","","ACL","Dublin, Ireland","en","","","https://paperswithcode.com/paper/unified-structure-generation-for-universal","https://github.com/universal-ie/UIE","DOI.org (Crossref)","[{""task"": ""Aspect-Based Sentiment Analysis (ABSA)"", ""dataset"": ""ASTE"", ""res"": ""72.86"", ""metric"": ""F1 (R16)""}, {""task"": ""Aspect-Based Sentiment Analysis (ABSA)"", ""dataset"": ""ASTE"", ""res"": ""62.94"", ""metric"": ""F1 (L14)""}, {""task"": ""Aspect-Based Sentiment Analysis (ABSA)"", ""dataset"": ""ASTE"", ""res"": ""64.41"", ""metric"": ""F1 (R15)""}, {""task"": ""Aspect-Based Sentiment Analysis (ABSA)"", ""dataset"": ""ASTE"", ""res"": ""72.55"", ""metric"": ""F1(R14)""}]","{'citing': ['10.3390/electronics11233913', '10.3390/app13158609', '10.3390/app13116680', '10.1109/tbdata.2023.3278977', '10.1007/s11063-024-11515-1', '10.1145/3539618.3591763', '10.1109/icsp58490.2023.10248524', '10.1109/dsc59305.2023.00012', '10.1145/3511808.3557189', '10.1109/bibm58861.2023.10385422', '10.1007/978-3-031-10983-6_10', '10.3390/app13179500', '10.1109/dsc59305.2023.00032', '10.1007/978-981-19-8300-9_18', '10.1007/978-981-19-8300-9_2', '10.1007/978-3-031-35320-8_18', '10.1109/tkde.2023.3303136', '10.1007/978-981-99-4826-0_11', '10.1007/978-981-99-4826-0_9', '10.1007/978-981-99-4826-0_8', '10.1145/3639479.3639484', '10.1109/access.2023.3299880', '10.1145/3607188', '10.1007/978-981-99-9864-7_14', '10.1007/978-3-031-53555-0_25', '10.1007/s40747-023-01321-y', '10.1007/s13042-023-01885-8', '10.1109/tkde.2023.3266495', '10.1109/ijcnn54540.2023.10191308', '10.3390/app14020527', '10.1145/3640912.3640993', '10.1109/icra48891.2023.10160906', '10.1109/tsc.2022.3207273', '10.1016/j.jmsy.2023.08.006', '10.4018/ijswis.327355', '10.1007/978-3-031-40292-0_31', '10.21203/rs.3.rs-2885630/v1', '10.1109/icaiic57133.2023.10067083', '10.1145/3543873.3587305', '10.1109/ijcnn54540.2023.10191495', '10.1109/icde55515.2023.00229', '10.1007/978-981-99-7393-4_54', '10.1007/s40747-023-01226-w', '10.1162/tacl_a_00635'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/837BRE8T/Lu et al. - 2022 - Unified Structure Generation for Universal Information Extraction.pdf","","DONE; PTM:T5; GRANULARITY:Sentences; ARCHI:Encoder-Decoder; LANG:English; DATATYPEPROP:String; INPUT:Text; LINEARIZEDGRAPH_BIN:1; LOSSUPDATE_BIN:1; LEARNINGMETHOD:Promptbased; NBTYPEREL:10¹; USENEGATIVEEXAMPLE_BIN:1; LEARNINGMETHOD:Instruct; SOURCE:Wikidata; LEARNINGMETHOD:Pretraining; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; TASK:NER; NBTYPEREL:10^0; TASK:EndToEndRE; OBJECTPROPERTIES_BIN:NSP; DATASET:ACE2004; DATASET:SciERC; DATASET:CASIE; DATASET:Conll03; DATASET:Conll04; DATASET:ACE2005; DATASET:Semeval2014; DATASET:Semeval2015; DATASET:Semeval2016; NBDATASET:12; SOURCE:ConceptNet; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","","","","","","","","","","","","",""
"EJWXCNCF","conferencePaper","2022","Rossiello, Gaetano; Chowdhury, Md Faisal Mahbub; Mihindukulasooriya, Nandana; Cornec, Owen; Gliozzo, Alfio Massimiliano","KnowGL: Knowledge Generation and Linking from Text","","","","10.1609/aaai.v37i13.27084","http://arxiv.org/abs/2210.13952","We propose KnowGL, a tool that allows converting text into structured relational data represented as a set of ABox assertions compliant with the TBox of a given Knowledge Graph (KG), such as Wikidata. We address this problem as a sequence generation task by leveraging pre-trained sequenceto-sequence language models, e.g. BART. Given a sentence, we ﬁne-tune such models to detect pairs of entity mentions and jointly generate a set of facts consisting of the full set of semantic annotations for a KG, such as entity labels, entity types, and their relationships. To showcase the capabilities of our tool, we build a web application consisting of a set of UI widgets that help users to navigate through the semantic data extracted from a given input text. We make the KnowGL model available at https://huggingface.co/ibm/knowgl-large.","2022-11-22","2023-10-30 16:40:49","2025-03-22 16:53:27","2023-02-28 16:04:58","","","","","","","KnowGL","","","","","ACM","","en","","","https://paperswithcode.com/paper/knowgl-knowledge-generation-and-linking-from","","arXiv.org","","{'citing': ['10.1109/iccp60212.2023.10398658'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/NNBD4QHL/Rossiello et al. - 2022 - KnowGL Knowledge Generation and Linking from Text.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Encoder-Decoder; LANG:English; PTM:Bart; INPUT:Graph; DECODINGMETHOD_BIN:1; LEARNINGMETHOD:Finetuning; LINEARIZEDGRAPH_BIN:1; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; OBJECTPROPERTIES_BIN:1; NBDATASET:2; NBTYPEREL:NSP; TASK:EndToEndRE; DATASET:REBEL; DATASET:TREX; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI-23","","","","","","","","","","","","","","",""
"6934WQ87","conferencePaper","2022","Xie, Xin; Zhang, Ningyu; Li, Zhoubo; Deng, Shumin; Chen, Hui; Xiong, Feiyu; Chen, Mosha; Chen, Huajun","From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer","Companion Proceedings of the Web Conference 2022","","","10.1145/3487553.3524238","http://arxiv.org/abs/2202.02113","Knowledge graph completion aims to address the problem of extending a KG with missing triples. In this paper, we provide an approach GenKGC, which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model. We further introduce relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Experimental results on three datasets show that our approach can obtain better or comparable performance than baselines and achieve faster inference speed compared with previous methods with pre-trained language models. We also release a new large-scale Chinese knowledge graph dataset OpenBG500 for research purpose1.","2022-04-25","2023-10-30 16:40:49","2025-03-22 16:53:22","2023-02-28 16:04:16","162-165","","","","","","GenKGC","","","","","ACM","","en","","","https://paperswithcode.com/paper/from-discrimination-to-generation-knowledge","","arXiv.org","[{""task"": ""Link Prediction"", ""dataset"": ""FB15k-237"", ""res"": ""0.355"", ""metric"": ""Hits@3""}, {""task"": ""Link Prediction"", ""dataset"": ""WN18RR"", ""res"": ""0.403"", ""metric"": ""Hits@3""}, {""task"": ""Link Prediction"", ""dataset"": ""WN18RR"", ""res"": ""0.535"", ""metric"": ""Hits@10""}, {""task"": ""Link Prediction"", ""dataset"": ""FB15k-237"", ""res"": ""0.192"", ""metric"": ""Hits@1""}, {""task"": ""Link Prediction"", ""dataset"": ""WN18RR"", ""res"": ""0.287"", ""metric"": ""Hits@1""}, {""task"": ""Link Prediction"", ""dataset"": ""FB15k-237"", ""res"": ""0.439"", ""metric"": ""Hits@10""}]","{'citing': ['10.3390/math11071624', '10.1142/s2737480723500012', '10.1007/978-981-19-8300-9_22', '10.3390/math11051073', '10.1007/s00521-022-07680-w', '10.1007/978-981-99-5971-6_19', '10.1007/s10489-023-04670-w', '10.1016/j.eswa.2023.119616', '10.1117/12.2685959', '10.1016/j.jmsy.2023.08.006', '10.1016/j.softx.2023.101474', '10.1109/icde55515.2023.00229'], 'cited': ['10.1145/3366423.3380089', '10.1145/3485447.3511921', '10.1145/3442381.3450043', '10.18653/v1/d19-1522', '10.18653/v1/p19-1466', '10.1609/aaai.v32i1.11573', '10.18653/v1/2020.acl-main.617', '10.18653/v1/d15-1174']}","","/root/snap/zotero-snap/common/Zotero/storage/S8VEVPJS/Xie et al. - 2022 - From Discrimination to Generation Knowledge Graph Completion with Generative Transformer.pdf","","star; DONE; GRANULARITY:Sentences; ARCHI:Encoder-Decoder; LANG:Chinese; DATASET:Fb15K-237; PTM:Bart; COSTEVAL_BIN:1; DECODINGMETHOD_BIN:1; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:0; SOURCE:Wikipedia; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBDATASET:2; NBTYPEREL:10^2; DATATYPEPROP:NSP; LINEARIZEDGRAPH_BIN:0; INPUT:TEXT; DATASET:WN18RR; INPUT:relation; INPUT:subject; SOURCE:OpenBG500; TASK:ObjectExtraction; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WWW","","","","","","","","","","","","","","",""
"ZJ3EJMAF","conferencePaper","2019",", Ming Jiang; , Jana Diesner","A Constituency Parsing Tree based Method for Relation Extraction from Abstracts of Scholarly Publications","","","","10.18653/v1/d19-5323","https://aclanthology.org/D19-5323","We present a simple, rule-based method for extracting entity networks from the abstracts of scientific literature. By taking advantage of selected syntactic features of constituent parsing trees, our method automatically extracts and constructs graphs in which nodes represent text-based entities (in this case, noun phrases) and their relationships (in this case, verb phrases or preposition phrases). We use two benchmark datasets for evaluation and compare with previously presented results for these data. Our evaluation results show that the proposed method leads to accuracy rates that are comparable to or exceed the results achieved with state-of-the-art, learning-based methods in several cases.","2019-11-01","2023-10-30 16:40:45","2024-12-29 12:23:03","","NA","","","NA","","","CTN","","","","","ACL","","","NA","","https://paperswithcode.com/paper/a-constituency-parsing-tree-based-method-for","na","","","{'citing': ['10.1002/pra2.303', '10.1007/978-3-030-64452-9_1', '10.1007/978-3-030-86362-3_16', '10.1007/978-3-030-85928-2_19', '10.1007/s00799-021-00313-y', '10.1109/rivf51545.2021.9642143'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/44PSU2PT/ and  - 2019 - A Constituency Parsing Tree based Method for Relat.pdf","","DONE; Granularity:Document; ARCHI:Rulesystem; LANG:English; DATASET:Scierc; INPUT:Text; USENEGATIVEEXAMPLE_BIN:0; NBTYPEREL:10³; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; NBDATASET:2; PTM:None; TASK:NER; ARCHI:Pipeline; OBJECTPROPERTIES_BIN:0; DATASET:SemEval2018; INPUT:ConsistencyParsing; LEARNINGMETHOD:None; DATATYPEPROP:Str; LINEARIZEDGRAPH_BIN:None; ARCHI:EntityMapping; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WS 2019 11","","","","","","","","","","","","","","",""
"2FQRJ3CJ","conferencePaper","2020","Yuan, Yue; Zhou, Xiaofei; Pan, Shirui; Zhu, Qiannan; Song, Zeliang; Guo, Li","A Relation-Specific Attention Network for Joint Entity and Relation Extraction","","","","10.24963/ijcai.2020/561","https://www.ijcai.org/proceedings/2020/561","Electronic proceedings of IJCAI 2020","2020-07-09","2023-10-30 16:40:49","2025-03-22 16:52:52","2023-02-28 16:13:02","4054-4060","","","4","","","RSAN","","","","","ACL","","en","","","https://paperswithcode.com/paper/a-relation-specific-attention-network-for","https://github.com/Anery/RSAN","www.ijcai.org","{""NYT"": {""F1"": ""84.6""}, ""WebNLG"": {""F1"": ""82.1""}}","{'citing': ['10.1145/3488560.3498409', '10.1145/3404835.3463070', '10.1109/mlccim55934.2022.00021', '10.1109/prml59573.2023.10348196', '10.1007/978-981-16-9492-9_302', '10.1016/j.ins.2021.09.028', '10.1007/978-3-031-44201-8_20', '10.1016/j.cogr.2022.11.001', '10.3390/app13074636', '10.1007/s12559-021-09917-7', '10.1007/978-3-030-89363-7_6', '10.1109/icceai55464.2022.00011', '10.3390/app131810538', '10.1016/j.knosys.2021.107677', '10.1109/tim.2022.3200429', '10.3390/app13074447', '10.3390/e26020162', '10.1007/978-3-030-86890-1_25', '10.1145/3442381.3449895', '10.1093/bib/bbac409', '10.1109/access.2022.3232493', '10.1145/3459637.3482045', '10.1016/j.knosys.2023.110550', '10.1145/3477495.3531831', '10.1007/978-3-031-34560-9_28', '10.1007/978-981-99-5971-6_2', '10.1109/imcec51613.2021.9482001', '10.1007/978-3-031-40289-0_2', '10.1007/s40747-023-01321-y', '10.1007/s13042-023-01923-5', '10.1016/j.eswa.2023.122007', '10.4018/ijswis.329965', '10.1109/iccsnt56096.2022.9972933', '10.1017/s1351324923000050', '10.1007/978-981-99-1075-5_3', '10.1109/icsai57119.2022.10005391', '10.1007/s00500-024-09629-8', '10.1007/s12559-023-10163-2', '10.1109/aiiot54504.2022.9817231', '10.1007/s43674-023-00063-1', '10.1007/978-3-031-10986-7_7', '10.1007/s10489-021-02699-3', '10.1109/ijcnn52387.2021.9533950', '10.1007/978-3-031-20865-2_13', '10.1007/978-3-031-20865-2_22', '10.1007/s10489-021-02600-2'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/N2H9CLK5/Yuan et al. - 2020 - A Relation-Specific Attention Network for Joint Entity and Relation Extraction.pdf","","DONE; ARCHI:Cnn; DATASET:Nyt; GRANULARITY:Sentences; NBDATASET:10°; ARCHI:Bilstm; TASK:Endtoendre; LANG:English; DATASET:Webnlg; DATATYPEPROP:String; DECODINGMETHOD_BIN:1; INPUT:Text; LEARNINGMETHOD:Finetuning; LINEARIZEDGRAPH_BIN:1; LOSSUPDATE_BIN:1; NBTYPEREL:10²; INPUT:Embedding; NBTYPEREL:10¹; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; SYNTHGENERATION_BIN:0; PTM:None; TO_EXCLUDE?; OBJECTPROPERTIES_BIN:NSP; ARCHI:Attention; DATASET:WebNLG; ARCHI:GateMechanism; ARCHI:RelEmbedding; TOCKECH; TASK:RelationIdentification; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Twenty-Ninth International Joint Conference on Artificial Intelligence","","","","","","","","","","","","","","",""
"AHPVM69F","conferencePaper","2022","Ma, Yubo; Wang, Zehao; Cao, Yixin; Li, Mukai; Chen, Meiqi; Wang, Kun; Shao, Jing","Prompt for Extraction? PAIE: Prompting Argument Interaction for Event Argument Extraction","Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2022.acl-long.466","https://aclanthology.org/2022.acl-long.466","In this paper, we propose an effective yet efficient model PAIE for both sentence-level and document-level Event Argument Extraction (EAE), which also generalizes well when there is a lack of training data. On the one hand, PAIE utilizes prompt tuning for extractive objectives to take the best advantages of Pre-trained Language Models (PLMs). It introduces two span selectors based on the prompt to select start/end tokens among input texts for each role. On the other hand, it captures argument interactions via multi-role prompts and conducts joint optimization with optimal span assignments via a bipartite matching loss. Also, with a flexible prompt design, PAIE can extract multiple arguments with the same role instead of conventional heuristic threshold tuning. We have conducted extensive experiments on three benchmarks, including both sentenceand document-level EAE. The results present promising improvements from PAIE (3.5% and 2.3% F1 gains in average on three benchmarks, for PAIE-base and PAIE-large respectively). Further analysis demonstrates the efficiency, generalization to few-shot settings, and effectiveness of different extractive prompt tuning strategies. Our code is available at https: //github.com/mayubo2333/PAIE.","2022","2023-10-30 16:40:49","2025-03-22 16:52:44","2023-02-28 16:06:35","6759-6774","","","","","","PAIE","","","","","Association for Computational Linguistics","Dublin, Ireland","en","","","https://paperswithcode.com/paper/prompt-for-extraction-paie-prompting-argument","","DOI.org (Crossref)","","{'citing': ['10.3390/app13053041', '10.1007/978-981-99-6207-5_11', '10.1109/bigdata59044.2023.10386217', '10.1109/ijcnn54540.2023.10191308', '10.1007/978-3-031-30675-4_39', '10.1109/medai59581.2023.00048', '10.1109/ijcnn54540.2023.10191495'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/NYQ7ZTT3/Ma et al. - 2022 - Prompt for Extraction PAIE Prompting Argument Interaction for Event Argument Extraction.pdf","","star; DONE; GRANULARITY:Document; GRANULARITY:Sentences; ARCHI:Encoder-Decoder; LANG:English; DATASET:Ace2005; PTM:Bart; COSTEVAL_BIN:1; DATATYPEPROP:String; DECODINGMETHOD_BIN:1; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; LEARNINGMETHOD:Promptbased; DATASET:Rams; DATASET:Wiki-Events; INPUT:Indexedspan; LEARNINGMETHOD:Promptuning; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; NBDATASET:3; TO_EXCLUDE?; INPUT:NER; TASK:RelationClassif; TOCKECH; TASK:RelationIdentification; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","","","","","","","","","","","","",""
"4GUBUIMT","conferencePaper","2021",", Chenhao Xie 0002; , Jiaqing Liang; , Jingping Liu; , Chengsong Huang; , Wenhao Huang; , Yanghua Xiao","Revisiting the Negative Data of Distantly Supervised Relation Extraction.","","","","10.18653/V1/2021.ACL-LONG.277","https://dblp.org/rec/journals/corr/abs-2105-10158","nan","2021","2024-04-11 17:32:24","2025-03-22 16:52:13","","3572-3581","","","nan","","","ReRe","","","","","nan","","","open","","https://paperswithcode.com/paper/revisiting-the-negative-data-of-distantly","https://github.com/redreamality/RERE-relation-extraction","","[{""task"": ""Relation Extraction"", ""dataset"": ""NYT10-HRL"", ""res"": ""73.4"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""NYT10-HRL"", ""res"": ""64.4"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""NYT11-HRL"", ""res"": ""56.23"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""NYT10-HRL"", ""res"": ""72.45"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""NYT10-HRL"", ""res"": ""71.93"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""NYT10-HRL"", ""res"": ""70.11"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""NYT11-HRL"", ""res"": ""53.8"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""NYT10-HRL"", ""res"": ""73.95"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""NYT11-HRL"", ""res"": ""55.47"", ""metric"": ""F1""}]","{'citing': ['10.3390/app13021159', '10.1145/3459637.3482491', '10.1109/icsp54964.2022.9778528', '10.1007/978-3-031-37717-4_48', '10.1007/978-3-031-40283-8_27', '10.1007/978-3-031-10986-7_7', '10.3390/app131910643'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/S2V8HZGP/et al. - 2021 - Revisiting the Negative Data of Distantly Supervised Relation Extraction..pdf","","DONE; PTM:Roberta; GRANULARITY:Sentences; LANG:Chinese; LANG:English; LEARNINGMETHOD:?; DATATYPEPROP:String; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; SOURCE:Wikidata; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; TASK:NER; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:NSP; NBDATASET:4; DATASET:NYT; OBJECTPROPERTIES_BIN:NSP; ARCHI:LSTM; PTM:BERT; DATASET:NYT10; TASK:RelationClassif; DATSET:NYT11; DATSET:SKE19; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL/IJCNLP","","","","","","","","","","","","","","",""
"GTSZHKSK","conferencePaper","2022",", Hieu Man; , Nghia Trung Ngo; , Linh Ngo Van 0001; , Thien Huu Nguyen","Selecting Optimal Context Sentences for Event-Event Relation Extraction.","","","","10.1609/AAAI.V36I10.21354","https://dblp.org/rec/conf/aaai/ManNVN22","nan","2022","2024-04-11 17:32:22","2025-03-22 16:52:31","","11058-11066","","","nan","","","SCS-EERE","","","","","nan","","","open","","https://paperswithcode.com/paper/selecting-optimal-context-sentences-for-event","https://github.com/hieumdt/SCS-EERE","","[{""task"": ""Relation Classification"", ""dataset"": ""MATRES"", ""res"": ""0.834"", ""metric"": ""F1""}, {""task"": ""Temporal Relation Classification"", ""dataset"": ""MATRES"", ""res"": ""83.4"", ""metric"": ""F1""}]","{'citing': ['10.1007/978-3-031-30678-5_1', '10.1016/j.knosys.2023.111256', '10.1007/978-3-031-53468-3_14', '10.1016/j.inffus.2023.101919', '10.1016/j.ipm.2023.103469', '10.2139/ssrn.4482481', '10.21203/rs.3.rs-3942857/v1', '10.1007/978-981-99-9243-0_6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/DLXQ9FPI/et al. - 2022 - Selecting Optimal Context Sentences for Event-Event Relation Extraction..pdf","","DONE; Granularity:Document; PTM:Roberta; LANG:English; LEARNINGMETHOD:Reinforcement; DATATYPEPROP:String; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; NBDATASET:4; NBTYPEREL:10^0; INPUT:NER; ARCHI:Embedding; TASK:EventExtraction; TASK:RelationClassif; DATASET:MATRES; TOCKECH; DATASET:Hieve; DATASET:TDD; PTM:ConceptNetNumbernatch; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"JKFC8624","conferencePaper","2021",", Xianming Li; , Xiaotian Luo; , Chenghao Dong; , Daichuan Yang; , Beidi Luan; , Zhen He","TDEER: An Efficient Translating Decoding Schema for Joint Extraction of Entities and Relations.","","","","10.18653/V1/2021.EMNLP-MAIN.635","https://dblp.org/rec/conf/emnlp/LiLDYLH21","nan","2021","2024-04-11 17:32:18","2025-03-22 16:52:26","","8055-8064","","","nan","","","TDEER","","","","","nan","","","open","","https://paperswithcode.com/paper/tdeer-an-efficient-translating-decoding","https://github.com/4AI/TDEER","","[{""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""WebNLG"", ""res"": ""93.1"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""WebNLG"", ""res"": ""93.1"", ""metric"": ""F1""}]","{'citing': ['10.1016/j.jksuci.2023.101748', '10.1109/prml59573.2023.10348196', '10.3389/fdata.2023.1278153', '10.1007/s11227-023-05442-6', '10.1145/3511808.3557323', '10.1109/tim.2022.3200429', '10.1016/j.nlp.2023.100017', '10.1109/ijcnn54540.2023.10191216', '10.1007/978-981-99-4826-0_3', '10.1049/itr2.12398', '10.3390/electronics12163430', '10.1007/s13042-023-01923-5', '10.1016/j.eswa.2023.122007', '10.1109/cscloud-edgecom58631.2023.00070', '10.1109/iccsnt56096.2022.9972990', '10.1109/bibm55620.2022.9995077', '10.1007/s00500-024-09629-8', '10.3389/fnbot.2022.914705'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/GUWDLR6M/et al. - 2021 - TDEER An Efficient Translating Decoding Schema for Joint Extraction of Entities and Relations..pdf","","DONE; GRANULARITY:Sentences; TASK:Endtoendre; COSTEVAL_BIN:1; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBTYPEREL:10^2; NBDATASET:3; DATASET:NYT; PTM:Glove; ARCHI:LSTM; DATASET:WebNLG; PTM:BERT; ARCHI:RelEmbedding; LANG:english; DATASET:NYT11; LINEARIZEDGRAPH_BIN:NSP; DatasetSplit:ChallengingCriteria","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP","","","","","","","","","","","","","","",""
"GH5PRMKD","conferencePaper","2020",", Yucheng Wang; , Bowen Yu 0002; , Yueyang Zhang; , Tingwen Liu; , Hongsong Zhu; , Limin Sun","TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking.","","","","10.18653/V1/2020.COLING-MAIN.138","https://dblp.org/rec/journals/corr/abs-2010-13415","nan","2020","2024-04-11 17:32:14","2025-03-22 16:52:24","","1572-1582","","","nan","","","TPLinker","","","","","nan","","","open","","https://paperswithcode.com/paper/tplinker-single-stage-joint-extraction-of","https://github.com/131250208/TPlinker-joint-extraction","","[{""task"": ""Relation Extraction"", ""dataset"": ""NYT10-HRL"", ""res"": ""72.45"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""NYT11-HRL"", ""res"": ""55.28"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""NYT10-HRL"", ""res"": ""71.93"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""WebNLG"", ""res"": ""91.9"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""NYT11-HRL"", ""res"": ""55.67"", ""metric"": ""F1""}]","{'citing': ['10.1007/978-3-030-82147-0_13', '10.1145/3488560.3498409', '10.1007/978-981-99-1428-9_3', '10.1109/ijcnn54540.2023.10191604', '10.1109/ijcnn54540.2023.10191693', '10.1016/j.jksuci.2023.101748', '10.1109/prml59573.2023.10348196', '10.3390/app122110824', '10.3389/fdata.2023.1278153', '10.1038/s41598-023-29454-7', '10.1007/978-3-031-44201-8_20', '10.1007/s11227-023-05442-6', '10.1109/ialp54817.2021.9675275', '10.1016/j.cogr.2022.11.001', '10.1109/ijcnn55064.2022.9892310', '10.1007/978-3-031-33455-9_20', '10.3390/app13074636', '10.1145/3539618.3591763', '10.1007/978-981-99-6207-5_15', '10.1016/j.jbi.2023.104456', '10.1007/s12559-021-09917-7', '10.1007/978-3-031-17120-8_21', '10.1145/3511808.3557459', '10.1145/3511808.3557323', '10.1145/3511808.3557189', '10.1109/tim.2022.3200429', '10.1007/978-3-031-30678-5_55', '10.1007/978-3-031-54321-0_1', '10.1038/s41598-022-26116-y', '10.3390/app13052962', '10.3390/app13074447', '10.3390/e26020162', '10.1145/3442381.3450029', '10.1007/978-981-19-8300-9_3', '10.1007/978-3-031-35415-1_16', '10.1109/ijcnn54540.2023.10191826', '10.1007/978-981-99-4749-2_11', '10.1109/tnnls.2021.3070843', '10.1093/bib/bbac342', '10.1007/978-981-19-2456-9_66', '10.1145/3459637.3482045', '10.1145/3514094.3534178', '10.1016/j.knosys.2023.110550', '10.1109/ijcnn54540.2023.10191216', '10.3390/app12136543', '10.3390/app12136361', '10.1145/3487553.3524637', '10.1007/978-981-99-4826-0_10', '10.1007/978-981-99-4826-0_2', '10.1007/978-981-99-4826-0_7', '10.1007/978-981-99-4826-0_8', '10.1007/978-981-99-4826-0_3', '10.1007/978-981-99-4826-0_12', '10.1049/itr2.12398', '10.1145/3639479.3639484', '10.1007/978-981-16-8430-2_16', '10.1007/978-3-031-25198-6_18', '10.1109/icme55011.2023.00101', '10.1038/s41598-023-30355-y', '10.1007/978-3-031-40289-0_2', '10.1007/978-981-99-9864-7_6', '10.1007/978-981-99-9864-7_11', '10.1007/978-981-99-9864-7_12', '10.1007/978-3-031-18315-7_11', '10.1007/978-3-031-53555-0_25', '10.1007/978-981-99-6222-8_20', '10.1007/s40747-023-01321-y', '10.3390/electronics12163430', '10.1007/s13042-023-01923-5', '10.1109/iros55552.2023.10342509', '10.3390/electronics12041013', '10.1109/icbaie56435.2022.9985876', '10.1371/journal.pone.0281055', '10.3390/app14041334', '10.1016/j.eswa.2023.122007', '10.1016/j.jmsy.2023.08.006', '10.1145/3578741.3578755', '10.1007/978-3-031-30108-7_18', '10.1145/3603781.3603909', '10.1007/978-981-19-6142-7_10', '10.1109/ictai56018.2022.00047', '10.4018/ijswis.329965', '10.3390/drones7060360', '10.1109/iccsnt56096.2022.9972933', '10.1109/nnice58320.2023.10105766', '10.1017/s1351324923000050', '10.1007/978-981-99-0105-0_19', '10.1109/ijcnn54540.2023.10191225', '10.1007/978-3-031-44198-1_20', '10.21203/rs.3.rs-2885630/v1', '10.1109/ijcnn54540.2023.10191391', '10.1109/ijcnn54540.2023.10191254', '10.1109/aict55583.2022.10013614', '10.1007/978-3-031-19433-7_37', '10.1145/3503161.3548765', '10.1109/icsai57119.2022.10005391', '10.1109/bibm55620.2022.9995210', '10.1109/bibm55620.2022.9995077', '10.1145/3579654.3579741', '10.1007/978-3-030-88480-2_24', '10.1007/978-3-030-88483-3_37', '10.1145/3519296', '10.1109/bibm58861.2023.10385477', '10.1109/bibm58861.2023.10385642', '10.1007/978-981-16-5188-5_2', '10.3390/app13137585', '10.1109/bigdia53151.2021.9619716', '10.1007/978-3-031-20627-6_23', '10.1007/978-3-031-20865-2_13', '10.3390/app13020842', '10.1016/j.cogsys.2023.101153', '10.1109/prai59366.2023.10331969', '10.1109/access.2023.3335623', '10.1371/journal.pone.0298974', '10.1145/3502223.3502245', '10.1109/icassp43922.2022.9746958', '10.1109/ccis57298.2022.10016347', '10.3390/app131910643'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/PS2I9GDN/et al. - 2020 - TPLinker Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking..pdf","","DONE; GRANULARITY:Sentences; ARCHI:Bilstm; LANG:English; DATASET:Webnlg; COSTEVAL_BIN:1; DATATYPEPROP:String; DECODINGMETHOD_BIN:1; LINEARIZEDGRAPH_BIN:1; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; NBDATASET:2; NBTYPEREL:10^2; TASK:NER; OBJECTPROPERTIES_BIN:0; TASK:EndToEndRE; DATASET:NYT; PTM:BERT; INPUT:TEXT; LEARNINGMETHOD:1; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","COLING","","","","","","","","","","","","","","",""
"FATE8VZE","conferencePaper","2020",", Colin Lockard; , Prashant Shiralkar; , Xin Luna Dong; , Hannaneh Hajishirzi","ZeroShotCeres: Zero-Shot Relation Extraction from Semi-Structured Webpages.","","","","10.18653/V1/2020.ACL-MAIN.721","https://dblp.org/rec/journals/corr/abs-2005-07105","nan","2020","2024-04-11 17:32:12","2025-03-22 16:54:17","","8105-8117","","","nan","","","ZeroShotCeres","","","","","nan","","","open","","https://paperswithcode.com/paper/zeroshotceres-zero-shot-relation-extraction","https://github.com/cdlockard/expanded_swde","","","{'citing': ['10.1109/icdm51629.2021.00187', '10.1007/s13740-021-00134-x', '10.1016/j.websem.2022.100757', '10.1016/j.eswa.2022.119369', '10.1109/access.2021.3068728', '10.1145/3453483.3454047', '10.1145/3485447.3512032', '10.1109/itaic54216.2022.9836511', '10.1145/3442381.3450090', '10.1109/iccv51070.2023.01788', '10.1145/3459637.3482491', '10.1145/3394486.3403153', '10.1007/s40747-023-01075-7'], 'cited': []}","","","","star; DONE; GRANULARITY:Document; TASK:Endtoendre; LANG:English; LEARNINGMETHOD:Fewshot; DATATYPEPROP:Date; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBDATASET:3; ARCHI:GNN; PTM:BERT; ARCHI:FNN; ARCHI:GraphAttentionNetwork; DATASET_CREATED:SWDE_Movie; DATASET_CREATED:SWDE_NBA; DATASET_CREATED:SWDE_University; DATASET:SWDE; INPUT:HTML; INPUT:Visual; MANUALANNOTATION:1; DATATYPEPROP:Values; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL","","","","","","","","","","","","","","",""
"KNABA3QA","conferencePaper","2021",", Tao Chen; , Haizhou Shi; , Siliang Tang; , Zhigang Chen 0003; , Fei Wu 0001; , Yueting Zhuang","CIL: Contrastive Instance Learning Framework for Distantly Supervised Relation Extraction.","","","","10.18653/V1/2021.ACL-LONG.483","https://dblp.org/rec/journals/corr/abs-2106-10855","nan","2021","2024-04-11 17:33:22","2025-03-22 16:52:19","","6191-6200","","","nan","","","","","","","","nan","","","open","","https://paperswithcode.com/paper/cil-contrastive-instance-learning-framework","https://github.com/antct/cil","","","{'citing': ['10.1007/978-3-031-40286-9_30', '10.1007/978-981-99-6207-5_10', '10.2174/0122102981269053230921074451', '10.3390/app122111068', '10.1007/978-981-16-8430-2_18', '10.1007/s00521-022-07312-3', '10.1016/j.ipm.2023.103417', '10.1145/3539597.3570485', '10.1109/icccs57501.2023.10150972', '10.1109/ijcnn54540.2023.10191666', '10.1109/ijcnn54540.2023.10191841', '10.1109/cisp-bmei60920.2023.10373223', '10.1007/s40747-023-01226-w'], 'cited': []}","","","","DONE; GRANULARITY:Sentences; LANG:English; DATATYPEPROP:?; LEARNINGMETHOD:Contrastive; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBDATASET:4; NBTYPEREL:10^0; DATASET:TACRED; INPUT:NER; ARCHI:PositionnalEMbed; PTM:BERT; DATASET:NYT10; TASK:RelationClassif; ARCHI:TokenEmbed; DATASET:NYT11; ARCHI:BAgEncoder; DATASET:GDS; DatasetSplit:Random; DatasetSplit:AnnotatedData","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL/IJCNLP","","","","","","","","","","","","","","",""
"BSMJ2X4N","conferencePaper","2020",", Hongbin Ye; , Ningyu Zhang 0001; , Shumin Deng; , Mosha Chen; , Chuanqi Tan; , Fei Huang 0004; , Huajun Chen","Contrastive Triple Extraction with Generative Transformer.","","","","10.1609/AAAI.V35I16.17677","https://dblp.org/rec/journals/corr/abs-2009-06207","Triple extraction is an essential task in information extraction for natural language processing and knowledge graph construction. In this paper, we revisit the end-to-end triple extraction task for sequence generation. Since generative triple extraction may struggle to capture long-term dependencies and generate unfaithful triples, we introduce a novel model, contrastive triple extraction with a generative transformer. Specifically, we introduce a single shared transformer module for encoder-decoder-based generation. To generate faithful results, we propose a novel triplet contrastive training object.  Moreover, we introduce two mechanisms to further improve model performance (i.e., batch-wise dynamic attention-masking and triple-wise calibration).  Experimental results on three datasets (i.e., NYT, WebNLG, and MIE) show that our approach achieves better performance than that of baselines.","2020","2024-04-11 17:33:19","2025-03-22 16:54:21","","14257-14265","","","nan","","","CGT","","","","","nan","","","open","","https://paperswithcode.com/paper/contrastive-triple-extraction-with-generative","1924446","","","{'citing': ['10.1145/3488560.3498409', '10.2139/ssrn.4573704', '10.1109/prml59573.2023.10348196', '10.1145/3641850', '10.3390/electronics11142161', '10.1038/s41598-023-29454-7', '10.1145/3477495.3531746', '10.1145/3485447.3511998', '10.1007/978-3-031-17120-8_13', '10.1109/iccwamtip60502.2023.10387023', '10.1016/j.knosys.2021.107677', '10.1109/tgrs.2023.3235002', '10.1109/qrs60937.2023.00046', '10.1007/s10579-023-09713-9', '10.1007/978-981-19-8300-9_18', '10.1007/978-3-031-35415-1_16', '10.1109/access.2022.3232493', '10.1145/3639479.3639484', '10.1007/s11633-023-1461-5', '10.1007/s10462-023-10580-7', '10.1109/wi-iat59888.2023.00023', '10.1007/978-3-031-40289-0_2', '10.1007/s13042-023-01831-8', '10.1007/s13042-023-01923-5', '10.1109/ijcnn54540.2023.10191162', '10.1016/j.eswa.2023.122007', '10.1016/j.jmsy.2023.08.006', '10.1109/iccsnt56096.2022.9972933', '10.1016/j.neunet.2023.03.001', '10.1017/s1351324923000050', '10.1007/978-3-031-44198-1_20', '10.1016/j.neucom.2024.127270', '10.1109/access.2023.3335623', '10.1007/s40747-023-01004-8', '10.1007/978-3-031-40725-3_20'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/LW6T2IAD/et al. - 2020 - Contrastive Triple Extraction with Generative Transformer..pdf","","DONE; GRANULARITY:Sentences; ARCHI:Encoder-Decoder; LANG:Chinese; LANG:English; DATASET:Webnlg; OBJECTPROPERTIES_BIN:?; SYNTHGENERATION_BIN:?; LEARNINGMETHOD:Contrastive; DATATYPEPROP:String; DECODINGMETHOD_BIN:1; INPUT:Text; LINEARIZEDGRAPH_BIN:1; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; NBTYPEREL:NSP; NBDATASET:3; TASK:EndToEndRE; ARCHI:Transformer; DATASET:NYT; PTM:BERT; DATASET:MIE; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"JV4E7CPB","conferencePaper","2021",", Tongtong Wu; , Xuekai Li; , Yuan-Fang Li; , Reza Haffari; , Guilin Qi; , Yujin Zhu; , Guoqiang Xu","Curriculum-Meta Learning for Order-Robust Continual Relation Extraction.","","","","10.1609/AAAI.V35I12.17241","https://dblp.org/rec/journals/corr/abs-2101-01926","Continual relation extraction is an important task that focuses on extracting new facts incrementally from unstructured text.  Given the sequential arrival order of the relations, this task is prone to two serious challenges, namely catastrophic forgetting and order-sensitivity. We propose a novel curriculum-meta learning method to tackle the above two challenges in continual relation extraction. We combine meta learning and curriculum learning to quickly adapt model parameters to a new task and to reduce interference of previously seen tasks on the current task.  We design a novel relation representation learning method through the distribution of domain and range types of relations.  Such representations are utilized to quantify the difficulty of tasks for the construction of curricula. Moreover, we also present novel difficulty-based metrics to quantitatively measure the extent of order-sensitivity of a given model, suggesting new ways to evaluate model robustness.  Our comprehensive experiments on three benchmark datasets show that our proposed method outperforms the state-of-the-art techniques.  The code is available at the anonymous GitHub repository: https://github.com/wutong8023/AAAI_CML.","2021","2024-04-11 17:33:16","2025-03-22 16:53:36","","10363-10369","","","nan","","","","","","","","nan","","","open","","https://paperswithcode.com/paper/curriculum-meta-learning-for-order-robust","https://github.com/wutong8023/AAAI-CML","","","{'citing': ['10.3390/app122412736', '10.1109/taslp.2022.3224302', '10.1007/978-3-031-17120-8_13', '10.1109/tkde.2022.3147455', '10.1016/j.knosys.2023.110288', '10.1109/tkde.2022.3188335', '10.1007/s10489-024-05327-y'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/4Q9IYXNW/et al. - 2021 - Curriculum-Meta Learning for Order-Robust Continual Relation Extraction..pdf","","DONE; GRANULARITY:Sentences; LANG:English; DATASET:Fewrel; SYNTHGENERATION_BIN:?; INPUT:Text; LEARNINGMETHOD:Continual; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; DATATYPEPROP:None; NBTYPEREL:10^1; NBTYPEREL:10^2; LINEARIZEDGRAPH_BIN:0; NBDATASET:3; DATASET:TACRED; OBJECTPROPERTIES_BIN:NSP; PTM:TransE; ARCHI:RelEmbedding; TASK:RelationClassif; DATASET:SimpleQuestions; DatasetSplit:Clustering; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"MQASGSDR","conferencePaper","2021",", Wang Xu; , Kehai Chen; , Tiejun Zhao","Discriminative Reasoning for Document-level Relation Extraction.","","","","10.18653/V1/2021.FINDINGS-ACL.144","https://dblp.org/rec/journals/corr/abs-2106-01562","nan","2021","2024-04-11 17:33:13","2025-03-22 16:52:17","","1653-1663","","","nan","","","","","","","","nan","","","open","","https://paperswithcode.com/paper/discriminative-reasoning-for-document-level","https://github.com/xwjim/DRN","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""61.37"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""54.35"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""59.15"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""56.33"", ""metric"": ""F1""}]","{'citing': ['10.1109/ijcnn55064.2022.9892647', '10.1007/978-3-031-28244-7_38', '10.3390/e26030210', '10.1007/s00521-022-07312-3', '10.1007/s00521-022-07223-3', '10.1109/ijcnn54540.2023.10191391', '10.1007/s00521-023-09336-9', '10.1007/s40747-023-01084-6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/M23ELB97/et al. - 2021 - Discriminative Reasoning for Document-level Relation Extraction..pdf","","DONE; Granularity:Document; ARCHI:Bilstm; LANG:English; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; INPUT:NER; PTM:Glove; ARCHI:MLP; ARCHI:GCN; PTM:BERT; LOSSUPDATE_BIN:NSP; DATASET:DocRED; ARCHI:ENtityEmbedding; TASK:RelationClassif; ARCHI:CorefEmbed; ARCHI:TypeEmbed; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL/IJCNLP","","","","","","","","","","","","","","",""
"H3K5XGQP","conferencePaper","2022",", Yiqing Xie; , Jiaming Shen; , Sha Li; , Yuning Mao; , Jiawei Han 0001","Eider: Empowering Document-level Relation Extraction with Efficient Evidence Extraction and Inference-stage Fusion.","","","","10.18653/V1/2022.FINDINGS-ACL.23","https://dblp.org/rec/conf/acl/XieSLM022","nan","2022","2024-04-11 17:33:09","2025-03-22 16:53:25","","257-268","","","nan","","","EIDER","","","","","nan","","","open","","https://paperswithcode.com/paper/eider-evidence-enhanced-document-level","https://github.com/yiqingxyq/Eider","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""62.47"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""62.85"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""60.42"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""64.79"", ""metric"": ""F1""}]","{'citing': ['10.1016/j.jksuci.2023.101643', '10.1007/978-3-031-28244-7_38', '10.3390/e25081217', '10.3390/e26030210', '10.1145/3572898', '10.1109/tkde.2023.3292974', '10.1109/ccis57298.2022.10016420'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/XQYE239B/et al. - 2022 - Eider Empowering Document-level Relation Extraction with Efficient Evidence Extraction and Inferenc.pdf","","DONE; Granularity:Document; PTM:Roberta; LANG:English; LEARNINGMETHOD:?; COSTEVAL_BIN:1; DATATYPEPROP:String; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; NBTYPEREL:10^0; DATASET:GDA; NBDATASET:3; TASK:EvidenceExtraction; INPUT:NER; ARCHI:classifLayer; PTM:BERT; DATASET:CDR; TASK:RelationClassif; DATASET:DocRed; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL","","","","","","","","","","","","","","",""
"ENZWR49T","conferencePaper","2019",", David Wadden; , Ulme Wennberg; , Yi Luan; , Hannaneh Hajishirzi","Entity, Relation, and Event Extraction with Contextualized Span Representations.","","","","10.18653/V1/D19-1585","https://dblp.org/rec/journals/corr/abs-1909-03546","nan","2019","2024-04-11 17:33:05","2025-03-22 16:53:03","","5783-5788","","","nan","","","DyGIE++","","","","","nan","","","open","","https://paperswithcode.com/paper/entity-relation-and-event-extraction-with","https://github.com/dwadden/dygiepp","","[{""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""SciERC"", ""res"": ""Yes"", ""metric"": ""Cross Sentence""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""SciERC"", ""res"": ""48.40"", ""metric"": ""Relation F1""}, {""task"": ""Joint Entity and Relation Extraction"", ""dataset"": ""SciERC"", ""res"": ""67.50"", ""metric"": ""Entity F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""BERT base"", ""metric"": ""Sentence Encoder""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""88.6"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""Yes"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""63.4"", ""metric"": ""RE Micro F1""}]","{'citing': ['10.1109/isi53945.2021.9624840', '10.1016/j.knosys.2022.109945', '10.3390/math11081815', '10.1109/ijcnn54540.2023.10191693', '10.1007/978-3-030-60450-9_65', '10.1007/978-3-030-60457-8_44', '10.1109/tkde.2022.3180362', '10.3390/app13053041', '10.3934/mbe.2022240', '10.1145/3508546.3508639', '10.3390/app13042724', '10.3390/info15020091', '10.32604/iasc.2022.028352', '10.1007/978-3-031-08751-6_34', '10.1007/978-3-030-80599-9_11', '10.3390/electronics11142161', '10.1007/s11063-022-10907-5', '10.1145/3477495.3531784', '10.1109/taslp.2022.3221009', '10.1145/3611651', '10.1109/taslp.2024.3350905', '10.1109/taslp.2023.3304481', '10.1080/09540091.2022.2026295', '10.1007/978-3-031-16443-9_63', '10.1109/ijcnn55064.2022.9892140', '10.1145/3539618.3591763', '10.1007/978-981-99-6207-5_11', '10.1016/j.jbi.2023.104318', '10.1016/j.jbi.2023.104371', '10.1016/j.jbi.2023.104456', '10.1007/978-981-99-4752-2_44', '10.1016/j.aap.2021.106501', '10.1007/978-3-030-62466-8_9', '10.1145/3442442.3451365', '10.1016/j.knosys.2022.109480', '10.1016/j.knosys.2022.109129', '10.1145/3491102.3501905', '10.1145/3491102.3502087', '10.1145/3485447.3511921', '10.1145/3485447.3511928', '10.1007/978-3-031-17120-8_16', '10.1007/978-3-031-17120-8_14', '10.1007/978-3-031-17120-8_25', '10.1145/3511808.3557422', '10.1145/3543873.3587360', '10.3390/app131810538', '10.5715/jnlp.29.187', '10.1007/978-3-030-82322-1_5', '10.1007/978-3-031-30678-5_2', '10.1007/978-3-031-21967-2_43', '10.1016/j.jbi.2021.103761', '10.1109/taslp.2021.3110126', '10.1109/taslp.2020.3024944', '10.1109/bigdata55660.2022.10020889', '10.1109/icites59818.2023.10356864', '10.1109/cvpr42600.2020.00379', '10.1145/3442381.3449895', '10.1109/compsac57700.2023.00053', '10.1007/978-3-030-93733-1_23', '10.1101/2021.04.26.21256038', '10.1109/bigdia51454.2020.00060', '10.1109/iv51561.2020.00051', '10.1145/3487553.3524654', '10.1145/3487553.3524199', '10.1109/access.2022.3220241', '10.2196/preprints.50865', '10.1109/bigdata52589.2021.9671616', '10.1109/sp46214.2022.9833673', '10.1016/j.knosys.2023.110375', '10.1002/pra2.303', '10.1162/coli_a_00415', '10.1007/978-3-030-93119-3_8', '10.1007/978-3-030-58592-1_36', '10.1007/s00521-022-07747-8', '10.1101/2022.08.30.22279318', '10.1109/comst.2023.3273282', '10.1109/access.2022.3229426', '10.1007/978-981-99-4826-0_2', '10.1007/978-981-99-4826-0_8', '10.1007/978-3-030-72113-8_6', '10.1109/ijcnn52387.2021.9533951', '10.1109/taslp.2022.3202123', '10.1007/978-3-030-91699-2_34', '10.1007/s11192-023-04694-6', '10.1007/s10462-023-10580-7', '10.9728/dcs.2023.24.12.3131', '10.1007/978-3-031-44192-9_8', '10.1007/978-3-031-39059-3_13', '10.1007/978-981-99-9864-7_11', '10.1007/978-3-031-43895-0_59', '10.1109/access.2022.3180830', '10.1109/icbk50248.2020.00050', '10.1109/icassp43922.2022.9747160', '10.1109/icassp43922.2022.9746923', '10.1080/10095020.2022.2076619', '10.1007/978-981-19-5391-0_6', '10.1016/j.eswa.2023.121488', '10.1016/j.eswa.2023.120435', '10.1016/j.ipm.2021.102636', '10.1016/j.ipm.2021.102563', '10.3390/electronics12061386', '10.3390/electronics12112483', '10.1007/978-3-031-33023-0_13', '10.1007/s10115-023-01898-3', '10.1007/s13042-022-01760-y', '10.1109/tkde.2022.3161584', '10.1109/tkde.2023.3266495', '10.3390/electronics12010121', '10.1007/s11036-023-02203-w', '10.1007/978-3-031-30675-4_51', '10.2139/ssrn.4183577', '10.1080/27660400.2023.2206532', '10.1109/isctis58954.2023.10213028', '10.1007/978-3-031-40292-0_31', '10.1145/3604811', '10.1109/smartworld-uic-atc-scalcom-digitaltwin-pricomp-metaverse56740.2022.00162', '10.1109/ijcnn54540.2023.10191254', '10.1016/j.csl.2023.101569', '10.1145/3573834.3574540', '10.1007/978-3-030-59028-4_10', '10.1007/978-3-031-19433-7_39', '10.1109/bibm55620.2022.9995077', '10.1007/978-3-031-36021-3_29', '10.1145/3539618.3591912', '10.1007/978-3-030-87571-8_44', '10.1109/aiiot54504.2022.9817231', '10.1145/3523150.3523176', '10.1007/978-3-030-72240-1_20', '10.1109/bigdata52589.2021.9671529', '10.1109/bigdata52589.2021.9671514', '10.1007/s13042-022-01655-y', '10.1109/ijcnn54540.2023.10191495', '10.1007/s10844-023-00794-0', '10.1007/s10844-023-00783-3', '10.1007/s00521-023-08977-0', '10.1007/978-3-030-86324-1_4', '10.1007/978-3-030-87626-5_4', '10.3390/app13127015', '10.1109/icassp49357.2023.10096096', '10.1109/icassp49357.2023.10095912', '10.1109/access.2021.3130956', '10.1007/978-3-031-12285-9_15', '10.1371/journal.pone.0235796', '10.1109/icicn52636.2021.9673905', '10.1109/ijcnn52387.2021.9533296', '10.1109/icassp49357.2023.10095955', '10.1007/s10278-022-00717-5', '10.1007/s40747-023-01004-8', '10.1007/978-3-031-23902-1_22', '10.1145/3529388', '10.1145/3597455'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/4WX3JTLJ/et al. - 2019 - Entity, Relation, and Event Extraction with Contextualized Span Representations..pdf","","DONE; GRANULARITY:Sentences; PTM:Bert; TASK:Endtoendre; LANG:Arabic; LANG:Chinese; LANG:English; DATASET:Scierc; DATASET:Ace2005; TASK:Coref; DATATYPEPROP:?; NBTYPEREL:?; SYNTHGENERATION_BIN:?; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:0; DATASET:Genia; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; OBJECTPROPERTIES_BIN:1; TASK:NER; LINEARIZEDGRAPH_BIN:0; TO_EXCLUDE?; NBDATASET:5; ARCHI:LSTM; ARCHI:SpanGraphPropagation; DATASET:WLPC; TOCKECH; TASK:RelationIdentification; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP/IJCNLP","","","","","","","","","","","","","","",""
"I4DV2X3R","conferencePaper","2020",", Fuzhao Xue; , Aixin Sun; , Hao Zhang 0048; , Eng Siong Chng","GDPNet: Refining Latent Multi-View Graph for Relation Extraction.","","","","10.1609/AAAI.V35I16.17670","https://dblp.org/rec/journals/corr/abs-2012-06780","nan","2020","2024-04-11 17:33:00","2025-03-22 16:54:29","","14194-14202","","","nan","","","GDPNet","","","","","nan","","","open","","https://paperswithcode.com/paper/gdpnet-refining-latent-multi-view-graph-for","https://github.com/XueFuzhao/GDPNet","","[{""task"": ""Dialog Relation Extraction"", ""dataset"": ""DialogRE"", ""res"": ""64.9"", ""metric"": ""F1 (v1)""}, {""task"": ""Dialog Relation Extraction"", ""dataset"": ""DialogRE"", ""res"": ""60.1"", ""metric"": ""F1c (v1)""}, {""task"": ""Relation Extraction"", ""dataset"": ""TACRED"", ""res"": ""70.5"", ""metric"": ""F1""}]","{'citing': ['10.1016/j.knosys.2022.109471', '10.1145/3603781.3603920', '10.1145/3477495.3531746', '10.1145/3485447.3511998', '10.1007/978-981-99-4402-6_28', '10.1016/j.knosys.2023.110873', '10.1016/j.knosys.2022.109184', '10.3390/app12136361', '10.2139/ssrn.4563840', '10.1109/taslp.2022.3153256', '10.1007/978-3-031-18315-7_11', '10.1109/cscwd57460.2023.10152766', '10.1016/j.eswa.2024.123478', '10.1109/tcbb.2022.3205113', '10.26599/bdma.2022.9020051', '10.1007/978-3-031-40292-0_15', '10.1007/978-3-031-43421-1_2', '10.1007/s12559-022-10105-4', '10.1007/978-3-030-88480-2_21', '10.1109/ijcnn54540.2023.10191909', '10.3390/app13137585'], 'cited': []}","","","","DONE; DATASET:Tacred; GRANULARITY:Document; GRANULARITY:Sentences; LANG:English; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBDATASET:3; INPUT:NER; ARCHI:classifLayer; ARCHI:GCN; PTM:BERT; ARCHI:DynamicTimeWarpingPooling; ARCHI:GaussianGraphGenerator; DATASET:DialogRE; DATASET:TACREV; TASK:TriggerExtraction; TASL:DialogRE; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"X985GHNU","conferencePaper","2021",", Severine Verlinden; , Klim Zaporojets; , Johannes Deleu; , Thomas Demeester; , Chris Develder","Injecting Knowledge Base Information into End-to-End Joint Entity and Relation Extraction and Coreference Resolution.","","","","10.18653/V1/2021.FINDINGS-ACL.171","https://dblp.org/rec/journals/corr/abs-2107-02286","nan","2021","2024-04-11 17:32:49","2025-03-22 16:52:21","","1952-1957","","","nan","","","KB-both","","","","","nan","","","open","","https://paperswithcode.com/paper/injecting-knowledge-base-information-into-end","https://github.com/klimzaporojets/e2e-kb-ie","","[{""task"": ""Coreference Resolution"", ""dataset"": ""DWIE"", ""res"": ""91.5"", ""metric"": ""Avg. F1""}, {""task"": ""Named Entity Recognition (NER)"", ""dataset"": ""DWIE"", ""res"": ""75.0"", ""metric"": ""F1-Hard""}, {""task"": ""Relation Extraction"", ""dataset"": ""DWIE"", ""res"": ""52.1"", ""metric"": ""F1-Hard""}]","{'citing': ['10.1109/imasbd57215.2022.00023', '10.1093/bib/bbac342', '10.1145/3477495.3531996', '10.1007/978-3-031-19433-7_3', '10.1145/3539618.3591912'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/V3NM6IBK/et al. - 2021 - Injecting Knowledge Base Information into End-to-End Joint Entity and Relation Extraction and Corefe.pdf","","DONE; Granularity:Document; TASK:Entitylinking; TASK:Endtoendre; LANG:English; TASK:Coref; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:0; SOURCE:Wikidata; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBDATASET:2; TASK:NER; LINEARIZEDGRAPH_BIN:0; TO_EXCLUDE?; PTM:Glove; ARCHI:CharacterEmbed; DATASET:DocRED; ARCHI:FFN; ARCHI:ATtention; ARCHI:ENtityEmbedding; DATASET:DWIE; TOCKECH; ARCHI:KB; ARCHi:LSTM; SOURCE/WIKIpedia; TASK:RelationIdentification; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL/IJCNLP","","","","","","","","","","","","","","",""
"6M75XEGP","conferencePaper","2021",", Oscar Sainz; , Oier Lopez de Lacalle; , Gorka Labaka; , Ander Barrena; , Eneko Agirre","Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction.","","","","10.18653/V1/2021.EMNLP-MAIN.92","https://dblp.org/rec/conf/emnlp/SainzLLBA21","nan","2021","2024-04-11 17:32:44","2025-03-22 16:52:16","","1199-1212","","","nan","","","","","","","","nan","","","open","","https://paperswithcode.com/paper/label-verbalization-and-entailment-for-1","https://github.com/osainz59/Ask2Transformers","","","{'citing': ['10.1155/2022/1879483', '10.1109/taslp.2023.3304481', '10.3390/info14050262', '10.1016/j.compbiomed.2023.107666', '10.1145/3514094.3534178', '10.1162/tacl_a_00485', '10.1007/978-3-031-44213-1_42', '10.1109/tkde.2023.3240851', '10.1007/s41666-024-00162-9', '10.1038/s42256-023-00654-0', '10.1145/3592601'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/ZFZK9BCB/et al. - 2021 - Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction..pdf","","DONE; PTM:Roberta; GRANULARITY:Sentences; TASK:Nlu; LANG:English; PTM:Albert; PTM:Deberta; LEARNINGMETHOD:Fewshot; COSTEVAL_BIN:1; LEARNINGMETHOD:Finetuning; SYNTHGENERATION_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; LEARNINGMETHOD:Zeroshot; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; NBTYPEREL:10^1; DATATYPEPROP:NSP; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; DATASET:TACRED; OBJECTPROPERTIES_BIN:NSP; INPUT:NER; INPUT:TypeEntity; INPUT:TEXT; PTM:BART; TASK:RelationClassif; TASK:Graph-To-Text; TOCKECH; DatasetSplit:SizeTrain; DatasetSplit:AnnotatedData; DatasetSplit:Template","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP","","","","","","","","","","","","","","",""
"TG6673V7","conferencePaper","2021",", Dongyu Ru; , Changzhi Sun; , Jiangtao Feng; , Lin Qiu; , Hao Zhou 0012; , Weinan Zhang 0001; , Yong Yu 0001; , Lei Li 0005","Learning Logic Rules for Document-Level Relation Extraction.","","","","10.18653/V1/2021.EMNLP-MAIN.95","https://dblp.org/rec/conf/emnlp/RuSFQ000021","nan","2021","2024-04-11 17:32:43","2025-03-22 16:52:15","","1239-1250","","","nan","","","LogiRE","","","","","nan","","","open","","https://paperswithcode.com/paper/learning-logic-rules-for-document-level-1","https://github.com/rudongyu/LogiRE","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""59.48"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""58.62"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""60.61"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""61.45"", ""metric"": ""F1""}]","{'citing': ['10.1109/taslp.2023.3293046', '10.1145/3511808.3557313', '10.3233/jifs-234202', '10.1109/tkde.2023.3292974', '10.1145/3597610'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/44UFFPEL/et al. - 2021 - Learning Logic Rules for Document-Level Relation Extraction..pdf","","DONE; Granularity:Document; LANG:English; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBDATASET:2; DATATYPEPROP:NSP; LINEARIZEDGRAPH_BIN:0; PTM:NSP; ARCHI:Transformer; INPUT:NER; DATASET:DocRED; TASK:RelationClassif; DATASET:DWIE; INPUT:RUle; LEARNINGMETHOD:EM_optimisation; TASK:RuleGeneration; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP","","","","","","","","","","","","","","",""
"38V8627M","conferencePaper","2021",", Manqing Dong; , Chunguang Pan; , Zhipeng Luo","MapRE: An Effective Semantic Mapping Approach for Low-resource Relation Extraction.","","","","10.18653/V1/2021.EMNLP-MAIN.212","https://dblp.org/rec/journals/corr/abs-2109-04108","nan","2021","2024-04-11 17:32:39","2025-03-22 16:52:22","","2694-2704","","","nan","","","","","","","","nan","","","open","","https://paperswithcode.com/paper/mapre-an-effective-semantic-mapping-approach","https://github.com/dongmanqing/MapRE-An-Effective-Semantic-Mapping-Approach-for-Low-resource-Relation-Extraction","","","{'citing': ['10.3390/app13148312', '10.23919/apsipaasc55919.2022.9979971', '10.1109/icsai61474.2023.10423340', '10.1109/tkde.2023.3240851', '10.1007/978-3-031-40283-8_13', '10.1371/journal.pone.0286915', '10.1109/icassp49357.2023.10096551'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/CE6G94ME/et al. - 2021 - MapRE An Effective Semantic Mapping Approach for Low-resource Relation Extraction..pdf","","DONE; GRANULARITY:Sentences; LANG:English; DATASET:Fewrel; LEARNINGMETHOD:Contrastive; LEARNINGMETHOD:Fewshot; COSTEVAL_BIN:1; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; TASK:NER; LINEARIZEDGRAPH_BIN:0; NBDATASET:4; DATASET:ChemProt; TO_EXCLUDE?; OBJECTPROPERTIES_BIN:NSP; PTM:BERT; ARCHI:Embedding; DATASET:Fewrel2.0; ARCHI:RelEmbedding; TASK:RelationClassif; TOCKECH; DATASET:FewRel2; DatasetSplit:Random; DatasetSplit:ExampleSelections","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP","","","","","","","","","","","","","","",""
"84SBK3V4","conferencePaper","2021",", Jingye Li; , Kang Xu; , Fei Li; , Hao Fei 0001; , Yafeng Ren; , Donghong Ji","MRN: A Locally and Globally Mention-Based Reasoning Network for Document-Level Relation Extraction.","","","","10.18653/V1/2021.FINDINGS-ACL.117","https://dblp.org/rec/conf/acl/LiXLFRJ21","nan","2021","2024-04-11 17:32:38","2025-03-22 16:52:27","","1359-1370","","","nan","","","MRN","","","","","nan","","","open","","https://paperswithcode.com/paper/mrn-a-locally-and-globally-mention-based","https://github.com/ljynlp/MRN","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""59.52"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""58.46"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""56.19"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""61.74"", ""metric"": ""F1""}]","{'citing': ['10.1016/j.jksuci.2023.101643', '10.3390/app13179948', '10.1109/taslp.2022.3221009', '10.1016/j.jbi.2023.104459', '10.1080/13658816.2023.2301316', '10.1109/bibm58861.2023.10385582', '10.1007/978-3-031-33374-3_25', '10.1016/j.knosys.2023.110428', '10.1145/3581783.3612091', '10.1145/3594409.3594421', '10.1007/s00521-022-07223-3', '10.1016/j.inffus.2023.101919', '10.1109/icassp49357.2023.10095437', '10.1007/s44196-023-00305-7', '10.1016/j.eswa.2023.121386', '10.3390/electronics12112483', '10.1016/j.array.2023.100331', '10.3390/electronics12153205', '10.1007/s11227-022-04875-9', '10.1007/s40747-023-01084-6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/2VI2C66M/et al. - 2021 - MRN A Locally and Globally Mention-Based Reasoning Network for Document-Level Relation Extraction..pdf","","DONE; Granularity:Document; ARCHI:Bilstm; LANG:English; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:10^0; DATASET:GDA; NBDATASET:3; OBJECTPROPERTIES_BIN:NSP; INPUT:NER; ARCHI:Attention; ARCHI:CNN; PTM:BERT; DATASET:CDR; DATASET:DocRED; ARCHI:FFN; TASK:RelationClassif; ARCHI:TypeEmbed; TOCKECH; ARCHI:LeakyRelu; DatasetSplit:ChallengingCriteria","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL/IJCNLP","","","","","","","","","","","","","","",""
"3K5C24WS","conferencePaper","2021",", Bo Li 0099; , Wei Ye 0004; , Canming Huang; , Shikun Zhang","Multi-view Inference for Relation Extraction with Uncertain Knowledge.","","","","10.1609/AAAI.V35I15.17563","https://dblp.org/rec/journals/corr/abs-2104-13579","nan","2021","2024-04-11 17:32:36","2025-03-22 16:52:11","","13234-13242","","","nan","","","MIUK","","","","","nan","","","open","","https://paperswithcode.com/paper/multi-view-inference-for-relation-extraction","https://github.com/pkuserc/AAAI2021-MIUK-Relation-Extraction","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""58.05"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""59.99"", ""metric"": ""F1""}]","{'citing': ['10.1016/j.knosys.2022.109721', '10.1016/j.jksuci.2023.101643', '10.1109/itaic54216.2022.9836511', '10.1016/j.knosys.2023.110471', '10.1016/j.inffus.2024.102249', '10.1109/ialp61005.2023.10337090', '10.1007/s11227-022-04875-9'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/F52L6A2Q/et al. - 2021 - Multi-view Inference for Relation Extraction with Uncertain Knowledge..pdf","","star; DONE; Granularity:Document; GRANULARITY:Sentences; LANG:English; DATASET:Ace2005; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:1; SOURCE:Wikipedia; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBDATASET:2; DATATYPEPROP:NSP; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:10^0; INPUT:NER; ARCHI:Attention; PTM:BERT; DATASET:DocRED; ARCHI:Embedding; ARCHI:ENtityEmbedding; TASK:RelationClassif; ARCHI:KB; INPUT:document; INPUT:EntityDesc; INPUT:UncertaintyProba; SOURCE:ProBase; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"ABUBHCUC","conferencePaper","2021",", Kai Sun; , Richong Zhang; , Samuel Mensah; , Yongyi Mao; , Xudong Liu 0001","Progressive Multi-task Learning with Controlled Information Flow for Joint Entity and Relation Extraction.","","","","10.1609/AAAI.V35I15.17632","https://dblp.org/rec/conf/aaai/SunZMM021","Multitask learning has shown promising performance in learning multiple related tasks simultaneously, and variants of model architectures have been proposed, especially for supervised classification problems. One goal of multitask learning is to extract a good representation that sufficiently captures the relevant part of the input about the output for each learning task. To achieve this objective, in this paper we design a multitask learning architecture based on the observation that correlations exist between outputs of some related tasks (e.g. entity recognition and relation extraction tasks), and they reflect the relevant features that need to be extracted from the input. As outputs are unobserved, our proposed model exploits task predictions in lower layers of the neural model, also referred to as early predictions in this work. But we control the injection of early predictions to ensure that we extract good task-specific representations for classification. We refer to this model as a Progressive Multitask learning model with Explicit Interactions (PMEI). Extensive experiments on multiple benchmark datasets produce state-of-the-art results on the joint entity and relation extraction task.","2021","2024-04-11 17:32:29","2025-03-22 16:52:29","","13851-13859","","","nan","","","PMEI","","","","","nan","","","open","","DBLP","https://github.com/BDBC-KG-NLP/Progressive AAAI2021","","","{'citing': ['10.1109/prml59573.2023.10348196', '10.1016/j.knosys.2023.110550', '10.1145/3639479.3639513', '10.1016/j.eswa.2023.122007', '10.1007/978-981-19-6142-7_9', '10.4018/ijswis.329965', '10.1190/geo2022-0275.1', '10.1007/s00521-023-08977-0', '10.1109/iccv51070.2023.00948', '10.1007/978-3-031-20865-2_13', '10.1007/978-3-031-20891-1_30', '10.1371/journal.pone.0298974', '10.1007/978-3-031-21648-0_11', '10.1007/s40747-023-01075-7'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/FZQVRR3A/et al. - 2021 - Progressive Multi-task Learning with Controlled Information Flow for Joint Entity and Relation Extra.pdf","","DONE; GRANULARITY:Sentences; ARCHI:Bilstm; INPUT:Text; LOSSUPDATE_BIN:1; NBTYPEREL:10²; USENEGATIVEEXAMPLE_BIN:0; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; DATATYPEPROP:NSP; TASK:NER; LINEARIZEDGRAPH_BIN:0; NBDATASET:4; ARCHI:GRU; TASK:EndToEndRE; OBJECTPROPERTIES_BIN:NSP; PTM:Glove; DATASET:WebNLG; ARCHI:MLP; PTM:BERT; LANG:ENglish; DATASET:NYT10; TASK:RelationClassif; LEARNINGMETHOD:Training; DATASET:NYT11; ARCHI:StochasticMap; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"49VP9PKA","conferencePaper","2022","Chen, Xiang; Zhang, Ningyu; Xie, Xin; Deng, Shumin; Yao, Yunzhi; Tan, Chuanqi; Huang, Fei; Si, Luo; Chen, Huajun","KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction","Proceedings of the ACM Web Conference 2022","","","10.1145/3485447.3511998","http://arxiv.org/abs/2104.07650","Recently, prompt-tuning has achieved promising results for specific few-shot classification tasks. The core idea of prompt-tuning is to insert text pieces (i.e., templates) into the input and transform a classification task into a masked language modeling problem. However, for relation extraction, determining an appropriate prompt template requires domain expertise, and it is cumbersome and timeconsuming to obtain a suitable label word. Furthermore, there exists abundant semantic and prior knowledge among the relation labels that cannot be ignored. To this end, we focus on incorporating knowledge among relation labels into prompt-tuning for relation extraction and propose a Knowledge-aware Prompt-tuning approach with synergistic optimization (KnowPrompt). Specifically, we inject latent knowledge contained in relation labels into prompt construction with learnable virtual type words and answer words. Then, we synergistically optimize their representation with structured constraints. Extensive experimental results on five datasets with standard and low-resource settings demonstrate the effectiveness of our approach. Our code and datasets are available in GitHub1 for reproducibility.","2022-04-25","2024-04-12 12:12:45","2025-03-22 16:53:31","2023-01-30 09:58:41","2778-2788","","","","","","KnowPrompt","","","","","ACM","","en","","","https://paperswithcode.com/paper/adaprompt-adaptive-prompt-based-finetuning","https://github.com/zjunlp/KnowPrompt","arXiv.org","[{""task"": ""Relation Extraction"", ""dataset"": ""SemEval-2010 Task 8"", ""res"": ""90.3"", ""metric"": ""F1""}, {""task"": ""Dialog Relation Extraction"", ""dataset"": ""DialogRE"", ""res"": ""66.0"", ""metric"": ""F1 (v1)""}]","{'citing': ['10.1016/j.eswa.2023.122723', '10.1016/j.ipm.2023.103639', '10.1109/tbdata.2023.3278977', '10.1145/3632410.3633292', '10.1007/s11063-024-11437-y', '10.1145/3485447.3512094', '10.1109/taslp.2023.3275028', '10.1145/3605943', '10.3390/app13021159', '10.1007/978-981-99-6207-5_20', '10.1016/j.jbi.2023.104417', '10.1016/j.jbi.2023.104416', '10.1109/dsc59305.2023.00012', '10.1007/978-3-031-17601-2_28', '10.1145/3511808.3557422', '10.3390/info14100526', '10.3390/info14030186', '10.1109/ase56229.2023.00143', '10.1109/smc53992.2023.10394554', '10.1109/smc53992.2023.10394492', '10.1109/bibm58861.2023.10385578', '10.1145/3560815', '10.3390/app13158700', '10.3390/e25091294', '10.1007/978-3-031-35894-4_3', '10.3390/app122111117', '10.1007/978-981-19-8300-9_11', '10.3390/math11051073', '10.1007/978-3-031-35415-1_16', '10.1109/bigdata55660.2022.10020568', '10.1109/bigdata55660.2022.10020399', '10.1016/j.knosys.2023.110605', '10.1007/978-981-99-1600-9_5', '10.1109/access.2023.3295776', '10.1109/taslp.2022.3199655', '10.1145/3597503.3623298', '10.1007/s11633-023-1461-5', '10.1186/s12911-023-02127-1', '10.1007/s10489-023-04964-z', '10.1007/s10489-023-04588-3', '10.1007/s13042-023-01898-3', '10.1007/s41666-024-00162-9', '10.1109/cac57257.2022.10055561', '10.3390/technologies11050123', '10.1145/3639631.3639665', '10.1016/j.eswa.2023.121725', '10.1016/j.eswa.2024.123248', '10.1016/j.eswa.2024.123478', '10.1145/3543507.3583504', '10.1145/3578741.3578787', '10.1007/978-3-031-40283-8_13', '10.1016/j.eswa.2023.121632', '10.1145/3597503.3608137', '10.1145/3597926.3598085', '10.1016/j.neunet.2023.03.001', '10.54097/fcis.v3i1.6362', '10.1109/iaecst57965.2022.10061961', '10.4018/ijitsa.328681', '10.1007/978-981-19-8991-9_26', '10.1145/3539618.3591641', '10.1109/icse48619.2023.00119', '10.1016/j.jksuci.2022.08.038', '10.1007/s13735-023-00286-5', '10.1109/iccv51070.2023.01436', '10.1007/s00354-024-00244-7', '10.1016/j.aei.2023.102333'], 'cited': ['10.18653/v1/d18-1120', '10.18653/v1/d18-1514', '10.18653/v1/d18-1244', '10.18653/v1/2021.emnlp-main.243', '10.1609/aaai.v35i16.17677', '10.18653/v1/p16-2034', '10.18653/v1/2020.coling-main.563', '10.18653/v1/2020.coling-main.488', '10.18653/v1/2020.coling-main.140', '10.18653/v1/2020.coling-main.265', '10.1145/3442381.3449917', '10.1145/3447548.3467057', '10.1145/3366423.3380252', '10.1145/3366423.3380282', '10.1145/3442381.3449895', '10.18653/v1/d19-1022', '10.18653/v1/p19-1024', '10.18653/v1/p19-1279', '10.18653/v1/2021.acl-long.295', '10.18653/v1/2021.acl-long.486', '10.24963/ijcai.2021', '10.18653/v1/d19-1005', '10.1145/3357384.3358119', '10.1162/tacl_a_00300', '10.18653/v1/d17-1004', '10.18653/v1/2021.eacl-main.20', '10.24963/ijcai.2021/551', '10.1007/3-540-60925-3_51', '10.18653/v1/2021.naacl-main.208', '10.1145/3411763.3451760', '10.1609/aaai.v35i16.17670', '10.1609/aaai.v34i05.6281', '10.18653/v1/2022.acl-long.556', '10.18653/v1/2022.findings-emnlp.512', '10.18653/v1/2020.acl-main.444', '10.18653/v1/2020.acl-main.142', '10.18653/v1/n19-1306', '10.18653/v1/d15-1203', '10.18653/v1/2021.acl-long.342', '10.1609/aaai.v33i01.33016407', '10.18653/v1/2021.acl-long.353', '10.18653/v1/2021.acl-long.381', '10.18653/v1/2020.emnlp-main.346', '10.18653/v1/2020.emnlp-main.523']}","","/root/snap/zotero-snap/common/Zotero/storage/D7P8CZTP/Chen et al. - 2022 - KnowPrompt Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction.pdf","","DONE; PTM:Roberta; DATASET:Tacred; GRANULARITY:Sentences; LANG:Chinese; LANG:English; DATASET:Retacred; DATATYPEPROP:String; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; LEARNINGMETHOD:Prompttuning; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; LINEARIZEDGRAPH_BIN:0; OBJECTPROPERTIES_BIN:0; DATASET:Semeval2010; NBDATASET:5; INPUT:NER; DATASET:DialogRE; DATASET:TACREV; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WWW","","","","","","","","","","","","","","",""
"ARE5V6DM","conferencePaper","2021",", Ningyu Zhang; , Xiang Chen; , Xin Xie; , Shumin Deng; , Chuanqi Tan; , Mosha Chen; , Fei Huang; , Luo Si; , Huajun Chen","Document-level Relation Extraction as Semantic Segmentation","Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence","","","10.24963/ijcai.2021/551","https://arxiv.org/abs/2106.03618v2","Document-level relation extraction aims to extract relations among multiple entity pairs from a document. Previously proposed graph-based or transformer-based models utilize the entities independently, regardless of global information among relational triples. This paper approaches the problem by predicting an entity-level relation matrix to capture local and global information, parallel to the semantic segmentation task in computer vision. Herein, we propose a Document U-shaped Network for document-level relation extraction. Specifically, we leverage an encoder module to capture the context information of entities and a U-shaped segmentation module over the image-style feature map to capture global interdependency among triples. Experimental results show that our approach can obtain state-of-the-art performance on three benchmark datasets DocRED, CDR, and GDA.","2021-06-07","2024-04-12 12:16:03","2025-03-22 16:53:39","","","","","","","","DocuNet","","","","","IJCAI","","","NA","","https://paperswithcode.com/paper/document-level-relation-extraction-as","https://github.com/wutong8023/Awesome_Information_Extraction","","[{""task"": ""Relation Extraction"", ""dataset"": ""GDA"", ""res"": ""85.3"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""62.4"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""64.55"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""CDR"", ""res"": ""76.3"", ""metric"": ""F1""}]","{'citing': ['10.1109/icpr56361.2022.9956191', '10.1016/j.cviu.2023.103799', '10.1109/tbdata.2023.3278977', '10.1145/3477495.3531746', '10.1145/3485447.3511998', '10.1145/3485447.3511921', '10.1007/978-3-031-17120-8_13', '10.1145/3511808.3557313', '10.1109/ijcnn55064.2022.9892647', '10.3390/info14070365', '10.1109/smc53992.2023.10394492', '10.1109/bibm58861.2023.10385582', '10.3390/e26030210', '10.3390/math11051073', '10.1109/bigdata55660.2022.10020399', '10.1145/3508546.3508633', '10.1007/978-3-031-44213-1_42', '10.1145/3477495.3531992', '10.1109/icmla55696.2022.00254', '10.1007/s00521-022-07223-3', '10.1007/s00521-021-06667-3', '10.1145/3404835.3462908', '10.1007/978-3-031-25198-6_8', '10.1109/icassp49357.2023.10096263', '10.1109/icme52920.2022.9859701', '10.3390/electronics12132968', '10.1109/ijcnn54540.2023.10191162', '10.1109/tcbb.2022.3233856', '10.1109/ialp61005.2023.10337090', '10.26599/bdma.2022.9020051', '10.1109/ijcnn54540.2023.10191391', '10.3233/jifs-237167', '10.1016/j.eswa.2022.117678', '10.1109/tkde.2023.3292974', '10.1145/3502223.3502237', '10.1155/2022/8477260', '10.1007/s40747-023-01084-6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/YJNF9UXT/et al. - 2021 - Document-level Relation Extraction as Semantic Segmentation.pdf","","DONE; PTM:Roberta; ARCHI:Cnn; GRANULARITY:Document; PTM:Bert; LANG:English; PTM:Scibert; DATASET:Docred; DATATYPEPROP:String; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; DATASET:Cdr; ARCHI:Unet; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:10^0; DATASET:GDA; NBDATASET:3; OBJECTPROPERTIES_BIN:NSP; INPUT:NER; INPUT:TEXT; ARCHI:RelEmbedding; ARCHI:ENtityEmbedding; TASK:RelationClassif; ARCHI:DocEmbeding; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IJCAI","","","","","","","","","","","","","","",""
"GTUBUDXA","conferencePaper","2020",", Guoshun Nan; , Zhijiang Guo; , Ivan Sekulić; , Wei Lu","Reasoning with Latent Structure Refinement for Document-Level Relation Extraction","","","","10.18653/v1/2020.acl-main.141","https://arxiv.org/abs/2005.06312v3","Document-level relation extraction requires integrating information within and across multiple sentences of a document and capturing complex interactions between inter-sentence entities. However, effective aggregation of relevant information in the document remains a challenging research question. Existing approaches construct static document-level graphs based on syntactic trees, co-references or heuristics from the unstructured text to model the dependencies. Unlike previous methods that may not be able to capture rich non-local interactions for inference, we propose a novel model that empowers the relational reasoning across sentences by automatically inducing the latent document-level graph. We further develop a refinement strategy, which enables the model to incrementally aggregate relevant information for multi-hop reasoning. Specifically, our model achieves an F1 score of 59.05 on a large-scale document-level dataset (DocRED), significantly improving over the previous results, and also yields new state-of-the-art results on the CDR and GDA dataset. Furthermore, extensive analyses show that the model is able to discover more accurate inter-sentence relations.","2020-05-13","2024-04-12 12:17:05","2025-03-22 16:54:25","","NA","","","NA","","","LSR","","","","","ACL","","","NA","","https://paperswithcode.com/paper/reasoning-with-latent-structure-refinement","https://github.com/scofield7419/DiaRE-D2G","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""54.18"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""GDA"", ""res"": ""82.2"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""52.15"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""56.97"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""59.05"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""CDR"", ""res"": ""64.8"", ""metric"": ""F1""}]","{'citing': ['10.1016/j.knosys.2022.109471', '10.1016/j.knosys.2022.110107', '10.1016/j.jksuci.2023.101643', '10.1016/j.neucom.2021.05.082', '10.1007/978-3-030-86523-8_35', '10.1109/ijcnn55064.2022.9892914', '10.1007/978-981-99-6207-5_20', '10.1016/j.jbi.2023.104459', '10.1016/j.engappai.2023.106212', '10.1007/s12559-021-09917-7', '10.1007/978-3-031-17120-8_64', '10.1007/978-3-031-17120-8_13', '10.1007/s10115-022-01781-7', '10.1007/s42524-022-0226-0', '10.1145/3511808.3557313', '10.1145/3511808.3557615', '10.1109/ijcnn55064.2022.9892647', '10.1109/ijcnn55064.2022.9892385', '10.3390/info14070365', '10.1109/bibm58861.2023.10385582', '10.1109/itaic54216.2022.9836511', '10.1109/taslp.2021.3082295', '10.1007/978-3-031-33374-3_25', '10.1007/978-3-031-28244-7_38', '10.23919/apsipaasc55919.2022.9979932', '10.1007/s42524-023-0273-1', '10.1080/09544828.2023.2301230', '10.1109/tkde.2021.3077524', '10.1109/cei57409.2022.9950087', '10.1145/3459637.3482268', '10.1016/j.knosys.2023.110428', '10.1145/3490354.3494416', '10.1145/3490354.3494412', '10.3390/app12031599', '10.1007/s12559-023-10110-1', '10.1145/3508546.3508633', '10.1007/978-3-030-91560-5_25', '10.1109/bibm52615.2021.9669590', '10.1007/978-981-19-9865-2_3', '10.1007/s00521-022-07223-3', '10.1007/978-3-031-25198-6_9', '10.1109/iccwamtip60502.2023.10387128', '10.1007/978-981-99-9864-7_10', '10.1109/icassp43922.2022.9747486', '10.1109/icme52920.2022.9859653', '10.1007/s44196-023-00305-7', '10.1109/icsai61474.2023.10423340', '10.1109/tkde.2023.3240851', '10.1109/gcce56475.2022.10014427', '10.1109/cscwd57460.2023.10152766', '10.1016/j.eswa.2024.123478', '10.1145/3534678.3539304', '10.1117/12.2641047', '10.1109/ialp61005.2023.10337090', '10.3233/jifs-234202', '10.1109/iccsnt56096.2022.9972949', '10.26599/bdma.2022.9020051', '10.5715/jnlp.30.557', '10.1109/ijcnn54540.2023.10191391', '10.1016/j.neucom.2022.12.038', '10.1007/978-3-031-19433-7_3', '10.1007/978-981-19-7596-7_4', '10.1145/3572898', '10.1109/icpr56361.2022.9956376', '10.3233/jifs-237167', '10.1007/s12559-022-10105-4', '10.1145/3539618.3591984', '10.1109/jas.2023.123540', '10.1007/978-3-030-88480-2_26', '10.1016/j.eswa.2022.117678', '10.1109/tkde.2023.3292974', '10.3389/fgene.2021.624307', '10.1007/s11227-022-04875-9', '10.1145/3597610', '10.1007/978-3-030-75765-6_56', '10.1007/978-3-030-75765-6_22', '10.1007/978-3-030-75768-7_30', '10.1007/s10489-022-03731-w', '10.1145/3502223.3502245', '10.1109/bibm52615.2021.9669319', '10.1007/s40747-023-01084-6'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/VD7PYVGK/ et al. - 2020 - Reasoning with Latent Structure Refinement for Doc.pdf","","DONE; GRANULARITY:Document; ARCHI:Bilstm; LANG:English; DATASET:Docred; INPUT:Text; LEARNINGMETHOD:Finetuning; DATASET:Cdr; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:NSP; USENEGATIVEEXAMPLE_BIN:NSP; DATASET:GDA; NBDATASET:3; ARCHI:classifLayer; PTM:Glove; ARCHI:GNN; ARCHI:GCN; PTM:BERT; INPUT:DependencyParsing; LOSSUPDATE_BIN:NSP; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2020 6","","","","","","","","","","","","","","",""
"QHZVBA8Z","conferencePaper","2019",", Kalpit Dixit; , Yaser Al-Onaizan","Span-Level Model for Relation Extraction","","","","10.18653/v1/p19-1525","https://aclanthology.org/P19-1525","Relation Extraction is the task of identifying entity mention spans in raw text and then identifying relations between pairs of the entity mentions. Recent approaches for this span-level task have been token-level models which have inherent limitations. They cannot easily define and implement span-level features, cannot model overlapping entity mentions and have cascading errors due to the use of sequential decoding. To address these concerns, we present a model which directly models all possible spans and performs joint entity mention detection and relation extraction. We report a new state-of-the-art performance of 62.83 F1 (prev best was 60.49) on the ACE2005 dataset.","2019-07-01","2024-04-12 12:19:07","2025-03-22 16:52:02","","NA","","","NA","","","Span-level","","","","","ACL","","","NA","","https://paperswithcode.com/paper/span-level-model-for-relation-extraction","na","","[{""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""ELMo"", ""metric"": ""Sentence Encoder""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""85.98"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""No"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""62.83"", ""metric"": ""RE Micro F1""}]","{'citing': ['10.3934/mbe.2022240', '10.1145/3508546.3508639', '10.1016/j.neucom.2022.04.059', '10.1016/j.neucom.2022.04.022', '10.2196/25670', '10.1109/taai54685.2021.00012', '10.1145/3502223.3502228', '10.1016/j.neucom.2020.09.044', '10.1109/taslp.2024.3350905', '10.1016/j.jbi.2023.104456', '10.1007/978-3-030-89363-7_6', '10.1145/3511808.3557459', '10.1016/j.knosys.2021.107298', '10.1007/978-981-16-2502-2_52', '10.1109/iccrd56364.2023.10080054', '10.1145/3540250.3549089', '10.1016/j.knosys.2022.110228', '10.1162/coli_a_00415', '10.1007/978-3-030-70665-4_203', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00090', '10.1007/s11192-023-04694-6', '10.1007/s10462-023-10580-7', '10.1145/3639479.3639513', '10.2196/preprints.25670', '10.1007/978-3-031-18315-7_11', '10.1007/978-981-19-5391-0_6', '10.1016/j.eswa.2023.120435', '10.1016/j.ipm.2021.102563', '10.1007/s40747-023-01321-y', '10.1109/tkde.2022.3161584', '10.1371/journal.pone.0281055', '10.1109/bibm55620.2022.9995045', '10.1109/bibm55620.2022.9995158', '10.1016/j.jksuci.2022.08.038', '10.1109/ijcnn48605.2020.9207021', '10.1093/bioinformatics/btaa993', '10.1007/978-3-031-10986-7_7', '10.1109/icicn52636.2021.9673905', '10.1007/978-3-030-84529-2_39'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/5J944ZGB/and - 2019 - Span-Level Model for Relation Extraction.pdf; /root/snap/zotero-snap/common/Zotero/storage/JPDIIW9K/and - 2019 - Span-Level Model for Relation Extraction.pdf","","EXAMPLE; DONE; GRANULARITY:Document; ARCHI:Bilstm; TASK:Entitylinking; TASK:Endtoendre; PTM:Elmo; LANG:Arabic; LANG:Chinese; LANG:English; DATASET:Ace2005; COSTEVAL_BIN:?; DATATYPEPROP:String; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; INPUT:Embedding; LEARNINGMETHOD:Pretraining; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; TASK:NER; LINEARIZEDGRAPH_BIN:0; ARCHi:MLP; NBDATASET:1; NBTYPEREL:NSP; PTM:ELMO; PTM:Senna; OBJECTPROPERTIES_BIN:0; NBTYPEREL:6; ARCHI:classifLayer; DECODINGMETHOD_BIN:NSP; ARCHI:MLP; DATATYPEPROP:0; ARCHI:CharacterEmbed; ARCHI:RelEmbedding; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2019 7","","","","","","","","","","","","","","",""
"YZ9RF7DT","conferencePaper","2019",", Zhi-Xiu Ye; , Zhen-Hua Ling","Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions","","","","10.18653/v1/n19-1288","http://arxiv.org/abs/1904.00143v1","This paper presents a neural relation extraction method to deal with the noisy training data generated by distant supervision. Previous studies mainly focus on sentence-level de-noising by designing neural networks with intra-bag attentions. In this paper, both intra-bag and inter-bag attentions are considered in order to deal with the noise at sentence-level and bag-level respectively. First, relation-aware bag representations are calculated by weighting sentence embeddings using intra-bag attentions. Here, each possible relation is utilized as the query for attention calculation instead of only using the target relation in conventional methods. Furthermore, the representation of a group of bags in the training set which share the same relation label is calculated by weighting bag representations using a similarity-based inter-bag attention module. Finally, a bag group is utilized as a training sample when building our relation extractor. Experimental results on the New York Times dataset demonstrate the effectiveness of our proposed intra-bag and inter-bag attention modules. Our method also achieves better relation extraction accuracy than state-of-the-art methods on this dataset.","2019-03-30","2024-04-12 12:19:48","2025-01-02 10:13:05","","NA","","","NA","","","","","","","","ACL","","","NA","","https://paperswithcode.com/paper/distant-supervision-relation-extraction-with","https://github.com/ZhixiuYe/Intra-Bag-and-Inter-Bag-Attentions","","","{'citing': ['10.1007/978-3-030-43887-6_6', '10.1007/978-3-030-32381-3_24', '10.1007/978-3-030-32381-3_24', '10.1007/978-3-030-32233-5_15', '10.1145/3404835.3463103', '10.1007/s10489-021-02632-8', '10.1007/978-981-16-2540-4_1', '10.1145/3442381.3449917', '10.3390/su13169391', '10.1007/s12559-021-09917-7', '10.1145/3494885.3494896', '10.1007/s11280-021-00979-z', '10.1007/978-981-16-8430-2_18', '10.2196/37804', '10.1007/s11633-022-1323-6', '10.2196/preprints.37804', '10.1007/978-3-031-00129-1_29', '10.1109/access.2021.3073428', '10.1061/(asce)cp.1943-5487.0001014', '10.1109/tkde.2020.2964747', '10.1109/taslp.2022.3153254', '10.1109/icccbda51879.2021.9442541', '10.1109/bigdata50022.2020.9378317', '10.1109/iceiec49280.2020.9152287', '10.1007/s10489-022-03547-8', '10.1109/csde50874.2020.9411604', '10.1109/cscwd54268.2022.9776118', '10.1109/icccs52626.2021.9449230', '10.1145/3477495.3531876', '10.1109/access.2021.3135381', '10.1007/978-3-031-10983-6_31', '10.1109/tcss.2022.3178416', '10.1109/ijcnn55064.2022.9892196', '10.1007/978-3-031-19496-2_8', '10.1016/j.neunet.2022.10.008'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/B4TH2JIA/and - 2019 - Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions.pdf","","DONE; ARCHI:Cnn; DATASET:Nyt; GRANULARITY:Document; GRANULARITY:Sentences; LANG:English; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:0; SOURCE:Freebase; COSTEVAL_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; PTM:None; DATATYPEPROP:NSP; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; ARCHI:PCNN; DECODINGMETHOD_BIN:NSP; ARCHI:HierarchicalAttention; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL 2019 6","","","","","","","","","","","","","","",""
"NMZUQ7J8","conferencePaper","2019",", Yuming Shang","Are Noisy Sentences Useless for Distant Supervised Relation Extraction?","","","","10.1609/AAAI.V34I05.6407","https://dblp.org/rec/journals/corr/abs-1911-09788","The noisy labeling problem has been one of the major obstacles for distant supervised relation extraction. Existing approaches usually consider that the noisy sentences are useless and will harm the model's performance. Therefore, they mainly alleviate this problem by reducing the influence of noisy sentences, such as applying bag-level selective attention or removing noisy sentences from sentence-bags. However, the underlying cause of the noisy labeling problem is not the lack of useful information, but the missing relation labels. Intuitively, if we can allocate credible labels for noisy sentences, they will be transformed into useful training data and benefit the model's performance. Thus, in this paper, we propose a novel method for distant supervised relation extraction, which employs unsupervised deep clustering to generate reliable labels for noisy sentences. Specifically, our model contains three modules: a sentence encoder, a noise detector and a label generator. The sentence encoder is used to obtain feature representations. The noise detector detects noisy sentences from sentence-bags, and the label generator produces high-confidence relation labels for noisy sentences. Extensive experimental results demonstrate that our model outperforms the state-of-the-art baselines on a popular benchmark dataset, and can indeed alleviate the noisy labeling problem","2019","2024-04-12 12:20:20","2025-03-22 16:53:44","","8799-8806","","","nan","","","","","","","","AAAI","","","open","","https://paperswithcode.com/paper/are-noisy-sentences-useless-for-distant","na","","","{'citing': ['10.1145/3503917', '10.1016/j.ins.2021.10.047', '10.1007/s10489-022-03677-z', '10.1016/j.neunet.2022.10.008', '10.1007/s12559-021-09917-7', '10.1109/bigdata50022.2020.9378317', '10.3390/app12178821', '10.1007/s00521-022-07733-0', '10.1109/imcec51613.2021.9482001', '10.1109/ijcnn54540.2023.10191666', '10.1109/tkde.2022.3177226', '10.1007/s10489-022-03547-8', '10.1016/j.neunet.2021.04.032'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/Q7I54HW6/2019 - Are Noisy Sentences Useless for Distant Supervised Relation Extraction.pdf","","EXAMPLE; DONE; GRANULARITY:Sentences; LANG:English; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; PTM:None; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; ARCHI:PCNN; TASK:NoiseClassif; INPUT:NER; ARCHI:Embedding; TASK:RelationClassif; ARCHI:POSEmbed; DATASET:Nyt10; DatasetSplit:0","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"GEZZN5G4","conferencePaper","2023",", Youmi Ma; , An Wang; , Naoaki Okazaki","DREEAM: Guiding Attention with Evidence for Improving Document-Level Relation Extraction","Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics","","","10.18653/v1/2023.eacl-main.145","https://arxiv.org/abs/2302.08675v1","Document-level relation extraction (DocRE) is the task of identifying all relations between each entity pair in a document. Evidence, defined as sentences containing clues for the relationship between an entity pair, has been shown to help DocRE systems focus on relevant texts, thus improving relation extraction. However, evidence retrieval (ER) in DocRE faces two major issues: high memory consumption and limited availability of annotations. This work aims at addressing these issues to improve the usage of ER in DocRE. First, we propose DREEAM, a memory-efficient approach that adopts evidence information as the supervisory signal, thereby guiding the attention modules of the DocRE system to assign high weights to evidence. Second, we propose a self-training strategy for DREEAM to learn ER from automatically-generated evidence on massive data without evidence annotations. Experimental results reveal that our approach exhibits state-of-the-art performance on the DocRED benchmark for both DocRE and ER. To the best of our knowledge, DREEAM is the first approach to employ ER self-training.","2023-02-17","2024-08-01 08:07:31","2024-12-13 10:37:02","","","","","","","","DREEAM","","","","","ACL","","","NA","","https://paperswithcode.com/paper/dreeam-guiding-attention-with-evidence-for","https://github.com/youmima/dreeam","","[{""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""65.47"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""67.53"", ""metric"": ""F1""}]","","","/root/snap/zotero-snap/common/Zotero/storage/UVV4EJ7B/ et al. - 2023 - DREEAM Guiding Attention with Evidence for Improv.pdf","","EXAMPLE; DONE; PTM:Roberta; GRANULARITY:Document; PTM:Bert; LANG:English; COSTEVAL_BIN:1; DATASET:Docred; DATATYPEPROP:String; INPUT:Text; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; ARCHI:Encoder; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; DATASET:ReDocRED; NBMODEL:6; ARCHI:BiLinearClassif; ARCHI:ATLOP; TASK:EvidenceExtraction; LEARNINGMETHOD:TeacherForcing; TASK:RelationClassif; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EACL","","","","","","","","","","","","","","",""
"3FXWXCYV","conferencePaper","2022","Josifoski, Martin; De Cao, Nicola; Peyrard, Maxime; Petroni, Fabio; West, Robert","GenIE: Generative Information Extraction","Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2022.naacl-main.342","https://aclanthology.org/2022.naacl-main.342","US president Biden was born in Pennsylvania.","2022","2024-08-01 08:10:01","2024-08-01 12:51:02","2023-05-02 07:12:23","4626-4643","","","","","","GenIE","","","","","ACL","Seattle, United States","en","","","https://paperswithcode.com/paper/genie-generative-information-extraction","https://github.com/epfl-dlab/genie","DOI.org (Crossref)","","{'citing': ['10.1007/978-3-031-19433-7_47'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/YPIYR6PG/Josifoski et al. - 2022 - GenIE Generative Information Extraction.pdf","","EXAMPLE; DONE; GRANULARITY:Sentences; ARCHI:Encoder-Decoder; TASK:Endtoendre; LANG:English; PTM:Bart; DATASET:Fewrel; COSTEVAL_BIN:1; DATASET:Rebel; DECODINGMETHOD_BIN:1; INPUT:Text; LEARNINGMETHOD:Finetuning; LINEARIZEDGRAPH_BIN:1; USENEGATIVEEXAMPLE_BIN:0; NBENTITY:10⁴; NBENTITY:10⁵; SOURCE:Wikidata; SOURCE:Wikipedia; NBENTITY:10²; NBENTITY:10⁶; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; NBTYPEREL:10^2; NBDATASET:4; DATASET:Wiki-NRE; DATASET:Geo-NRE; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","","","","","","","","","","","","",""
"EJBUJPQU","journalArticle","2019","Pang, Yihe; Liu, Jie; Liu, Lizhen; Yu, Zhengtao; Zhang, Kai","A Deep Neural Network Model for Joint Entity and Relation Extraction","IEEE Access","","2169-3536","10.1109/ACCESS.2019.2949086","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8880633&tag=1","Joint extraction of entities and their relations from the text is an essential issue in automatic knowledge graph construction, which is also known as the joint extraction of relational triplets. The relational triplets in sentence are complicated, multiple and different relational triplets may have overlaps, which is commonly seen in reality. However, multiple pairs of triplets cannot be efficiently extracted in most of the previous works. To mitigate this problem, we propose a deep neural network model based on the sequence-to-sequence learning, namely, the hybrid dual pointer networks (HDP), which extracts multiple pairs of triplets from the given sentence by generating the hybrid dual pointer sequence. In experiments, we tested our model using the New York Times (NYT) public dataset. The experimental results demonstrated that our model outperformed the state-of-the-art work, and achieved a 17.1% improvement on the F1 values.","2019","2024-08-01 08:11:33","2025-03-22 16:53:06","","179143-179150","","","7","","","HDP","","","","","","","","","","https://paperswithcode.com/paper/end-to-end-neural-relation-extraction-using","","IEEE Xplore","[{""task"": ""Named Entity Recognition (NER)"", ""dataset"": ""JNLPBA"", ""res"": ""82.0"", ""metric"": ""F1""}, {""task"": ""Named Entity Recognition (NER)"", ""dataset"": ""BC2GM"", ""res"": ""85.1"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""GAD"", ""res"": ""84.3"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DDI"", ""res"": ""81.9"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ChemProt"", ""res"": ""77.5"", ""metric"": ""F1""}]","{'citing': ['10.1016/j.jbi.2021.103761', '10.3390/app10186429', '10.1093/bib/bbac342', '10.3390/app12199691', '10.1109/access.2022.3232493', '10.1109/access.2023.3240898', '10.1007/s10462-022-10239-9', '10.1109/tiv.2022.3160502', '10.1093/bioinformatics/btaa667', '10.1016/j.aei.2024.102364'], 'cited': ['10.18653/v1/p17-1085', '10.18653/v1/p18-1047', '10.18653/v1/d18-1307', '10.1145/2736277.2741093', '10.18653/v1/p16-1014', '10.18653/v1/p16-1105', '10.18653/v1/p16-1123', '10.1016/j.neucom.2016.12.075', '10.3115/1596374.1596399', '10.24963/ijcai.2018/620', '10.18653/v1/d17-1181', '10.3115/v1/p14-1038', '10.3115/v1/d14-1200', '10.18653/v1/p17-1113', '10.18653/v1/p17-1099', '10.18653/v1/d15-1205', '10.1609/aaai.v33i01.33017080']}","","/root/snap/zotero-snap/common/Zotero/storage/G7Q6HMNB/Pang et al. - 2019 - A Deep Neural Network Model for Joint Entity and Relation Extraction.pdf","","EXAMPLE; DONE; PTM:Word2Vec; DATASET:Nyt; GRANULARITY:Sentences; ARCHI:Bilstm; TASK:Endtoendre; LANG:English; ARCHI:Pointernet; DATATYPEPROP:String; DECODINGMETHOD_BIN:1; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; ARCHI:Encoder; COSTEVAL_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBDATASET:1; TO_EXCLUDE?; ARCHI:RelEmbedding; ARCHI:POSEmbed; TOCKECH; TASK:RelationIdentification; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GHN7RGKM","conferencePaper","2022","Zhou, Yucheng; Shen, Tao; Geng, Xiubo; Long, Guodong; Jiang, Daxin","ClarET: Pre-training a Correlation-Aware Context-To-Event Transformer for Event-Centric Generation and Classification","Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2022.acl-long.183","https://aclanthology.org/2022.acl-long.183","Generating new events given context with correlated ones plays a crucial role in many eventcentric reasoning tasks. Existing works either limit their scope to specific scenarios or overlook event-level correlations. In this paper, we propose to pre-train a general Correlationaware context-to-Event Transformer (ClarET) for event-centric reasoning. To achieve this, we propose three novel event-centric objectives, i.e., whole event recovering, contrastive eventcorrelation encoding and prompt-based event locating, which highlight event-level correlations with effective training. The proposed ClarET is applicable to a wide range of eventcentric reasoning scenarios, considering its versatility of (i) event-correlation types (e.g., causal, temporal, contrast), (ii) application formulations (i.e., generation and classification), and (iii) reasoning types (e.g., abductive, counterfactual and ending reasoning). Empirical fine-tuning results, as well as zero- and fewshot learning, on 9 benchmarks (5 generation and 4 classification tasks covering 4 reasoning types with diverse event correlations), verify its effectiveness and generalization ability.","2022","2024-08-01 08:12:37","2025-03-22 16:53:14","2023-02-28 16:02:00","2559-2575","","","","","","ClarET","","","","","Association for Computational Linguistics","Dublin, Ireland","en","","","https://paperswithcode.com/paper/claret-pre-training-a-correlation-aware","","DOI.org (Crossref)","","{'citing': ['10.1145/3557893', '10.1007/978-3-031-33383-5_20'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/RVW3JHJE/Zhou et al. - 2022 - ClarET Pre-training a Correlation-Aware Context-To-Event Transformer for Event-Centric Generation a.pdf","","EXAMPLE; DONE; GRANULARITY:Document; GRANULARITY:Sentences; ARCHI:Encoder-Decoder; LANG:English; PTM:Bart; LEARNINGMETHOD:Contrastive; LEARNINGMETHOD:Fewshot; COSTEVAL_BIN:1; DECODINGMETHOD_BIN:1; INPUT:Text; LEARNINGMETHOD:Continual; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; LEARNINGMETHOD:Promptbased; USENEGATIVEEXAMPLE_BIN:1; LEARNINGMETHOD:Pretraining; SYNTHGENERATION_BIN:0; Task:reasoning; DATATYPEPROP:NSP; NBDATASET:10^1; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:NSP; OBJECTPROPERTIES_BIN:0; SOURCE:BOOKCORPUS; MODEL:T5; MODEL:GPT; MODEL:GPT2; MODEL:DELOREAN; MODEL:ROBERTA; MODEL:DEBERTA; MODEL:EventBERT; DATASET:AbductiveCSReasoning; DATASET:CounterfactualStory; DATASET:StoryEndingGen; DATASET:EventProcessComplet; DATASET:CS.StoryGen; NBMODEL:1; MODEL:BART; TASK:EventReasoning; TO_EXCLUDE?; TASK:RelationClassif; TOCKECH; DATASET:MCNC; TASK:RelationIdentification; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","","","","","","","","","","","","",""
"WN9H6KJM","conferencePaper","2023","Josifoski, Martin; Sakota, Marija; Peyrard, Maxime; West, Robert","Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction","","","","10.18653/v1/2023.emnlp-main.96","http://arxiv.org/abs/2303.04132","Large language models (LLMs) show great potential for synthetic data generation. This work shows that useful data can be synthetically generated even for tasks that cannot be solved directly by the LLM: we show that, for problems with structured outputs, it is possible to prompt an LLM to perform the task in the opposite direction, to generate plausible text for the target structure. Leveraging the asymmetry in task difficulty makes it possible to produce large-scale, high-quality data for complex tasks. We demonstrate the effectiveness of this approach on closed information extraction, where collecting ground-truth data is challenging, and no satisfactory dataset exists to date. We synthetically generate a dataset of 1.8M data points, demonstrate its superior quality compared to existing datasets in a human evaluation and use it to finetune small models (220M and 770M parameters). The models we introduce, SynthIE, outperform existing baselines of comparable size with a substantial gap of 57 and 79 absolute points in micro and macro F1, respectively. Code, data, and models are available at https://github.com/epfl-dlab/SynthIE.","2023-03-07","2024-11-19 10:24:54","2025-03-22 16:52:32","2023-03-20 09:04:52","","","","","","","SynthIE","","","","","ACL","","","","","https://paperswithcode.com/paper/exploiting-asymmetry-for-synthetic-training","https://github.com/epfl-dlab/synthie","arXiv.org","","{'citing': ['10.1109/access.2024.3365742'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/6E9A8EXK/Josifoski et al. - 2023 - Exploiting Asymmetry for Synthetic Training Data Generation SynthIE and the Case of Information Ext.pdf","","EXAMPLE; DONE; GRANULARITY:Sentences; NBDATASET:10°; ARCHI:Encoder-Decoder; LANG:English; PTM:Flant5; INPUT:Graph; COSTEVAL_BIN:1; DATASET:Rebel; DECODINGMETHOD_BIN:1; INPUT:Text; LEARNINGMETHOD:Finetuning; LINEARIZEDGRAPH_BIN:1; SYNTHGENERATION_BIN:1; USENEGATIVEEXAMPLE_BIN:0; LEARNINGMETHOD:Promptbased; SOURCE:Wikidata; LOSSUPDATE_BIN:0; DATATYPEPROP:None; OBJECTPROPERTIES_BIN:1; NBTYPEREL:10^2; PTM:Gpt3.5; TASK:EndToEndRE; DATASET_CREATED:WikiCIE_Code; DATASET_CREATED:WikiCIE_Text; MANUALANNOTATION:1; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZI2B39V6","conferencePaper","2021",", Tuan Lai; , Heng Ji; , ChengXiang Zhai; , Quan Hung Tran","Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced Collective Inference","","","","10.18653/v1/2021.acl-long.488","https://arxiv.org/abs/2105.13456v2","Compared to the general news domain, information extraction (IE) from biomedical text requires much broader domain knowledge. However, many previous IE methods do not utilize any external knowledge during inference. Due to the exponential growth of biomedical publications, models that do not go beyond their fixed set of parameters will likely fall behind. Inspired by how humans look up relevant information to comprehend a scientific text, we present a novel framework that utilizes external knowledge for joint entity and relation extraction named KECI (Knowledge-Enhanced Collective Inference). Given an input text, KECI first constructs an initial span graph representing its initial understanding of the text. It then uses an entity linker to form a knowledge graph containing relevant background knowledge for the the entity mentions in the text. To make the final predictions, KECI fuses the initial span graph and the knowledge graph into a more refined graph using an attention mechanism. KECI takes a collective approach to link mention spans to entities by integrating global relational information into local representations using graph convolutional networks. Our experimental results show that the framework is highly effective, achieving new state-of-the-art results in two different benchmark datasets: BioRelEx (binding interaction detection) and ADE (adverse drug event extraction). For example, KECI achieves absolute improvements of 4.59% and 4.91% in F1 scores over the state-of-the-art on the BioRelEx entity and relation extraction tasks.","2021-05-27","2024-11-19 10:39:04","2025-03-22 16:53:04","","NA","","","NA","","","BioRelex","","","","","ACL","","","NA","","https://paperswithcode.com/paper/joint-biomedical-entity-and-relation","https://github.com/laituan245/bio_relex","","","{'citing': ['10.1007/978-981-99-6207-5_15', '10.1016/j.jbi.2023.104418', '10.1016/j.jbi.2023.104456', '10.1016/j.knosys.2022.109129', '10.1109/itaic54216.2022.9836511', '10.1007/978-981-99-4826-0_3', '10.1109/bibm52615.2021.9669360', '10.1007/s11633-023-1461-5', '10.1007/s10489-022-04307-4', '10.1007/978-981-99-9864-7_8', '10.1016/j.eswa.2023.120182', '10.3390/electronics12183939', '10.1109/tcbb.2022.3205113', '10.3390/math11020354', '10.1007/s11633-022-1323-6', '10.1109/bibm55620.2022.9995158', '10.1109/bibm55620.2022.9995077', '10.1007/s00521-023-09226-0', '10.1109/bibm58861.2023.10385666', '10.1109/bibm58861.2023.10385642', '10.1109/access.2021.3130956', '10.1007/s00500-023-08882-7'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/FUIUH8AR/et al. - 2021 - Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced Collective Inference.pdf","","EXAMPLE; DONE; GRANULARITY:Sentences; ARCHI:Gcn; TASK:Endtoendre; LANG:English; PTM:Scibert; INPUT:Graph; DATASET:Ade; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; USENEGATIVEEXAMPLE_BIN:0; NBTYPEREL:10¹; ARCHI:Encoder; LEARNINGMETHOD:Pretraining; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; DATASET:BioRelEx; NBDATASET:10⁰; TO_EXCLUDE?; TOCKECH; TASK:RelationIdentification; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2021 5","","","","","","","","","","","","","","",""
"FM7L9L9F","conferencePaper","2021",", Ningyu Zhang; , Xiang Chen; , Xin Xie; , Shumin Deng; , Chuanqi Tan; , Mosha Chen; , Fei Huang; , Luo Si; , Huajun Chen","Document-level Relation Extraction as Semantic Segmentation","Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence","","","10.24963/ijcai.2021/551","https://arxiv.org/abs/2106.03618v2","Document-level relation extraction aims to extract relations among multiple entity pairs from a document. Previously proposed graph-based or transformer-based models utilize the entities independently, regardless of global information among relational triples. This paper approaches the problem by predicting an entity-level relation matrix to capture local and global information, parallel to the semantic segmentation task in computer vision. Herein, we propose a Document U-shaped Network for document-level relation extraction. Specifically, we leverage an encoder module to capture the context information of entities and a U-shaped segmentation module over the image-style feature map to capture global interdependency among triples. Experimental results show that our approach can obtain state-of-the-art performance on three benchmark datasets DocRED, CDR, and GDA.","2021-06-07","2024-11-19 15:46:40","2024-12-13 10:49:00","","","","","","","","DocuNet","","","","","IJCAI","","","NA","","https://paperswithcode.com/paper/document-level-relation-extraction-as","https://github.com/wutong8023/Awesome_Information_Extraction","","[{""task"": ""Relation Extraction"", ""dataset"": ""GDA"", ""res"": ""85.3"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""62.4"", ""metric"": ""Ign F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""DocRED"", ""res"": ""64.55"", ""metric"": ""F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""CDR"", ""res"": ""76.3"", ""metric"": ""F1""}]","{'citing': ['10.1145/3404835.3462908', '10.1007/s00521-021-06667-3', '10.1145/3508546.3508633', '10.1145/3485447.3511921', '10.1145/3485447.3511998', '10.1007/s00521-022-07223-3', '10.1145/3477495.3531992', '10.1145/3477495.3531746', '10.1109/icme52920.2022.9859701', '10.1007/978-3-031-17120-8_13', '10.1016/j.eswa.2022.117678', '10.1145/3511808.3557313', '10.1109/icpr56361.2022.9956191', '10.1109/ijcnn55064.2022.9892647'], 'cited': []}","","","","EXAMPLE; DONE; PTM:Roberta; ARCHI:Cnn; GRANULARITY:Document; PTM:Bert; LANG:English; PTM:Scibert; DATASET:Docred; DATATYPEPROP:Date; DATATYPEPROP:String; DECODINGMETHOD_BIN:1; INPUT:Text; LEARNINGMETHOD:Finetuning; USENEGATIVEEXAMPLE_BIN:0; ARCHI:Encoder; DATASET:Cdr; ARCHI:Unet; COSTEVAL_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; NBTYPEREL:NSP; NBDATASET:10^0; ARCHI:BiLinearClassif; DATASET:GDA; TASK:RelationClassif; DATATYPEPROP:Values; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IJCAI","","","","","","","","","","","","","","",""
"LQ4KHMGG","conferencePaper","2020","Wang, Jue; Lu, Wei","Two are Better than One: Joint Entity and Relation Extraction with Table-Sequence Encoders","Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","","","10.18653/v1/2020.emnlp-main.133","https://www.aclweb.org/anthology/2020.emnlp-main.133","","2020","2024-11-19 15:56:51","2025-03-22 16:52:34","2023-02-28 16:15:26","1706-1721","","","","","","Table-Sequence","","","","","ACL","Online","en","","","https://paperswithcode.com/paper/two-are-better-than-one-joint-entity-and","https://github.com/LorrinWWW/two-are-better-than-one","DOI.org (Crossref)","[{""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""64.3"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""80.1"", ""metric"": ""RE Macro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""59.6"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""88.6"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""59.6"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""64.3"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""No"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""ALBERT"", ""metric"": ""Sentence Encoder""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""89.7"", ""metric"": ""NER Macro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""67.6"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""No"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""63.3"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""80.1"", ""metric"": ""RE+ Macro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""63.3"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""89.5"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""67.6"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Zero-shot Relation Triplet Extraction"", ""dataset"": ""Wiki-ZSL"", ""res"": ""6.4"", ""metric"": ""Avg. F1""}, {""task"": ""Zero-shot Relation Triplet Extraction"", ""dataset"": ""FewRel"", ""res"": ""6.37"", ""metric"": ""Avg. F1""}]","{'citing': ['10.1109/icpr56361.2022.9956191', '10.1109/ijcnn54540.2023.10191251', '10.1109/ijcnn54540.2023.10191693', '10.1007/s13278-023-01095-8', '10.1007/s10115-022-01665-w', '10.3390/app122110824', '10.1007/978-3-031-39965-7_49', '10.1016/j.neucom.2022.04.059', '10.32604/iasc.2022.028352', '10.1109/tai.2022.3205567', '10.1016/j.compag.2022.106776', '10.1109/taslp.2024.3350905', '10.1080/09540091.2022.2026295', '10.1145/3554734', '10.3390/app13074636', '10.1007/978-981-99-6207-5_15', '10.1016/j.jbi.2023.104456', '10.1007/s12559-021-09917-7', '10.1016/j.knosys.2022.109129', '10.1109/cscwd54268.2022.9776159', '10.1007/978-3-031-17120-8_21', '10.3390/app131810538', '10.5715/jnlp.29.187', '10.1038/s41598-022-26116-y', '10.1109/cisp-bmei60920.2023.10373243', '10.1109/ijcnn54540.2023.10191826', '10.1007/978-3-030-93733-1_23', '10.1145/3530190.3534850', '10.1093/bib/bbac342', '10.1109/access.2022.3232493', '10.1109/bigdata55660.2022.10020994', '10.1016/j.jii.2021.100301', '10.1016/j.knosys.2023.110471', '10.1109/bigdata55660.2022.10020308', '10.2478/cait-2023-0014', '10.1109/tkde.2023.3303136', '10.1162/coli_a_00415', '10.3390/app12126231', '10.1007/978-3-031-34560-9_28', '10.1017/s1471068423000297', '10.1109/icmla55696.2022.00254', '10.1007/978-3-031-37717-4_48', '10.1109/access.2023.3299880', '10.1186/s12911-023-02127-1', '10.1007/s10489-023-04970-1', '10.1007/978-3-031-24755-2_8', '10.1080/10095020.2022.2076619', '10.1007/978-3-031-18315-7_11', '10.1016/j.eswa.2023.120182', '10.1016/j.eswa.2023.120435', '10.1007/s40747-023-01321-y', '10.1049/cim2.12073', '10.3390/electronics12010121', '10.1016/j.eswa.2023.122007', '10.1007/978-981-19-6142-7_10', '10.1007/s11633-022-1323-6', '10.1016/j.neunet.2023.03.001', '10.1038/s41746-022-00742-2', '10.1007/978-3-030-88483-3_37', '10.1109/bigdata52589.2021.9671514', '10.1016/j.jksuci.2022.08.038', '10.1109/bibm58861.2023.10385666', '10.1007/978-981-16-5188-5_2', '10.1109/iccc54389.2021.9674535', '10.1007/978-3-031-44223-0_9', '10.1016/j.cogsys.2023.101153', '10.1371/journal.pone.0298974', '10.1007/s40747-023-01004-8', '10.3389/fdgth.2021.620828'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/3FW2S3GN/Wang and Lu - 2020 - Two are Better than One Joint Entity and Relation Extraction with Table-Sequence Encoders.pdf","","EXAMPLE; DONE; PTM:Roberta; ARCHI:Cnn; GRANULARITY:Document; PTM:Bert; PTM:Elmo; LANG:Arabic; LANG:Chinese; LANG:English; PTM:Albert; DATASET:Ace2005; DATASET:Fewrel; DATASET:Ade; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; INPUT:Embedding; USENEGATIVEEXAMPLE_BIN:1; ARCHI:Encoder; NBTYPEREL:10³; DATASET:Conll; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; OBJECTPROPERTIES_BIN:1; DATATYPEPROP:NSP; TASK:NER; DATASET:Ace2004; LINEARIZEDGRAPH_BIN:0; NBDATASET:10^0; ARCHI:RNN; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","","","","","","","","","","","","","","",""
"4T4GGUQJ","conferencePaper","2020",", Hao Peng; , Tianyu Gao; , Xu Han; , Yankai Lin; , Peng Li; , Zhiyuan Liu; , Maosong Sun; , Jie zhou","Learning from Context or Names? An Empirical Study on Neural Relation Extraction","","","","10.18653/v1/2020.emnlp-main.298","https://arxiv.org/abs/2010.01923v2","Neural models have achieved remarkable success on relation extraction (RE) benchmarks. However, there is no clear understanding which type of information affects existing RE models to make decisions and how to further improve the performance of these models. To this end, we empirically study the effect of two main information sources in text: textual context and entity mentions (names). We find that (i) while context is the main source to support the predictions, RE models also heavily rely on the information from entity mentions, most of which is type information, and (ii) existing datasets may leak shallow heuristics via entity mentions and thus contribute to the high performance on RE benchmarks. Based on the analyses, we propose an entity-masked contrastive pre-training framework for RE to gain a deeper understanding on both textual context and type information while avoiding rote memorization of entities or use of superficial cues in mentions. We carry out extensive experiments to support our views, and show that our framework can improve the effectiveness and robustness of neural models in different RE scenarios. All the code and datasets are released at https://github.com/thunlp/RE-Context-or-Names.","2020-10-05","2024-11-19 16:23:47","2025-03-22 16:52:43","","NA","","","NA","","","MTB","","","","","ACL","","","NA","","https://paperswithcode.com/paper/learning-from-context-or-names-an-empirical","https://github.com/thunlp/RE-Context-or-Names","","{""TACRED"": {""F1"": ""69.5""}}","{'citing': ['10.1145/3539618.3591911', '10.3934/mbe.2022240', '10.3390/electronics11223715', '10.1145/3474085.3476968', '10.1109/taslp.2022.3226680', '10.3390/app13148312', '10.1145/3511808.3557313', '10.1145/3511808.3557459', '10.1109/smc53992.2023.10394492', '10.1007/s00500-022-07195-5', '10.1007/978-3-031-30678-5_10', '10.1109/taslp.2022.3161146', '10.1007/978-3-031-10983-6_31', '10.1007/s11280-023-01142-6', '10.3390/e26030210', '10.1016/j.knosys.2023.110471', '10.1016/j.knosys.2022.109184', '10.1145/3477495.3531789', '10.3390/a16020102', '10.1007/978-3-031-08473-7_29', '10.1007/978-981-99-4826-0_3', '10.1007/978-3-031-34560-9_28', '10.1109/taslp.2022.3153256', '10.1007/s10462-023-10580-7', '10.1007/978-3-031-18315-7_7', '10.1016/j.eswa.2023.120435', '10.1162/dint_a_00190', '10.3390/electronics12132912', '10.1109/tkde.2023.3240851', '10.1109/tkde.2022.3208617', '10.1016/j.datak.2023.102265', '10.1371/journal.pone.0281055', '10.1007/978-3-031-40283-8_13', '10.1371/journal.pone.0286915', '10.1016/j.neucom.2023.03.005', '10.1134/s1995080223010456', '10.1109/bibm55620.2022.9995416', '10.1145/3539618.3591984', '10.1007/978-3-030-84186-7_13', '10.1007/978-3-030-88480-2_23', '10.1007/978-3-030-88483-3_40', '10.1109/ijcnn54540.2023.10191841', '10.1109/tkde.2023.3292974', '10.1109/tkde.2022.3177226', '10.1145/3462244.3479895', '10.1007/s10489-022-03596-z', '10.1007/s10489-022-03210-2', '10.1109/icassp49357.2023.10096551', '10.1109/cisp-bmei60920.2023.10373223', '10.3390/app122211522'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/YN9DG2DD/et al. - 2020 - Learning from Context or Names An Empirical Study on Neural Relation Extraction.pdf","","EXAMPLE; DONE; ARCHI:Cnn; GRANULARITY:Sentences; PTM:Bert; LANG:English; DATASET:Fewrel; LEARNINGMETHOD:Contrastive; LEARNINGMETHOD:Fewshot; COSTEVAL_BIN:1; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LOSSUPDATE_BIN:1; LEARNINGMETHOD:Promptbased; USENEGATIVEEXAMPLE_BIN:1; SOURCE:Wikidata; LEARNINGMETHOD:Pretraining; DECODINGMETHOD_BIN:0; SYNTHGENERATION_BIN:0; NBTYPEREL:10^1; OBJECTPROPERTIES_BIN:1; LINEARIZEDGRAPH_BIN:0; DATASET:TACRED; PTM:MTB; DATASET:ChemProt; DATASET:Semeval2010; NBDATASET:10⁰; ARCHI:ProtoNet; TO_EXCLUDE?; INPUT:NER; DATASET:Fewrel2.0; TASK:RelationClassif; TOCKECH; DatasetSplit:Random","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2020 11","","","","","","","","","","","","","","",""