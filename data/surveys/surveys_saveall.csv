"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"MHQK7WDB","conferencePaper","2022","Ali, Manzoor; Saleem, Muhammad; Ngomo, Axel-Cyrille Ngonga","REBench: Microbenchmarking Framework for Relation Extraction Systems","The Semantic Web – ISWC 2022","","","10.1007/978-3-031-19433-7_37","https://link.springer.com/10.1007/978-3-031-19433-7_37","In recent years, several relation extractions (RE) models have been developed to extract knowledge from natural language texts. Accordingly, several benchmark datasets have been proposed to evaluate these models. These RE datasets consisted of natural language sentences with a fixed number of relations from a particular domain. Albeit useful for general-purpose RE benchmarking, they do not allow the generation of customized microbenchmarks according to user-specified criteria for a specific use case. Microbenchmarks are key to testing the individual functionalities of a system and hence pinpoint component-based insights. This article proposes REBench, a framework for microbenchmarking RE systems, which can select customized relation samples from existing RE datasets from diverse domains. The framework is flexible enough to choose relation samples of different sizes and according to the user-defined criteria on essential features to be considered for RE benchmarking. We used various clustering algorithms to generate microbenchmarks. We evaluated the state-of-the-art RE systems using different RE benchmarking samples. The evaluation results show that specialized microbenchmarking is crucial for identifying the limitations of various RE models and their components.","2022","2023-02-28 15:36:32","2025-02-04 17:18:54","2023-02-28 15:36:32","643-659","","","13489","","","","","","","","Springer","","en","False but accesible","","","","DOI.org (Crossref)","","{'citing': [], 'cited': ['10.1007/978-3-319-25007-6_4', '10.1007/978-3-642-15939-8_10', '10.1007/s10115-022-01665-w', '10.1016/j.ipm.2021.102563', '10.1145/1376616.1376746', '10.1145/3442381.3449917', '10.1145/375663.375774', '10.1162/089120100561737', '10.18653/v1/2020.acl-main.136', '10.18653/v1/2020.acl-main.669', '10.18653/v1/2020.coling-main.138', '10.18653/v1/2020.emnlp-main.304', '10.18653/v1/2021.emnlp-main.17', '10.18653/v1/2021.findings-acl.34', '10.18653/v1/2021.findings-emnlp.204', '10.18653/v1/d15-1056', '10.18653/v1/d17-1004', '10.18653/v1/d17-1108', '10.18653/v1/d17-1188', '10.18653/v1/d18-1360', '10.18653/v1/d18-1514', '10.18653/v1/p17-1017', '10.18653/v1/p17-1053', '10.18653/v1/p18-1047', '10.18653/v1/p19-1074', '10.18653/v1/p19-1128', '10.18653/v1/p19-1279', '10.3115/1621969.1621986', '10.48550/arxiv.2009.06207', '10.48550/arxiv.2102.01373']}","","/root/snap/zotero-snap/common/Zotero/storage/GIX6HHNU/Ali et al. - 2022 - REBench Microbenchmarking Framework for Relation .pdf","","manual; SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_task:Classif; SAT_type:Benchmark; SAT_focus:datasets; FOCUS_STUDY_OCT; CHECKED1023; SAT_nbModel:4; SAT_interest:10; SAT_focus_period:2015-2021; SAT_dataset:RELD; SAT_nbDataset:8; SAT_model:REBEL; SAT_model:BREDS; SAT_focus:Selection; SAT_task:TripleClustering; SAT_typology_dim:Supervised; SAT_typology_dim:Boostraping","","Sattler, Ulrike; Hogan, Aidan; Keet, Maria; Presutti, Valentina; Almeida, João Paulo A.; Takeda, Hideaki; Monnin, Pierre; Pirrò, Giuseppe; d’Amato, Claudia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ISWC","","","","","","","","","","","","","","",""
"3QMV7B8U","conferencePaper","2022","Bassignana, Elisa; Plank, Barbara","What do You Mean by Relation Extraction? A Survey on Datasets and Study on Scientific Relation Classification","Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop","","","10.18653/v1/2022.acl-srw.7","http://arxiv.org/abs/2204.13516","Over the last ﬁve years, research on Relation Extraction (RE) witnessed extensive progress with many new dataset releases. At the same time, setup clarity has decreased, contributing to increased difﬁculty of reliable empirical evaluation (Taillé et al., 2020). In this paper, we provide a comprehensive survey of RE datasets, and revisit the task deﬁnition and its adoption by the community. We ﬁnd that crossdataset and cross-domain setups are particularly lacking. We present an empirical study on scientiﬁc Relation Classiﬁcation across two datasets. Despite large data overlap, our analysis reveals substantial discrepancies in annotation. Annotation discrepancies strongly impact Relation Classiﬁcation performance, explaining large drops in cross-dataset evaluations. Variation within further sub-domains exists but impacts Relation Classiﬁcation only to limited degrees. Overall, our study calls for more rigour in reporting setups in RE and evaluation across multiple test sets.","2022-04-28","2023-03-28 11:47:04","2025-02-04 17:18:54","2023-03-28 11:47:04","","","","","","","","","","","","ACL","","en","True","","","","arXiv.org","","{'citing': ['10.3390/math10224378'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/9AMG42D8/Bassignana and Plank - 2022 - What do You Mean by Relation Extraction A Survey .pdf","","star; SAT_model:BERT; SAT_oldTag:CHECKED0923; SAT_task:RC; SAT_focus:TransferLearning; SAT_archi:Transformer; SAT_archi:CNN; SAT_model:SciBERT; SAT_domain:science; SAT_type:Benchmark; SAT_focus:datasets; SAT_focus:Pipeline; SAT_focus:JoinModel; SAT_focus:Embeddings; SAT_typology:False; SAT_nbDataset:17; FOCUS_STUDY_OCT; CHECKED1023; SAT_dataset:ACE; SAT_benchmark_type:Quantitative; SAT_dataset:SemEval; SAT_dataset:FewRel; SAT_dataset:DocRED; SAT_interest:10; SAT_type:DetailedSurvey; SAT_focus_period:2017-2021; SAT_dataset:CONLL; SAT_dataset:FSL TACRED; SAT_dataset:DWIE; SAT_dataset:SciERC; SAT_dataset:ScienceIE; SAT_dataset:GoogleRE; SAT_dataset:SMiler; SAT_nbModel:28; SAT_focus:AnnotationQuality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL-SRW","","","","","","","","","","","","","","",""
"FZDVWGJS","conferencePaper","2013","Gangemi, Aldo","A Comparison of Knowledge Extraction Tools for the Semantic Web","The Semantic Web: Semantics and Big Data","978-3-642-38288-8","","10.1007/978-3-642-38288-8_24","","In the last years, basic NLP tasks: NER, WSD, relation extraction, etc. have been configured for Semantic Web tasks including ontology learning, linked data population, entity resolution, NL querying to linked data, etc. Some assessment of the state of art of existing Knowledge Extraction (KE) tools when applied to the Semantic Web is then desirable. In this paper we describe a landscape analysis of several tools, either conceived specifically for KE on the Semantic Web, or adaptable to it, or even acting as aggregators of extracted data from other tools. Our aim is to assess the currently available capabilities against a rich palette of ontology design constructs, focusing specifically on the actual semantic reusability of KE output.","2013","2023-02-03 16:42:51","2023-06-06 06:39:55","","351-366","","","","","","","Lecture Notes in Computer Science","","","","Springer","Berlin, Heidelberg","en","","","","","Springer Link","","{'citing': ['10.1007/978-3-319-53640-8_5', '10.1007/978-3-319-04244-2_19', '10.1007/s13278-022-00894-9', '10.1145/2843043.2843378', '10.1109/aike.2019.00043', '10.2139/ssrn.3248493', '10.1007/978-3-319-70863-8_18', '10.1007/s13218-016-0425-0', '10.1109/mitp.2018.011291354', '10.1007/s10257-018-0368-0', '10.3233/ds-170012', '10.1007/978-3-319-18818-8_34', '10.1007/978-3-319-20267-9_31', '10.2139/ssrn.3199181', '10.1007/978-3-319-11955-7_29', '10.4018/ijswis.2018100106', '10.1007/978-3-319-25518-7_10', '10.1007/978-3-319-41718-9_7', '10.1007/978-3-319-34129-3_50', '10.1007/s10844-020-00621-w', '10.1109/icsc50631.2021.00024', '10.1016/j.jksuci.2020.05.008', '10.1007/978-3-319-27478-2_11', '10.1007/978-3-319-11955-7_13', '10.1007/978-3-319-24309-2_28', '10.1109/bigdata.2017.8258091', '10.1145/3014812.3014867', '10.3233/sw-140158', '10.4018/978-1-5225-0846-5.ch012', '10.1007/978-3-030-16181-1_27', '10.1145/2899005', '10.3233/sw-160228', '10.3390/info13010004', '10.1145/3148011.3148035', '10.1142/s0218194019500487', '10.2139/ssrn.3198924', '10.1007/978-3-319-11964-9_33', '10.1109/icde51399.2021.00012', '10.1007/978-3-319-34129-3_53', '10.3233/sw-160240', '10.3233/sw-180333', '10.1007/978-3-319-39396-4_30', '10.1007/978-3-319-46565-4_22', '10.3233/sw-160221', '10.1007/978-3-319-19581-0_33', '10.1007/978-3-319-70407-4_9', '10.1145/2740908.2741709', '10.3233/sw-212838', '10.1007/978-3-030-35758-0_23', '10.1142/s0218194020400197', '10.1145/3448016.3457238', '10.1007/978-3-030-51253-8_7', '10.3233/web-210491', '10.1145/3213586.3226208', '10.1109/dsaa.2017.33', '10.1007/978-3-319-49004-5_21', '10.1007/978-3-319-26561-2_44', '10.1007/978-3-319-58068-5_18', '10.1109/iiai-aai.2017.21', '10.1145/2740908.2742842', '10.1007/978-3-319-09870-8_15', '10.1007/978-3-319-07443-6_55', '10.1145/2851613.2851845', '10.1016/j.websem.2014.11.001'], 'cited': ['10.1007/978-3-642-38288-8_24']}","","/root/snap/zotero-snap/common/Zotero/storage/MEJ7EIBC/Gangemi - 2013 - A Comparison of Knowledge Extraction Tools for the.pdf","","light","Entity Recognition; Knowledge Extraction; Natural Language Processing; Relation Extraction; Word Sense Disambiguation","Cimiano, Philipp; Corcho, Oscar; Presutti, Valentina; Hollink, Laura; Rudolph, Sebastian","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ESWC","","","","","","","","","","","","","","",""
"EC6K8WQN","conferencePaper","2022",", Mourad Sarrouti; , Carson Tao; , Yoann Mamy Randriamihaja","Comparing Encoder-Only and Encoder-Decoder Transformers for Relation Extraction from Biomedical Texts: An Empirical Study on Ten Benchmark Datasets","BioNLP (ACL) 2022 5","","","10.18653/v1/2022.bionlp-1.37","https://aclanthology.org/2022.bionlp-1.37","Biomedical relation extraction, aiming to automatically discover high-quality and semantic relations between the entities from free text, is becoming a vital step for automated knowledge discovery. Pretrained language models have achieved impressive performance on various natural language processing tasks, including relation extraction. In this paper, we perform extensive empirical comparisons of encoder-only transformers with the encoder-decoder transformer, specifically T5, on ten public biomedical relation extraction datasets. We study the relation extraction task from four major biomedical tasks, namely chemical-protein relation extraction, disease-protein relation extraction, drug-drug interaction, and protein-protein interaction. We also explore the use of multi-task fine-tuning to investigate the correlation among major biomedical relation extraction tasks. We report performance (micro F-score) using T5, BioBERT and PubMedBERT, demonstrating that T5 and multi-task learning can improve the performance of the biomedical relation extraction task.","2022-05-01","2023-05-03 16:17:32","2025-02-04 17:18:54","","NA","","","NA","","","","","","","","ACL","","","NA","","https://paperswithcode.com/paper/comparing-encoder-only-and-encoder-decoder","NA","","","","","/root/snap/zotero-snap/common/Zotero/storage/5NSJPX6B/ et al. - 2022 - Comparing Encoder-Only and Encoder-Decoder Transfo.pdf","","SAT_task:RE; SAT_granularity:sentence; SAT_focus:TransferLearning; SAT_model:T5; SAT_domain:biomedical; SAT_model:PubMedBERT; SAT_model:BioBERT; SAT_type:Benchmark; SAT_focus:LLM; FOCUS_STUDY_OCT; CHECKED1023; SAT_benchmark_type:Quantitative; SAT_interest:10; SAT_nbDataset:10; SAT_focus:ErrorAnalysis; SAT_focus_period:2019-2021; donthavecode; notbenchmarked; SAT_focus:EncoderVSEncoderDecoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","BioNLP","","","","","","","","","","","","","","",""
"RIW5I4ZX","journalArticle","2023","Lingfeng Zhong, Jia Wu; , Qian Li; , Hao Peng; , Xindong Wu","A Comprehensive Survey on Automatic Knowledge Graph Construction","ACM","","","not found","nan","Automatic knowledge graph construction aims to manufacture structured human knowledge. To this end, much effort has historically been spent extracting informative fact patterns from different data sources. However, more recently, research interest has shifted to acquiring conceptualized structured knowledge beyond informative data. In addition, researchers have also been exploring new ways of handling sophisticated construction tasks in diversified scenarios. Thus, there is a demand for a systematic review of paradigms to organize knowledge structures beyond data-level mentions. To meet this demand, we comprehensively survey more than 300 methods to summarize the latest developments in knowledge graph construction. A knowledge graph is built in three steps: knowledge acquisition, knowledge refinement, and knowledge evolution. The processes of knowledge acquisition are reviewed in detail, including obtaining entities with fine-grained types and their conceptual linkages to knowledge graphs; resolving coreferences; and extracting entity relationships in complex scenarios. The survey covers models for knowledge refinement, including knowledge graph completion, and knowledge fusion. Methods to handle knowledge evolution are also systematically presented, including condition knowledge acquisition, condition knowledge graph completion, and knowledge dynamic. We present the paradigms to compare the distinction among these methods along the axis of the data environment, motivation, and architecture. Additionally, we also provide briefs on accessible resources that can help readers to develop practical knowledge graph systems. The survey concludes with discussions on the challenges and possible directions for future exploration.","2023-02-10","2023-03-01 14:34:10","2025-02-04 17:18:54","","","","","","","ACM Comput. Surv.","","","","","","","","","nan","","Arxiv","http://arxiv.org/abs/2302.05019v1","","","","","","","acm; SAT_focus:OpenIE; SAT_focus:KnowledgeIntegration; SAT_focus:KnowledgeAcquisition; SAT_model:BERT; SAT_task:RE; SAT_task:Reasoning; SAT_granularity:document; SAT_granularity:sentence; SAT_task:RC; SAT_task:CorefReso; SAT_task:EntityLinking; SAT_task:EntityTyping; SAT_task:NER; SAT_archi:BiLSTM; SAT_archi:CNN; SAT_task:KnowledgeFusion; SAT_archi:GCN; SAT_archi:LSTM; SAT_context:MultiModal; SAT_model:Elmo; SAT_archi:MaxPooling; SAT_archi:PCNN; SAT_focus:BackgroundKnowledge; SAT_focus:FewSHot; SAT_type:Survey; SAT_focus:distant; FOCUS_STUDY_OCT; SAT_task:JoinRE; CHECKED1023; SAT_nbModel:31; SAT_interest:8; SAT_task:TripleClustering; HERE; SAT_task:KnowledgeCompletion; SAT_archi:RSN; SAT_archi:MIML; SAT_archi:Markov","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GMUXZ944","preprint","2022",", Wei Li; , Wenhao Wu; , Moye Chen; , Jiachen Liu; , Xinyan Xiao; , Hua Wu","Faithfulness in Natural Language Generation: A Systematic Survey of Analysis, Evaluation and Optimization Methods","","","","not found","https://arxiv.org/abs/2203.05227v1","Natural Language Generation (NLG) has made great progress in recent years due to the development of deep learning techniques such as pre-trained language models. This advancement has resulted in more fluent, coherent and even properties controllable (e.g. stylistic, sentiment, length etc.) generation, naturally leading to development in downstream tasks such as abstractive summarization, dialogue generation, machine translation, and data-to-text generation. However, the faithfulness problem that the generated text usually contains unfaithful or non-factual information has become the biggest challenge, which makes the performance of text generation unsatisfactory for practical applications in many real-world scenarios. Many studies on analysis, evaluation, and optimization methods for faithfulness problems have been proposed for various tasks, but have not been organized, compared and discussed in a combined manner. In this survey, we provide a systematic overview of the research progress on the faithfulness problem of NLG, including problem analysis, evaluation metrics and optimization methods. We organize the evaluation and optimization methods for different tasks into a unified taxonomy to facilitate comparison and learning across tasks. Several research trends are discussed further.","2022-03-10","2023-04-07 15:36:58","2023-10-23 21:53:02","","","","","","","","","","","","","","","","NA","","https://paperswithcode.com/paper/faithfulness-in-natural-language-generation-a","NA","","","","","/root/snap/zotero-snap/common/Zotero/storage/GQUJPK4T/ et al. - 2022 - Faithfulness in Natural Language Generation A Sys.pdf","","SAT_focus:OpenIE; SAT_task:Translation; SAT_task:TextGeneration; SAT_task:Summarization; SAT_learning:adversarial; SAT_model:T5; SAT_model:BART; SAT_learning:contrastive; SAT_archi:GCN; SAT_type:Survey; SAT_focus:models; SAT_task:Data-to-text; CHECKED1023; SAT_interest:10; HERE; SAT_model:OpenIE; SAT_focus:TextGeneration; SAT_typology_dim:Optimisation; SAT_typology_dim:ProblemAnalysis; SAT_typology_dim:Eval; SAT_task:DialogGeneration; SAT_focus:Faithfulness; SAT_typology_dim:ErrorAnalysi; SAT_model:PEGASUS; SAT_model:TranS2S; SAT_model:BERTSum; SAT_focus_period:1983-2022; SAT_task:Dialog; SAT_focus:EVAL; SAT_task:Summazization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VXP7RU79","journalArticle","2022",", William Hogan","An Overview of Distant Supervision for Relation Extraction with a Focus on Denoising and Pre-training Methods","","","","10.48550/arXiv.2207.08286","https://www.semanticscholar.org/paper/c69bf57b78c1c00925754c11449ae623ef14c1bb","Relation Extraction (RE) is a foundational task of natural language processing. RE seeks to transform raw, unstructured text into structured knowledge by identifying relational information between entity pairs found in text. RE has numerous uses, such as knowledge graph completion, text summarization, question-answering, and search querying. The history of RE methods can be roughly organized into four phases: pattern-based RE, statistical-based RE, neural-based RE, and large language model-based RE. This survey begins with an overview of a few exemplary works in the earlier phases of RE, highlighting limitations and shortcomings to contex-tualize progress. Next, we review popular benchmarks and critically examine metrics used to assess RE performance. We then dis-cuss distant supervision, a paradigm that has shaped the development of modern RE methods. Lastly, we review recent RE works focusing on denoising and pre-training methods.","2022-07-17","2023-02-03 15:56:23","2023-03-20 09:00:06","","nan","","nan","abs/2207.08286","","ArXiv","","","","","","","","","FALSE","","SemanticScholar","c69bf57b78c1c00925754c11449ae623ef14c1bb","","","","","","","remarkable","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8LGLFV9M","conferencePaper","2018","Nam, Sangha; Han, Kijong; Kim, Eun-Kyung; Choi, Key-Sun","Distant Supervision for Relation Extraction with Multi-sense Word Embedding","Proceedings of the 9th Global Wordnet Conference","","","","https://aclanthology.org/2018.gwc-1.27","Distant supervision can automatically generate labeled data between a large-scale corpus and a knowledge base without utilizing human efforts. Therefore, many studies have used the distant supervision approach in relation extraction tasks. However, existing studies have a disadvantage in that they do not reflect the homograph in the word embedding used as an input of the relation extraction model. Thus, it can be seen that the relation extraction model learns without grasping the meaning of the word accurately. In this paper, we propose a relation extraction model with multi-sense word embedding. We learn multi-sense word embedding using a word sense disambiguation module. In addition, we use convolutional neural network and piecewise max pooling convolutional neural network relation extraction models that efficiently grasp key features in sentences. To evaluate the performance of the proposed model, two additional methods of word embedding were learned and compared. Accordingly, our method showed the highest performance among them.","2018-01","2023-02-28 17:41:17","2023-02-28 17:41:17","2023-02-28 17:41:17","239–244","","","","","","","","","","","Global Wordnet Association","Nanyang Technological University (NTU), Singapore","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/57JUXQDT/Nam et al. - 2018 - Distant Supervision for Relation Extraction with M.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","GWC 2018","","","","","","","","","","","","","","",""
"4YP7MES2","preprint","2020","Luo, Guoqing; Pan, Jiaxin; Peng, Min","RDSGAN: Rank-based Distant Supervision Relation Extraction with Generative Adversarial Framework","","","","10.48550/arXiv.2009.14722","http://arxiv.org/abs/2009.14722","Distant supervision has been widely used for relation extraction but suffers from noise labeling problem. Neural network models are proposed to denoise with attention mechanism but cannot eliminate noisy data due to its non-zero weights. Hard decision is proposed to remove wrongly-labeled instances from the positive set though causes loss of useful information contained in removed instances. In this paper, we propose a novel generative neural framework named RDSGAN (Rank-based Distant Supervision GAN) which automatically generates valid instances for distant supervision relation extraction. Our framework combines soft attention and hard decision to learn the distribution of true positive instances via adversarial training and selects valid instances conforming to the distribution via rank-based distant supervision, which addresses the false positive problem. Experimental results show the superiority of our framework over strong baselines.","2020-09-30","2023-02-28 17:40:58","2023-02-28 17:40:58","2023-02-28 17:40:58","","","","","","","RDSGAN","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2009.14722 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/57PKZE8T/Luo et al. - 2020 - RDSGAN Rank-based Distant Supervision Relation Ex.pdf; /root/snap/zotero-snap/common/Zotero/storage/7R9AZNHY/2009.html","","","Computer Science - Computation and Language; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2009.14722","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7KVCE3VP","preprint","2018","Qin, Pengda; Xu, Weiran; Wang, William Yang","DSGAN: Generative Adversarial Training for Distant Supervision Relation Extraction","","","","10.48550/arXiv.1805.09929","http://arxiv.org/abs/1805.09929","Distant supervision can effectively label data for relation extraction, but suffers from the noise labeling problem. Recent works mainly perform soft bag-level noise reduction strategies to find the relatively better samples in a sentence bag, which is suboptimal compared with making a hard decision of false positive samples in sentence level. In this paper, we introduce an adversarial learning framework, which we named DSGAN, to learn a sentence-level true-positive generator. Inspired by Generative Adversarial Networks, we regard the positive samples generated by the generator as the negative samples to train the discriminator. The optimal generator is obtained until the discrimination ability of the discriminator has the greatest decline. We adopt the generator to filter distant supervision training dataset and redistribute the false positive instances into the negative set, in which way to provide a cleaned dataset for relation classification. The experimental results show that the proposed strategy significantly improves the performance of distant supervision relation extraction comparing to state-of-the-art systems.","2018-05-24","2023-02-28 17:31:31","2023-02-28 17:31:31","2023-02-28 17:31:31","","","","","","","DSGAN","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1805.09929 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/ATZMXBJP/Qin et al. - 2018 - DSGAN Generative Adversarial Training for Distant.pdf; /root/snap/zotero-snap/common/Zotero/storage/ULR8UN6B/1805.html","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:1805.09929","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EV9UILU4","preprint","2017","Madan, Gagan","A Survey of Distant Supervision Methods using PGMs","","","","10.48550/arXiv.1705.03751","http://arxiv.org/abs/1705.03751","Relation Extraction refers to the task of populating a database with tuples of the form $r(e_1, e_2)$, where $r$ is a relation and $e_1$, $e_2$ are entities. Distant supervision is one such technique which tries to automatically generate training examples based on an existing KB such as Freebase. This paper is a survey of some of the techniques in distant supervision which primarily rely on Probabilistic Graphical Models (PGMs).","2017-05-10","2023-02-28 17:31:22","2023-02-28 17:31:22","2023-02-28 17:31:22","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1705.03751 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/UBIWWWYI/Madan - 2017 - A Survey of Distant Supervision Methods using PGMs.pdf; /root/snap/zotero-snap/common/Zotero/storage/7TJW7BNX/1705.html","","","Computer Science - Computation and Language; Computer Science - Artificial Intelligence","","","","","","","","","","","","","","","","","","","arXiv:1705.03751","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZSRQIDKW","conferencePaper","2013",", Wei Xu; , Raphael Hoffmann; , Le Zhao; , R. Grishman","Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction","","","","nan","https://www.semanticscholar.org/paper/81bed85b8533c6efb07757ca825fa05adad38bde","Distant supervision has attracted recent interest for training information extraction systems because it does not require any human annotation but rather employs existing knowledge bases to heuristically label a training corpus. However, previous work has failed to address the problem of false negative training examples mislabeled due to the incompleteness of knowledge bases. To tackle this problem, we propose a simple yet novel framework that combines a passage retrieval model using coarse features into a state-of-the-art relation extractor using multi-instance learning with fine features. We adapt the information retrieval technique of pseudorelevance feedback to expand knowledge bases, assuming entity pairs in top-ranked passages are more likely to express a relation. Our proposed technique significantly improves the quality of distantly supervised relation extraction, boosting recall from 47.7% to 61.2% with a consistently high level of precision of around 93% in the experiments.","2013","2023-02-03 15:59:29","2023-02-03 16:29:39","","665-670","","","nan","","","","","","","","nan","","","FALSE","","SemanticScholar","81bed85b8533c6efb07757ca825fa05adad38bde","","","","","","","automatic","⚠️ Invalid DOI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Annual Meeting of the Association for Computational Linguistics","","","","","","","","","","","","","","",""
"JHBSUA97","conferencePaper","2010","Riedel, Sebastian; Yao, Limin; McCallum, Andrew","Modeling Relations and Their Mentions without Labeled Text","Machine Learning and Knowledge Discovery in Databases","978-3-642-15939-8","","10.1007/978-3-642-15939-8_10","","Several recent works on relation extraction have been applying the distant supervision paradigm: instead of relying on annotated text to learn how to predict relations, they employ existing knowledge bases (KBs) as source of supervision. Crucially, these approaches are trained based on the assumption that each sentence which mentions the two related entities is an expression of the given relation. Here we argue that this leads to noisy patterns that hurt precision, in particular if the knowledge base is not directly related to the text we are working with. We present a novel approach to distant supervision that can alleviate this problem based on the following two ideas: First, we use a factor graph to explicitly model the decision whether two entities are related, and the decision whether this relation is mentioned in a given sentence; second, we apply constraint-driven semi-supervision to train this model without any knowledge about which sentences express the relations in our training KB. We apply our approach to extract relations from the New York Times corpus and use Freebase as knowledge base. When compared to a state-of-the-art approach for relation extraction under distant supervision, we achieve 31% error reduction.","2010","2023-03-20 09:03:25","2023-04-05 12:45:54","","148-163","","","","","","","Lecture Notes in Computer Science","","","","Springer","Berlin, Heidelberg","en","","","","","Springer Link","","{'citing': ['10.1109/idsta53674.2021.9660801', '10.1007/978-3-030-04284-4_5', '10.4018/ijswis.2020040101', '10.3390/app12136361', '10.1002/cae.22122', '10.1109/itaic54216.2022.9836511', '10.1145/3554734', '10.1007/s11280-019-00765-y', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00096', '10.1007/978-3-030-55130-8_11', '10.1007/978-3-319-26832-3_55', '10.1007/978-981-10-7359-5_6', '10.1109/ictai.2019.00040', '10.1007/978-3-319-11382-1_12', '10.1007/978-3-319-78583-7_2', '10.1109/dsc50466.2020.00021', '10.1155/2021/7466114', '10.1016/j.knosys.2020.105912', '10.1088/1742-6596/1550/3/032065', '10.1007/978-3-030-41407-8_12', '10.1145/3207677.3278063', '10.1007/978-3-030-21348-0_3', '10.1007/978-3-030-00671-6_3', '10.1007/978-3-319-77525-8_285', '10.1145/3340531.3412164', '10.1007/s10115-020-01502-y', '10.1007/978-3-030-22744-9_23', '10.1186/s12859-022-04646-6', '10.1007/978-3-030-30793-6_25', '10.1016/j.asoc.2022.108604', '10.1109/icbk50248.2020.00042', '10.1162/dint_a_00103', '10.1007/978-3-319-93935-3_6', '10.1007/978-3-642-37186-8_9', '10.1145/3366424.3383757', '10.1007/978-3-030-79463-7_21', '10.1109/icmcce.2017.14', '10.1007/s00778-016-0437-2', '10.1049/cit2.12008', '10.1371/journal.pone.0171929', '10.1007/s00799-015-0139-1', '10.1007/978-3-030-21348-0_19', '10.1145/3402885', '10.1145/3488560.3498377', '10.1109/qr2mse46217.2019.9021234', '10.1177/0165551515610989', '10.1109/ijcnn48605.2020.9206648', '10.1007/s11280-021-00982-4', '10.1145/3488560.3498409', '10.37882/2223-2966.2021.05.15', '10.1109/icsp54964.2022.9778528', '10.1145/2783258.2788580', '10.1049/cit2.12033', '10.1007/978-3-030-71590-8_5', '10.1007/978-3-319-69005-6_16', '10.1145/3451471.3451506', '10.1007/978-3-319-45880-9_12', '10.1007/s10489-021-02699-3', '10.1007/978-3-642-53917-6_37', '10.1007/978-3-030-32236-6_8', '10.1007/s10489-021-02492-2', '10.1145/3038912.3052708', '10.1038/s42256-020-0189-y', '10.2200/s00860ed1v01y201806dmk015', '10.1007/978-3-030-36808-1_10', '10.1007/978-3-030-03667-6_27', '10.1109/taslp.2016.2573050', '10.1007/978-3-030-75768-7_33', '10.1145/3486622.3494010', '10.1007/978-3-319-59858-1_5', '10.1016/j.ipm.2021.102563', '10.3390/app12178821', '10.1007/978-3-319-48740-3_42', '10.1007/978-981-16-0100-2_10', '10.1007/978-3-030-34223-4_20', '10.1007/s10115-019-01351-4', '10.1007/978-3-030-82147-0_13', '10.1007/978-3-642-40585-3_25', '10.1093/bib/bbz087', '10.1007/s00521-021-06667-3', '10.1186/s13638-020-01720-6', '10.1109/access.2017.2785229', '10.1007/978-3-030-60450-9_41', '10.1007/978-3-030-00671-6_12', '10.1007/978-3-030-26072-9_6', '10.1007/978-3-030-18590-9_29', '10.1016/j.jbi.2021.103956', '10.1007/978-3-319-50496-4_44', '10.1186/s12859-020-3457-2', '10.1145/3510030', '10.1016/j.neucom.2020.07.077', '10.1109/access.2019.2938986', '10.1007/s00521-019-04430-3', '10.1145/2882903.2904442', '10.1007/978-3-319-12277-9_14', '10.1109/tkde.2017.2754499', '10.1007/s10489-021-02632-8', '10.1109/access.2019.2925502', '10.1109/icarm.2017.8273158', '10.1145/3077136.3080666', '10.1109/bigdata.2017.8258168', '10.1016/j.neunet.2018.01.006', '10.3233/sw-180333', '10.1016/j.websem.2021.100656', '10.3233/sw-150180', '10.1007/978-3-030-49461-2_6', '10.1093/bioinformatics/btaa430', '10.1145/3477495.3531876', '10.1016/j.jksuci.2014.06.004', '10.1007/978-3-031-19433-7_37', '10.1016/j.eswa.2021.114922', '10.1007/978-981-10-2993-6_6', '10.3233/ida-194492', '10.1007/s11280-020-00816-9', '10.1007/978-3-030-32233-5_15', '10.1109/taslp.2022.3153254', '10.5715/jnlp.28.183', '10.1007/s11063-021-10548-0', '10.1109/ijcnn52387.2021.9534215', '10.1109/icbk.2018.00022', '10.1109/cvpr52688.2022.01348', '10.1109/tvcg.2020.3030443', '10.1016/j.neunet.2021.03.030', '10.1007/s11431-020-1673-6', '10.1007/978-3-031-10986-7_7', '10.1007/978-3-319-23708-4_7', '10.1007/978-981-10-7877-4_30', '10.1007/978-3-030-32381-3_19', '10.1007/978-981-16-5188-5_2', '10.1007/s10462-022-10239-9', '10.1145/3436369.3437431', '10.1145/2641730.2641735', '10.1007/978-3-030-32381-3_24', '10.1007/978-3-030-41407-8_18', '10.23919/eusipco47968.2020.9287502', '10.1007/978-3-319-93417-4_17', '10.1007/s10489-022-03677-z', '10.1109/bsb.2016.7552135', '10.1007/978-3-030-14596-5_1', '10.1007/s10489-021-02596-9', '10.2200/s01078ed2v01y202002hlt049', '10.1109/iccsmt51754.2020.00082', '10.1007/978-3-030-32236-6_2', '10.1109/access.2018.2888508', '10.1109/cscwd54268.2022.9776118', '10.1007/978-3-031-06794-5_12', '10.1109/icaaid51067.2022.9799502', '10.1109/iceiec49280.2020.9152287', '10.1038/s41392-021-00568-6', '10.1109/icnidc.2016.7974612', '10.1007/978-3-319-70096-0_57', '10.1007/s13042-021-01491-6', '10.1007/978-981-19-1742-4_40', '10.1016/j.knosys.2019.03.025', '10.1007/s00521-022-07312-3', '10.1007/978-3-030-04618-7_2', '10.1016/j.knosys.2020.105548', '10.1109/aiiot54504.2022.9817231', '10.1109/ivs.2019.8814147', '10.1145/3159652.3159709', '10.1109/iceca52323.2021.9675884', '10.1007/978-981-10-8438-6_5', '10.1007/978-3-030-32236-6_72', '10.1145/3394486.3403047', '10.1007/s11633-022-1323-6', '10.1007/978-3-031-10983-6_31', '10.1109/access.2019.2892724', '10.1101/2020.03.11.986836', '10.1007/s10115-013-0675-1', '10.1007/978-3-030-03667-6_12', '10.1007/978-981-15-1956-7_6', '10.1007/978-3-031-07472-1_16', '10.1007/978-3-319-13704-9_3', '10.1016/j.ins.2020.10.030', '10.1109/icassp43922.2022.9746958', '10.3233/ida-184238', '10.1109/cvpr.2018.00168', '10.1109/access.2022.3164688', '10.1109/icccs52626.2021.9449230', '10.1145/3055167.3055184', '10.1109/smds49396.2020.00015', '10.1007/978-3-319-99495-6_18', '10.1109/bigdata50022.2020.9378317', '10.1109/icsess52187.2021.9522255', '10.1109/compcomm.2017.8322795', '10.1007/978-3-030-16142-2_16', '10.1109/access.2020.2980859', '10.1145/3457682.3457765', '10.1145/3404835.3463103', '10.1145/3459637.3482045', '10.1145/2983323.2983725', '10.1145/3495162', '10.3233/ida-194476', '10.1007/s00521-020-05642-8', '10.1109/tkde.2020.2964747', '10.1109/taslp.2021.3082295', '10.1007/978-3-031-00123-9_9', '10.1007/978-3-319-63962-8_285-1', '10.1007/978-3-030-29908-8_12', '10.1109/ijcnn.2019.8852408', '10.1109/access.2020.2970119', '10.1016/j.neucom.2022.04.067', '10.1109/access.2021.3073428', '10.1007/s00778-019-00552-1', '10.1162/tacl_a_00456', '10.1007/978-3-642-45068-6_30', '10.1109/ijcnn52387.2021.9533807', '10.1007/978-981-15-8101-4_10', '10.1007/s10032-022-00399-3', '10.1587/transinf.2020edp7249', '10.1109/ijcnn.2019.8851951', '10.1007/978-3-030-75768-7_29', '10.1007/978-3-319-25816-4_21', '10.1186/s12859-020-03889-5', '10.1007/978-3-030-43887-6_6', '10.1007/978-3-319-63962-8_285-2', '10.5715/jnlp.28.965', '10.1007/s00799-021-00313-y', '10.1007/978-981-19-5391-0_5', '10.1007/978-3-030-32381-3_20', '10.1109/iciea48937.2020.9248138', '10.1145/3209978.3210031', '10.1155/2021/6110885', '10.1109/cds52072.2021.00022', '10.1145/3340531.3411858', '10.1007/978-3-319-12277-9_15', '10.1007/s10489-022-03547-8', '10.3233/idt-180352', '10.1109/ictai.2019.00210', '10.1007/978-981-16-2540-4_1', '10.1007/978-3-030-73197-7_32', '10.1109/access.2019.2932041', '10.1109/ijcnn55064.2022.9892310', '10.1007/978-3-319-26535-3_29', '10.1109/icde48307.2020.00093', '10.1007/978-981-16-9492-9_302', '10.1109/ichi.2019.8904821', '10.1007/978-981-19-6142-7_10', '10.1109/ijcnn.2019.8852286', '10.1007/978-3-319-12580-0_2', '10.1007/978-3-319-41706-6_18', '10.1007/s11837-021-04902-9', '10.1007/978-3-319-90596-9_3', '10.1007/978-3-030-72240-1_47', '10.1145/3511808.3557323', '10.1007/978-3-030-79463-7_52', '10.1007/978-3-030-32236-6_9', '10.1007/s11280-021-00979-z', '10.1051/matecconf/201818903025', '10.1145/3357384.3357986', '10.1109/citsm47753.2019.8965423', '10.1109/imcec51613.2021.9482001', '10.1007/978-981-10-0515-2_12', '10.1007/978-3-030-89363-7_23', '10.1145/3289600.3291004', '10.3389/fnbot.2022.914705', '10.1007/978-3-319-98812-2_7', '10.1145/3474198.3478487', '10.1007/978-3-030-00671-6_11', '10.1016/j.procs.2017.08.208', '10.1109/bibm.2018.8621136', '10.1109/iccst50977.2020.00059', '10.1109/compcomm.2018.8780970', '10.1145/3241741', '10.1016/j.jbi.2020.103425', '10.1007/978-3-030-01421-6_26', '10.1016/j.asoc.2021.107080', '10.1145/3357384.3357997', '10.1007/978-3-030-75762-5_64', '10.1109/taslp.2021.3110126', '10.4218/etrij.2020-0460', '10.1007/978-3-030-00072-1_5', '10.1007/978-3-319-16354-3_46', '10.1109/taslp.2022.3199655', '10.1007/978-3-030-60450-9_22', '10.1007/978-3-030-32233-5_26', '10.1109/icbda.2016.7509818', '10.1109/ijcnn.2019.8852378', '10.1007/978-3-319-70139-4_22', '10.1007/s10489-021-03002-0', '10.1109/icde53745.2022.00018', '10.1109/ijcnn.2018.8489631', '10.1101/626226', '10.1007/978-3-030-88480-2_24', '10.1007/978-3-031-19496-2_8', '10.1007/s12559-016-9425-5', '10.1145/3335656.3335694', '10.1371/journal.pone.0216913', '10.1007/978-3-030-89698-0_64', '10.1145/3210713.3210728', '10.1371/journal.pone.0260426', '10.1007/978-3-030-02922-7_28', '10.3233/jcm-193723', '10.1007/978-3-031-00129-1_29', '10.1155/2019/6789520', '10.1007/s11432-018-9721-7', '10.1145/3384544.3384582', '10.1007/978-3-031-20865-2_13', '10.1007/978-3-030-55130-8_13', '10.1109/tbdata.2022.3144151', '10.1007/s12559-021-09917-7', '10.1016/j.neucom.2020.06.061', '10.1109/icosc.2015.7050814', '10.1109/iccse49874.2020.9201713', '10.1007/978-3-030-23551-2_3', '10.1007/978-3-319-11915-1_32', '10.1007/978-3-030-18590-9_75', '10.1145/3077136.3080735', '10.1109/bibm47256.2019.8983057', '10.1007/978-3-319-77113-7_33', '10.1145/3374217'], 'cited': ['10.1007/978-3-642-15939-8_10']}","","/root/snap/zotero-snap/common/Zotero/storage/YQRQYFSL/Riedel et al. - 2010 - Modeling Relations and Their Mentions without Labe.pdf","","","Relation Extraction; Computational Linguistics; Factor Graph; Related Entity; Relation Type","Balcázar, José Luis; Bonchi, Francesco; Gionis, Aristides; Sebag, Michèle","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N8SCVSVW","journalArticle","2018","Yankai Lin, Xu Han; , Ruobing Xie; , Zhiyuan Liu; , Maosong Sun","Knowledge Representation Learning: A Quantitative Review","","","","not found","https://www.semanticscholar.org/paper/Knowledge-Representation-Learning%3A-A-Quantitative-Lin-Han/1537c97b32b364ce97a17b4057973a3c6aee8824","Knowledge representation learning (KRL) aims to represent entities and relations in knowledge graph in low-dimensional semantic space","2018","2023-03-01 14:57:49","2023-04-15 14:38:16","","","","","information retrieval","","","","","","","","","","","","","","","","","","","","","","⚠️ Invalid DOI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LTPY2CHK","journalArticle","2021","Hedderich, Michael A.; Lange, Lukas; Adel, Heike; Strötgen, Jannik; Klakow, Dietrich","A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2021.naacl-main.201","https://aclanthology.org/2021.naacl-main.201","Deep neural networks and huge language models are becoming omnipresent in natural language applications. As they are known for requiring large amounts of training data, there is a growing body of work to improve the performance in low-resource settings. Motivated by the recent fundamental changes towards neural models and the popular pre-train and fine-tune paradigm, we survey promising approaches for low-resource natural language processing. After a discussion about the different dimensions of data availability, we give a structured overview of methods that enable learning when training data is sparse. This includes mechanisms to create additional labeled data like data augmentation and distant supervision as well as transfer learning settings that reduce the need for target supervision. A goal of our survey is to explain how these methods differ in their requirements as understanding them is essential for choosing a technique suited for a specific low-resource setting. Further key aspects of this work are to highlight open issues and to outline promising directions for future research.","2021","2023-03-01 15:29:07","2023-04-15 14:16:07","2023-03-01 15:29:07","2545-2568","","","","","","","","","","","","","en","","","","","Semantic Scholar","","{'citing': ['10.1007/978-3-030-99739-7_63', '10.1007/s10489-022-03511-6', '10.7717/peerj-cs.1142', '10.1017/s1351324921000152', '10.1145/3477495.3531789', '10.1162/tacl_a_00500', '10.1007/978-3-031-19496-2_4', '10.1016/j.knosys.2021.107791', '10.37661/1816-0301-2022-19-1-96-110', '10.1109/access.2022.3141200', '10.1162/tacl_a_00467', '10.4000/books.aaccademia.10445', '10.1017/s1351324922000213', '10.1016/j.patrec.2021.06.024', '10.1162/coli_a_00425', '10.1007/978-3-030-90072-4_23', '10.1007/978-3-030-98305-5_12'], 'cited': ['10.18653/v1/2021.naacl-main.201']}","","/root/snap/zotero-snap/common/Zotero/storage/WHW29YMM/Hedderich et al. - 2021 - A Survey on Recent Approaches for Natural Language.pdf; ","https://www.semanticscholar.org/paper/A-Survey-on-Recent-Approaches-for-Natural-Language-Hedderich-Lange/455cdafd55a5b5ddefa029bf97801327e142646d","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DXMFXT95","conferencePaper","2019","Shi, Yong; Xiao, Yang; Niu, Lingfeng","A Brief Survey of Relation Extraction Based on Distant Supervision","","978-3-030-22743-2 978-3-030-22744-9","","10.1007/978-3-030-22744-9_23","https://link.springer.com/10.1007/978-3-030-22744-9_23","As a core task and important part of Information ExtractionEntity Relation Extraction can realize the identification of the semantic relation between entity pairs. And it plays an important role in semantic understanding of sentences and the construction of entity knowledge base. It has the potential of employing distant supervision method, end-to-end model and other deep learning model with the creation of large datasets. In this review, we compare the contributions and defect of the various models that have been used for the task, to help guide the path ahead.","2019","2023-03-01 15:29:02","2023-04-15 14:16:06","2023-03-01 15:29:02","293-303","","","11538","","","","","","","","Springer International Publishing","Cham","en","","","","","Semantic Scholar","","{'citing': ['10.1007/s10489-022-03547-8', '10.1007/978-3-031-21686-2_12', '10.1007/s10489-021-02958-3', '10.1007/s12559-021-09917-7', '10.1088/1742-6596/1744/2/022066', '10.1007/978-3-031-14054-9_16', '10.1109/csde50874.2020.9411604'], 'cited': ['10.1007/978-3-030-22744-9_23']}","","","https://www.semanticscholar.org/paper/A-Brief-Survey-of-Relation-Extraction-Based-on-Shi-Xiao/a7462af62309c8a39df796abedbef6b2c601cdca","","","Rodrigues, João M. F.; Cardoso, Pedro J. S.; Monteiro, Jânio; Lam, Roberto; Krzhizhanovskaya, Valeria V.; Lees, Michael H.; Dongarra, Jack J.; Sloot, Peter M.A.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3GB7STIB","journalArticle","2016","Augenstein, Isabelle; Maynard, Diana; Ciravegna, Fabio","Distantly supervised Web relation extraction for knowledge base population","Semantic Web","","22104968, 15700844","10.3233/SW-150180","https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/SW-150180","Extracting information from Web pages for populating large, cross-domain knowledge bases requires methods which are suitable across domains, do not require manual effort to adapt to new domains, are able to deal with noise, and integrate information extracted from different Web pages. Recent approaches have used existing knowledge bases to learn to extract information with promising results, one of those approaches being distant supervision. Distant supervision is an unsupervised method which uses background information from the Linking Open Data cloud to automatically label sentences with relations to create training data for relation classiﬁers. In this paper we propose the use of distant supervision for relation extraction from the Web. Although the method is promising, existing approaches are still not suitable for Web extraction as they suffer from three main issues: data sparsity, noise and lexical ambiguity. Our approach reduces the impact of data sparsity by making entity recognition tools more robust across domains and extracting relations across sentence boundaries using unsupervised coreference resolution methods. We reduce the noise caused by lexical ambiguity by employing statistical methods to strategically select training data. To combine information extracted from multiple sources for populating knowledge bases we present and evaluate several information integration strategies and show that those beneﬁt immensely from additional relation mentions extracted using co-reference resolution, increasing precision by 8%. We further show that strategically selecting training data can increase precision by a further 3%.","2016-05-27","2023-02-28 17:45:05","2023-04-15 14:16:05","2023-02-28 17:45:05","335-349","","4","7","","SW","","","","","","","","en","","","","","DOI.org (Crossref)","","{'citing': ['10.1007/978-3-319-70407-4_3', '10.1145/3241741', '10.1177/0165551520934387', '10.2200/s00741ed1v01y201611wbe015', '10.1145/3184558.3191546', '10.3233/sw-190369', '10.1145/3474085.3476968', '10.1016/j.websem.2019.100546', '10.1007/978-3-319-63962-8_285-1', '10.4018/978-1-7998-4730-4.ch019', '10.1007/s10489-018-1208-0', '10.3233/sw-180333', '10.1007/978-3-319-77525-8_285', '10.3390/app12199691', '10.1007/978-3-030-16181-1_47', '10.1007/978-3-030-21395-4_7', '10.1186/s12859-018-2200-8', '10.3233/sw-212838', '10.1007/978-3-319-63962-8_285-2', '10.1016/j.eswa.2018.07.017', '10.1145/3488560.3498424', '10.1007/978-3-319-93037-4_29', '10.1101/2022.04.14.488416'], 'cited': ['10.3233/sw-150180']}","","/root/snap/zotero-snap/common/Zotero/storage/7J33PDT9/Augenstein et al. - 2016 - Distantly supervised Web relation extraction for k.pdf","","","","Janowicz, Krzysztof; Schlobach, Stefan; Schlobach, Stefan; Janowicz, Krzysztof","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LKRWJ5G6","conferencePaper","2014","Pershina, Maria; Min, Bonan; Xu, Wei; Grishman, Ralph","Infusion of Labeled Data into Distant Supervision for Relation Extraction","Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)","","","10.3115/v1/P14-2119","http://aclweb.org/anthology/P14-2119","Distant supervision usually utilizes only unlabeled data and existing knowledge bases to learn relation extraction models. However, in some cases a small amount of human labeled data is available. In this paper, we demonstrate how a state-of-theart multi-instance multi-label model can be modiﬁed to make use of these reliable sentence-level labels in addition to the relation-level distant supervision from a database. Experiments show that our approach achieves a statistically signiﬁcant increase of 13.5% in F-score and 37% in area under the precision recall curve.","2014","2023-02-28 17:31:36","2023-04-15 14:16:04","2023-02-28 17:31:36","732-738","","","","","","","","","","","Association for Computational Linguistics","Baltimore, Maryland","en","","","","","DOI.org (Crossref)","","{'citing': ['10.1007/978-981-10-2993-6_6', '10.1016/j.is.2018.09.003', '10.1145/3241741', '10.1145/3387634', '10.1145/3340531.3412039', '10.1007/s10489-022-03547-8', '10.1109/jstars.2021.3127246', '10.1109/geoinformatics.2015.7378569', '10.1007/978-3-319-50496-4_44', '10.1007/978-3-319-48740-3_42', '10.1145/3077136.3080666', '10.1007/s11227-015-1535-4', '10.1109/cyberc.2015.77', '10.1109/icccbda.2018.8386544', '10.1145/3555552', '10.1145/3290605.3300761', '10.1109/icbda.2016.7509818', '10.1007/978-3-030-84186-7_22', '10.1016/j.eswa.2022.117113', '10.3233/ida-194492'], 'cited': ['10.3115/v1/p14-2119']}","","/root/snap/zotero-snap/common/Zotero/storage/6X29YY32/Pershina et al. - 2014 - Infusion of Labeled Data into Distant Supervision .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)","","","","","","","","","","","","","","",""
"BRHSBCP5","conferencePaper","2013","Roth, Benjamin; Barth, Tassilo; Wiegand, Michael; Klakow, Dietrich","A survey of noise reduction methods for distant supervision","Proceedings of the 2013 workshop on Automated knowledge base construction","","","10.1145/2509558.2509571","","","2013","2023-01-18 09:10:18","2023-04-15 14:16:03","","73–78","","","","","","","","","","","","","","","","","","Google Scholar","","{'citing': ['10.1007/s10489-022-03547-8', '10.1109/access.2021.3130956', '10.1145/3184558.3191546', '10.1109/icbda.2016.7509818', '10.1007/978-3-319-93037-4_29', '10.1101/626226', '10.1007/s12559-020-09800-x', '10.1371/journal.pone.0216913', '10.5715/jnlp.23.37', '10.3233/sw-150180', '10.1007/s11063-021-10548-0', '10.1007/978-3-319-72926-8_13', '10.1145/3241741'], 'cited': ['10.1145/2509558.2509571']}","","/root/snap/zotero-snap/common/Zotero/storage/EWGH4R33/Roth et al. - 2013 - A survey of noise reduction methods for distant su.pdf; /root/snap/zotero-snap/common/Zotero/storage/JSDIGZR2/2509558.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZGZ9D7FK","journalArticle","2018","Smirnova, Alisa; Cudré-Mauroux, Philippe","Relation Extraction Using Distant Supervision: A Survey","ACM Computing Surveys","","0360-0300","10.1145/3241741","https://doi.org/10.1145/3241741","Relation extraction is a subtask of information extraction where semantic relationships are extracted from natural language text and then classified. In essence, it allows us to acquire structured knowledge from unstructured text. In this article, we present a survey of relation extraction methods that leverage pre-existing structured or semi-structured data to guide the extraction process. We introduce a taxonomy of existing methods and describe distant supervision approaches in detail. We describe, in addition, the evaluation methodologies and the datasets commonly used for quality assessment. Finally, we give a high-level outlook on the field, highlighting open problems as well as the most promising research directions.","2018-11-19","2023-02-06 09:33:54","2023-04-15 14:16:01","2023-02-06 09:33:54","106:1–106:35","","5","51","","ACM Comput. Surv.","Relation Extraction Using Distant Supervision","","","","","","","","","","","","September 2019","","{'citing': ['10.1145/3445965', '10.1109/icpm49681.2020.00023', '10.1016/j.ijdrr.2021.102482', '10.1142/s0218194022500279', '10.1109/bigdata52589.2021.9671514', '10.1155/2020/8893749', '10.1109/iscid51228.2020.00046', '10.1016/j.knosys.2022.108956', '10.2200/s01125ed1v01y202109dsk022', '10.3390/app112311472', '10.14778/3476311.3476393', '10.1007/s10579-022-09577-5', '10.1145/3442381.3449917', '10.1007/s10489-022-03547-8', '10.1007/978-3-030-74837-1_11', '10.1007/978-3-030-66891-4_11', '10.2200/s01123ed1v01y202108hlt053', '10.3233/jifs-219241', '10.1145/3511808.3557352', '10.1007/s10115-022-01665-w', '10.1016/j.jnca.2021.103076', '10.1007/978-3-030-86334-0_31', '10.1145/3511095.3531284', '10.1109/iaeac50856.2021.9390651', '10.1007/s10506-022-09332-9', '10.1007/978-3-030-62327-2_37', '10.1007/s12021-022-09571-w', '10.3233/sw-190371', '10.1093/database/baab077', '10.1145/3503917', '10.1007/978-981-16-9573-5_37', '10.1109/jcdl52503.2021.00014', '10.1007/s10462-022-10239-9', '10.1007/s00521-021-06667-3', '10.1177/1043986220910297', '10.1007/978-3-319-63962-8_285-2', '10.1145/3477495.3531876', '10.1145/3485447.3511932', '10.1109/icsess52187.2021.9522255', '10.1016/j.compeleceng.2022.108261', '10.1007/978-3-031-19496-2_8', '10.1109/aiiot54504.2022.9817231', '10.3390/app10196835', '10.3390/data7070090', '10.1016/j.eswa.2022.117606', '10.1109/iwcmc48107.2020.9148384', '10.1016/j.websem.2021.100638', '10.1109/sds.2019.000-6', '10.1093/bib/bbz087', '10.3390/info13040161'], 'cited': ['10.1145/3241741']}","","","","manual","Relation extraction; distant supervision; knowledge graph","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V2XW8D9J","journalArticle","2022","Mohamad Zamini, H. Reza; , M. Rabiei","A Review of Knowledge Graph Completion","","","","10.3390/info13080396","https://www.mdpi.com/2078-2489/13/8/396","Information extraction methods proved to be effective at triple extraction from structured or unstructured data. The organization of such triples in the form of (head entity, relation, tail entity) is called the construction of Knowledge Graphs (KGs). Most of the current knowledge graphs are incomplete. In order to use KGs in downstream tasks, it is desirable to predict missing links in KGs. Different approaches have been recently proposed for representation learning of KGs by embedding both entities and relations into a low-dimensional vector space aiming to predict unknown triples based on previously visited triples. According to how the triples will be treated independently or dependently, we divided the task of knowledge graph completion into conventional and graph neural network representation learning and we discuss them in more detail. In conventional approaches, each triple will be processed independently and in GNN-based approaches, triples also consider their local neighborhood.","2022","2023-03-01 14:57:47","2023-04-15 14:15:49","","15bcddf2d3ac05f54879e7153c434a532ec13c64","","https://www.semanticscholar.org/paper/15bcddf2d3ac05f54879e7153c434a532ec13c64","2022-08-21","","SemanticScholar","","","","","","","","","triples also consider their local neighborhood.","","","relation","","","{'citing': ['10.3390/electronics11233897', '10.3390/su142214975', '10.3390/electronics11233866'], 'cited': ['10.3390/info13080396']}","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S3MC9ZKA","preprint","2022","Pai Liu, Wenyang Gao; , Wenjie Dong; , Songfang Huang; , Yue Zhang","Open Information Extraction from 2007 to 2022 -- A Survey","","","","not found","nan","Open information extraction is an important NLP task that targets extracting structured information from unstructured text without limitations on the relation type or the domain of the text. This survey paper covers open information extraction technologies from 2007 to 2022 with a focus on new models not covered by previous surveys. We propose a new categorization method from the source of information perspective to accommodate the development of recent OIE technologies. In addition, we summarize three major approaches based on task settings as well as current popular datasets and model evaluation metrics. Given the comprehensive review, several future directions are shown from datasets, source of information, output form, method, and evaluation metric aspects.","2022-08-18","2023-03-01 14:33:53","2023-10-10 10:24:50","","","","","","","","","","","","","","","","nan","","Arxiv","http://arxiv.org/abs/2208.08690v1","","","","","","","OpenIE; EC1.5; SAT_focus:OpenIE; SAT_task:RE; SAT_type:Survey","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77XMQUMR","preprint","2022","William Hogan","An Overview of Distant Supervision for Relation Extraction with a Focus   on Denoising and Pre-training Methods","","","","not found","nan","Relation Extraction (RE) is a foundational task of natural language processing. RE seeks to transform raw, unstructured text into structured knowledge by identifying relational information between entity pairs found in text. RE has numerous uses, such as knowledge graph completion, text summarization, question-answering, and search querying. The history of RE methods can be roughly organized into four phases: pattern-based RE, statistical-based RE, neural-based RE, and large language model-based RE. This survey begins with an overview of a few exemplary works in the earlier phases of RE, highlighting limitations and shortcomings to contextualize progress. Next, we review popular benchmarks and critically examine metrics used to assess RE performance. We then discuss distant supervision, a paradigm that has shaped the development of modern RE methods. Lastly, we review recent RE works focusing on denoising and pre-training methods.","2022-07-17","2023-03-01 14:33:54","2023-10-23 12:06:32","","","","","","","","","","","","","","","","nan","","Arxiv","http://arxiv.org/abs/2207.08286v1","","","","","","","star; SAT_model:BERT; HERE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KPPE4BCN","preprint","2017","Pawar, Sachin; Palshikar, Girish K.; Bhattacharyya, Pushpak","Relation Extraction : A Survey","","","","not found","http://arxiv.org/abs/1712.05191","With the advent of the Internet, large amount of digital text is generated everyday in the form of news articles, research publications, blogs, question answering forums and social media. It is important to develop techniques for extracting information automatically from these documents, as lot of important information is hidden within them. This extracted information can be used to improve access and management of knowledge hidden in large text corpora. Several applications such as Question Answering, Information Retrieval would benefit from this information. Entities like persons and organizations, form the most basic unit of the information. Occurrences of entities in a sentence are often linked through well-defined relations; e.g., occurrences of person and organization in a sentence may be linked through relations such as employed at. The task of Relation Extraction (RE) is to identify such relations automatically. In this paper, we survey several important supervised, semi-supervised and unsupervised RE techniques. We also cover the paradigms of Open Information Extraction (OIE) and Distant Supervision. Finally, we describe some of the recent trends in the RE techniques and possible future research directions. This survey would be useful for three kinds of readers - i) Newcomers in the field who want to quickly learn about RE; ii) Researchers who want to know how the various RE techniques evolved over time and what are possible future research directions and iii) Practitioners who just need to know which RE technique works best in various settings.","2017-12-14","2023-05-23 13:15:28","2023-10-10 10:24:36","2023-05-23 13:15:28","","","","","","","Relation Extraction","","","","","arXiv","","","","","","","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/NKDZE36J/Pawar et al. - 2017 - Relation Extraction  A Survey.pdf; /root/snap/zotero-snap/common/Zotero/storage/I9R6HL8W/1712.html","","MANUALMODELS; SAT_task:RE; SAT_type:Survey","Computer Science - Computation and Language; Computer Science - Artificial Intelligence; Computer Science - Information Retrieval","","","","","","","","","","","","","","","","","","","arXiv:1712.05191","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NDBLXKGQ","journalArticle","2018","Yan, Jihong; Wang, Chengyu; Cheng, Wenliang; Gao, Ming; Zhou, Aoying","A retrospective of knowledge graphs","Frontiers","","2095-2236","10.1007/s11704-016-5228-9","https://doi.org/10.1007/s11704-016-5228-9","Information on the Internet is fragmented and presented in different data sources, which makes automatic knowledge harvesting and understanding formidable for machines, and even for humans. Knowledge graphs have become prevalent in both of industry and academic circles these years, to be one of the most efficient and effective knowledge integration approaches. Techniques for knowledge graph construction can mine information from either structured, semi-structured, or even unstructured data sources, and finally integrate the information into knowledge, represented in a graph. Furthermore, knowledge graph is able to organize information in an easy-to-maintain, easy-to-understand and easy-to-use manner.","2018-02-01","2023-05-23 13:13:32","2025-02-04 17:20:33","2023-05-23 13:13:32","55-74","","1","12","","Front. Comput. Sci.","","Frontiers of Computer Science","","","","","","en","","","","","Springer Link","","{'citing': ['10.3390/info11040182', '10.1093/bib/bbab437', '10.1007/s11227-019-03046-7', '10.1007/978-3-030-64949-4_12', '10.1088/1742-6596/1427/1/012001', '10.1109/icss50103.2020.00017', '10.1109/aiic54368.2022.9914031', '10.3233/efi-220028', '10.3390/info11030129', '10.1109/access.2021.3077916', '10.1145/3341069.3342973', '10.1145/3447772', '10.1088/1757-899x/750/1/012207', '10.1016/j.autcon.2021.104118', '10.1016/j.knosys.2022.109703', '10.1109/access.2019.2960659', '10.1145/3411764.3445368', '10.3390/systems10050178', '10.1002/isaf.1491', '10.1109/access.2021.3070395', '10.1109/cei52496.2021.9574515', '10.3390/info13040161', '10.1007/978-981-13-2206-8_16', '10.1088/1742-6596/1982/1/012123', '10.1007/978-3-030-14401-2_10', '10.1007/978-3-030-14401-2_29', '10.1007/978-3-030-04284-4_20', '10.1007/978-3-030-52287-2_28', '10.1007/978-3-030-62466-8_27', '10.3233/sw-210442', '10.32517/0234-0453-2021-36-10-33-42', '10.1007/978-3-030-50267-6_22', '10.12688/hrbopenres.13403.2', '10.1145/3196321.3196335', '10.1016/j.jss.2020.110572', '10.1098/rspa.2019.0825', '10.12688/hrbopenres.13403.1', '10.1049/gtd2.12040', '10.3390/ijgi10120835', '10.1007/978-3-030-53187-4_54', '10.1145/3487664.3487803', '10.3390/info13020099', '10.1088/1742-6596/1982/1/012122', '10.1109/etfa46521.2020.9211994', '10.1007/978-3-030-92836-0_40', '10.1007/978-3-030-29374-1_19', '10.3390/fi14050129', '10.1016/j.eswa.2019.112965', '10.1109/phm-yantai55411.2022.9941854', '10.1016/b978-0-12-822468-7.00012-2', '10.1142/s0218194021400040', '10.1109/access.2020.2973928', '10.1371/journal.pone.0274164', '10.1142/s0218194021500339', '10.1002/smr.2262', '10.3390/electronics10121500', '10.1007/978-3-031-07802-6_21', '10.1002/9781119764175.ch10', '10.1007/978-3-030-63955-6_9', '10.3389/fenrg.2022.896836', '10.1016/j.visinf.2020.01.001', '10.1016/j.websem.2022.100713', '10.21203/rs.3.rs-2180206/v1', '10.1007/s00500-021-05756-8', '10.1109/edocw52865.2021.00026', '10.1007/978-3-030-62412-5_15', '10.3390/app11199160', '10.1111/bjet.12841', '10.1007/978-3-030-78424-9_60', '10.1007/978-3-030-63161-1_15'], 'cited': ['10.1007/s11704-016-5228-9']}","","","","MANUALMODELS; SAT_task:RE; SAT_task:RC; SAT_task:EntityLinking; SAT_task:NER; SAT_type:Review; SAT_focus:KB; FOCUS_STUDY_OCT; CHECKED1023; SAT_benchmark_type:Qualitative; HERE; SAT_interest:5; SAT_focus:Reasoning; SAT_focus_period:1980-2016","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"74XUWXDZ","journalArticle","2020","Gerhard Weikum, Luna Dong; , Simon Razniewski; , Fabian Suchanek","Machine Knowledge: Creation and Curation of Comprehensive Knowledge   Bases","ACM","","","10.1561/1900000064","nan","Equipping machines with comprehensive knowledge of the world's entities and their relationships has been a long-standing goal of AI. Over the last decade, large-scale knowledge bases, also known as knowledge graphs, have been automatically constructed from web contents and text sources, and have become a key asset for search engines. This machine knowledge can be harnessed to semantically interpret textual phrases in news, social media and web tables, and contributes to question answering, natural language processing and data analytics. This article surveys fundamental concepts and practical methods for creating and curating large knowledge bases. It covers models and methods for discovering and canonicalizing entities and their semantic types and organizing them into clean taxonomies. On top of this, the article discusses the automatic extraction of entity-centric properties. To support the long-term life-cycle and the quality assurance of machine knowledge, the article presents methods for constructing open schemas and for knowledge curation. Case studies on academic projects and industrial knowledge graphs complement the survey of concepts and methods.","2020-09-24","2023-03-01 14:34:12","2025-02-04 17:18:54","","","","","","","Foundations and Trends in Databases","","","","","","","","","True","","Arxiv","http://arxiv.org/abs/2009.11564v2","","","{'citing': ['10.1007/978-3-030-80418-3_24', '10.3233/sw-212865', '10.1162/tacl_a_00456', '10.1145/3529372.3530924', '10.1145/3514221.3526049', '10.1007/978-3-031-16802-4_43', '10.1145/3511808.3557158'], 'cited': []}","","","","star; SAT_focus:OpenIE; SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_focus:LongTailRelation; SAT_task:EntityLinking; SAT_task:NER; SAT_focus:distant; SAT_typology:False; SAT_task:Labelling; SAT_focus:RulesBased; SAT_task:KnowledgeCuration; SAT_task:Embed; SAT_focus:HTML; SAT_focus:Math; FOCUS_STUDY_OCT; CHECKED1023; SAT_type:DetailedSurvey; SAT_interest:7; SAT_focus:Model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UXZJKRAG","conferencePaper","2022","Shaowen Zhou, Bowen Yu; , Aixin Sun; , Cheng Long; , Jingyang Li; , Haiyang Yu; , Jian Sun; , Yongbin Li","A Survey on Neural Open Information Extraction: Current Status and   Future Directions","Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence","","","10.24963/ijcai.2022/793","nan","Open Information Extraction (OpenIE) facilitates domain-independent discovery of relational facts from large corpora. The technique well suits many open-world natural language understanding scenarios, such as automatic knowledge base construction, open-domain question answering, and explicit reasoning. Thanks to the rapid development in deep learning technologies, numerous neural OpenIE architectures have been proposed and achieve considerable performance improvement. In this survey, we provide an extensive overview of the-state-of-the-art neural OpenIE models, their key design decisions, strengths and weakness. Then, we discuss limitations of current solutions and the open issues in OpenIE problem itself. Finally we list recent trends that could help expand its scope and applicability, setting up promising directions for future research in OpenIE. To our best knowledge, this paper is the first review on this specific topic.","2022-05-24","2023-03-01 14:33:55","2025-02-04 17:18:54","","","","","","","","","","","","","IJCAI","","","Open","","Arxiv","http://arxiv.org/abs/2205.11725v2","","","","","","","SAT_focus:OpenIE; SAT_model:BERT; SAT_task:RE; SAT_granularity:sentence; SAT_archi:BiLSTM; SAT_task:OpenRE; SAT_archi:CNN; SAT_archi:RNN; SAT_archi:Rules; SAT_archi:LSTM; SAT_archi:GRU; SAT_archi:GAN; SAT_type:Survey; SAT_type:Benchmark; SAT_archi:Graph; FOCUS_STUDY_OCT; CHECKED1023; SAT_focus:adversarial; SAT_benchmark:True; SAT_interest:4; SAT_typology_dim:Generative; SAT_typology_dim:Tag; SAT_nbDataset:5; SAT_focus:flexibility; SAT_focus:Dependancy; SAT_focus_period:2013-2021; SAT_nbModel:12","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ijcai 2022","","","","","","","","","","","","","","",""
"ADDDCU4Z","journalArticle","2021","Zhang, Jing; Chen, Bo; Zhang, Lingxi; Ke, Xirui; Ding, Haipeng","Neural, symbolic and neural-symbolic reasoning on knowledge graphs","Elsevier","","2666-6510","10.1016/j.aiopen.2021.03.001","https://www.sciencedirect.com/science/article/pii/S2666651021000061","Knowledge graph reasoning is the fundamental component to support machine learning applications such as information extraction, information retrieval, and recommendation. Since knowledge graphs can be viewed as the discrete symbolic representations of knowledge, reasoning on knowledge graphs can naturally leverage the symbolic techniques. However, symbolic reasoning is intolerant of the ambiguous and noisy data. On the contrary, the recent advances of deep learning have promoted neural reasoning on knowledge graphs, which is robust to the ambiguous and noisy data, but lacks interpretability compared to symbolic reasoning. Considering the advantages and disadvantages of both methodologies, recent efforts have been made on combining the two reasoning methods. In this survey, we take a thorough look at the development of the symbolic, neural and hybrid reasoning on knowledge graphs. We survey two specific reasoning tasks — knowledge graph completion and question answering on knowledge graphs, and explain them in a unified reasoning framework. We also briefly discuss the future directions for knowledge graph reasoning.","2021","2023-05-23 14:09:01","2025-02-04 17:18:54","","14-35","","","2","","AI Open","","","","","","","","","","","","","","","{'citing': ['10.3390/j4040061', '10.1016/j.cej.2022.136669', '10.1007/978-3-031-06981-9_5', '10.1109/taslp.2022.3164218', '10.1016/j.inffus.2022.09.003', '10.1109/iscas48785.2022.9937699', '10.3233/sw-223228', '10.23919/ccc55666.2022.9901564'], 'cited': ['10.1007/s00778-015-0394-1', '10.1016/j.eswa.2019.112948', '10.1038/323533a0', '10.1145/3065386', '10.1037/h0042519', '10.1109/tc.1986.1676819', '10.14778/2350229.2350236', '10.14778/3236187.3236192', '10.1613/jair.5714', '10.1007/bf00116835', '10.1016/0004-3702(94)90105-8', '10.1109/tpami.2006.79', '10.1162/tacl_a_00153', '10.1007/bf00114160', '10.1007/s10994-010-5205-8', '10.1145/42372.42377', '10.14778/3055540.3055549', '10.1007/s00778-016-0444-3', '10.1007/s10994-006-5833-1', '10.1023/a:1010924021315', '10.1109/tkde.2017.2754499', '10.1162/neco.2006.18.7.1527']}","","","","star; NOT A SURVEY ?; SAT_task:Reasoning; FOCUS_STUDY_OCT; but out of scope","Knowledge graph embedding; Knowledge graph reasoning; Neural-symbolic reasoning; Symbolic reasoning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G73M849Z","journalArticle","2021","Yohan Bonescki Gumiel, Lucas Emanuel Silva e Oliveira; , V. Claveau; , N. Grabar; , E. Paraiso; , C. Moro; , D. Carvalho","Temporal Relation Extraction in Clinical Texts","ACM","","","10.1145/3462475","https://www.semanticscholar.org/paper/97fa60a81a1e800a8ecbe5ef13d6798fc13dc799","Unstructured data in electronic health records, represented by clinical texts, are a vast source of healthcare information because they describe a patient's journey, including clinical findings, procedures, and information about the continuity of care. The publication of several studies on temporal relation extraction from clinical texts during the last decade and the realization of multiple shared tasks highlight the importance of this research theme. Therefore, we propose a review of temporal relation extraction in clinical texts. We analyzed 105 articles and verified that relations between events and document creation time, a coarse temporality type, were addressed with traditional machine learning–based models with few recent initiatives to push the state-of-the-art with deep learning–based models. For temporal relations between entities (event and temporal expressions) in the document, factors such as dataset imbalance because of candidate pair generation and task complexity directly affect the system's performance. The state-of-the-art resides on attention-based models, with contextualized word representations being fine-tuned for temporal relation extraction. However, further experiments and advances in the research topic are required until real-time clinical domain applications are released. Furthermore, most of the publications mainly reside on the same dataset, hindering the need for new annotation projects that provide datasets for different medical specialties, clinical text types, and even languages.","2021-09-17","2023-02-03 15:59:14","2025-02-04 17:18:54","","1 - 36","","nan","54","","ACM Computing Surveys (CSUR)","","","","","","","","","TRUE","","SemanticScholar","97fa60a81a1e800a8ecbe5ef13d6798fc13dc799","","","{'citing': ['10.1186/s13326-022-00269-1', '10.1109/icsp54964.2022.9778554', '10.1109/bdai56143.2022.9862667'], 'cited': ['10.1016/j.jbi.2015.06.030', '10.1007/s10618-019-00671-x', '10.1016/j.ijmedinf.2019.103985', '10.1016/j.jbi.2009.05.002', '10.1016/j.jbi.2013.09.007', '10.1016/j.jbi.2015.06.013', '10.1016/j.jbi.2015.08.013', '10.1016/j.jbi.2017.11.011', '10.1016/j.jbi.2020.103488', '10.1136/amiajnl-2014-002642', '10.1136/jamia.2009.001560', '10.1145/1273496.1273513', '10.1145/182.358434', '10.1197/jamia.m2467', '10.18653/v1/n18-1202', '10.18653/v1/s15-2136', '10.18653/v1/s16-1175', '10.18653/v1/s16-1198', '10.18653/v1/s17-2180', '10.18653/v1/w16-2914', '10.18653/v1/w18-2303', '10.3115/v1/p14-2082', '10.1007/s10579-017-9382-y', '10.1016/j.jbi.2013.08.003', '10.1016/j.jbi.2013.09.010', '10.1016/j.jbi.2015.08.011', '10.1016/j.jbi.2015.09.002', '10.1016/j.jbi.2016.06.006', '10.1016/j.jbi.2017.07.012', '10.1016/j.jbi.2019.103309', '10.1136/amiajnl-2013-001635', '10.1186/s12911-018-0627-5', '10.18653/v1/k19-1062', '10.18653/v1/s15-2137', '10.18653/v1/s16-1165', '10.18653/v1/s16-1193', '10.18653/v1/s16-1199', '10.18653/v1/s17-2098', '10.18653/v1/w17-2341', '10.18653/v1/w19-1909', '10.4258/hir.2018.24.3.179', '10.5715/jnlp.27.383', '10.1007/s10579-005-7882-7', '10.1016/j.cmpb.2019.01.007', '10.1016/j.jbi.2015.09.006', '10.1038/sdata.2016.35', '10.1136/amiajnl-2011-000295', '10.1136/amiajnl-2013-001612', '10.1136/amiajnl-2013-001619', '10.1155/2015/636371', '10.1186/s12859-014-0373-3', '10.1186/s12911-020-01208-9', '10.13063/2327-9214.1079', '10.18653/v1/d19-1642', '10.18653/v1/e17-2118', '10.18653/v1/p17-2035', '10.18653/v1/s17-2093', '10.18653/v1/s17-2178', '10.18653/v1/w18-5619', '10.18653/v1/w18-5620', '10.2196/12239', '10.3115/v1/p14-2014', '10.1007/s10579-005-7884-5', '10.1007/s41666-019-00049-0', '10.1016/j.jbi.2015.05.009', '10.1016/j.jbi.2015.06.014', '10.1016/j.jbi.2015.08.009', '10.1016/j.jbi.2019.103219', '10.1093/jamia/ocv113', '10.1136/amiajnl-2013-001622', '10.1136/amiajnl-2013-001627', '10.1136/amiajnl-2013-002463', '10.1162/tacl_a_00172', '10.1186/s12911-019-0735-x', '10.1371/journal.pmed.1000097', '10.18653/v1/p19-1280', '10.18653/v1/s16-1190', '10.18653/v1/s16-1194', '10.18653/v1/s16-1197', '10.18653/v1/s17-2181', '10.18653/v1/w19-1917', '10.1016/j.artmed.2020.101860', '10.1016/j.ijmedinf.2016.10.021', '10.1016/j.jbi.2013.11.001', '10.1016/j.jbi.2015.08.025', '10.1038/nrg3208', '10.1109/time.2006.27', '10.1136/amiajnl-2012-001607', '10.1136/amiajnl-2013-001624', '10.1136/amiajnl-2013-001628', '10.1136/amiajnl-2013-001760', '10.1136/jamia.2010.004804', '10.1162/tacl_a_00182', '10.18653/v1/2020.bionlp-1.7', '10.18653/v1/e17-1108', '10.18653/v1/e17-2117', '10.18653/v1/p16-1105', '10.18653/v1/s16-1192', '10.18653/v1/s17-2177', '10.18653/v1/w18-5607', '10.18653/v1/w19-5026']}","","/root/snap/zotero-snap/common/Zotero/storage/63UQXKDX/Yohan Bonescki Gumiel et al. - 2021 - Temporal Relation Extraction in Clinical Texts.pdf","","manual; star; automatic; SAT_model:BERT; SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_archi:BiLSTM; SAT_rel_type:temporal; SAT_archi:CRF; SAT_archi:CNN; SAT_domain:medical; SAT_task:EventExtraction; SAT_archi:GRU; SAT_archi:SVM; SAT_focus:TemporalRel; SAT_focus:RulesBased; SAT_nbDataset:alot; SAT_nbModel:alot; FOCUS_STUDY_OCT; CHECKED1023; SAT_defined_protocol:True; SAT_interest:10; SAT_focus_period:2001-2020; SAT_type:SystematicReview","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XBJZA36V","journalArticle","2022","Yang, Jie; Han, Soyeon Caren; Poon, Josiah","A survey on extraction of causal relations from natural language text","Springer","","0219-3116","10.1007/s10115-022-01665-w","https://doi.org/10.1007/s10115-022-01665-w","As an essential component of human cognition, cause–effect relations appear frequently in text, and curating cause–effect relations from text helps in building causal networks for predictive tasks. Existing causality extraction techniques include knowledge-based, statistical machine learning (ML)-based, and deep learning-based approaches. Each method has its advantages and weaknesses. For example, knowledge-based methods are understandable but require extensive manual domain knowledge and have poor cross-domain applicability. Statistical machine learning methods are more automated because of natural language processing (NLP) toolkits. However, feature engineering is labor-intensive, and toolkits may lead to error propagation. In the past few years, deep learning techniques attract substantial attention from NLP researchers because of its powerful representation learning ability and the rapid increase in computational resources. Their limitations include high computational costs and a lack of adequate annotated training data. In this paper, we conduct a comprehensive survey of causality extraction. We initially introduce primary forms existing in the causality extraction: explicit intra-sentential causality, implicit causality, and inter-sentential causality. Next, we list benchmark datasets and modeling assessment methods for causal relation extraction. Then, we present a structured overview of the three techniques with their representative systems. Lastly, we highlight existing open challenges with their potential directions.","2022-05-01","2023-03-06 19:02:26","2023-10-23 11:43:29","2023-03-06 19:02:26","1161-1186","","5","64","","Knowl Inf Syst","","Knowledge and Information Systems","","","","","","en","","","","","Springer Link","","{'citing': ['10.1007/978-3-031-12670-3_3', '10.1007/978-3-031-16075-2_59', '10.1007/978-3-031-19433-7_37'], 'cited': ['10.1007/978-3-030-47426-3_57', '10.1007/978-3-319-13650-9_24', '10.1007/978-3-642-04962-0_53', '10.1007/978-94-017-0073-3_4', '10.1007/bfb0026799', '10.1007/s10579-009-9083-2', '10.1016/0005-2795(75)90109-9', '10.1016/j.datak.2013.08.004', '10.1016/j.eswa.2014.05.044', '10.1016/j.eswa.2018.07.032', '10.1016/j.ipm.2005.04.004', '10.1016/j.jbi.2012.04.008', '10.1016/j.jksuci.2014.06.001', '10.1016/j.neucom.2015.09.066', '10.1016/j.neucom.2020.08.078', '10.1016/j.procs.2017.08.252', '10.1038/nature14539', '10.1093/bioinformatics/btz682', '10.1093/database/baw042', '10.1093/llc/13.4.177', '10.1109/icmcce.2017.14', '10.1109/ijcnn48605.2020.9207554', '10.1109/med.2007.4433808', '10.1109/second.2006.1629336', '10.1109/tkde.2007.190623', '10.1145/1321440.1321461', '10.1145/2187836.2187958', '10.1145/234173.234209', '10.1145/2505515.2505612', '10.1145/3018661.3018737', '10.1145/3241741', '10.1145/502585.502679', '10.1155/2014/298473', '10.1186/1471-2105-11-101', '10.1186/1471-2105-15-64', '10.1186/1471-2105-8-50', '10.1186/1471-2105-9-s11-s2', '10.1186/1475-925x-13-s2-s1', '10.1186/s12859-017-1609-9', '10.1186/s12864-019-6413-7', '10.12720/jiii.1.3.169-173', '10.13053/rcs-117-1-8', '10.1609/aaai.v33i01.33017370', '10.18653/v1/2020.acl-demos.14', '10.18653/v1/2020.acl-main.527', '10.18653/v1/2020.emnlp-main.127', '10.18653/v1/2020.emnlp-main.133', '10.18653/v1/2020.emnlp-main.303', '10.18653/v1/2020.findings-emnlp.409', '10.18653/v1/d15-1206', '10.18653/v1/d17-1004', '10.18653/v1/d17-1134', '10.18653/v1/d18-1244', '10.18653/v1/d18-1307', '10.18653/v1/d19-1021', '10.18653/v1/d19-1238', '10.18653/v1/d19-1371', '10.18653/v1/d19-1498', '10.18653/v1/n18-1202', '10.18653/v1/n19-1423', '10.18653/v1/p16-1123', '10.18653/v1/p16-1135', '10.18653/v1/p16-1163', '10.18653/v1/p18-2014', '10.18653/v1/p19-1024', '10.18653/v1/p19-1074', '10.18653/v1/p19-1132', '10.18653/v1/w17-0903', '10.18653/v1/w18-5035', '10.18653/v1/w19-5006', '10.18653/v1/w19-5031', '10.2307/1912791', '10.24963/ijcai.2020/558', '10.3115/1073083.1073145', '10.3115/1075218.1075261', '10.3115/1119312.1119322', '10.3115/1557690.1557740', '10.3115/1621474.1621477', '10.3115/1621969.1621986', '10.3115/1690219.1690287', '10.3115/1699510.1699555', '10.3115/v1/e14-1068', '10.3115/v1/p14-5010', '10.3389/fgene.2021.669328', '10.3389/fimmu.2018.01783', '10.3389/fphys.2021.658633']}","","/root/snap/zotero-snap/common/Zotero/storage/927N8M42/Yang et al. - 2022 - A survey on extraction of causal relations from na.pdf","","SAT_model:BERT; SAT_rel_type:Cross-sentence; SAT_task:RE; SAT_archi:CNN; SAT_archi:RNN; SAT_archi:GCN; SAT_rel_type:causal; SAT_archi:LSTM; SAT_rel_type:implicit; SAT_type:Survey; SAT_focus:Causal; SAT_typology_dim:Architecture; CHECKED1023; SAT_benchmark_type:Qualitative; SAT_benchmark_type:Quantitative; SAT_dataset:SemEval; SAT_dataset:TACRED; SAT_interest:8; SAT_nbDataset:6; SAT_dataset:ADE; SAT_dataset:PDTB; SAT_dataset:BioInfer; SAT_archi:GAT; SAT_nbModel:48; SAT_focus_period:1998-2020; SAT_focus:EVAL; SAT_rel_type:causality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JWINAZVE","journalArticle","2019","Xiang, Wei; Wang, Bang","A Survey of Event Extraction From Text","IEEE","","2169-3536","10.1109/ACCESS.2019.2956831","","Numerous important events happen everyday and everywhere but are reported in different media sources with different narrative styles. How to detect whether real-world events have been reported in articles and posts is one of the main tasks of event extraction. Other tasks include extracting event arguments and identifying their roles, as well as clustering and tracking similar events from different texts. As one of the most important research themes in natural language processing and understanding, event extraction has a wide range of applications in diverse domains and has been intensively researched for decades. This article provides a comprehensive yet up-to-date survey for event extraction from text. We not only summarize the task definitions, data sources and performance evaluations for event extraction, but also provide a taxonomy for its solution approaches. In each solution group, we provide detailed analysis for the most representative methods, especially their origins, basics, strengths and weaknesses. Last, we also present our envisions about future research directions.","2019","2023-03-01 14:40:25","2025-02-04 17:18:54","","173111-173137","","","7","","IEEE Access","","","","","","","","","","","","","IEEE Xplore","","{'citing': ['10.25209/2079-3316-2020-11-4-31-53', '10.1016/j.patrec.2020.08.019', '10.1016/j.ipm.2020.102261', '10.1016/j.aiia.2021.07.003', '10.1016/j.aiia.2021.07.003', '10.1007/978-981-16-0882-7_45', '10.1016/j.ipm.2021.102636', '10.1007/978-3-030-80418-3_31', '10.1007/978-3-030-77961-0_56', '10.1007/978-3-030-86324-1_19', '10.1007/s11063-021-10627-2', '10.1007/978-3-030-91699-2_34', '10.1007/978-3-030-88483-3_5', '10.1371/journal.pone.0260701', '10.1007/978-3-030-96585-3_1', '10.3390/fi14010026', '10.1007/978-3-030-98305-5_16', '10.3389/fnins.2021.739535', '10.1109/iwecai55315.2022.00084', '10.1109/etcce51779.2020.9350891', '10.1007/s10489-022-03598-x', '10.1109/access.2021.3130956', '10.1109/icmla51294.2020.00166', '10.1002/widm.1473', '10.1109/icsc50631.2021.00064', '10.3390/ijgi11060345', '10.1109/iske54062.2021.9755329', '10.1109/taslp.2021.3138670', '10.1007/978-3-031-11217-1_12', '10.3390/math10142437', '10.1007/978-3-031-06767-9_41', '10.1007/978-3-031-06767-9_49', '10.1145/3501247.3531565', '10.1007/978-981-19-5209-8_10', '10.1007/s10462-022-10239-9', '10.1109/jcsse54890.2022.9836294', '10.1049/gtd2.12598', '10.1371/journal.pone.0272353', '10.1007/s13042-022-01655-y', '10.1007/978-3-031-10983-6_9', '10.1109/access.2022.3205314', '10.1109/aemcse55572.2022.00077'], 'cited': ['10.18653/v1/w17-2315', '10.18653/v1/w17-4211', '10.21437/interspeech.2010-343', '10.24963/ijcai.2018/584', '10.3115/1075218.1075228', '10.3115/1075671.1075684', '10.3115/1118693.1118694', '10.3115/1572340.1572343', '10.3115/1572340.1572346', '10.3115/1572340.1572347', '10.3115/1572340.1572348', '10.3115/1572340.1572361', '10.3115/1620853.1620910', '10.3115/1621829.1621838', '10.3115/1629235.1629236', '10.3115/1641968.1641972', '10.3115/974147.974158', '10.3115/992730.992782', '10.3115/v1/d14-1090', '10.3115/v1/d14-1179', '10.3115/v1/d14-1181', '10.3115/v1/d14-1198', '10.3115/v1/p14-1062', '10.3115/v1/p14-2105', '10.3115/v1/p14-2114', '10.3115/v1/p14-2136', '10.3115/v1/p15-1017', '10.3115/v1/p15-1150', '10.3115/v1/p15-2060', '10.3115/v1/p15-3005', '10.3115/v1/w14-2905', '10.3115/v1/w14-2907', '10.3115/v1/w15-0812', '10.3115/v1/w15-1506', '10.3390/fi10100095', '10.1006/csla.1998.0102', '10.1007/11581772_66', '10.1007/3-540-36182-0_30', '10.1007/978-0-387-87685-6_27', '10.1007/978-3-030-01012-6_20', '10.1007/978-3-030-01012-6_21', '10.1007/978-3-030-04221-9_23', '10.1007/978-3-030-15712-8_51', '10.1007/978-3-319-47674-2_17', '10.1007/978-3-319-50496-4_23', '10.1007/978-3-319-50496-4_27', '10.1007/978-3-319-69005-6_11', '10.1007/978-3-319-99501-4_20', '10.1007/978-3-540-72035-5_22', '10.1007/978-3-540-88906-9_26', '10.1007/978-3-642-33185-5_10', '10.1007/978-3-642-34399-5_9', '10.1007/s10489-018-1269-0', '10.1016/j.artmed.2011.08.002', '10.1016/j.dss.2016.02.006', '10.1016/j.elerap.2018.02.006', '10.1016/j.jbi.2019.103156', '10.1016/j.knosys.2019.01.008', '10.1016/j.websem.2015.12.004', '10.1080/08874417.2015.11645768', '10.1088/1742-6596/978/1/012078', '10.1093/bioinformatics/btq180', '10.1093/bioinformatics/bts237', '10.1093/bioinformatics/bts487', '10.1093/bioinformatics/btz607', '10.1109/69.469825', '10.1109/access.2019.2900124', '10.1109/asonam.2014.6921613', '10.1109/bigdata.2018.8622198', '10.1109/dsc.2018.00140', '10.1109/kse.2012.34', '10.1109/tcbb.2015.2476876', '10.1109/tcbb.2018.2868078', '10.1109/tkde.2013.133', '10.1109/tnn.2008.2005605', '10.1111/coin.12017', '10.1111/j.1467-8640.2011.00400.x', '10.1111/j.1467-8640.2011.00401.x', '10.1142/s0219720010004586', '10.1145/1031171.1031258', '10.1145/1076034.1076055', '10.1145/2339530.2339704', '10.1145/2567948.2577348', '10.1145/2983323.2983821', '10.1145/2994600', '10.1145/3219819.3219827', '10.1145/3269206.3271674', '10.1145/3308558.3313659', '10.1145/383952.384068', '10.1155/2014/205239', '10.1155/2015/571381', '10.1162/dint_a_00014', '10.1186/1471-2105-12-s2-s4', '10.1186/1471-2105-14-175', '10.1186/1471-2105-9-78', '10.1186/1477-5956-11-s1-s17', '10.1186/2041-1480-2-s5-s6', '10.1504/ijwet.2010.038242', '10.1609/aaai.v33i01.33016754', '10.1609/aaai.v33i01.33016851', '10.18653/v1/d15-1247', '10.18653/v1/d16-1038', '10.18653/v1/d16-1085', '10.18653/v1/d18-1122', '10.18653/v1/d18-1127', '10.18653/v1/d18-1156', '10.18653/v1/d18-1158', '10.18653/v1/d18-1517', '10.18653/v1/d19-1032', '10.18653/v1/e17-1076', '10.18653/v1/n16-1030', '10.18653/v1/n16-1033', '10.18653/v1/n16-1034', '10.18653/v1/n18-2058', '10.18653/v1/n19-1105', '10.18653/v1/n19-4019', '10.18653/v1/p16-1025', '10.18653/v1/p16-1101', '10.18653/v1/p16-1105', '10.18653/v1/p16-1116', '10.18653/v1/p16-1201', '10.18653/v1/p16-2006', '10.18653/v1/p16-2011', '10.18653/v1/p16-2060', '10.18653/v1/p17-1038', '10.18653/v1/p17-1164', '10.18653/v1/p18-1048', '10.18653/v1/p18-1145', '10.18653/v1/p18-1201', '10.18653/v1/p18-2066', '10.18653/v1/p18-4009', '10.18653/v1/p19-1276', '10.18653/v1/p19-1521', '10.18653/v1/s15-1018', '10.18653/v1/w16-1618']}","","/root/snap/zotero-snap/common/Zotero/storage/SNKBQ8Y9/8918013.html; /root/snap/zotero-snap/common/Zotero/storage/8PLN9P6G/Xiang and Wang - 2019 - A Survey of Event Extraction From Text.pdf","","SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_archi:BiLSTM; SAT_archi:CNN; SAT_archi:RNN; SAT_lang:chinese; SAT_task:EventExtraction; SAT_archi:GNN; SAT_lang:english; SAT_type:Survey; SAT_focus:Event; SAT_typology:False; FOCUS_STUDY_OCT; CHECKED1023; SAT_focus:adversarial; SAT_benchmark:True; SAT_nbModel:51; SAT_dataset:ACE; SAT_nbDataset:1; SAT_interest:4; SAT_focus_period:1982-2019","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NJJXLFRU","journalArticle","2022","Wu, Kehan; Zhang, Xueying; Dang, Yulong; Ye, Peng","Deep learning models for spatial relation extraction in text","Taylor&Francis","","1009-5020","10.1080/10095020.2022.2076619","https://doi.org/10.1080/10095020.2022.2076619","Spatial relation extraction is the process of identifying geographic entities from text and determining their corresponding spatial relations. Traditional spatial relation extraction mainly uses rule-based pattern matching, supervised learning-based or unsupervised learning-based methods. However, these methods suffer from poor time-sensitive, high labor cost and high dependence on large-scale data. With the development of pre-trained language models greatly alleviating the shortcomings of traditional methods, supervised learning methods incorporating pre-trained language models have become the mainstream relation extraction methods. Pipeline extraction and joint extraction, as the two most dominant ideas of relation extraction, both have obtained good performance on different datasets, and whether to share the contextual information of entities and relations is the main differences between the two ideas. In this paper, we compare the performance of two ideas oriented to spatial relation extraction based on Chinese corpus data in the field of geography and verify which method based on pre-trained language models is more suitable for Chinese spatial relation extraction. We fine-tuned the hyperparameters of the two models to optimize the extraction accuracy before the comparison experiments. The results of the comparison experiments show that pipeline extraction performs better than joint extraction of spatial relation extraction for Chinese text data with sentence granularity, because different tasks have different focus on contextual information, and it is difficult to take account into the needs of both tasks by sharing contextual information. In addition, we further compare the performance of the two models with the rule-based template approach in extracting topological, directional and distance relations, summarize the shortcomings of this experiment and provide an outlook for future work.","2022-09-07","2023-03-06 19:42:57","2023-10-23 06:18:56","2023-03-06 19:42:57","1-13","","0","26","","Geo-spatial Information Science","","","","","","","","","True","","","","Taylor and Francis+NEJM","","{'citing': [], 'cited': ['10.1007/978-3-642-32597-7_5', '10.1007/s11431-020-1647-3', '10.1080/13658816.2016.1212356', '10.1109/cise.2009.5363900', '10.1109/esiat.2009.429', '10.1109/geoinformatics.2015.7378569', '10.1109/icsdm.2011.5969102', '10.1109/tpami.2013.50', '10.1162/jocn_a_01724', '10.1162/tacl_a_00300', '10.1609/aaai.v34i05.6374', '10.18653/v1/2020.acl-main.136', '10.18653/v1/2020.emnlp-main.133', '10.18653/v1/2021.naacl-main.5', '10.18653/v1/d18-1307', '10.18653/v1/d19-1585', '10.18653/v1/p16-1105', '10.18653/v1/p17-1113', '10.3115/1118693.1118703', '10.3321/j.issn:1671-8860.2005.06.016', '10.3969/j.issn.1560-8999.2007.06.014']}","","/root/snap/zotero-snap/common/Zotero/storage/G6YHG6B6/Wu et al. - 2022 - Deep learning models for spatial relation extracti.pdf","","SAT_task:RE; SAT_lang:chinese; SAT_archi:Rules; SAT_focus:models; SAt_focus:SpatialRel; SAT_task:JoinRE; CHECKED1023; SAT_benchmark:True; SAT_benchmark_type:Qualitative; SAT_nbModel:2; SAT_model:PURE; SAT_focus:PipelineVSJoinRE; SAT_rel_type:spatial; SAT_archi:Pipeline; SAT_model:CasRel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"62UHZHSR","journalArticle","2019","Nora Madi, Rawan N. Al-Matham; , Hend Suliman Al-Khalifa","Grammar checking and relation extraction in text: approaches, techniques and open challenges","Emerald","","","10.1108/dta-01-2019-0001","https://www.semanticscholar.org/paper/3c6f4464b007ca9c1f8e587514751c62678029fa","Purpose The purpose of this paper is to provide an overall review of grammar checking and relation extraction (RE) literature, their techniques and the open challenges associated with them; and, finally, suggest future directions. Design/methodology/approach The review on grammar checking and RE was carried out using the following protocol: we prepared research questions, planed for searching strategy, addressed paper selection criteria to distinguish relevant works, extracted data from these works, and finally, analyzed and synthesized the data. Findings The output of error detection models could be used for creating a profile of a certain writer. Such profiles can be used for author identification, native language identification or even the level of education, to name a few. The automatic extraction of relations could be used to build or complete electronic lexical thesauri and knowledge bases. Originality/value Grammar checking is the process of detecting and sometimes correcting erroneous words in the text, while RE is the process of detecting and categorizing predefined relationships between entities or words that were identified in the text. The authors found that the most obvious challenge is the lack of data sets, especially for low-resource languages. Also, the lack of unified evaluation methods hinders the ability to compare results.","2019-06-14","2023-02-03 15:59:28","2025-02-04 17:20:33","","373-394","","nan","53","","Data Technol. Appl.","","","","","","","","","False but accesible","","SemanticScholar","3c6f4464b007ca9c1f8e587514751c62678029fa","","","{'citing': ['10.1109/scse49731.2020.9313051'], 'cited': ['10.1002/spe.653', '10.1002/tee.21696', '10.1007/s10579-009-9081-4', '10.1007/s10772-015-9301-9', '10.1007/s11390-017-1757-4', '10.1016/j.jksuci.2017.09.004', '10.1016/j.knosys.2015.03.017', '10.1017/s1351324906004190', '10.1515/pralin-2016-0006', '10.2200/s00562ed1v01y201401hlt025', '10.2200/s00741ed1v01y201611wbe015', '10.2200/s00762ed1v01y201703hlt037', '10.22452/mjcs.vol29no1.5', '10.5121/ijcsit.2016.8107']}","","","","star; automatic; SAT_task:RE; SAT_archi:CNN; SAT_lang:chinese; SAT_archi:Rules; SAT_rel_type:causal; SAT_model:word2vec; SAT_lang:english; SAT_lang:arabic; SAT_lang:german; SAT_lang:turkish; SAT_focus:FewSHot; SAT_focus:datasets; SAT_typology_dim:Architecture; FOCUS_STUDY_OCT; CHECKED1023; SAT_dataset:ACE; SAT_benchmark_type:Qualitative; SAT_dataset:SemEval; SAT_interest:7; SAT_type:SystematicReview; SAT_dataset:CONLL; SAT_task:GrammarChecking; SAT_dataset:NLPCC; SAT_rel_type:semantic; SAT_rel_type:composition; SAT_focus:lang; SAT_focus_period:1992-2019; SAT_nbDataset:10; SAT_NBModel:34; SAT_lang:greek; SAT_lang:Danish","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6NF77N5F","journalArticle","2021","M. Aydar, Özge Bozal; , Furkan Özbay","Neural relation extraction: a review","Tubitak","","","10.3906/elk-2005-119","https://www.semanticscholar.org/paper/2c3c0a1e693ed35b088a8ea2d6d99db0a35f599e","Neural relation extraction discovers semantic relations between entities from unstructured text using deep learning methods. In this study, we make a clear categorization of the existing relation extraction methods in terms of data expressiveness and data supervision, and present a comprehensive and comparative review. We describe the evaluation methodologies and the datasets used for model assessment. We explicitly state the common challenges in relation extraction task and point out the potential of the pretrained models to solve them. Accordingly, we investigate additional research directions and improvement ideas in this field.","2021-03-30","2023-02-03 15:59:21","2023-10-23 11:31:43","","1029-1043","","nan","29","","Turkish J. Electr. Eng. Comput. Sci.","","","","","","","","","TRUE","","SemanticScholar","2c3c0a1e693ed35b088a8ea2d6d99db0a35f599e","","","","","/root/snap/zotero-snap/common/Zotero/storage/5Q8SEMCS/M. Aydar and  - 2021 - Neural relation extraction a review.pdf","","star; automatic; SAT_model:BERT; SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_archi:BiLSTM; SAT_archi:CNN; SAT_focus:Denoising; SAT_model:GPT3; SAT_archi:LSTM; SAT_rel_type:overlapping; SAT_model:GPT2; SAT_model:Transformer; SAT_focus:FewSHot; SAT_type:Review; SAT_focus:distant; SAT_focus:NeuralModels; SAT_nbDataset:7; SAT_focus:Alignement; CHECKED1023; SAT_dataset:NYT; SAT_benchmark_type:Quantitative; SAT_dataset:SemEval; SAT_dataset:TACRED; SAT_dataset:FewRel; SAT_focus:FewShot; SAT_dataset:DocRED; SAT_focus_period:1992-2020; SAT_interest:8; SAT_dataset:Wiki80; SAT_model:TransformerXL; SAT_nbModel:20; SAT_focus:EVAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9P87DI5W","journalArticle","2022","Ji, Shaoxiong; Pan, Shirui; Cambria, Erik; Marttinen, Pekka; Yu, Philip S.","A Survey on Knowledge Graphs: Representation, Acquisition and Applications","IEEE","","2162-237X, 2162-2388","10.1109/TNNLS.2021.3070843","http://arxiv.org/abs/2002.00388","Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction towards cognition and human-level intelligence. In this survey, we provide a comprehensive review of knowledge graph covering overall research topics about 1) knowledge graph representation learning, 2) knowledge acquisition and completion, 3) temporal knowledge graph, and 4) knowledge-aware applications, and summarize recent breakthroughs and perspective directions to facilitate future research. We propose a full-view categorization and new taxonomies on these topics. Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information. For knowledge acquisition, especially knowledge graph completion, embedding methods, path inference, and logical rule reasoning, are reviewed. We further explore several emerging topics, including meta relational learning, commonsense reasoning, and temporal knowledge graphs. To facilitate future research on knowledge graphs, we also provide a curated collection of datasets and open-source libraries on different tasks. In the end, we have a thorough outlook on several promising research directions.","2022-02","2022-12-14 08:23:30","2025-02-04 17:18:54","2022-12-14 08:23:30","494-514","","2","33","","IEEE Trans. Neural Netw. Learning Syst.","","","","","IEEE Transactions on Neural Networks and Learning Systems","","","en","True","","","","arXiv.org","","{'citing': ['10.3390/electronics11233913', '10.3390/systems10050178', '10.54097/ijeh.v3i1.395', '10.1109/access.2021.3130956', '10.1109/isi53945.2021.9624688', '10.1142/s0218194022500279', '10.1109/tai.2021.3087116', '10.1007/978-3-031-18315-7_21', '10.1360/ssi-2021-0100', '10.1007/978-981-19-7596-7_1', '10.1016/j.ipm.2022.103157', '10.1007/s00158-022-03425-4', '10.1360/ssi-2021-0217', '10.1016/j.aei.2022.101780', '10.1016/j.eswa.2022.119122', '10.1007/978-3-031-18461-1_22', '10.1109/acit54803.2022.9913123', '10.1109/tmm.2021.3094296', '10.1007/s11063-022-10831-8', '10.1007/s11063-022-10831-8', '10.1080/13658816.2022.2092115', '10.1080/13658816.2022.2092115', '10.1007/s12204-022-2474-x', '10.3390/electronics11152287', '10.3389/fnins.2022.911767', '10.1109/icscde54196.2021.00082', '10.1007/978-3-031-09593-1_21', '10.34133/2022/9841548', '10.1109/jsen.2022.3178111', '10.3390/app12146993', '10.1109/access.2022.3187178', '10.1007/s11761-022-00338-4', '10.1109/lra.2022.3191194', '10.1109/kst53302.2022.9729073', '10.3390/ijgi11070360', '10.1109/iccve52871.2022.9742971', '10.2196/preprints.39888', '10.1007/s10489-022-03721-y', '10.1155/2022/8300672', '10.1109/globecom46510.2021.9685056', '10.1002/aaai.12056', '10.1002/aaai.12056', '10.1109/bigdata52589.2021.9671344', '10.1109/bigdata52589.2021.9671616', '10.1016/j.ailsci.2022.100036', '10.3390/math10162846', '10.1007/s10489-022-04048-4', '10.1016/j.compeleceng.2022.108261', '10.1016/j.compeleceng.2022.108261', '10.3233/sw-222991', '10.1016/j.knosys.2022.109703', '10.2196/39888', '10.1109/tim.2022.3200429', '10.1109/tim.2022.3200429', '10.1093/bioinformatics/btac478', '10.1007/978-981-19-6226-4_80', '10.3390/jmse10101352', '10.3390/jmse10101352', '10.1016/j.inffus.2022.09.020', '10.1016/j.inffus.2022.09.020', '10.23919/ascc56756.2022.9828336', '10.1007/s10489-022-03981-8', '10.1007/s10489-022-03983-6', '10.1038/s41524-022-00853-0', '10.1038/s41524-022-00853-0', '10.1016/j.knosys.2022.109688', '10.1016/j.knosys.2022.109688', '10.1109/vl/hcc53370.2022.9833109', '10.3390/rs14174391', '10.1109/access.2022.3203735', '10.1109/access.2022.3203735', '10.3390/su14169870', '10.1111/mice.12904', '10.1016/j.knosys.2022.109889', '10.1016/j.knosys.2022.109889', '10.1109/jsac.2022.3191112', '10.3390/app12168024', '10.1155/2022/2348375', '10.3389/fenrg.2022.988280', '10.1109/jbhi.2022.3173558', '10.3390/min12091080', '10.1109/tii.2022.3178414', '10.1186/s13677-022-00334-1', '10.1007/978-3-031-19433-7_35', '10.1007/978-3-031-19433-7_47', '10.1145/3511808.3557352', '10.1145/3511808.3557355', '10.1145/3511808.3557361', '10.1145/3511808.3557374', '10.1007/s10115-022-01764-8', '10.1111/bjet.13283', '10.1007/978-3-031-21422-6_15', '10.1007/978-3-031-21422-6_2', '10.1007/978-3-031-21422-6_25', '10.1007/978-3-031-21422-6_6', '10.1145/3503161.3548089', '10.1007/978-3-031-10983-6_32', '10.1007/978-3-031-10983-6_19', '10.1007/978-3-031-10983-6_30', '10.1109/kse56063.2022.9953802', '10.3390/jsan11040078', '10.1007/978-3-031-20865-2_10', '10.3390/app121910107', '10.3390/math10224182', '10.1016/j.artmed.2022.102439', '10.1016/j.neunet.2022.11.010', '10.1109/phm-yantai55411.2022.9942091', '10.1109/phm-yantai55411.2022.9941854', '10.1016/j.eswa.2022.119216', '10.1007/978-3-031-21753-1_19', '10.1016/j.ins.2022.11.096', '10.1007/s13735-022-00256-3', '10.1016/j.inffus.2022.10.009', '10.1109/ijcnn55064.2022.9892443', '10.1109/ijcnn55064.2022.9892979', '10.1155/2022/7708376', '10.1109/tpami.2021.3124805', '10.1007/978-3-030-73203-5_17', '10.1186/s40537-021-00492-0', '10.1186/s12859-021-04292-4', '10.1016/j.knosys.2021.107258', '10.1007/s00500-021-05756-8', '10.1016/j.neucom.2021.03.132', '10.1016/j.knosys.2021.107220', '10.1016/j.neucom.2021.02.100', '10.1007/978-3-030-77385-4_25', '10.1016/j.knosys.2021.107347', '10.1016/j.neucom.2021.02.099', '10.1016/j.neucom.2021.02.101', '10.1007/978-3-030-77385-4_24', '10.1007/978-981-15-9774-9_2', '10.1016/j.neucom.2021.03.134', '10.1016/j.neucom.2021.05.100', '10.1007/978-3-030-77385-4_26', '10.1016/j.fmre.2021.09.003', '10.1007/s10844-021-00671-8', '10.1007/978-3-030-88361-4_5', '10.1101/2021.08.17.456616', '10.1007/978-3-030-88361-4_16', '10.3390/make3040040', '10.1007/978-3-030-82136-4_39', '10.1007/978-3-030-86365-4_14', '10.1016/j.patcog.2021.108230', '10.1016/j.future.2021.08.005', '10.1007/s00607-021-00999-7', '10.1145/3474198.3478487', '10.1016/j.patcog.2021.108433', '10.1016/j.fmre.2021.08.018', '10.1007/978-981-16-6372-7_25', '10.1007/s00607-020-00842-5', '10.1007/s00607-020-00842-5', '10.1101/2021.11.04.21265952', '10.3390/s22010003', '10.1007/978-3-030-89657-7_29', '10.1007/s11280-021-00972-6', '10.1007/978-3-030-90888-1_24', '10.1016/j.aei.2021.101419', '10.1186/s40537-021-00519-6', '10.1016/j.knosys.2021.107711', '10.1016/j.cmpbup.2021.100042', '10.1007/s00521-021-06573-8', '10.1007/s11280-022-01022-5', '10.1155/2022/1615596', '10.1145/3502223.3502242', '10.3233/sw-212892', '10.3389/frai.2022.796793', '10.1155/2022/8693937', '10.1007/978-3-030-95481-9_4', '10.1007/s10489-021-03136-1', '10.1101/2022.01.12.475995', '10.1101/2022.01.12.475995', '10.1016/j.neucom.2021.12.079', '10.1093/bioinformatics/btac094', '10.3390/rs14040922', '10.1063/5.0064875', '10.1007/978-3-030-95408-6_10', '10.1007/978-981-16-9247-5_23', '10.1007/s41651-021-00097-4', '10.3233/sw-222925', '10.1007/978-981-16-9995-5_7', '10.3390/cryst12020280', '10.1111/tgis.12911', '10.1177/01655515221074336', '10.3928/00989134-20220308-02', '10.1038/s41467-022-29993-z', '10.1038/s41467-022-29993-z', '10.3233/sw-222970', '10.1007/s11280-022-01030-5', '10.1007/s11280-022-01030-5', '10.1007/s41066-022-00315-4', '10.7717/peerj.13061', '10.1007/978-3-031-00129-1_10', '10.1145/3485447.3512207', '10.3390/info13030133', '10.1038/s41598-022-08454-z', '10.1038/s41598-022-08454-z', '10.3390/info13040161', '10.3390/app12083935', '10.1088/1742-6596/2182/1/012033', '10.1109/access.2021.3092019', '10.1109/access.2021.3106324', '10.1016/j.neucom.2022.07.031', '10.1080/1331677x.2022.2081865', '10.1007/978-3-031-06981-9_15', '10.1007/978-3-031-06981-9_3', '10.3390/min12060669', '10.1109/cscwd54268.2022.9776127', '10.1007/978-3-031-05654-3_8', '10.1007/s40747-022-00742-5', '10.1109/rtsi50628.2021.9597339', '10.1155/2022/4139323', '10.3390/s22103722', '10.1109/bigdia53151.2021.9619694', '10.1109/icisfall51598.2021.9627485', '10.1002/wcms.1597', '10.1109/access.2021.3098417', '10.1109/icsess52187.2021.9522255'], 'cited': ['10.18653/v1/p18-1148', '10.18653/v1/p18-1199', '10.18653/v1/p19-1024', '10.18653/v1/p19-1026', '10.18653/v1/p19-1129', '10.18653/v1/p19-1138', '10.18653/v1/p19-1139', '10.18653/v1/p19-1259', '10.18653/v1/p19-1279', '10.18653/v1/p19-1466', '10.24963/ijcai.2017/209', '10.24963/ijcai.2017/438', '10.24963/ijcai.2017/595', '10.24963/ijcai.2018/556', '10.24963/ijcai.2018/596', '10.24963/ijcai.2018/611', '10.24963/ijcai.2019/268', '10.24963/ijcai.2019/698', '10.24963/ijcai.2019/754', '10.3115/1690219.1690287', '10.3115/v1/d14-1044', '10.3115/v1/d14-1167', '10.3115/v1/d14-1200', '10.3115/v1/d14-1207', '10.3115/v1/p15-1009', '10.3115/v1/p15-1016', '10.3115/v1/p15-1067', '10.3115/v1/w15-1506', '10.3233/sw-160218', '10.3390/su10093245', '10.1007/978-3-030-34223-4_37', '10.1007/978-3-319-68288-4_37', '10.1007/978-3-319-93417-4_38', '10.1007/978-3-642-73402-1_12', '10.1007/s10994-010-5205-8', '10.1007/s10994-013-5363-6', '10.1016/j.eswa.2019.112948', '10.1016/j.websem.2018.12.008', '10.1109/jproc.2015.2483592', '10.1109/tkde.2017.2754499', '10.1109/tkde.2019.2941685', '10.1145/2187836.2187874', '10.1145/2213836.2213891', '10.1145/2488388.2488425', '10.1145/2623330.2623623', '10.1145/2806416.2806502', '10.1145/2939672.2939673', '10.1145/2939672.2939822', '10.1145/3178876.3186175', '10.1145/3184558.3191639', '10.1145/3219819.3220010', '10.1145/3269206.3271704', '10.1145/3289600.3291004', '10.1145/3289600.3291014', '10.1145/3292500.3330838', '10.1145/3292500.3330989', '10.1145/3308558.3313411', '10.1145/3308558.3313612', '10.1145/3331184.3331203', '10.1145/3366423.3380123', '10.1162/tacl_a_00104', '10.1162/tacl_a_00360', '10.14778/3407790.3407828', '10.1609/aaai.v33i01.3301297', '10.1609/aaai.v33i01.33013060', '10.1609/aaai.v33i01.33013363', '10.1609/aaai.v33i01.33015329', '10.1609/aaai.v33i01.33016300', '10.1609/aaai.v33i01.33016407', '10.1609/aaai.v33i01.33017072', '10.1609/aaai.v33i01.330177', '10.1609/aaai.v34i03.5681', '10.1609/aaai.v34i03.5701', '10.1609/aaai.v34i04.5815', '10.1609/aaai.v34i05.6304', '10.1609/aaai.v34i05.6392', '10.18653/v1/2020.acl-main.136', '10.18653/v1/2020.acl-main.519', '10.18653/v1/2020.acl-main.572', '10.18653/v1/2020.acl-main.579', '10.18653/v1/2020.acl-main.617', '10.18653/v1/2020.coling-main.138', '10.18653/v1/2020.coling-main.327', '10.18653/v1/2020.emnlp-main.667', '10.18653/v1/2020.emnlp-main.722', '10.18653/v1/2020.findings-emnlp.207', '10.18653/v1/d15-1203', '10.18653/v1/d15-1206', '10.18653/v1/d16-1019', '10.18653/v1/d16-1260', '10.18653/v1/d17-1060', '10.18653/v1/d17-1186', '10.18653/v1/d17-1187', '10.18653/v1/d17-1191', '10.18653/v1/d17-1277', '10.18653/v1/d18-1223', '10.18653/v1/d18-1225', '10.18653/v1/d18-1243', '10.18653/v1/d18-1244', '10.18653/v1/d18-1247', '10.18653/v1/d18-1358', '10.18653/v1/d18-1362', '10.18653/v1/d18-1454', '10.18653/v1/d18-1516', '10.18653/v1/d19-1250', '10.18653/v1/d19-1269', '10.18653/v1/d19-1282', '10.18653/v1/d19-1334', '10.18653/v1/d19-1431', '10.18653/v1/d19-1522', '10.18653/v1/e17-1013', '10.18653/v1/k16-1026', '10.18653/v1/n16-1030', '10.18653/v1/n18-1165', '10.18653/v1/n18-2047', '10.18653/v1/n18-2053', '10.18653/v1/n19-1299', '10.18653/v1/n19-1306', '10.18653/v1/p16-1072', '10.18653/v1/p16-1076', '10.18653/v1/p16-1105', '10.18653/v1/p16-1200', '10.18653/v1/p16-1219', '10.18653/v1/p16-2034', '10.18653/v1/p17-1085', '10.18653/v1/p17-1088', '10.18653/v1/p17-1113', '10.18653/v1/p17-1166', '10.18653/v1/p17-2088', '10.18653/v1/p18-1046']}","","/root/snap/zotero-snap/common/Zotero/storage/AJD4K8ML/Ji et al. - 2022 - A Survey on Knowledge Graphs Representation, Acqu.pdf","","manual; star; SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_task:Reasoning; SAT_context:Graph; SAT_granularity:sentence; SAT_task:NER; SAT_focus:NoisyLabel; SAT_task:JointRE; SAT_archi:GCN; SAT_archi:LSTM; SAT_task:Ranking; SAT_type:Survey; SAT_focus:distant; SAT_focus:TemporalRel; SAT_task:Embed; SAT_focus:Math; SAT_task:GraphCompletion; SAT_typology:True; SAT_typology_dim:Architecture; FOCUS_STUDY_OCT; SAT_typology_dim:Features; CHECKED1023; SAT_focus:Reinforcement; SAT_focus:adversarial; SAT_interest:10; SAT_focus_period:1970-2020; SAT_nbModel:23","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VKM5PMNW","conferencePaper","2022","Zhao, Jun; Hu, Yuan; Xu, Nuo; Gui, Tao; Zhang, Qi; Chen, Yunwen; Gao, Xiang","An Exploration of Prompt-Based Zero-Shot Relation Extraction Method","Chinese Computational Linguistics: 21st China National Conference, CCL 2022, Nanchang, China, October 14–16, 2022, Proceedings","978-3-031-18314-0","","10.1007/978-3-031-18315-7_6","https://aclanthology.org/2022.ccl-1.70.pdf","Zero-shot relation extraction is an important method for dealing with the newly emerging relations in the real world which lacks labeled data. However, the mainstream two-tower zero-shot methods usually rely on large-scale and in-domain labeled data of predefined relations. In this work, we view zero-shot relation extraction as a semantic matching task optimized by prompt-tuning, which still maintains superior generalization performance when the labeled data of predefined relations are extremely scarce. To maximize the efficiency of data exploitation, instead of directly fine-tuning, we introduce a prompt-tuning technique to elicit the existing relational knowledge in pre-trained language model (PLMs). In addition, very few relation descriptions are exposed to the model during training, which we argue is the performance bottleneck of two-tower methods. To break through the bottleneck, we model the semantic interaction between relational instances and their descriptions directly during encoding. Experiment results on two academic datasets show that (1) our method outperforms the previous state-of-the-art method by a large margin with different samples of predefined relations; (2) this advantage will be further amplified in the low-resource scenario.","2022-10-14","2023-03-06 19:38:44","2025-02-04 17:18:54","2023-03-06","81–95","","","","","","","","","","","Springer-Verlag","Berlin, Heidelberg","","True","","","","ACM Digital Library","","{'citing': [], 'cited': ['10.1145/3038912.3052558', '10.1145/3357384.3358119', '10.1145/3560815', '10.1162/tacl_a_00324', '10.1609/aaai.v28i1.8870', '10.18653/v1/2021.acl-long.353', '10.18653/v1/2021.naacl-main.272', '10.18653/v1/2021.naacl-main.398', '10.18653/v1/d17-1004', '10.18653/v1/d18-1179', '10.18653/v1/d18-1245', '10.18653/v1/d18-1514', '10.18653/v1/k17-1034', '10.18653/v1/n19-1419', '10.18653/v1/n19-1423', '10.18653/v1/p16-2034', '10.18653/v1/p17-1152', '10.18653/v1/p18-1136', '10.18653/v1/p19-1356', '10.18653/v1/w18-5511', '10.18653/v1/w19-4828', '10.1145/3038912.3052558', '10.1145/3357384.3358119', '10.1145/3560815', '10.1162/tacl_a_00324', '10.1609/aaai.v28i1.8870', '10.18653/v1/2021.acl-long.353', '10.18653/v1/2021.naacl-main.272', '10.18653/v1/2021.naacl-main.398', '10.18653/v1/d17-1004', '10.18653/v1/d18-1179', '10.18653/v1/d18-1245', '10.18653/v1/d18-1514', '10.18653/v1/k17-1034', '10.18653/v1/n19-1419', '10.18653/v1/n19-1423', '10.18653/v1/p16-2034', '10.18653/v1/p17-1152', '10.18653/v1/p18-1136', '10.18653/v1/p19-1356', '10.18653/v1/w18-5511', '10.18653/v1/w19-4828']}","","","","SAT_task:RE; SAT_focus:FewSHot; FOCUS_STUDY_OCT; CHECKED1023; SAT_interest:10","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CCL","","","","","","","","","","","","","","",""
"SHSHBTRH","conferencePaper","2020","Wouter Baes, François Portet; , Hamid Mirisaee; , C. Labbé","RDF triples extraction from company web pages: comparison of state-of-the-art Deep Models","1st International Workshop Deep Learning meets Ontologies and Natural Language Processing","","","not found","nan","Relation extraction (RE) is a promising way to extend the semantic web from web pages. However, it is unclear how RE can deal with the several challenges of web pages such as noise, data sparsity and conflicting information. In this paper, we benchmark state-of-the-art RE approaches on the particular case of company web pages, since company web pages are important source of information for Fin-tech and BusinnessTech. To this end, we present a method to build a corpus mimicking web pages characteristics. This corpus was used to evaluate several deep learning RE models and compared to another benchmark corpus.","2020","2023-02-03 15:59:20","2025-02-04 17:20:33","","nan","","","nan","","","","","","","","CEUR-WS","","","nan","","nan","hal-02941935","","","","","","","automatic; SAT_model:BERT; SAT_task:RE; SAT_archi:CNN; SAT_type:Benchmark; SAT_focus:models; SAT_focus:RDF; FOCUS_STUDY_OCT; CHECKED1023; SAT_benchmark_type:Quantitative; SAT_dataset:WebNLG; SAT_nbModel:4; SAT_nbDataset:2; SAT_model:CNN; SAT_dataset:WCC; SAT_domain:company_website; SAT_focus_period:2010-2020; SAT_interest:6","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ESWC","","","","","","","","","","","","","","",""
"UTCJJF76","journalArticle","2021","Bekoulis, Giannis; Papagiannopoulou, Christina; Deligiannis, Nikos","A Review on Fact Extraction and Verification","ACM Computing Surveys","","0360-0300","10.1145/3485127","https://doi.org/10.1145/3485127","We study the fact-checking problem, which aims to identify the veracity of a given claim. Specifically, we focus on the task of Fact Extraction and VERification (FEVER) and its accompanied dataset. The task consists of the subtasks of retrieving the relevant documents (and sentences) from Wikipedia and validating whether the information in the documents supports or refutes a given claim. This task is essential and can be the building block of applications such as fake news detection and medical claim verification. In this article, we aim at a better understanding of the challenges of the task by presenting the literature in a structured and comprehensive way. We describe the proposed methods by analyzing the technical perspectives of the different approaches and discussing the performance results on the FEVER dataset, which is the most well-studied and formally structured dataset on the fact extraction and verification task. We also conduct the largest experimental study to date on identifying beneficial loss functions for the sentence retrieval component. Our analysis indicates that sampling negative sentences is important for improving the performance and decreasing the computational complexity. Finally, we describe open issues and future challenges, and we motivate future research in the task.","2021-11-23","2023-03-01 14:40:27","2025-02-04 17:18:54","2023-03-01 14:40:27","12:1–12:35","","1","55","","ACM Comput. Surv.","","","","","","","","","","","","","January 2023","","{'citing': ['10.3390/bdcc6020033', '10.1007/s40747-022-00828-0', '10.1145/3477495.3531812'], 'cited': ['10.1002/pra2.2015.145052010082', '10.1016/j.ins.2019.05.035', '10.1089/big.2020.0062', '10.18653/v1/2020.acl-main.549', '10.18653/v1/2020.acl-main.703', '10.18653/v1/w18-5516', '10.1109/tnnls.2021.3084806', '10.1145/3161603', '10.1162/neco.1997.9.8.1735', '10.14778/3229863.3229880', '10.18653/v1/2020.emnlp-main.368', '10.18653/v1/s17-2006', '10.18653/v1/w18-5520', '10.1007/978-3-030-45442-5_45', '10.1162/089976602760128018', '10.18653/v1/2020.fever-1.6', '10.18653/v1/d15-1075', '10.18653/v1/p19-1085', '10.18653/v1/w18-5517', '10.1016/j.eswa.2018.07.032', '10.1016/j.eswa.2019.112943', '10.1145/3369026', '10.18653/v1/2020.findings-emnlp.97', '10.18653/v1/p17-1152', '10.18653/v1/w18-5515', '10.1037/h0031619', '10.1145/3077136.3080809', '10.18653/v1/2020.acl-main.656', '10.18653/v1/2020.emnlp-main.153', '10.18653/v1/2020.emnlp-main.550', '10.18653/v1/w18-5521']}","","/root/snap/zotero-snap/common/Zotero/storage/54ZD6LC6/Bekoulis et al. - 2021 - A Review on Fact Extraction and Verification.pdf","","acm; NOT A SURVEY ?; FOCUS; SAT_task:RE; SAT_task:FactChecking; SAT_type:Survey; SAT_type:Review; FOCUS_STUDY_OCT","claim verification; Fact extraction; fake news; sentence retrieval","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BD6U8MQS","journalArticle","2020","Martinez-Rodriguez, Jose L.; Hogan, Aidan; Lopez-Arevalo, Ivan","Information extraction meets the Semantic Web: A survey","Semantic Web","","22104968, 15700844","10.3233/SW-180333","https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/SW-180333","We provide a comprehensive survey of the research literature that applies Information Extraction techniques in a Semantic Web setting. Works in the intersection of these two areas can be seen from two overlapping perspectives: using Semantic Web resources (languages/ontologies/knowledge-bases/tools) to improve Information Extraction, and/or using Information Extraction to populate the Semantic Web. In more detail, we focus on the extraction and linking of three elements: entities, concepts and relations. Extraction involves identifying (textual) mentions referring to such elements in a given unstructured or semi-structured input source. Linking involves associating each such mention with an appropriate disambiguated identiﬁer referring to the same element in a Semantic Web knowledge-base (or ontology), in some cases creating a new identiﬁer where necessary. With respect to entities, works involving (Named) Entity Recognition, Entity Disambiguation, Entity Linking, etc. in the context of the Semantic Web are considered. With respect to concepts, works involving Terminology Extraction, Keyword Extraction, Topic Modeling, Topic Labeling, etc., in the context of the Semantic Web are considered. Finally, with respect to relations, works involving Relation Extraction in the context of the Semantic Web are considered. The focus of the majority of the survey is on works applied to unstructured sources (text in natural language); however, we also provide an overview of works that develop custom techniques adapted for semi-structured inputs, namely markup documents and web tables.","2020-02-05","2022-04-20 05:56:32","2023-10-20 12:49:31","2022-04-20 05:56:32","255-335","","2","11","","SW","","","","","","","","en","","","","","DOI.org (Crossref)","","{'citing': ['10.1007/978-3-030-16181-1_47', '10.1007/978-3-030-21348-0_36', '10.1007/978-3-030-21395-4_7', '10.3233/sw-180334', '10.3390/ijgi8020059', '10.3390/ijgi9030146', '10.1007/978-3-030-30796-7_24', '10.1007/978-3-030-30796-7_29', '10.1007/978-3-030-40907-4_8', '10.3233/sw-190387', '10.3233/sw-190387', '10.1007/978-3-030-32327-1_41', '10.1525/elementa.418', '10.4018/978-1-7998-4730-4.ch019', '10.4018/978-1-7998-4730-4.ch019', '10.1016/j.websem.2020.100561', '10.3390/math8112090', '10.3390/ijgi10050330', '10.1007/978-3-030-76346-6_34', '10.3390/fi13060158', '10.1007/s13740-021-00134-x', '10.1007/978-3-030-80599-9_10', '10.1016/j.ipm.2021.102683', '10.1007/978-3-030-86159-9_37', '10.1007/978-3-030-91608-4_13', '10.3233/web-210465', '10.1145/3488662.3498658', '10.2200/s01125ed1v01y202109dsk022', '10.3390/knowledge2010001', '10.3233/sw-212838', '10.3390/electronics11030453', '10.1016/j.knosys.2021.108092', '10.1016/j.cageo.2022.105082', '10.23919/cisti52073.2021.9476446', '10.3389/frai.2022.830299', '10.1145/3508259.3508277', '10.1007/978-3-031-01333-1_2', '10.1016/j.ins.2022.03.079', '10.1016/j.ins.2022.03.079', '10.3390/fi14050129', '10.1145/3485447.3511932', '10.1109/ivmem53963.2021.00011', '10.1145/3511095.3531287', '10.1109/tale48869.2020.9368364', '10.1109/icci54321.2022.9756069', '10.1109/access.2022.3151048', '10.1109/ismsit52890.2021.9604538', '10.1109/bigdata52589.2021.9671514', '10.1007/978-981-19-3311-0_6', '10.3233/web-210491', '10.3233/web-210491', '10.3233/web-210491', '10.3233/web-210491', '10.1007/s40747-022-00805-7', '10.1002/widm.1482', '10.1007/s11761-022-00353-5', '10.15622/ia.21.6.4'], 'cited': ['10.1109/mic.2008.68', '10.1109/mic.2015.81', '10.1109/mis.2003.1179189', '10.1109/mis.2003.1179190', '10.1109/mitp.2014.85', '10.1109/saner.2017.7884609', '10.1109/tkde.2011.245', '10.1109/tkde.2016.2602206', '10.1109/wi-iat.2011.127', '10.1109/wi-iat.2012.23', '10.1109/wi-iat.2012.26', '10.1109/wkdd.2010.113', '10.1111/j.1749-6632.1976.tb25467.x', '10.1111/j.1749-818x.2010.00187.x', '10.1145/1321440.1321475', '10.1145/1376616.1376746', '10.1145/1458082.1458150', '10.1145/1459352.1459355', '10.1145/1557019.1557073', '10.1145/1871437.1871689', '10.1145/1935826.1935869', '10.1145/1935826.1935904', '10.1145/2063518.2063519', '10.1145/2124295.2124364', '10.1145/2133806.2133826', '10.1145/2187836.2187898', '10.1145/2187836.2187900', '10.1145/219717.219748', '10.1145/2213836.2213848', '10.1145/2237867.2237871', '10.1145/2333112.2333115', '10.1145/2339530.2339753', '10.1145/2382936.2382973', '10.1145/2396761.2396832', '10.1145/2396761.2398718', '10.1145/2433396.2433454', '10.1145/2487788.2488157', '10.1145/2488388.2488411', '10.1145/2488388.2488420', '10.1145/2503792.2503799', '10.1145/2505515.2505601', '10.1145/2506182.2506198', '10.1145/2513204.2513212', '10.1145/2556195.2556266', '10.1145/2566486.2568003', '10.1145/2588555.2610525', '10.1145/2600428.2600734', '10.1145/2623330.2623623', '10.1145/2629489', '10.1145/2633211.2634349', '10.1145/2633211.2634350', '10.1145/2633211.2634351', '10.1145/2633211.2634353', '10.1145/2633211.2634358', '10.1145/2633211.2634360', '10.1145/2633211.2634363', '10.1145/2660517.2660520', '10.1145/2684822.2685324', '10.1145/2736277.2741139', '10.1145/2736277.2741626', '10.1145/2797115.2797124', '10.1145/2872427.2874809', '10.1145/2872427.2883061', '10.1145/313238.313437', '10.1145/3148011.3148024', '10.1145/362007.362035', '10.1145/502512.502559', '10.1145/505168.505194', '10.1145/775152.775178', '10.1145/988672.988735', '10.1162/089120100561601', '10.1162/089120101753342653', '10.1177/0165551509360123', '10.1186/1472-6947-15-s1-s4', '10.1186/1678-4804-20-1', '10.14778/1453856.1453916', '10.14778/1920841.1921005', '10.14778/2002938.2002939', '10.1561/1900000003', '10.1613/jair.1648', '10.18653/v1/w15-4306', '10.2307/411934', '10.3115/1613715.1613796', '10.3115/974499.974526', '10.3233/978-1-61499-421-3-111', '10.3233/sw-140134', '10.3233/sw-150178', '10.3233/sw-150180', '10.3233/sw-160221', '10.3233/sw-160240', '10.3233/sw-160242', '10.3233/sw-170269', '10.3233/sw-170273', '10.3233/sw-2010-0016', '10.5120/14849-3211', '10.5120/19161-0607', '10.5441/002/edbt.2017.20', '10.7763/ijmlc.2011.v1.17', '10.1002/9780470758335.ch8', '10.1007/11765448_3', '10.1002/9780470689646.ch1', '10.1002/asi.21231', '10.1002/asi.23398', '10.1002/int.20448', '10.1007/11428817_21', '10.1007/11816508', '10.1007/3-540-32394-5_20', '10.1007/3-540-44686-9_43', '10.1007/3-540-45014-9_1', '10.1007/978-0-387-39252-3', '10.1007/978-1-4419-6981-1', '10.1007/978-3-319-10587-1_2', '10.1007/978-3-319-10816-2_35', '10.1007/978-3-319-11587-0_30', '10.1007/978-3-319-11964-9_16', '10.1007/978-3-319-11964-9_18', '10.1007/978-3-319-11964-9_29', '10.1007/978-3-319-11964-9_33', '10.1007/978-3-319-13560-1_44', '10.1007/978-3-319-18818-8_31', '10.1007/978-3-319-24309-2_28', '10.1007/978-3-319-25007-6_25', '10.1007/978-3-319-25007-6_26', '10.1007/978-3-319-25518-7_3', '10.1007/978-3-319-30319-2_4', '10.1007/978-3-319-30671-1_18', '10.1007/978-3-319-34129-3_1', '10.1007/978-3-319-34129-3_12', '10.1007/978-3-319-46565-4_2', '10.1007/978-3-319-46565-4_3', '10.1007/978-3-319-48472-3_46', '10.1007/978-3-319-49004-5_19', '10.1007/978-3-319-58068-5_19', '10.1007/978-3-319-59888-8_4', '10.1007/978-3-540-25956-5_3', '10.1007/978-3-540-45218-8_4', '10.1007/978-3-540-72667-8_44', '10.1007/978-3-540-75195-3_15', '10.1007/978-3-540-78624-5_3', '10.1007/978-3-540-87696-0_29', '10.1007/978-3-540-88564-1_15', '10.1007/978-3-642-00382-0_12', '10.1007/978-3-642-04930-9_28', '10.1007/978-3-642-04930-9_49', '10.1007/978-3-642-15939-8_10', '10.1007/978-3-642-16438-5_13', '10.1007/978-3-642-16438-5_41', '10.1007/978-3-642-17749-1_25', '10.1007/978-3-642-21043-3_10', '10.1007/978-3-642-25093-4_13', '10.1007/978-3-642-25106-1_18', '10.1007/978-3-642-30284-8_21', '10.1007/978-3-642-33876-2_10', '10.1007/978-3-642-38288-8_24', '10.1007/978-3-642-38288-8_25', '10.1007/978-3-642-38288-8_37', '10.1007/978-3-642-41335-3_23', '10.1007/978-3-642-41335-3_9', '10.1007/978-3-642-41338-4_7', '10.1007/978-3-642-45068-6_28', '10.1007/bf01263048', '10.1007/s007999900023', '10.1007/s10791-015-9262-2', '10.1016/j.artint.2012.06.001', '10.1016/j.artint.2012.06.007', '10.1016/j.datak.2006.04.002', '10.1016/j.eswa.2008.12.034', '10.1016/j.eswa.2013.05.005', '10.1016/j.ipm.2014.10.006', '10.1016/j.jbi.2008.06.003', '10.1016/j.jvlc.2014.11.001', '10.1016/j.knosys.2016.05.023', '10.1016/j.websem.2005.10.002', '10.1016/j.websem.2006.12.002', '10.1016/j.websem.2007.07.001', '10.1016/j.websem.2014.04.001', '10.1016/j.websem.2014.07.005', '10.1016/j.websem.2015.05.001', '10.1016/j.websem.2016.01.001', '10.1016/j.websem.2016.03.001', '10.1016/j.websem.2016.03.004', '10.1016/s0019-9958(67)80007-x', '10.1017/s135132490400347x', '10.1017/s1351324904003523', '10.1017/s1351324913000119', '10.1023/a:1007502103375', '10.1023/a:1007617005950', '10.1023/a:1014348124664', '10.1075/li.30.1.03nad', '10.1075/term.19.1.01mac', '10.1093/nar/gks563', '10.1109/5254.920602', '10.1109/compsac.2012.72', '10.1109/dexa.2008.120', '10.1109/iccv.2015.524', '10.1109/icdm.2004.10004', '10.1109/icmla.2015.88', '10.1109/icsc.2008.53', '10.1109/iri.2013.6642462', '10.1109/isspa.2012.6310552', '10.1075/slcs.150.10fel', '10.1075/veaw.g29', '10.1109/iccea.2010.221', '10.1109/kse.2009.20', '10.1117/12.488853', '10.1162/tacl_a_00179', '10.1186/2041-1480-2-s5-s3', '10.1201/9780203487068.ch21', '10.1515/9783110882629', '10.18653/v1/d15-1102', '10.18653/v1/d15-1104', '10.18653/v1/d15-1203', '10.18653/v1/d16-1245', '10.18653/v1/p16-1200', '10.18653/v1/p16-1220', '10.18653/v1/s16-1168', '10.2200/s00741ed1v01y201611wbe015', '10.3115/1075178.1075195', '10.3115/1075218.1075254', '10.3115/1118693.1118694', '10.3115/1219840.1219885', '10.3115/1596374.1596407', '10.3115/1626481.1626503', '10.3115/1699510.1699529', '10.3115/980845.980860', '10.3115/981658.981705', '10.3115/990820.990845', '10.3115/992133.992154', '10.3115/v1/d14-1082', '10.3115/v1/n15-1024', '10.3115/v1/p14-5010', '10.3115/v1/p15-2049', '10.1075/term.11.1.04gil', '10.1162/tacl_a_00094', '10.1162/tacl_a_00141', '10.1162/tacl_a_00197', '10.1162/coli_a_00402', '10.1609/aaai.v29i1.9498', '10.3115/1690219.1690287', '10.4000/ijcol.392']}","","/root/snap/zotero-snap/common/Zotero/storage/92BD53BX/Martinez-Rodriguez et al. - 2020 - Information extraction meets the Semantic Web A s.pdf","","manual; star; survey; SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_task:RC; SAT_task:EntityLinking; SAT_task:NER; SAT_task:KeywordExtraction; SAT_focus:distant; SAT_focus:Pipeline; SAT_focus:sources; SAT_focus:RDF; SAT_nbModel:27; SAT_focus:KB; CHECKED1023; SAT_benchmark:True; SAT_benchmark_type:Qualitative; SAT_interest:10; SAT_focus_period:2001-2019; SAT_type:DetailedSurvey; SAT_focus:EVAL","","Hotho, Andreas","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CEPYEPA4","journalArticle","2021","Nasar, Zara; Jaffry, Syed Waqar; Malik, Muhammad Kamran","Named Entity Recognition and Relation Extraction: State-of-the-Art","ACM Computing Surveys","","0360-0300","10.1145/3445965","https://doi.org/10.1145/3445965","With the advent of Web 2.0, there exist many online platforms that result in massive textual-data production. With ever-increasing textual data at hand, it is of immense importance to extract information nuggets from this data. One approach towards effective harnessing of this unstructured textual data could be its transformation into structured text. Hence, this study aims to present an overview of approaches that can be applied to extract key insights from textual data in a structured way. For this, Named Entity Recognition and Relation Extraction are being majorly addressed in this review study. The former deals with identification of named entities, and the latter deals with problem of extracting relation between set of entities. This study covers early approaches as well as the developments made up till now using machine learning models. Survey findings conclude that deep-learning-based hybrid and joint models are currently governing the state-of-the-art. It is also observed that annotated benchmark datasets for various textual-data generators such as Twitter and other social forums are not available. This scarcity of dataset has resulted into relatively less progress in these domains. Additionally, the majority of the state-of-the-art techniques are offline and computationally expensive. Last, with increasing focus on deep-learning frameworks, there is need to understand and explain the under-going processes in deep architectures.","2021-02-11","2023-02-06 09:33:58","2025-02-04 17:20:33","2023-02-06 09:33:58","20:1–20:39","","1","54","","ACM Comput. Surv.","","","","","","","","","False but accesible","","","","January 2022","","{'citing': ['10.1016/j.fmre.2021.09.003', '10.1016/j.fmre.2021.08.018', '10.1145/3503917', '10.3390/heritage5030084', '10.1093/database/baac047', '10.19053/0121053x.n39.2022.13436', '10.1109/aiiot54504.2022.9817231', '10.1093/bib/bbac342', '10.3390/rs14194725', '10.1007/978-3-031-15342-6_30', '10.1108/ajim-03-2022-0124', '10.1002/int.23015', '10.1016/j.jfranklin.2022.09.045', '10.1007/s10115-022-01779-1', '10.1109/ijcnn55064.2022.9892841', '10.1016/j.aei.2022.101780'], 'cited': ['10.1007/11766247_23', '10.1007/s11192-018-2921-5', '10.1016/j.neunet.2018.01.006', '10.1093/database/baw068', '10.1145/1031171.1031279', '10.1145/3241741', '10.3115/1118693.1118694', '10.1007/978-3-319-12580-0_2', '10.1007/s00500-017-2852-8', '10.1023/a:1007502103375', '10.1075/li.30.1.03nad', '10.1109/taslp.2018.2856625', '10.1587/transinf.2016edp7179', '10.18653/v1/p16-1101', '10.18653/v1/p16-1105', '10.4018/jswis.2012070101', '10.1016/j.engappai.2016.01.027', '10.1016/j.neucom.2016.10.052', '10.1093/bioinformatics/btl616', '10.1162/tacl_a_00094', '10.1186/s12859-017-1609-9', '10.1371/journal.pone.0157989', '10.3115/v1/d14-1165', '10.7763/ijmlc.2014.v4.428', '10.1016/j.artint.2005.03.001', '10.1016/j.ipm.2007.07.013', '10.1016/j.ipm.2018.04.002', '10.1016/j.jbi.2013.08.004', '10.1023/a:1007558221122', '10.1145/988672.988687', '10.1162/tacl_a_00221', '10.1371/journal.pone.0179488', '10.1007/978-3-642-53917-6_37', '10.1016/j.jbi.2013.12.006', '10.1145/1089815.1089819', '10.1145/2487788.2488003', '10.1162/neco_a_00970', '10.18653/v1/n18-1202', '10.3115/1219044.1219066']}","","","","manual; star; acm; FOCUS; SAT_task:RE; SAT_lang:multi; SAT_task:NER; SAT_archi:CRF; SAT_archi:CNN; SAT_archi:LSTM; SAT_archi:SVM; SAT_type:Survey; SAT_focus:distant; SAT_focus:RulesBased; SAT_typology:True; SAT_typology_dim:Architecture; SAT_type:MetaSurvey; FOCUS_STUDY_OCT; SAT_typology_dim:Features; CHECKED1023; SAT_benchmark:True; SAT_dataset:ACE; SAT_benchmark_type:Qualitative; SAT_defined_protocol:True; SAT_dataset:OntoNote; SAT_dataset:MUC; SAT_dataset:NYT; SAT_dataset:Wikipedia; SAT_benchmark_type:Quantitative; SAT_nbModel:40; SAT_interest:10; SAT_focus_period:1995-2019","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JH6YH56L","journalArticle","2022","Rui, Yong; Carmona, Vicente Ivan Sanchez; Pourvali, Mohsen; Xing, Yun; Yi, Wei-Wen; Ruan, Hui-Bin; Zhang, Yu","Knowledge Mining: A Cross-disciplinary Survey","Machine Intelligence Research","","2731-5398","10.1007/s11633-022-1323-6","https://doi.org/10.1007/s11633-022-1323-6","Knowledge mining is a widely active research area across disciplines such as natural language processing (NLP), data mining (DM), and machine learning (ML). The overall objective of extracting knowledge from data source is to create a structured representation that allows researchers to better understand such data and operate upon it to build applications. Each mentioned discipline has come up with an ample body of research, proposing different methods that can be applied to different data types. A significant number of surveys have been carried out to summarize research works in each discipline. However, no survey has presented a cross-disciplinary review where traits from different fields were exposed to further stimulate research ideas and to try to build bridges among these fields. In this work, we present such a survey.","2022-04-01","2023-03-06 19:23:28","2025-02-04 17:18:54","2023-03-06 19:23:28","89-114","","2","19","","Mach. Intell. Res.","","","","","","","","en","","","","","Springer Link","","{'citing': [], 'cited': ['10.1002/widm.1207', '10.1007/978-3-030-60457-8_37', '10.1007/978-3-319-25789-1_1', '10.1007/978-3-319-46307-0_29', '10.1007/978-3-642-15939-8_10', '10.1007/s10618-006-0059-1', '10.1016/0950-7051(96)81920-4', '10.1016/j.dss.2010.12.003', '10.1016/j.eswa.2015.03.004', '10.1016/j.ins.2020.10.001', '10.1016/s0004-3702(00)00077-1', '10.1016/s0004-3702(96)00034-3', '10.1016/s0169-7161(04)24002-0', '10.1017/9781108684163', '10.1023/a:1022812808206', '10.1023/b:dami.0000005258.31418.83', '10.1109/69.846291', '10.1109/access.2020.2974104', '10.1109/access.2020.3029302', '10.1109/icde.1995.380415', '10.1109/icde.1997.581756', '10.1109/icde.2012.145', '10.1109/icdm.2005.149', '10.1109/ijcnn.2001.938448', '10.1109/tcyb.2019.2896267', '10.1109/tcyb.2019.2896267', '10.1109/vis49827.2021.9623303', '10.1145/1089815.1089817', '10.1145/1089815.1089817', '10.1145/1321440.1321499', '10.1145/1557019.1557030', '10.1145/233269.233311', '10.1145/2396761.2396773', '10.1145/2488388.2488420', '10.1145/2488388.2488425', '10.1145/2594473.2594475', '10.1145/2939672.2939778', '10.1145/2939672.2939778', '10.1145/3219819.3220072', '10.1145/3219819.3220072', '10.1145/3236009', '10.1145/3236009', '10.1145/335191.335372', '10.1145/335191.335372', '10.1162/0899766053630350', '10.1162/0899766053630350', '10.1162/neco.1997.9.8.1735', '10.1162/neco.1997.9.8.1735', '10.1162/tacl_a_00095', '10.1162/tacl_a_00104', '10.1371/journal.pone.0179488', '10.1609/aimag.v17i3.1230', '10.18653/v1/2020.acl-main.386', '10.18653/v1/2020.acl-main.669', '10.18653/v1/2020.emnlp-main.133', '10.18653/v1/2020.emnlp-main.300', '10.18653/v1/2020.findings-emnlp.99', '10.18653/v1/2021.acl-long.486', '10.18653/v1/2021.acl-long.488', '10.18653/v1/2021.emnlp-main.94', '10.18653/v1/2021.naacl-main.269', '10.18653/v1/d15-1203', '10.18653/v1/d17-1004', '10.18653/v1/d18-1248', '10.18653/v1/d19-1021', '10.18653/v1/d19-1371', '10.18653/v1/n16-1030', '10.18653/v1/n18-1081', '10.18653/v1/n19-1078', '10.18653/v1/n19-1288', '10.18653/v1/n19-1423', '10.18653/v1/p16-1101', '10.18653/v1/p16-1105', '10.18653/v1/p16-1200', '10.18653/v1/p17-1088', '10.18653/v1/p19-1129', '10.18653/v1/p19-1136', '10.18653/v1/p19-1279', '10.3115/1072228.1072282', '10.3115/1119176.1119206', '10.3115/1218955.1219008', '10.3115/1218955.1219009', '10.3115/1219840.1219893', '10.3115/v1/d14-1162', '10.3115/v1/n15-1118', '10.3115/v1/w14-1609', '10.3233/ida-1998-2303', '10.35111/77ba-9x74']}","","/root/snap/zotero-snap/common/Zotero/storage/LJX5MVQG/Rui et al. - 2022 - Knowledge Mining A Cross-disciplinary Survey.pdf","","SAT_task:RE; SAT_task:NER; SAT_archi:Rules; SAT_type:Survey; SAT_focus:Math; FOCUS_STUDY_OCT; CHECKED1023; SAT_typology_dim:Distant; SAT_task:AssociationLearning; SAT_focus_period:1992-2021; SAT_interest:3; SAT_focus:EVAL; SAT_focus:Intepretability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ALFM36CV","journalArticle","2023","Wang, Yuqi; Wang, Wei; Chen, Qi; Huang, Kaizhu; Nguyen, Anh; De, Suparna; Hussain, Amir","Fusing external knowledge resources for natural language understanding techniques: A survey","Information Fusion","","1566-2535","10.1016/j.inffus.2022.11.025","https://www.sciencedirect.com/science/article/pii/S1566253522002354","Knowledge resources, e.g. knowledge graphs, which formally represent essential semantics and information for logic inference and reasoning, can compensate for the unawareness nature of many natural language processing techniques based on deep neural networks. This paper provides a focused review of the emerging but intriguing topic that fuses quality external knowledge resources in improving the performance of natural language processing tasks. Existing methods and techniques are summarised in three main categories: (1) static word embeddings, (2) sentence-level deep learning models, and (3) contextualised language representation models, depending on when, how and where external knowledge is fused into the underlying learning models. We focus on the solutions to mitigate two issues: knowledge inclusion and inconsistency between language and knowledge. Details on the design of each representative method, as well as their strength and limitation, are discussed. We also point out some potential future directions in view of the latest trends in natural language processing research.","2023-04-01","2023-03-06 19:14:29","2025-02-04 17:18:54","2023-03-06 19:14:29","190-204","","","92","","Information Fusion","","","","","","","","en","True","","","","ScienceDirect","","{'citing': [], 'cited': ['10.1007/s10115-008-0152-4', '10.1007/s10994-015-5494-z', '10.1007/s11431-020-1647-3', '10.1016/j.aiopen.2021.06.004', '10.1016/j.inffus.2016.10.004', '10.1016/j.inffus.2021.07.014', '10.1016/j.inffus.2021.09.022', '10.1016/s1364-6613(99)01294-2', '10.1073/pnas.1611835114', '10.1080/01690969108406936', '10.1109/5.726791', '10.1109/tkde.2017.2754499', '10.1109/tkde.2018.2807452', '10.1109/tnnls.2020.2979670', '10.1109/tnnls.2020.3002798', '10.1145/1376616.1376746', '10.1145/219717.219748', '10.1145/2382577.2382582', '10.1145/2629489', '10.1145/2661829.2662038', '10.1145/3360901.3364441', '10.1145/3434237', '10.1162/neco.1997.9.8.1735', '10.1162/tacl_a_00063', '10.1162/tacl_a_00069', '10.1162/tacl_a_00143', '10.1162/tacl_a_00302', '10.1162/tacl_a_00360', '10.1177/107769905303000401', '10.14311/nnw.2020.30.011', '10.1609/aaai.v29i1.9491', '10.1609/aaai.v30i1.10089', '10.1609/aaai.v31i1.11164', '10.18653/v1/2020.acl-main.423', '10.18653/v1/2020.coling-main.118', '10.18653/v1/2020.coling-main.153', '10.18653/v1/2020.coling-main.327', '10.18653/v1/2020.coling-main.571', '10.18653/v1/2020.deelio-1.5', '10.18653/v1/2020.emnlp-main.11', '10.18653/v1/2020.emnlp-main.400', '10.18653/v1/2020.emnlp-main.523', '10.18653/v1/2020.emnlp-main.567', '10.18653/v1/2020.findings-emnlp.207', '10.18653/v1/2020.findings-emnlp.71', '10.18653/v1/2021.eacl-main.20', '10.18653/v1/2021.findings-acl.102', '10.18653/v1/2021.findings-acl.121', '10.18653/v1/2021.naacl-main.288', '10.18653/v1/2022.acl-long.158', '10.18653/v1/2022.findings-acl.150', '10.18653/v1/d15-1031', '10.18653/v1/d15-1174', '10.18653/v1/d15-1242', '10.18653/v1/d19-1005', '10.18653/v1/d19-1250', '10.18653/v1/d19-1395', '10.18653/v1/d19-1404', '10.18653/v1/k16-1025', '10.18653/v1/k16-1026', '10.18653/v1/k17-1034', '10.18653/v1/n16-1018', '10.18653/v1/n16-1174', '10.18653/v1/p16-2074', '10.18653/v1/p17-1149', '10.18653/v1/p18-1004', '10.18653/v1/p19-1139', '10.18653/v1/p19-1470', '10.18653/v1/w15-4004', '10.18653/v1/w18-3026', '10.24963/ijcai.2017/183', '10.24963/ijcai.2017/478', '10.24963/ijcai.2017/578', '10.24963/ijcai.2021/597', '10.3115/v1/d14-1162', '10.3115/v1/d14-1167', '10.3115/v1/n15-1100', '10.3115/v1/n15-1184', '10.3115/v1/p14-2089', '10.3115/v1/p15-1067', '10.3115/v1/p15-1145', '10.3115/v1/p15-1173']}","","","","new_models; SAT_focus:NotOnlyRE; SAT_model:BERT; SAT_task:NLU; SAT_archi:CNN; SAT_archi:LSTM; SAT_archi:GNN; SAT_model:GPT; SAT_type:Survey; SAT_task:Embed; SAT_focus:Math; FOCUS_STUDY_OCT; CHECKED1023; SAT_benchmark_type:Qualitative; SAT_interest:10; SAT_focus:Embed; SAT_typology_dim:KnowledgeIntegration; SAT_focus:postProcessMethod; SAT_model:TranEsGCN; SAT_focus_period:1991-2022","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B6R2GG52","preprint","2018",", Yankai Lin; , Xu Han; , Ruobing Xie; , Zhiyuan Liu; , Maosong Sun","Knowledge Representation Learning: A Quantitative Review","","","","not found","http://arxiv.org/abs/1812.10901v1","Knowledge representation learning (KRL) aims to represent entities and relations in knowledge graph in low-dimensional semantic space, which have been widely used in massive knowledge-driven tasks. In this article, we introduce the reader to the motivations for KRL, and overview existing approaches for KRL. Afterwards, we extensively conduct and quantitative comparison and analysis of several typical KRL methods on three evaluation tasks of knowledge acquisition including knowledge graph completion, triple classification, and relation extraction. We also review the real-world applications of KRL, such as language modeling, question answering, information retrieval, and recommender systems. Finally, we discuss the remaining challenges and outlook the future directions for KRL. The codes and datasets used in the experiments can be found in https://github.com/thunlp/OpenKE.","2018-12-28","2023-05-03 15:56:21","2023-10-23 12:06:32","","","","","","","","","","","","","","","","NA","","https://paperswithcode.com/paper/knowledge-representation-learning-a","https://github.com/shaoxiongji/awesome-knowledge-graph","","","","","/root/snap/zotero-snap/common/Zotero/storage/9PTIQTM4/ et al. - 2018 - Knowledge Representation Learning A Quantitative .pdf","","SAT_task:QA; SAT_task:RE; SAT_task:RC; SAT_task:Classif; SAT_task:Retrieval; SAT_type:Review; SAT_task:Embed; SAT_task:GraphCompletion; havecode; HERE; notbenchmarked; SAT_task:Recomandation; SAT_task:TripleClassif","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WWT5P2WL","conferencePaper","2018","Niklaus, Christina; Cetto, Matthias; Freitas, André; Handschuh, Siegfried","A Survey on Open Information Extraction","Proceedings of the 27th International Conference on Computational Linguistics","","","not found","http://arxiv.org/abs/1806.05599","We provide a detailed overview of the various approaches that were proposed to date to solve the task of Open Information Extraction. We present the major challenges that such systems face, show the evolution of the suggested approaches over time and depict the specific issues they address. In addition, we provide a critique of the commonly applied evaluation procedures for assessing the performance of Open IE systems and highlight some directions for future work.","2018-06-14","2023-02-06 09:34:06","2025-02-04 17:20:33","2023-02-06 09:34:06","","","","","","","","","","","","ACLL","","","","","","","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/LNRP6IIM/Niklaus et al. - 2018 - A Survey on Open Information Extraction.pdf; /root/snap/zotero-snap/common/Zotero/storage/SVWTUWHQ/1806.html","","manual; SAT_focus:OpenIE; SAT_task:RE; SAT_type:Survey; SAT_focus:RulesBased; FOCUS_STUDY_OCT; CHECKED1023; SAT_focus:metrics; SAT_interest:4; SAT_nbDataset:2; SAT_model:OLLIE; SAT_model:TextRunner; SAT_model:REVERB; SAT_model:ClausIE; SAT_nbModel:15; SAT_focus_period:1999-2018","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","COLING","","","","","","","","","","","","","","",""
"5G7H7825","journalArticle","2020","Hao Wang, Bin Guo; , Wei Wu; , Zhiwen Yu","Towards information-rich, logical text generation with   knowledge-enhanced neural models","Elsevier","","","not found","nan","Text generation system has made massive promising progress contributed by deep learning techniques and has been widely applied in our life. However, existing end-to-end neural models suffer from the problem of tending to generate uninformative and generic text because they cannot ground input context with background knowledge. In order to solve this problem, many researchers begin to consider combining external knowledge in text generation systems, namely knowledge-enhanced text generation. The challenges of knowledge enhanced text generation including how to select the appropriate knowledge from large-scale knowledge bases, how to read and understand extracted knowledge, and how to integrate knowledge into generation process. This survey gives a comprehensive review of knowledge-enhanced text generation systems, summarizes research progress to solving these challenges and proposes some open issues and research directions.","2020-03-02","2023-03-01 14:34:19","2025-02-04 17:18:54","","","","","","","Neurocomputing","","","","","","","","","nan","","Arxiv","http://arxiv.org/abs/2003.00814v1","","","","","","","SAT_task:TextGeneration; SAT_archi:BiLSTM; SAT_archi:Transformer; SAT_archi:RNN; SAT_archi:GCN; SAT_archi:Encoder-Decoder; SAT_archi:LSTM; SAT_type:Review; SAT_focus:models; SAT_focus:distant; FOCUS_STUDY_OCT; CHECKED1023; SAT_focus:Reinforcement; SAT_interest:5; SAT_focus_period:2003-2020","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7AWZG73F","conferencePaper","2019",", Yifan Peng; , Shankai Yan; , Zhiyong Lu","Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets","18th BioNLP Workshop and Shared Task","","","10.18653/v1/w19-5006","https://arxiv.org/abs/1906.05474v2","NA","2019-06-13","2023-04-05 15:10:40","2025-02-04 17:20:33","","","","","","","","","","","","","Association for Computational Linguistics","","","NA","","https://paperswithcode.com/paper/transfer-learning-in-biomedical-natural","NA","","","{'citing': ['10.1016/j.jbi.2022.104114', '10.2196/preprints.39077', '10.1186/s12911-022-01897-4', '10.1002/smr.2463', '10.1109/iscc50000.2020.9219640', '10.1109/icears53579.2022.9752241', '10.1016/j.jbi.2022.104120', '10.1038/s41467-022-30070-8', '10.1007/978-3-031-10464-0_52', '10.1109/jbhi.2021.3062322', '10.1007/978-3-031-09342-5_38', '10.1038/s41551-022-00898-y', '10.1109/bibm52615.2021.9669699', '10.1016/j.knosys.2022.109460', '10.1109/access.2022.3157854', '10.1109/ictai50040.2020.00072', '10.1109/rivf48685.2020.9140783', '10.1115/1.4054203', '10.1109/embc46164.2021.9630043', '10.1109/tencon54134.2021.9707441', '10.1109/jbhi.2021.3095478', '10.1109/jbhi.2021.3123192', '10.1109/iccvw54120.2021.00372', '10.1109/jbhi.2021.3112130', '10.1145/3512732.3533584', '10.1016/j.ijmedinf.2022.104805', '10.1038/s41597-022-01350-1', '10.1109/access.2022.3197769', '10.1093/database/baac069', '10.1016/j.jbi.2022.104161', '10.1007/978-3-031-13643-6_10', '10.1007/978-3-031-13643-6_16', '10.1186/s12911-022-01967-7', '10.23919/picmet53225.2022.9882736', '10.1016/j.jag.2022.102967', '10.1101/2022.08.21.22278835', '10.1007/s10278-022-00692-x', '10.1109/ichi54592.2022.00117', '10.1109/ichi54592.2022.00016', '10.1162/tacl_a_00500', '10.1101/2022.09.22.22280246', '10.1007/978-3-031-16443-9_69', '10.2196/preprints.40992', '10.1101/2022.08.02.502449', '10.1093/database/baac066', '10.1371/journal.pdig.0000086', '10.1016/j.ijmedinf.2022.104864', '10.1101/2022.08.23.22279119', '10.1007/s42979-022-01295-7', '10.1016/j.ins.2022.10.063', '10.1371/journal.pone.0276539', '10.1007/978-3-031-09108-7_7', '10.1016/j.jbi.2022.104215', '10.1007/s10278-022-00714-8', '10.2196/39077', '10.1101/2022.10.11.511776', '10.1109/wimob55322.2022.9941720', '10.1109/access.2022.3218646', '10.1186/s12911-022-02003-4', '10.1007/978-3-031-18315-7_16', '10.1007/978-3-031-14771-5_28', '10.1109/tcbb.2022.3173562', '10.1007/978-981-19-3679-1_47', '10.2196/preprints.43483', '10.1093/bib/bbaa057', '10.1007/978-3-030-45442-5_29', '10.12688/f1000research.24552.1', '10.1101/2020.10.28.359828', '10.1007/978-3-030-56725-5_5', '10.3389/fcell.2020.00673', '10.1145/3410530.3414436', '10.2196/19735', '10.1101/2020.12.03.409094', '10.1101/2020.12.03.410829', '10.1101/2020.12.04.20244210', '10.1101/2020.12.23.424215', '10.2196/18055', '10.2196/23357', '10.2196/preprints.18055', '10.2196/preprints.19735', '10.2196/preprints.22982', '10.1016/j.jbi.2020.103607', '10.1016/j.jbi.2020.103530', '10.1016/j.jbi.2020.103392', '10.1016/j.jbi.2020.103451', '10.1038/s41597-021-00875-1', '10.1016/j.neucom.2021.02.071', '10.1080/15567036.2020.1869867', '10.1007/s00521-021-06053-z', '10.1145/3404835.3462797', '10.1007/978-3-030-68763-2_48', '10.1007/978-3-030-74251-5_21', '10.1146/annurev-biodatasci-030421-030931', '10.3389/fpsyt.2020.533949', '10.1016/j.procs.2021.06.082', '10.1101/2021.07.15.21260082', '10.2196/preprints.23101', '10.2196/23101', '10.1371/journal.pone.0246310', '10.1371/journal.pone.0253905', '10.1016/j.jclinepi.2021.01.010', '10.1101/2020.08.08.20170753', '10.1134/s0005117920120097', '10.1038/s41746-021-00404-9', '10.1371/journal.pone.0248663', '10.1007/s00799-021-00306-x', '10.1021/acs.jpclett.1c00578', '10.2196/preprints.32523', '10.1016/j.future.2021.01.013', '10.1038/s41597-021-00929-4', '10.1016/j.drudis.2021.06.009', '10.1145/3450439.3451862', '10.1016/j.knosys.2021.106869', '10.14801/jaitc.2020.10.2.139', '10.1007/978-3-030-82147-0_14', '10.1007/978-3-030-82153-1_21', '10.1101/2021.09.10.459845', '10.1007/978-3-030-85896-4_20', '10.1145/3447548.3467118', '10.1145/3469096.3474926', '10.1007/s12559-021-09917-7', '10.1145/3462476', '10.1093/jamia/ocab158', '10.1186/s12859-021-04141-4', '10.1145/3487664.3487701', '10.1186/s12859-021-04260-y', '10.1186/s12859-021-04236-y', '10.1016/j.jbi.2021.103982', '10.2196/29398', '10.2196/32903', '10.1007/s11192-020-03718-9', '10.2196/preprints.27386', '10.1016/j.compchemeng.2021.107599', '10.1145/3458754', '10.1186/s12911-021-01614-7', '10.1007/978-3-030-88483-3_4', '10.2196/27386', '10.1145/3397271.3401442', '10.1007/978-3-030-91100-3_14', '10.2196/26777', '10.1016/j.asoc.2021.107975', '10.1007/s10462-022-10144-1', '10.1016/j.jbi.2021.103983', '10.1371/journal.pone.0262182', '10.1371/journal.pone.0266198', '10.2196/preprints.32903', '10.1007/s10115-022-01665-w', '10.1080/10494820.2022.2052110', '10.1186/s12859-022-04642-w', '10.1016/j.jbi.2022.104050', '10.1016/j.jbi.2022.104059', '10.4103/tpsy.tpsy_9_22', '10.1186/s12859-022-04688-w', '10.1101/2022.03.31.486574', '10.1145/3485447.3511946', '10.1109/ichi52183.2021.00032', '10.1109/ichi52183.2021.00058', '10.1109/ichi52183.2021.00088', '10.1109/ichi52183.2021.00091', '10.1109/ichi52183.2021.00092', '10.1109/ichi52183.2021.00093', '10.1109/ichi52183.2021.00095', '10.1109/ialp54817.2021.9675275', '10.1093/bioinformatics/btac422'], 'cited': []}","","","","SAT_model:BERT; SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_task:Classif; SAT_focus:TransferLearning; SAT_task:NLI; SAT_task:NER; SAT_task:Retrieval; SAT_task:Similarity; SAT_domain:biomedical; SAT_model:Elmo; SAT_type:Benchmark; SAT_focus:datasets; SAT_focus:LLM; SAT_typology:False; FOCUS_STUDY_OCT; CHECKED1023; SAT_nbModel:3; SAT_interest:7; SAT_focus_period:2017-2019; SAT_task:Benchmark","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","BioNLP","","","","","","","","","","","","","","",""
"DMSZSNBF","journalArticle","2020","Mahouachi, Mechket Emna; Suchanek, Fabian","Extracting Complex Information from Natural Language Text: A Survey","CEUR-WS","","","not found","","Information Extraction is the art of extracting structured information from natural language text, and it has come a long way in recent years. Many systems focus on binary relationships between two entities – a subject and an object. However, most natural language text contains complex information such as beliefs, causality, anteriority, or relationships that span several sentences. In this paper, we survey existing approaches at this frontier, and outline promising directions of future work.","2020","2022-08-08 09:56:30","2025-02-04 17:20:33","","8","","","","","CEUR-WS","","roceedings of the CIKM 2020 Workshops,","","","","","","en","","","","","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/DWI8R2VT/Mahouachi and Suchanek - Extracting Complex Information from Natural Langua.pdf","","manual; survey; SAT_focus:OpenIE; SAT_rel_type:causal; SAT_rel_type:nary; SAT_granularity:cross-document; SAT_type:Survey; FOCUS_STUDY_OCT; CHECKED1023; SAT_interest:4; SAT_model:ClausIE; SAT_rel_type:anteriority; SAT_rel_type:negation; SAT_rel_type:anaphora; SAT_rel_type:Contrast; SAT_model:FRED; SAT_model:OpenIE; SAT_model:MinIE; SAT_focus_period:2006-2018","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VFG4D73M","conferencePaper","2022","Ye, Hongbin; Zhang, Ningyu; Chen, Hui; Chen, Huajun","Generative Knowledge Graph Construction: A Review","EMNLP","","","10.18653/v1/2022.emnlp-main.1","http://arxiv.org/abs/2210.12714","Generative Knowledge Graph Construction (KGC) refers to those methods that leverage the sequence-to-sequence framework for building knowledge graphs, which is ﬂexible and can be adapted to widespread tasks. In this study, we summarize the recent compelling progress in generative knowledge graph construction. We present the advantages and weaknesses of each paradigm in terms of different generation targets and provide theoretical insight and empirical analysis. Based on the review, we suggest promising research directions for the future. Our contributions are threefold: (1) We present a detailed, complete taxonomy for the generative KGC methods; (2) We provide a theoretical and empirical analysis of the generative KGC methods; (3) We propose several research directions that can be developed in the future.","2022-12-01","2022-12-13 18:12:06","2025-02-04 17:18:54","2022-12-13 18:12:06","","","","","","","","","","","","ACL","","en","","","","","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/QXDJKEIA/Ye et al. - 2022 - Generative Knowledge Graph Construction A Review.pdf","","manual; star; SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_task:EntityLinking; SAT_task:Event; SAT_type:Review; SAT_task:GraphCompletion; FOCUS_STUDY_OCT; CHECKED1023; SAT_dataset:ACE; SAT_benchmark_type:Qualitative; SAT_dataset:NYT; SAT_benchmark_type:Quantitative; SAT_interest:10; SAT_typology_dim:GenerationTaskVSTarget; SAT_nbModel:37; SAT_nbDataset:2; SAT_typology_dim:GenerativeStrategy; SAT_focus_period:2018-2022","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FZXLIAF7","journalArticle","2020","Zhang, Tianlin; Leng, Jiaxu; Liu, Ying","Deep learning for drug–drug interaction extraction from the literature: a review","Ofxord Academic","","1477-4054","10.1093/bib/bbz087","https://doi.org/10.1093/bib/bbz087","Drug–drug interactions (DDIs) are crucial for drug research and pharmacovigilance. These interactions may cause adverse drug effects that threaten public health and patient safety. Therefore, the DDIs extraction from biomedical literature has been widely studied and emphasized in modern biomedical research. The previous rules-based and machine learning approaches rely on tedious feature engineering, which is labourious, time-consuming and unsatisfactory. With the development of deep learning technologies, this problem is alleviated by learning feature representations automatically. Here, we review the recent deep learning methods that have been applied to the extraction of DDIs from biomedical literature. We describe each method briefly and compare its performance in the DDI corpus systematically. Next, we summarize the advantages and disadvantages of these deep learning models for this task. Furthermore, we discuss some challenges and future perspectives of DDI extraction via deep learning methods. This review aims to serve as a useful guide for interested researchers to further advance bioinformatics algorithms for DDIs extraction from the literature.","2020-09-25","2023-05-31 15:16:52","2023-10-23 08:55:32","2023-05-31 15:16:52","1609-1627","","5","21","","Briefings in Bioinformatics","Deep learning for drug–drug interaction extraction from the literature","","","","","","","","","","","","Silverchair","","{'citing': ['10.1093/bib/bbaa057', '10.1055/s-0040-1702001', '10.1055/s-0040-1702001', '10.1093/bib/bbaa161', '10.1093/bib/bbaa161', '10.1093/bib/bbaa161', '10.1093/bib/bbaa161', '10.1101/2020.11.09.375626', '10.1145/3388440.3414862', '10.1093/bib/bbab133', '10.1016/j.ailsci.2021.100005', '10.3390/math9070772', '10.1016/j.drudis.2021.06.009', '10.1002/hup.2802', '10.22159/ajpcr.2021.v14i8.41979', '10.1093/bib/bbab451', '10.1002/wcms.1581', '10.1093/bib/bbab526', '10.1124/dmd.121.000420', '10.1016/j.compbiomed.2021.105159', '10.1016/j.ymeth.2022.02.002', '10.1002/wcms.1597', '10.1016/j.eswa.2022.116616', '10.1145/3488933.3489030', '10.1089/cmb.2022.0113', '10.1089/cmb.2022.0113', '10.1089/cmb.2022.0113', '10.1089/cmb.2022.0113', '10.3390/molecules27093004', '10.1016/j.biopha.2022.113350', '10.1016/j.csbj.2022.05.057', '10.3390/jcm11164715', '10.1109/tcbb.2021.3081268', '10.1007/978-981-19-7596-7_5', '10.3390/app122110987', '10.1109/tfuzz.2022.3173379'], 'cited': ['10.1002/pds.1351', '10.1002/pds.1641', '10.1002/sim.1157', '10.1007/978-3-319-69179-4_39', '10.1007/978-3-642-15939-8_10', '10.1007/978-3-642-20192-9', '10.1007/s00228-005-0943-4', '10.1007/s00228-007-0374-5', '10.1007/s00228-014-1786-7', '10.1016/0004-3702(90)90005-k', '10.1016/j.artint.2005.03.001', '10.1016/j.ins.2009.12.006', '10.1016/j.ins.2017.06.021', '10.1016/j.jacc.2016.07.761', '10.1016/j.jbi.2013.07.011', '10.1016/j.jbi.2015.03.002', '10.1016/j.tips.2013.01.006', '10.1016/s2173-5085(09)70079-6', '10.1023/a:1007379606734', '10.1038/nature14539', '10.1067/mem.2001.119456', '10.1093/bioinformatics/btu557', '10.1093/bioinformatics/btw486', '10.1093/database/baw118', '10.1093/jamia/ocu041', '10.1093/nar/gkh061', '10.1093/nar/gkt1068', '10.1109/5.726791', '10.1109/access.2018.2845840', '10.1109/bibm.2018.8621405', '10.1109/icassp.2013.6638947', '10.1109/taslp.2014.2339736', '10.1109/tasl.2013.2244083', '10.1109/tkde.2017.2754499', '10.1109/tmm.2015.2477044', '10.1111/j.1365-2125.2004.02125.x', '10.1111/j.1365-2125.2004.02244.x', '10.1113/jphysiol.1968.sp008455', '10.1126/scitranslmed.3003377', '10.1145/2939672.2939778', '10.1145/3241741', '10.1162/089976600300015015', '10.1162/coli.2008.34.1.35', '10.1162/neco.1997.9.8.1735', '10.1162/tacl_a_00049', '10.1162/tacl_a_00234', '10.1186/s12859-015-0553-9', '10.1186/s12859-017-1855-x', '10.1186/s12859-017-1962-8', '10.1186/s12859-018-2195-1', '10.1208/s12248-008-9042-7', '10.1208/s12248-009-9106-3', '10.1214/aoms/1177729586', '10.1371/journal.pone.0140816', '10.1517/17425255.2014.894507', '10.18653/v1/d15-1203', '10.18653/v1/d15-1206', '10.18653/v1/d16-1264', '10.18653/v1/d18-1246', '10.18653/v1/d18-1247', '10.18653/v1/d18-1248', '10.18653/v1/d18-1307', '10.18653/v1/d18-1514', '10.18653/v1/p16-1200', '10.18653/v1/p16-2034', '10.18653/v1/p17-1085', '10.18653/v1/p18-2108', '10.2146/ajhp040567', '10.2174/138920021505141126102223', '10.3115/v1/p14-1055', '10.4172/2329-6887.1000e110', '10.3233/jrs-2012-0567', '10.1145/2396761.2398409', '10.1145/2766462.2767830']}","","/root/snap/zotero-snap/common/Zotero/storage/E3B32YF5/Zhang et al. - 2020 - Deep learning for drug–drug interaction extraction.pdf; /root/snap/zotero-snap/common/Zotero/storage/XKNDK5SZ/5610007.html","","SAT_task:RE; SAT_archi:BiLSTM; SAT_archi:CNN; SAT_archi:GCN; SAT_archi:LSTM; SAT_domain:biomedical; SAT_type:Review; SAT_focus:NeuralModels; SAT_typology_dim:Architecture; CHECKED1023; SAT_benchmark_type:Qualitative; SAT_interest:10; SAT_archi:MCCNN; SAT_archi:SCNN; SAT_archi:DeepCN; SAT_archi:DCN; SAT_archi:ACN; SAT_nbModel:29; SAT_dataset:DDI; SAT_focus:Embed; SAT_focus:Archi; SAT_focus_period:1998-2019","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R3HSD4G5","conferencePaper","2021","Gao, Tianyu; Han, Xu; Bai, Yuzhuo; Qiu, Keyue; Xie, Zhiyu; Lin, Yankai; Liu, Zhiyuan; Li, Peng; Sun, Maosong; Zhou, Jie","Manual Evaluation Matters: Reviewing Test Protocols of Distantly Supervised Relation Extraction","Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021","","","10.18653/v1/2021.findings-acl.112","https://aclanthology.org/2021.findings-acl.112","","2021","2023-03-22 11:24:46","2023-10-20 13:05:38","2023-03-22 11:24:46","1306-1318","","","","","","","","","","","ACL","Online","en","","","https://paperswithcode.com/paper/manual-evaluation-matters-reviewing-test","","DOI.org (Crossref)","","{'citing': ['10.1186/s12859-022-04646-6', '10.3390/s22134911', '10.1186/s12859-022-04646-6', '10.3390/s22134911', '10.1186/s12859-022-04646-6', '10.3390/s22134911'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/6PBLV8P2/Gao et al. - 2021 - Manual Evaluation Matters Reviewing Test Protocol.pdf","","star; NOT A SURVEY ?; SAT_model:BERT; SAT_task:RE; SAT_granularity:sentence; SAT_archi:CNN; SAT_archi:PCNN; SAT_type:Benchmark; SAT_focus:distant; CHECKED1023; SAT_dataset:NYT; SAT_dataset:Wiki20; SAT_granularity:bag; SAT_nbModel:4; SAT_focus_period:2015-2021; SAT_interest:8; SAT_focus:EVAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL-IJCNLP","","","","","","","","","","","","","","",""
"4D5QJ33V","journalArticle","2021","Nayak, Tapas; Majumder, Navonil; Goyal, Pawan; Poria, Soujanya","Deep Neural Approaches to Relation Triplets Extraction: A Comprehensive Survey","Springer","","1866-9956, 1866-9964","10.1007/s12559-021-09917-7","http://arxiv.org/abs/2103.16929","Recently, with the advances made in continuous representation of words (word embeddings) and deep neural architectures, many research works are published in the area of relation extraction and it is very difﬁcult to keep track of so many papers. To help future research, we present a comprehensive review of the recently published research works in relation extraction. We mostly focus on relation extraction using deep neural networks which have achieved state-of-the-art performance on publicly available datasets. In this survey, we cover sentence-level relation extraction to document-level relation extraction, pipeline-based approaches to joint extraction approaches, annotated datasets to distantly supervised datasets along with few very recent research directions such as zero-shot or fewshot relation extraction, noise mitigation in distantly supervised datasets. Regarding neural architectures, we cover convolutional models, recurrent network models, attention network models, and graph convolutional models in this survey.","2021-09","2022-04-20 06:17:20","2025-02-04 17:20:33","2022-04-20 06:17:20","1215-1232","","5","13","","Cogn Comput","","","","","","","","en","","","","","arXiv.org","","{'citing': ['10.1007/s00521-021-06667-3', '10.3390/math10224378'], 'cited': ['10.18653/v1/d17-1187', '10.18653/v1/d19-1602', '10.18653/v1/k19-1055', '10.18653/v1/p17-1113', '10.18653/v1/p18-1047', '10.18653/v1/p19-1023', '10.3115/1614164.1614177', '10.3115/1690219.1690287', '10.3115/v1/d14-1162', '10.3115/v1/p14-1054', '10.1007/10704656_11', '10.1016/j.jbi.2012.04.008', '10.1093/bioinformatics/btz682', '10.1145/2629489', '10.1145/988672.988687', '10.1186/s12859-017-1609-9', '10.18653/v1/2020.acl-main.136', '10.18653/v1/2020.coling-main.136', '10.18653/v1/2020.emnlp-main.133', '10.18653/v1/d15-1203', '10.18653/v1/d18-1157', '10.18653/v1/d19-1498', '10.18653/v1/p16-1101', '10.18653/v1/p16-1200', '10.18653/v1/p17-1017', '10.18653/v1/p18-1199', '10.18653/v1/p19-1129', '10.18653/v1/p19-1279', '10.25046/aj040208', '10.3115/1621969.1621986', '10.3115/v1/p15-2047', '10.1016/j.eswa.2018.07.032', '10.1101/007443', '10.1109/access.2020.2996642', '10.1145/1999676.1999697', '10.1145/3038912.3052708', '10.1145/3395260.3395276', '10.1609/aaai.v33i01.33017273', '10.1609/aaai.v34i05.6300', '10.1609/aaai.v34i05.6342', '10.1609/aaai.v34i05.6374', '10.18653/v1/2020.coling-main.566', '10.18653/v1/2020.emnlp-main.127', '10.18653/v1/d17-1279', '10.18653/v1/d19-1020', '10.18653/v1/e17-1110', '10.18653/v1/k19-1056', '10.18653/v1/n18-1202', '10.18653/v1/p19-1024', '10.18653/v1/p19-1074', '10.18653/v1/p19-1136', '10.18653/v1/w18-2401', '10.2139/ssrn.3199424', '10.24963/ijcai.2020/561', '10.1007/978-981-10-7359-5_6', '10.1007/s10115-007-0110-6', '10.1016/j.jbi.2013.07.011', '10.1016/j.jbi.2018.08.005', '10.1093/database/baw042', '10.1162/tacl_a_00104', '10.1609/aaai.v33i01.3301419', '10.18653/v1/2020.acl-main.141', '10.18653/v1/2020.coling-main.138', '10.18653/v1/2020.coling-main.8', '10.18653/v1/d17-1004', '10.18653/v1/d18-1244', '10.18653/v1/e17-1111', '10.18653/v1/p16-1087', '10.18653/v1/p16-1105', '10.18653/v1/p16-1145', '10.18653/v1/p19-1135', '10.18653/v1/p19-1430', '10.24963/ijcai.2020/559', '10.3115/1693756.1693801', '10.3115/v1/p15-1150', '10.3115/v1/w14-4012', '10.1007/978-3-030-15712-8_47', '10.1007/978-3-030-22744-9_23', '10.1007/978-3-030-47426-3_16', '10.1007/978-3-642-15939-8_10', '10.1145/1376616.1376746', '10.1162/neco.1997.9.8.1735', '10.1609/aaai.v33i01.33017072', '10.1609/aaai.v34i05.6495', '10.18653/v1/2020.acl-main.457', '10.18653/v1/2020.coling-main.461', '10.18653/v1/2020.emnlp-main.304', '10.18653/v1/d18-1246', '10.18653/v1/d19-1649', '10.18653/v1/d19-5713', '10.18653/v1/k17-1034', '10.18653/v1/n16-1030', '10.18653/v1/n19-1152', '10.18653/v1/n19-1288', '10.18653/v1/p16-1123', '10.18653/v1/p18-1046', '10.18653/v1/p19-1423', '10.18653/v1/w19-5006', '10.3115/1073445.1073456', '10.1136/amiajnl-2011-000203', '10.1162/tacl_a_00021', '10.1162/tacl_a_00049', '10.1162/tacl_a_00300', '10.1186/s12859-020-03889-5', '10.1609/aaai.v33i01.33017484', '10.1609/aaai.v34i05.6407', '10.18653/v1/2020.acl-main.670', '10.18653/v1/2020.coling-main.565', '10.18653/v1/2020.emnlp-main.303', '10.18653/v1/d15-1206']}","","/root/snap/zotero-snap/common/Zotero/storage/E5DJEXSD/Nayak et al. - 2021 - Deep Neural Approaches to Relation Triplets Extrac.pdf","","manual; star; bert; survey; SAT_model:BERT; SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_task:NER; SAT_archi:CNN; SAT_archi:PipeLine; SAT_archi:LSTM; SAT_model:SpanBERT; SAT_model:Elmo; SAT_focus:AnnotationQyality; SAT_focus:FewSHot; SAT_type:Survey; SAT_focus:datasets; SAT_focus:models; SAT_focus:Eval; SAT_focus:JoinModel; SAT_typology:True; SAT_typology_dim:Architecture; SAT_nbDataset:13; SAT_archi:Graph; SAT_focus:Noise; SAT_focus:EntityType; SAT_nbModel:13; FOCUS_STUDY_OCT; CHECKED1023; SAT_benchmark:True; SAT_dataset:ACE; SAT_dataset:NYT; SAT_benchmark_type:Quantitative; SAT_dataset:SemEval; SAT_dataset:TACRED; SAT_archi:AttentionBased; SAT_focus:FewShot; SAT_dataset:GDS; SAT_dataset:FewRel2; SAT_dataset:WikiReading; SAT_dataset:DocRED; SAT_focus_period:2016-2021; SAT_survey_scope:PERSON/ORG/LOC; SAT_interest:10","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7C6XSCCK","journalArticle","2020","Tiange Xu, Fu Zhang","A Brief Review of Relation Extraction Based on Pre-Trained Language Models","IOS Press","","","10.3233/faia200755","https://www.semanticscholar.org/paper/72969efbebf0884fec3cb8d416dc329be83651b8","Relation extraction is to extract the semantic relation between entity pairs in text, and it is a key point in building Knowledge Graphs and information extraction. The rapid development of deep learning in recent years has resulted in rich research results in relation extraction tasks. At present, the accuracy of relation extraction tasks based on pre-trained language models such as BERT exceeds the methods based on Convolutional or Recurrent Neural Networks. This review mainly summarizes the research progress of pre-trained language models such as BERT in supervised learning and distant supervision relation extraction. In addition, the directions for future research and some comparisons and analyses are discussed in our whole survey. The survey may help readers understand and catch some key techniques about the issue, and identify some future research directions.","2020","2023-02-03 15:59:43","2025-02-04 17:18:54","","775-789","","","nan","","Frontiers in Artificial Intelligence and Applications","","","","","","","","","TRUE","","SemanticScholar","72969efbebf0884fec3cb8d416dc329be83651b8","","","","","/root/snap/zotero-snap/common/Zotero/storage/P72RRPI4/Tiange Xu - 2020 - A Brief Review of Relation Extraction Based on Pre.pdf","","star; automatic; SAT_focus:KnowledgeIntegration; SAT_model:BERT; SAT_model:RoBERTA; SAT_oldTag:CHECKED0923; SAT_granularity:document; SAT_task:RC; SAT_focus:NoisyLabel; SAT_archi:CNN; SAT_task:JointRE; SAT_archi:RNN; SAT_model:AlBERT; SAT_archi:GCN; SAT_archi:LSTM; SAT_rel_type:overlapping; SAT_model:XLNET; SAT_model:SpanBERT; SAT_model:Ernie; SAT_archi:PCNN; SAT_focus:Context; SAT_model:GPT2; SAT_type:Review; SAT_focus:distant; SAT_focus:LLM; SAT_typology:True; SAT_typology_dim:Architecture; SAT_archi:Graph; SAT_focus:Interpretability; SAT_nbModel:13; SAT_nbDataset:11; FOCUS_STUDY_OCT; CHECKED1023; SAT_dataset:NYT; SAT_dataset:SemEval; SAT_dataset:TACRED; SAT_dataset:FewRel; SAT_interest:10; SAT_dataset:SciERC; SAT_typology_dim:Supervised; SAT_archi:JoinModels; SAT_focus_period:12003-2020; SAT_model:TransformerXL; SAT_typology_dim:Distant; SAt_dataset:WEBNLG","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DRR95MM6","journalArticle","2020","Hogan, Aidan","The Semantic Web: Two decades on","IOS Press","","1570-0844","10.3233/SW-190387","https://content.iospress.com/articles/semantic-web/sw190387","More than two decades have passed since the establishment of the initial cornerstones of the Semantic Web. Since its inception, opinions have remained divided regarding the past, present and potential future impact of the Semantic Web. In this paper","2020-01-01","2023-05-31 15:08:25","2023-10-19 15:28:32","2023-05-31 15:08:25","169-185","","1","11","","","","","","","","","","en","","","","","content.iospress.com","","{'citing': ['10.1016/j.cageo.2020.104620', '10.14778/3476311.3476386', '10.1145/3472749.3474822', '10.1016/j.cageo.2022.105082', '10.1109/tii.2021.3130052', '10.3233/sw-223212'], 'cited': ['10.1002/bult.2010.1720360610', '10.1007/978-3-030-00668-6_23', '10.1007/978-3-319-11964-9', '10.1007/978-3-319-11964-9_18', '10.1007/978-3-319-46547-0', '10.1007/978-3-540-30475-3_4', '10.1007/978-3-540-76298-0_13', '10.1007/978-3-540-92913-0_12', '10.1007/978-3-642-02121-3', '10.1007/978-3-642-04930-9_48', '10.1007/978-3-642-25073-6', '10.1007/978-3-642-38721-0_1', '10.1007/978-3-642-39784-4', '10.1007/978-3-642-41338-4_18', '10.1016/j.websem.2011.05.004', '10.1016/j.websem.2011.05.004', '10.1016/j.websem.2011.06.003', '10.1016/j.websem.2011.11.010', '10.1016/j.websem.2011.11.010', '10.1016/j.websem.2012.02.001', '10.1080/17460441.2019.1586880', '10.1080/17460441.2019.1586880', '10.1109/icde.2008.4497533', '10.1109/ictai.2007.181', '10.1109/mic.2014.124', '10.1109/mis.2006.62', '10.1136/amiajnl-2013-001636', '10.1145/1376616.1376746', '10.1145/1567274.1567278', '10.1145/1567274.1567278', '10.1145/2320765.2320803', '10.1145/2629489', '10.1145/2797115.2797124', '10.1145/2797115.2797124', '10.1145/2815072.2815073', '10.1145/2815072.2815073', '10.1145/2844544', '10.1145/2844544', '10.1145/2872518.2890529', '10.1145/3068333', '10.1145/3068333', '10.1145/3078714.3078751', '10.1145/3078714.3078751', '10.1145/3104031', '10.1145/3104031', '10.1145/3178876', '10.1145/3178876.3186002', '10.1371/journal.pone.0038869', '10.1504/ijmso.2008.021204', '10.2200/s00334ed1v01y201102wbe001', '10.3233/sw-140134', '10.3233/sw-150175', '10.3233/sw-160213', '10.3233/sw-160216', '10.3233/sw-160249', '10.3233/sw-180333', '10.3233/sw-180333', '10.3233/sw-2012-0066', '10.4018/jswis.2009040101', '10.4018/jswis.2009040101', '10.5281/zenodo.3229401', '10.5441/002/edbt.2014.82', '10.5591/978-1-57735-516-8/ijcai11-385', '10.5402/2012/271878']}","","","","NOT A SURVEY ?; NEW; NEW_citations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ETFM4HET","journalArticle","2020","Liu, Kang","A survey on neural relation extraction","Springer","","1674-7321, 1869-1900","10.1007/s11431-020-1673-6","https://link.springer.com/10.1007/s11431-020-1673-6","","2020-10","2023-05-31 15:32:59","2023-10-20 12:51:56","2023-05-31 15:32:59","1971-1989","","10","63","","Sci. China Technol. Sci.","","","","","","","","en","False but accesible","","","","DOI.org (Crossref)","","{'citing': ['10.1007/978-3-030-73200-4_38', '10.3390/sym13040539', '10.1016/j.ins.2021.09.028', '10.1007/s00521-021-06667-3', '10.1108/ajim-03-2022-0129', '10.1007/s10462-022-10239-9', '10.1109/access.2022.3219455'], 'cited': ['10.1007/978-3-642-15939-8_10', '10.1016/j.artint.2019.07.004', '10.1016/j.websem.2008.06.001', '10.1016/j.websem.2009.07.002', '10.1145/3191513', '10.1145/3308558.3313573', '10.1145/988672.988687', '10.1162/tacl_a_00049', '10.18653/v1/2020.acl-main.136', '10.18653/v1/d15-1203', '10.18653/v1/d15-1206', '10.18653/v1/d18-1157', '10.18653/v1/d18-1245', '10.18653/v1/d18-1246', '10.18653/v1/d18-1514', '10.18653/v1/d19-1020', '10.18653/v1/d19-1022', '10.18653/v1/d19-1035', '10.18653/v1/d19-1037', '10.18653/v1/d19-1039', '10.18653/v1/d19-1250', '10.18653/v1/p19-1024', '10.18653/v1/p19-1074', '10.18653/v1/p19-1128', '10.18653/v1/p19-1132', '10.18653/v1/p19-1134', '10.18653/v1/p19-1135', '10.18653/v1/p19-1139', '10.18653/v1/p19-1423', '10.18653/v1/p19-1430', '10.24963/ijcai.2017/559', '10.24963/ijcai.2018/630', '10.3115/1118693.1118703', '10.1145/2623330.2623623', '10.3115/1621969.1621986', '10.3115/v1/d14-1162', '10.1145/1376616.1376746']}","","","","SAT_focus:KnowledgeIntegration; SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_archi:CNN; SAT_archi:RNN; SAT_archi:GNN; SAT_focus:MultipleRelations; SAT_focus:FewSHot; SAT_type:Survey; SAT_focus:datasets; SAT_typology:True; SAT_focus:Noise; CHECKED1023; SAT_focus:Reinforcement; SAT_focus:adversarial; SAT_dataset:ACE; SAT_dataset:NYT; SAT_focus:metrics; SAT_nbDataset:9; SAT_dataset:SemEval; SAT_dataset:TACRED; SAT_dataset:WebNLG; SAT_dataset:FewRel; SAT_typology_dim:Representation; SAT_typology_dim:Training; SAT_typology_dim:ComplexRelations; SAT_typology_dim:JoinRE; SAT_archi:AttentionBased; SAT_archi:CapsuleNetwoprk; SAT_focus_period:2001-2019","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"972G722V","preprint","2023","Pan, Shirui; Luo, Linhao; Wang, Yufei; Chen, Chen; Wang, Jiapu; Wu, Xindong","Unifying Large Language Models and Knowledge Graphs: A Roadmap","","","","not found","http://arxiv.org/abs/2306.08302","Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolving by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs, which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; 2) LLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and 3) Synergized LLMs + KGs, in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions.","2023-06-20","2023-08-18 16:20:26","2023-10-23 20:01:10","2023-08-18 16:20:26","","","","","","","Unifying Large Language Models and Knowledge Graphs","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2306.08302 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/RUR228X9/Pan et al. - 2023 - Unifying Large Language Models and Knowledge Graph.pdf; /root/snap/zotero-snap/common/Zotero/storage/76FCNRI8/2306.html","","SAT_model:BERT; SAT_model:RoBERTA; SAT_model:mT5; SAT_model:T5; SAT_model:BART; SAT_model:GPT3; SAT_model:AlBERT; SAT_model:DeBerta; SAT_model:GPT; SAT_model:XLNET; SAT_model:Ernie; SAT_model:GLM; CHECKED1023; SAT_interest:10; HERE; SAT_type:RoadMap; SAT_model:T0; SAT_model:FlanT5; SAT_model:DistillBert; SAT_model:ELectra; SAT_model:GOpher; SAT_model:LamDA; SAT_model:BARD; SAT_model:Alpaca; SAT_focus:Model; SAT_focus:KnowledgeGraph; SAT_focus:Application; SAT_typology_dim:KGEnhancedLLM; SAT_typology_dim:LLMAugmentedKG; SAT_typology_dim:LLMANDKG; SAT_nbModel:94; SAT_model:LLAMA; SAT_model:VICUNA","","","","","","","","","","","","","","","","","","","","arXiv:2306.08302","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L2JJH4KK","preprint","2022","Zhen, Chaoqi; Shang, Yanlei; Liu, Xiangyu; Li, Yifei; Chen, Yong; Zhang, Dell","A Survey on Knowledge-Enhanced Pre-trained Language Models","","","","10.1109/tkde.2023.3310002","http://arxiv.org/abs/2212.13428","Natural Language Processing (NLP) has been revolutionized by the use of Pre-trained Language Models (PLMs) such as BERT. Despite setting new records in nearly every NLP task, PLMs still face a number of challenges including poor interpretability, weak reasoning capability, and the need for a lot of expensive annotated data when applied to downstream tasks. By integrating external knowledge into PLMs, Knowledge-Enhanced Pre-trained Language Models (KEPLMs) have the potential to overcome the above-mentioned limitations. In this paper, we examine KEPLMs systematically through a series of studies. Speciﬁcally, we outline the common types and different formats of knowledge to be integrated into KEPLMs, detail the existing methods for building and evaluating KEPLMS, present the applications of KEPLMs in downstream tasks, and discuss the future research directions. Researchers will beneﬁt from this survey by gaining a quick and comprehensive overview of the latest developments in this ﬁeld.","2022-12-27","2023-08-18 16:20:51","2023-10-23 21:56:19","2023-08-18 16:20:51","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2212.13428 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/IVQHJB8D/Zhen et al. - 2022 - A Survey on Knowledge-Enhanced Pre-trained Languag.pdf","","SAT_focus:KnowledgeIntegration; SAT_task:QA; SAT_task:Reasoning; SAT_task:SentimentAnanlysis; SAT_task:TextGeneration; SAT_domain:science; SAT_domain:justice; SAT_type:Survey; SAT_focus:models; SAT_focus:LLM; HERE; SAT_domain:company_website; SAT_task:KnowledgeCompletion; SAT_context:code; SAT_typology_dim:SourceKnowledge","","","","","","","","","","","","","","","","","","","","arXiv:2212.13428","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CPT4AHKL","preprint","2022","Yin, Da; Dong, Li; Cheng, Hao; Liu, Xiaodong; Chang, Kai-Wei; Wei, Furu; Gao, Jianfeng","A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models","","","","not found","http://arxiv.org/abs/2202.08772","With the increasing of model capacity brought by pre-trained language models, there emerges boosting needs for more knowledgeable natural language processing (NLP) models with advanced functionalities including providing and making ﬂexible use of encyclopedic and commonsense knowledge. The mere pre-trained language models, however, lack the capacity of handling such knowledge-intensive NLP tasks alone. To address this challenge, large numbers of pre-trained language models augmented with external knowledge sources are proposed and in rapid development. In this paper, we aim to summarize the current progress of pre-trained language modelbased knowledge-enhanced models (PLMKEs) by dissecting their three vital elements: knowledge sources, knowledge-intensive NLP tasks, and knowledge fusion methods. Finally, we present the challenges of PLMKEs based on the discussion regarding the three elements and attempt to provide NLP practitioners with potential directions for further research.","2022-02-17","2023-08-18 16:21:09","2023-10-23 12:06:32","2023-08-18 16:21:09","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2202.08772 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/UFKQ5PXS/Yin et al. - 2022 - A Survey of Knowledge-Intensive NLP with Pre-Train.pdf","","SAT_type:Survey; SAT_focus:LLM; HERE","","","","","","","","","","","","","","","","","","","","arXiv:2202.08772","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WA2GANGD","conferencePaper","2022","AlKhamissi, Badr; Li, Millicent; Celikyilmaz, Asli; Diab, Mona; Ghazvininejad, Marjan","A Review on Language Models as Knowledge Bases","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","10.18653/v1/D19-1250","http://arxiv.org/abs/2204.06031","Recently, there has been a surge of interest in the NLP community on the use of pretrained Language Models (LMs) as Knowledge Bases (KBs). Researchers have shown that LMs trained on a sufficiently large (web) corpus will encode a significant amount of knowledge implicitly in its parameters. The resulting LM can be probed for different kinds of knowledge and thus acting as a KB. This has a major advantage over traditional KBs in that this method requires no human supervision. In this paper, we present a set of aspects that we deem a LM should have to fully act as a KB, and review the recent literature with respect to those aspects.","2022-04-12","2023-08-18 16:21:16","2025-02-04 17:20:33","2023-08-18 16:21:16","","","","","","","","","","","","ACL","","en","","","","","arXiv.org","","{'citing': ['10.1016/j.inffus.2022.11.025', '10.1007/978-3-031-19815-1_4', '10.1109/ijcnn55064.2022.9892147', '10.1109/ijcnn55064.2022.9892715', '10.1007/978-3-031-21062-4_48', '10.1007/978-981-19-7596-7_11', '10.1080/15391523.2022.2142872', '10.1145/3540250.3549113', '10.4000/books.aaccademia.10872', '10.15622/ia.21.6.4', '10.1007/978-3-031-16500-9_11', '10.1007/978-3-031-19842-7_21', '10.3389/frai.2022.900943', '10.1007/978-3-031-09108-7_4', '10.1016/j.eswa.2022.119369', '10.1145/3503161.3548021', '10.3390/info11020074', '10.1145/3360901.3364451', '10.1145/3360901.3364451', '10.1145/3360901.3364451', '10.1145/3360901.3364451', '10.3389/frai.2020.00036', '10.1162/tacl_a_00324', '10.1145/3383313.3412249', '10.1007/978-3-030-61377-8_38', '10.1007/s11431-020-1647-3', '10.1007/s11431-020-1673-6', '10.1007/978-3-030-62419-4_17', '10.1007/978-3-030-62419-4_26', '10.1162/tacl_a_00342', '10.1162/tacl_a_00349', '10.1007/978-3-030-58539-6_34', '10.1016/j.inffus.2019.12.012', '10.5715/jnlp.28.3', '10.1162/tacl_a_00356', '10.1145/3442381.3450117', '10.1162/tacl_a_00359', '10.1371/journal.pone.0253905', '10.1145/3442442.3452324', '10.1162/tacl_a_00410', '10.1145/3464377', '10.1016/j.aiopen.2021.08.002', '10.1162/tacl_a_00407', '10.1007/978-3-030-87234-2_57', '10.1007/978-3-030-86230-5_58', '10.1007/978-3-030-82099-2_25', '10.1016/j.jbi.2021.103982', '10.14778/3476311.3476393', '10.1145/3459637.3481987', '10.1145/3459637.3482369', '10.2200/s01123ed1v01y202108hlt053', '10.2200/s0113ed1v01y202109icr076', '10.1101/2021.11.29.470486', '10.1007/s10670-021-00491-w', '10.1145/3485477', '10.1145/3472714.3473659', '10.1145/3488560.3498529', '10.1007/978-3-030-95481-9_3', '10.1016/j.eswa.2022.116592', '10.1145/3511599', '10.3389/frai.2022.796793', '10.1017/s1351324922000031', '10.1146/annurev-linguistics-031120-122924', '10.1007/s00521-022-06975-2', '10.5715/jnlp.29.259', '10.1007/978-3-030-98305-5_36', '10.1007/978-3-030-99739-7_26', '10.1145/3485447.3511932', '10.1162/tacl_a_00471', '10.1162/tacl_a_00459', '10.1038/s42256-022-00458-8', '10.1038/s42256-022-00458-8', '10.1109/taslp.2021.3120636', '10.1109/icassp43922.2022.9746935', '10.1007/978-3-031-10989-8_41', '10.1109/tnnls.2021.3070843', '10.1109/icmla52953.2021.00042', '10.1109/ijcnn52387.2021.9534355', '10.1145/3531146.3533192', '10.1109/icodt252288.2021.9441517', '10.1109/access.2021.3130956', '10.1162/tacl_a_00476', '10.1007/s11263-022-01653-1', '10.1145/3477495.3531979', '10.1109/jbhi.2021.3062322', '10.1109/taslp.2020.3008390', '10.1109/taslp.2021.3065201', '10.1145/3519939.3523709', '10.1109/icassp43922.2022.9746910', '10.1145/3477495.3531971', '10.1109/cvpr46437.2021.01389', '10.1162/tacl_a_00454', '10.3390/sym14081715', '10.5715/jnlp.29.762', '10.1145/3487553.3524648', '10.1007/978-3-031-17189-5_20', '10.4467/20843976zk.22.003.15869', '10.1109/taslp.2022.3193222', '10.1007/s11704-022-1244-0', '10.1109/taslp.2022.3199655', '10.1007/978-3-031-15931-2_47', '10.1016/j.eng.2022.04.024', '10.1109/cvpr52688.2022.00514', '10.1109/cvpr52688.2022.01452', '10.1109/cvpr52688.2022.01631', '10.1109/cvpr52688.2022.00458', '10.1145/3534678.3539305', '10.1145/3534678.3539443', '10.1145/3534678.3542607', '10.1109/cvprw56347.2022.00539', '10.1007/978-3-031-16270-1_12', '10.1109/taslp.2022.3202123', '10.1007/978-3-031-19433-7_1', '10.1145/3511808.3557484', '10.1016/j.ins.2022.10.063', '10.1145/3524610.3527921'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/HXV6VEHB/AlKhamissi et al. - 2022 - A Review on Language Models as Knowledge Bases.pdf","","SAT_type:Review; SAT_focus:models; SAT_typology:True; FOCUS_STUDY_OCT; CHECKED1023; SAT_typology_dim:Acess; SAT_typology_dim:Consistency; SAT_typology_dim:Edit; SAT_typology_dim:Reasoning; SAT_typology_dim:Explainability; SAT_typology_dim:Interpretability; SAT_interest:10; SAT_focus_period:2019-2022; SAT_nbtypes_entity:28","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP-IJCNLP","","","","","","","","","","","","","","",""
"NHC3PMAN","preprint","2021","Wei, Xiaokai; Wang, Shen; Zhang, Dejiao; Bhatia, Parminder; Arnold, Andrew","Knowledge Enhanced Pretrained Language Models: A Compreshensive Survey","","","","not found","http://arxiv.org/abs/2110.08455","Pretrained Language Models (PLM) have established a new paradigm through learning informative contextualized representations on large-scale text corpus. This new paradigm has revolutionized the entire field of natural language processing, and set the new state-of-the-art performance for a wide variety of NLP tasks. However, though PLMs could store certain knowledge/facts from training corpus, their knowledge awareness is still far from satisfactory. To address this issue, integrating knowledge into PLMs have recently become a very active research area and a variety of approaches have been developed. In this paper, we provide a comprehensive survey of the literature on this emerging and fast-growing field - Knowledge Enhanced Pretrained Language Models (KE-PLMs). We introduce three taxonomies to categorize existing work. Besides, we also survey the various NLU and NLG applications on which KE-PLM has demonstrated superior performance over vanilla PLMs. Finally, we discuss challenges that face KE-PLMs and also promising directions for future research.","2021-10-15","2023-08-18 16:21:19","2023-10-23 16:43:21","2023-08-18 16:21:19","","","","","","","Knowledge Enhanced Pretrained Language Models","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2110.08455 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/3IQQDX8J/Wei et al. - 2021 - Knowledge Enhanced Pretrained Language Models A C.pdf","","SAT_model:BERT; SAT_task:QA; SAT_task:Translation; SAT_task:SentimentAnanlysis; SAT_task:TextGeneration; SAT_task:Summarization; SAT_task:NER; SAT_model:T5; SAT_task:SemanticParsing; SAT_model:BART; SAT_domain:medical; SAT_archi:GNN; SAT_model:GPT; SAT_model:Ernie; SAT_source:Wikidata; SAT_source:Wikipedia; SAT_type:Survey; SAT_focus:LLM; HERE; SAT_model:COMET; SAT_domain:company_website; SAT_model:LUKE; SAT_source:WordNet; SAT_source:Conceptnet; SAT_source:ATOMIC; SAT_focus:KnowledgeSource; SAT_typology_dim:KnowledgeSource; SAT_typology_dim:Granularity; SAT_typology_dim:Applications; SAT_focus:CommonSense; SAT_model:CokeBERT; SAT_model:KGBART","","","","","","","","","","","","","","","","","","","","arXiv:2110.08455","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ACSZBN68","journalArticle","2022","Zhu, Xiangru; Li, Zhixu; Wang, Xiaodan; Jiang, Xueyao; Sun, Penglei; Wang, Xuwu; Xiao, Yanghua; Yuan, Nicholas Jing","Multi-Modal Knowledge Graph Construction and Application: A Survey","IEEE Transactions on Knowledge and Data Engineering","","1041-4347, 1558-2191, 2326-3865","10.1109/TKDE.2022.3224228","http://arxiv.org/abs/2202.05786","Recent years have witnessed the resurgence of knowledge engineering which is featured by the fast growth of knowledge graphs. However, most of existing knowledge graphs are represented with pure symbols, which hurts the machine's capability to understand the real world. The multi-modalization of knowledge graphs is an inevitable key step towards the realization of human-level machine intelligence. The results of this endeavor are Multi-modal Knowledge Graphs (MMKGs). In this survey on MMKGs constructed by texts and images, we first give definitions of MMKGs, followed with the preliminaries on multi-modal tasks and techniques. We then systematically review the challenges, progresses and opportunities on the construction and application of MMKGs respectively, with detailed analyses of the strength and weakness of different solutions. We finalize this survey with open research problems relevant to MMKGs.","2022","2023-08-18 16:22:22","2023-10-23 11:59:14","2023-08-18 16:22:22","1-20","","","","","IEEE Trans. Knowl. Data Eng.","Multi-Modal Knowledge Graph Construction and Application","","","","","","","","","","","","arXiv.org","","arXiv:2202.05786 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/5FKRBCJW/Zhu et al. - 2022 - Multi-Modal Knowledge Graph Construction and Appli.pdf; /root/snap/zotero-snap/common/Zotero/storage/S6UE8KIS/2202.html","","SAT_focus:Multimodal; SAT_focus:VisualRE; SAT_task:RE; SAT_task:NER; SAT_task:ImageCaptioning; SAT_task:LinkPred; SAT_type:Survey; SAT_focus:Math; CHECKED1023; SAT_interest:4; SAT_task:TripleClustering; SAT_focus:ImageKnowledgeGRaph; SAT_focus:ImageObjectRecognition; SAT_focus_period:2003-2022; SAT_focus:EVAL; SAT_model:CLIP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QAZSPLVC","journalArticle","2021","Min, Bonan; Ross, Hayley; Sulem, Elior; Veyseh, Amir Pouran Ben; Nguyen, Thien Huu; Sainz, Oscar; Agirre, Eneko; Heinz, Ilana; Roth, Dan","Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey","ACM","","","10.48550/arXiv.2111.01243","http://arxiv.org/abs/2111.01243","Large, pre-trained transformer-based language models such as BERT have drastically changed the Natural Language Processing (NLP) field. We present a survey of recent work that uses these large language models to solve NLP tasks via pre-training then fine-tuning, prompting, or text generation approaches. We also present approaches that use pre-trained language models to generate data for training augmentation or other purposes. We conclude with discussions on limitations and suggested directions for future research.","2021-11-01","2023-08-18 16:22:27","2025-02-04 17:18:54","2023-08-18 16:22:27","","","","","","ACM Comput. Surv.","Recent Advances in Natural Language Processing via Large Pre-Trained Language Models","","","","","","","","","","","","arXiv.org","","arXiv:2111.01243 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/H8T2DMKH/Min et al. - 2021 - Recent Advances in Natural Language Processing via.pdf; /root/snap/zotero-snap/common/Zotero/storage/KLXGQH7A/2111.html","","SAT_model:BERT; SAT_model:RoBERTA; SAT_task:QA; SAT_task:RE; SAT_task:NER; SAT_task:Retrieval; SAT_task:SlotFilling; SAT_model:T5; SAT_task:SemanticParsing; SAT_task:Event; SAT_model:mBERT; SAT_model:BART; SAT_model:GPT3; SAT_model:GPT2; SAT_type:Survey; SAT_focus:LLM; SAT_focus:domain; FOCUS_STUDY_OCT; SAT_task:JoinRE; CHECKED1023; SAT_interest:10; SAT_focus:lang; SAT_model:XLM; SAT_focus:PretrainFinetune; SAT_focus:TextGeneration; SAT_focus_period:2018-2021; SAT_focus:Prompt","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P2755PC4","preprint","2023","Zhu, Yuqi; Wang, Xiaohan; Chen, Jing; Qiao, Shuofei; Ou, Yixin; Yao, Yunzhi; Deng, Shumin; Chen, Huajun; Zhang, Ningyu","LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities","","","","not found","http://arxiv.org/abs/2305.13168","This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We employ eight distinct datasets that encompass aspects including entity, relation and event extraction, link prediction, and question answering. Empirically, our ﬁndings suggest that GPT-4 outperforms ChatGPT in the majority of tasks and even surpasses ﬁne-tuned models in certain reasoning and question-answering datasets. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, which culminates in the presentation of the Virtual Knowledge Extraction task and the development of the VINE dataset. Drawing on these empirical ﬁndings, we further propose AutoKG, a multiagent-based approach employing LLMs for KG construction and reasoning, which aims to chart the future of this ﬁeld and offer exciting opportunities for advancement. We anticipate that our research can provide invaluable insights for future undertakings of KG1.","2023-05-22","2023-09-27 10:05:20","2025-02-04 17:18:54","2023-09-27 10:05:20","","","","","","","LLMs for Knowledge Graph Construction and Reasoning","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2305.13168 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/GVJG82KX/Zhu et al. - 2023 - LLMs for Knowledge Graph Construction and Reasonin.pdf","","SAT_task:QA; SAT_task:RE; SAT_task:NER; SAT_task:Event; SAT_task:LinkPred; SAT_focus:FewSHot; FOCUS_STUDY_OCT; CHECKED1023; SAT_benchmark_type:Quantitative; SAT_dataset:TACRED; SAT_interest:10; SAT_dataset:SciERC; SAT_nbDataset:8; HERE; SAT_model:GPT4; SAT_dataset:RETRACRED; SAT_dataset:MAVEN; SAT_dataset:FB15K-237; SAT_dataset:ATOMIC; SAT_dataset:FreeBaseQA; SAT_dataset:TriviaQA; SAT_dataset:MetaQA; SAT_dataset:WikiMovies; SAT_nbModel:1","","","","","","","","","","","","","","","","","","","","arXiv:2305.13168","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UAC8CK3B","conferencePaper","2022","Schneider, Phillip; Schopf, Tim; Vladika, Juraj; Galkin, Mikhail; Simperl, Elena; Matthes, Florian","A Decade of Knowledge Graphs in Natural Language Processing: A Survey","Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","","not found","https://aclanthology.org/2022.aacl-main.46","In pace with developments in the research field of artificial intelligence, knowledge graphs (KGs) have attracted a surge of interest from both academia and industry. As a representation of semantic relations between entities, KGs have proven to be particularly relevant for natural language processing (NLP), experiencing a rapid spread and wide adoption within recent years. Given the increasing amount of research work in this area, several KG-related approaches have been surveyed in the NLP research community. However, a comprehensive study that categorizes established topics and reviews the maturity of individual research streams remains absent to this day. Contributing to closing this gap, we systematically analyzed 507 papers from the literature on KGs in NLP. Our survey encompasses a multifaceted review of tasks, research types, and contributions. As a result, we present a structured overview of the research landscape, provide a taxonomy of tasks, summarize our findings, and highlight directions for future work.","2022-11","2023-10-08 16:37:41","2025-02-04 17:18:54","2023-10-08 16:37:41","601–614","","","","","","A Decade of Knowledge Graphs in Natural Language Processing","","","","","Association for Computational Linguistics","Online only","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/F8WSTYTD/Schneider et al. - 2022 - A Decade of Knowledge Graphs in Natural Language P.pdf","","SAT_focus:KnowledgeAcquisition; SAT_model:BERT; SAT_task:NLU; SAT_task:QA; SAT_task:TextGeneration; SAT_task:EntityLinking; SAT_task:NER; SAT_task:Retrieval; SAT_model:GPT; SAT_task:Ontologies; SAT_model:Ernie; SAT_type:Survey; SAT_task:Embed; SAT_task:GraphCompletion; SAT_type:MetaSurvey; FOCUS_STUDY_OCT; CHECKED1023; SAT_interest:10; SAT_focus_period:2013-2021; SAT_RQ:TrendsInKGandNLP?; SAT_RQ:tasks; SAT_typology_dim:researchType; SAT_model:COMET; SAT_model:KBERT; SAT_model:KEPLER; SAT_typology_dim:ContributionType; SAT_typology_dim:Domain; SAT_focus:Reasoning; SAT_task:KnowledgeIntegration; SAT_focus:Application","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AACL-IJCNLP 2022","","","","","","","","","","","","","","",""
"858SJ45J","journalArticle","2023",", David Fraile Navarro; , Kiran Ijaz; , Dana Rezazadegan; , Hania Rahimi-Ardabili; , Mark Dras; , Enrico W. Coiera; , Shlomo Berkovsky","Clinical named entity recognition and relation extraction using natural language processing of medical free text: A systematic review.","","","","10.1016/J.IJMEDINF.2023.105122","https://dblp.org/rec/journals/ijmi/NavarroIRRDCB23","nan","2023","2025-02-05 17:33:56","2025-02-05 17:33:56","","105122","","nan","nan","","Int. J. Medical Informatics","","","","","","","","","open","","DBLP","595420","","","","","","","EXCLUDED; ARCHI:?; BENCHMARKTYPE:?; DATASET:?; DOMAIN:?; GRANULARITY:?; LANG:?; NBDATASET:?; NBMODEL:?; PTM:?; TASK:?; SURVEY_METHODO_BIN:?; MANUALANNOTATION:?","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7DKV68UY","journalArticle","2023",", Tuo M.","Review of entity relation extraction","IOS Press","","","10.3233/JIFS-223915","https://api.elsevier.com/content/abstract/scopus_id/85164100525","nan","2023-05-04","2025-02-05 17:33:56","2025-02-05 17:33:56","","7391-7405","","5.0","44","","Journal of Intelligent and Fuzzy Systems","","","","","","","","","False","","OpenAlex;DBLP;Elsevier*;Elsevier**","23917","","","","","","","EXCLUDED; ARCHI:?; BENCHMARKTYPE:?; DATASET:?; DOMAIN:?; GRANULARITY:?; LANG:?; NBDATASET:?; NBMODEL:?; PTM:?; TASK:?; SURVEY_METHODO_BIN:?; MANUALANNOTATION:?","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RTWRHU4L","journalArticle","2023",", Chen Y.","A Survey on Multimodal Knowledge Graphs: Construction, Completion and Applications","","","","10.3390/math11081815","https://api.elsevier.com/content/abstract/scopus_id/85153946999","nan","2023-04-01","2025-02-05 17:33:56","2025-02-05 17:33:56","","nan","","8.0","11","","Mathematics","","","","","","","","","1","","Elsevier*;Elsevier*","21100830702","","","","","/root/snap/zotero-snap/common/Zotero/storage/XT2IXWX7/2023 - A Survey on Multimodal Knowledge Graphs Construction, Completion and Applications.pdf","","EXCLUDED; BENCHMARKTYPE:?; DATASET:?; DOMAIN:?; GRANULARITY:?; NBDATASET:?; NBMODEL:?; ARCHI:Cnn; TASK:Ner; ARCHI:Lstm; ARCHI:Rnn; PTM:Bert; TASK:Entitylinking; SURVEY_METHODO_BIN:?; ARCHI:Crf; ARCHI:Rulesystem; ARCHI:; MANUALANNOTATION:?; ARCHI:Cgc; ARCHI:Markovchain; LANG:Chines; TASK:Relationclassification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NRYER6V3","journalArticle","2023",", Jiahui Wang; , Kun Yue; , Liang Duan","Models and Techniques for Domain Relation Extraction: A Survey","BonView","","","https://doi.org/10.47852/bonviewjdsis3202973","https://doi.org/10.47852/bonviewjdsis3202973","nan","2023-05-31","2025-02-05 17:33:56","2025-02-05 17:33:56","","65-82","","2.0","1","","Journal of Data Science and Intelligent Systems","","","","","","","","","TRUE","","OpenAlex","https://openalex.org/W4378876733","","","","","/root/snap/zotero-snap/common/Zotero/storage/MQHHRGPL/et al. - 2023 - Models and Techniques for Domain Relation Extraction A Survey.pdf","","DONE; SURVEY_METHODO_BIN:0; ARCHI:Cnn; BENCHMARKTYPE:Quali; DATASET:Tacred; GRANULARITY:Document; GRANULARITY:Sentences; TASK:Ner; ARCHI:Gcn; ARCHI:Rnn; PTM:Bert; PTM:Gpt; DOMAIN:Biomedical; ARCHI:Rulesystem; LANG:Chinese; LANG:English; DATASET:Ace2005; DOMAIN:General; DOMAIN:Legal; DATASET:Fewrel; DATASET:Webnlg; DATASET:Docred; DATASET:Cdr; DOMAIN:Litterature; DOMAIN:Bio; DOMAIN:Military; DATASET:Ace2004; NBDATASET:10^1; DATASET:Semeval2010; ARCHI:Transformer; ARCHI:Embedding; DATASET:Biographical; DATASET:Biored; DATASET:Biorel; DATASET:Chineseclinical; DATASET:Chineselit; DATASET:Cmeie; DATASET:Codered; DATASET:Drugcombi; DATASET:Duie; DATASET:Finred; DATASET:Hacred; DATASET:Mnre; DATASET:Tbga; DOMAIN:Agriculture; DOMAIN:Social; MANUALANNOTATION:Nso; NBMODEL:Nsp; TASK:Relationextraction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""