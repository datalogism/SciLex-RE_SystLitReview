"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"XLKZYLTP","conferencePaper","2018","Elsahar, Hady; Vougiouklis, Pavlos; Remaci, Arslen; Gravier, Christophe; Hare, Jonathon; Simperl, Elena; Laforest, Frederique","T-REx: A Large Scale Alignment of Natural Language with Knowledge Base Triples","LREC2018","","","not found","https://aclanthology.org/L18-1544","Alignments between natural language and Knowledge Base (KB) triples are an essential prerequisite for training machine learning approaches employed in a variety of Natural Language Processing problems. These include Relation Extraction, KB Population, Question Answering and Natural Language Generation from KB triples. Available datasets that provide those alignments are plagued by signiﬁcant shortcomings – they are of limited size, they exhibit a restricted predicate coverage, and/or they are of unreported quality. To alleviate these shortcomings, we present T-REx, a dataset of large scale alignments between Wikipedia abstracts and Wikidata triples. T-REx consists of 11 million triples aligned with 3.09 million Wikipedia abstracts (6.2 million sentences). T-REx is two orders of magnitude larger than the largest available alignments dataset and covers 2.5 times more predicates. Additionally, we stress the quality of this language resource thanks to an extensive crowdsourcing evaluation. T-REx is publicly available at https://w3id.org/t-rex.","2018","2024-07-23 13:45:12","2025-01-15 09:23:07","","","","","","","","T-REx","","","","","European Language Resources Association (ELRA)","","en","True","","https://paperswithcode.com/paper/t-rex-a-large-scale-alignment-of-natural","https://github.com/hadyelsahar/RE-NLG-Dataset","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/ZEVI2PVR/Elsahar et al. - 2018 - T-REx A Large Scale Alignment of Natural Language.pdf","","DONE; GRANULARITY:Document; TASK:Entitylinking; LANG:English; TASK:Coref; DATATYPEPROP:Date; NBTYPEREL:10²; DOMAIN:Encyclo; SOURCE:Wikidata; SOURCE:Wikipedia; SOURCE:Dbpedia; NBTRIPLES:10⁶; NBENTITY:10⁶; NBSENT:10⁶; NBDOC:10⁶; SYNTHGENERATION_BIN:0; NBTYPEENTITY:NSP; TASK:NER; DATATYPEPROP:Values; TASK:RelationIdentification; DatasetSplit:Random","⚠️ Invalid DOI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LEP38FCD","conferencePaper","2023","Cabot, Pere-Lluís Huguet; Tedeschi, Simone; Ngomo, Axel-Cyrille Ngonga; Navigli, Roberto","RED$^{\rm FM}$: a Filtered and Multilingual Relation Extraction Dataset","","","","10.18653/v1/2023.acl-long.237","https://aclanthology.org/2023.acl-long.237/","Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English.","2023-06-19","2025-03-04 10:44:21","2025-03-04 10:46:10","2023-07-21 16:01:56","","","","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","REDfm","","","","","ACL","","en","True","","https://paperswithcode.com/paper/red-rm-fm-a-filtered-and-multilingual","https://github.com/babelscape/rebel","arXiv.org","[{""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""64.3"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""80.1"", ""metric"": ""RE Macro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""59.6"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""88.6"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""59.6"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""64.3"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""No"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""ALBERT"", ""metric"": ""Sentence Encoder""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""89.7"", ""metric"": ""NER Macro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""67.6"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""No"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""63.3"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""80.1"", ""metric"": ""RE+ Macro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""63.3"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""89.5"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""67.6"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Zero-shot Relation Triplet Extraction"", ""dataset"": ""Wiki-ZSL"", ""res"": ""6.4"", ""metric"": ""Avg. F1""}, {""task"": ""Zero-shot Relation Triplet Extraction"", ""dataset"": ""FewRel"", ""res"": ""6.37"", ""metric"": ""Avg. F1""}]","","","","","DONE; NBDATASET:?; GRANULARITY:Sentences; LANG:Multi; DOMAIN:General; PTM:Bart; COSTEVAL_BIN:?; DATATYPEPROP:?; INPUT:?; LOSSUPDATE_BIN:?; NBTYPEREL:?; OBJECTPROPERTIES_BIN:?; SYNTHGENERATION_BIN:?; USENEGATIVEEXAMPLE_BIN:?; DATASET:Rebel; LEARNINGMETHOD:Finetuning; LINEARIZEDGRAPH_BIN:1; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; DOMAIN:Encyclo; SOURCE:Wikidata; SOURCE:Wikipedia; PTM:Mbart; DECODINGMETHOD_BIN:NSP; TASK:RelationClassif; TASK:RelationIdentification; DatasetSplit:?","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TEWFQWSU","conferencePaper","2021",", Yuan YAO; , Jiaju Du; , Yankai Lin; , Peng Li; , Zhiyuan Liu; , Jie zhou; , Maosong Sun","CodRED: A Cross-Document Relation Extraction Dataset for Acquiring Knowledge in the Wild","","","","10.18653/v1/2021.emnlp-main.366","https://aclanthology.org/2021.emnlp-main.366","Existing relation extraction (RE) methods typically focus on extracting relational facts between entity pairs within single sentences or documents. However, a large quantity of relational facts in knowledge bases can only be inferred across documents in practice. In this work, we present the problem of cross-document RE, making an initial step towards knowledge acquisition in the wild. To facilitate the research, we construct the first human-annotated cross-document RE dataset CodRED. Compared to existing RE datasets, CodRED presents two key challenges: Given two entities, (1) it requires finding the relevant documents that can provide clues for identifying their relations; (2) it requires reasoning over multiple documents to extract the relational facts. We conduct comprehensive experiments to show that CodRED is challenging to existing RE methods including strong BERT-based models.","2021-11-01","2025-03-04 10:46:15","2025-03-04 10:46:56","","NA","","","NA","","","CodRED","","","","","ACL","","","True","","https://paperswithcode.com/paper/codred-a-cross-document-relation-extraction","https://github.com/thunlp/CodRED","","","","","","","DONE; LANG:?; GRANULARITY:Document; GRANULARITY:Sentences; DATATYPEPROP:?; NBTYPEREL:?; OBJECTPROPERTIES_BIN:?; SYNTHGENERATION_BIN:?; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; DOMAIN:Encyclo; SOURCE:Wikidata; SOURCE:Wikipedia; DOMAIN:general; Task:reasoning; TASK:RelationIdentification; DatasetSplit:?","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2021 11","","","","","","","","","","","","","","",""
"H9H8D2PT","conferencePaper","2019","Gao, Tianyu; Han, Xu; Zhu, Hao; Liu, Zhiyuan; Li, Peng; Sun, Maosong; Zhou, Jie","FewRel 2.0: Towards More Challenging Few-Shot Relation Classification","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","10.18653/v1/d19-1649","https://aclanthology.org/D19-1649","We present FewRel 2.0, a more challenging task to investigate two aspects of few-shot relation classification models: (1) Can they adapt to a new domain with only a handful of instances? (2) Can they detect none-of-the-above (NOTA) relations? To construct FewRel 2.0, we build upon the FewRel dataset by adding a new test set in a quite different domain, and a NOTA relation choice. With the new dataset and extensive experimental analysis, we found (1) that the state-of-the-art few-shot relation classification models struggle on these two aspects, and (2) that the commonly-used techniques for domain adaptation and NOTA detection still cannot handle the two challenges well. Our research calls for more attention and further efforts to these two real-world issues. All details and resources about the dataset and baselines are released at https://github.com/thunlp/fewrel.","2019-11","2025-03-04 10:47:03","2025-03-04 10:48:01","2023-02-28 16:25:14","6250–6255","","","","","","FewRel2","","","","","Association for Computational Linguistics","Hong Kong, China","","True","","https://paperswithcode.com/paper/fewrel-20-towards-more-challenging-few-shot","https://github.com/thunlp/fewrel","ACLWeb","","{'citing': ['10.1145/3340531.3411858', '10.1145/3340531.3412153', '10.1007/978-3-030-67661-2_37', '10.2196/25670', '10.2196/preprints.25670', '10.1016/j.ipm.2021.102596', '10.1162/tacl_a_00392', '10.1145/3447548.3467438', '10.1007/s12559-021-09917-7', '10.1007/978-3-030-82136-4_9', '10.1007/978-3-030-84186-7_13', '10.1016/j.jii.2021.100301', '10.1007/978-3-030-88480-2_56', '10.1145/3459637.3482268', '10.1145/3459637.3482280', '10.1016/j.ipm.2021.102863', '10.1007/s00521-021-06667-3', '10.1016/j.neucom.2022.04.067', '10.1109/ssci50451.2021.9660108', '10.1007/978-3-030-93119-3_8', '10.1016/j.csl.2022.101432', '10.1007/s13042-022-01604-9', '10.1145/3510030', '10.1007/s10489-022-03596-z', '10.1109/taslp.2022.3153254', '10.1117/12.2631869', '10.1109/s.a.i.ence50533.2020.9303192', '10.1109/icccs52626.2021.9449297', '10.1109/iv51561.2020.00051', '10.1109/cvprw56347.2022.00447', '10.3390/electronics11152423', '10.1145/3511808.3557323', '10.1145/3511808.3557422', '10.1109/taffc.2022.3205358', '10.3390/math10224378'], 'cited': []}","","","","DONE; LANG:?; GRANULARITY:Sentences; DOMAIN:Biomedical; DOMAIN:General; DATATYPEPROP:?; NBTYPEREL:?; OBJECTPROPERTIES_BIN:?; SYNTHGENERATION_BIN:?; USENEGATIVEEXAMPLE_BIN:?; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; TASK:NER; MANUALANNOTATION:?; USE_NER:?; SOURCE:FewRel; TASK:RelationIdentification; DatasetSplit:?","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP-IJCNLP 2019","","","","","","","","","","","","","","",""