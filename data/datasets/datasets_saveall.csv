"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"9NS8CKIQ","conferencePaper","2022",", Alistair Plum; , Tharindu Ranasinghe; , Spencer Jones; , Constantin Orasan; , Ruslan Mitkov","Biographical: A Semi-Supervised Relation Extraction Dataset","SIGIR '22","","","10.1145/3477495.3531742","https://arxiv.org/abs/2205.00806v1","Extracting biographical information from online documents is a popular research topic among the information extraction (IE) community. Various natural language processing (NLP) techniques such as text classification, text summarisation and relation extraction are commonly used to achieve this. Among these techniques, RE is the most common since it can be directly used to build biographical knowledge graphs. RE is usually framed as a supervised machine learning (ML) problem, where ML models are trained on annotated datasets. However, there are few annotated datasets for RE since the annotation process can be costly and time-consuming. To address this, we developed Biographical, the first semi-supervised dataset for RE. The dataset, which is aimed towards digital humanities (DH) and historical research, is automatically compiled by aligning sentences from Wikipedia articles with matching structured data from sources including Pantheon and Wikidata. By exploiting the structure of Wikipedia articles and robust named entity recognition (NER), we match information with relatively high precision in order to compile annotated relation pairs for ten different relations that are important in the DH domain. Furthermore, we demonstrate the effectiveness of the dataset by training a state-of-the-art neural model to classify relation pairs, and evaluate it on a manually annotated gold standard set. Biographical is primarily aimed at training neural models for RE within the domain of digital humanities and history, but as we discuss at the end of this paper, it can be useful for other purposes as well.","2022-05-02","2023-04-05 15:11:32","2023-10-17 16:37:17","","","","","","","","Biographical","","","","","ACM","","","True","","https://paperswithcode.com/paper/biographical-a-semi-supervised-relation","https://plumaj.github.io/biographical/","","","{'citing': [], 'cited': ['10.1093/jamia/ocw041', '10.1145/2629489', '10.1145/3357384.3358119', '10.1609/aaai.v34i05.6374', '10.18653/v1/2020.emnlp-main.470', '10.18653/v1/2020.emnlp-main.518', '10.18653/v1/2020.emnlp-main.523', '10.18653/v1/d15-1205', '10.18653/v1/p16-1105', '10.18653/v1/p16-2034', '10.3115/1614108.1614133']}","","","","SAT_granularity:Cross-sentence; SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_task:CorefReso; SAT_task:NER; SAT_source:Wikidata; SAT_source:Wikipedia; SAT_All_checked:False; SAT_source:Pantheon; SAT_nbtypes_relations:10; SAT_rel_type:explicit; SAT_rel_type:implicit; SAT_rel_type:unclear; SAT_domain:DH; SAT_domain:history; SAT_task:Classification; SAT_task:GraphGeneration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SIGIR","","","","","","","","","","","","","","",""
"G7MHTGAM","conferencePaper","2017",", Greg Durrett; , Jonathan K. Kummerfeld; , Taylor Berg-Kirkpatrick; , Rebecca S. Portnoff; , Sadia Afroz; , Damon McCoy; , Kirill Levchenko; , Vern Paxson","Identifying Products in Online Cybercrime Marketplaces: A Dataset for Fine-grained Domain Adaptation","","","","10.18653/v1/d17-1275","http://arxiv.org/abs/1708.09609v1","One weakness of machine-learned NLP models is that they typically perform poorly on out-of-domain data. In this work, we study the task of identifying products being bought and sold in online cybercrime forums, which exhibits particularly challenging cross-domain effects. We formulate a task that represents a hybrid of slot-filling information extraction and named entity recognition and annotate data from four different forums. Each of these forums constitutes its own ""fine-grained domain"" in that the forums cover different market sectors with different properties, even though all forums are in the broad domain of cybercrime. We characterize these domain differences in the context of a learning-based system: supervised models see decreased accuracy when applied to new forums, and standard techniques for semi-supervised learning and domain adaptation have limited effectiveness on this data, which suggests the need to improve these techniques. We release a dataset of 1,938 annotated posts from across the four forums.","2017-08-31","2023-05-03 15:49:42","2023-06-07 08:10:49","","NA","","","NA","","","","","","","","ACL","","","NA","","https://paperswithcode.com/paper/identifying-products-in-online-cybercrime","NA","","","{'citing': ['10.1145/3409289', '10.1145/3292006.3300036', '10.1186/s40163-018-0094-4', '10.1145/3196494.3196529', '10.1109/sp40001.2021.00075', '10.1145/3488560.3498469', '10.1109/eurospw55150.2022.00016', '10.1145/3359789.3359817', '10.1145/3355369.3355597'], 'cited': ['10.18653/v1/d17-1275']}","","","","PWC:notbenchmarked; Pwc_task:Named Entity Recognition (NER); Pwc_task:Slot Filling; PWC:havecode; Pwc_task:slot-filling; Pwc_task:Named Entity Recognition; Pwc_task:named-entity-recognition; Pwc_task:Domain Adaptation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2017 9","","","","","","","","","","","","","","",""
"QHKCSGCB","conferencePaper","2016",", Andrej {\v{Z}}ukov-Gregori{\v{c}}; , Zhiyuan Luo; , Bartal Veyhe","IBC-C: A Dataset for Armed Conflict Analysis","","","","10.18653/v1/p16-2061","https://aclanthology.org/P16-2061","NA","2016-08-01","2023-05-03 15:51:49","2023-10-17 16:34:46","","NA","","","NA","","","IBC-C","","","","","ACL","","","False","","https://paperswithcode.com/paper/ibc-c-a-dataset-for-armed-conflict-analysis","NA","","","","","","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_task:NER; SAT_task:SlotFilling; SAT_nbDoc:16405; SAT_nbSent:35295; SAT_nbtypes_entity:9; SAT_domain:military","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2016 8","","","","","","","","","","","","","","",""
"S7FNZGHZ","conferencePaper","2018",", M; , Angrosh ya; , Danushka Bollegala; , Frans Coenen; , Katie Atkinson","A Dataset for Inter-Sentence Relation Extraction using Distant Supervision","","","","not found","https://aclanthology.org/L18-1246","NA","2018-05-01","2023-05-03 15:55:51","2023-10-17 16:26:13","","NA","","","NA","","","InterSentenceRE","","","","","ACL","","","False","","https://paperswithcode.com/paper/a-dataset-for-inter-sentence-relation","NA","","","","","","","SAT_granularity:Cross-sentence; SAT_oldTag:CHECKED0923; SAT_rel_type:Cross-sentence; SAT_task:RE; SAT_granularity:sentence; SAT_task:CorefReso; SAT_task:NER; SAT_task:Retrieval; SAT_granularity:paragraph; SAT_method_selection:Human; SAT_source:FreeBase; SAT_All_checked:False; SAT_method_selection:Distant; SAT_nbSent:87514; SAT_NbEntity:14861; SAT_nbDoc:31970; SAT_nbtypes_relations:19","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LREC 2018 5","","","","","","","","","","","","","","",""
"K2WPX4WJ","conferencePaper","2019",", Aakanksha Naik; , Luke Breitfeller; , Carolyn Rose","TDDiscourse: A Dataset for Discourse-Level Temporal Ordering of Events","","","","10.18653/v1/w19-5929","https://aclanthology.org/W19-5929","Prior work on temporal relation classification has focused extensively on event pairs in the same or adjacent sentences (local), paying scant attention to discourse-level (global) pairs. This restricts the ability of systems to learn temporal links between global pairs, since reliance on local syntactic features suffices to achieve reasonable performance on existing datasets. However, systems should be capable of incorporating cues from document-level structure to assign temporal relations. In this work, we take a first step towards discourse-level temporal ordering by creating TDDiscourse, the first dataset focusing specifically on temporal links between event pairs which are more than one sentence apart. We create TDDiscourse by augmenting TimeBank-Dense, a corpus of English news articles, manually annotating global pairs that cannot be inferred automatically from existing annotations. Our annotations double the number of temporal links in TimeBank-Dense, while possessing several desirable properties such as focusing on long-distance pairs and not being automatically inferable. We adapt and benchmark the performance of three state-of-the-art models on TDDiscourse and observe that existing systems indeed find discourse-level temporal ordering harder.","2019-09-01","2023-05-03 16:05:08","2023-10-17 16:50:40","","NA","","","NA","","","TDDiscourse","","","","","ACL","","","True","","https://paperswithcode.com/paper/tddiscourse-a-dataset-for-discourse-level","https://github.com/aakanksha19/TDDiscourse","","","{'citing': ['10.1007/978-3-031-17120-8_15', '10.1109/ijcnn55064.2022.9892554'], 'cited': []}","","","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_task:RC; SAT_rel_type:temporal; SAT_task:ArgumentExtraction; SAT_rel_type:argument; SAT_method_selection:Human; SAT_nbtypes_relations:5; SAT_All_checked:False; SAT_method_selection:Inference; SAT_nbEvalEx:650; SAT_nbEvalEx:1435; SAT_nbTrainEx:32609; SAT_nbTestEx:1500; SAT_nbTestEx:4258; SAT_nbTrainEx:4000; SAT_method_selection:MultiHuman; SAT_method_selection:Heuristic; SAT_extend:TimeBank; SAT_extend: TimeBank-Dense; SAT_extend:EventTime; SAT_nbDoc:36; SAT_task:Classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WS 2019 9","","","","","","","","","","","","","","",""
"66BJAKED","conferencePaper","2020",", Ruben Kruiper; , Julian F. V. Vincent; , Jessica Chen-Burger; , Marc P. Y. Desmulliez; , Ioannis Konstas","A Scientific Information Extraction Dataset for Nature Inspired Engineering","","","","not found","https://arxiv.org/abs/2005.07753v2","Nature has inspired various ground-breaking technological developments in applications ranging from robotics to aerospace engineering and the manufacturing of medical devices. However, accessing the information captured in scientific biology texts is a time-consuming and hard task that requires domain-specific knowledge. Improving access for outsiders can help interdisciplinary research like Nature Inspired Engineering. This paper describes a dataset of 1,500 manually-annotated sentences that express domain-independent relations between central concepts in a scientific biology text, such as trade-offs and correlations. The arguments of these relations can be Multi Word Expressions and have been annotated with modifying phrases to form non-projective graphs. The dataset allows for training and evaluating Relation Extraction algorithms that aim for coarse-grained typing of scientific biological documents, enabling a high-level filter for engineers.","2020-05-15","2023-05-03 16:06:56","2023-10-17 16:20:15","","NA","","","NA","","","FOBIE","","","","","ACL","","","True","","https://paperswithcode.com/paper/a-scientific-information-extraction-dataset","https://github.com/rubenkruiper/FOBIE","","","","","/root/snap/zotero-snap/common/Zotero/storage/PHRHAH3P/ et al. - 2020 - A Scientific Information Extraction Dataset for Na.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:sentence; SAT_method_selection:Human; SAT_domain:science; SAT_nbSent:1500; SAT_nbtypes_relations:3; SAT_nbTriples:4780; SAT_task:Spanning; havecode","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LREC 2020 5","","","","","","","","","","","","","","",""
"C9P9W24D","conferencePaper","2020",", Omar Adjali; , Romaric Besan{\c{c}}on; , Olivier Ferret; , Herv{\'e} Le Borgne; , Brigitte Grau","Building a Multimodal Entity Linking Dataset From Tweets","","","","not found","https://aclanthology.org/2020.lrec-1.528","The task of Entity linking, which aims at associating an entity mention with a unique entity in a knowledge base (KB), is useful for advanced Information Extraction tasks such as relation extraction or event detection. Most of the studies that address this problem rely only on textual documents while an increasing number of sources are multimedia, in particular in the context of social media where messages are often illustrated with images. In this article, we address the Multimodal Entity Linking (MEL) task, and more particularly the problem of its evaluation. To this end, we propose a novel method to quasi-automatically build annotated datasets to evaluate methods on the MEL task. The method collects text and images to jointly build a corpus of tweets with ambiguous mentions along with a Twitter KB defining the entities. We release a new annotated dataset of Twitter posts associated with images. We study the key characteristics of the proposed dataset and evaluate the performance of several MEL approaches on it.","2020-05-01","2023-05-03 16:07:10","2023-10-17 16:22:10","","NA","","","NA","","","MEL_Tweets","","","","","ACL","","","True","","https://paperswithcode.com/paper/building-a-multimodal-entity-linking-dataset","https://github.com/OA256864/MEL_Tweets","","","","","/root/snap/zotero-snap/common/Zotero/storage/69UPCMWY/ et al. - 2020 - Building a Multimodal Entity Linking Dataset From .pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_task:EntityLinking; SAT_task:Event; SAT_context:Text; SAT_context:Image; SAT_context:MultiModal; SAT_source:Twitter; SAT_nbDoc:85k; SAT_NbEntity:5571","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LREC 2020 5","","","","","","","","","","","","","","",""
"FARQ6VC5","conferencePaper","2020",", Abdullatif K{\""o}ksal; , Arzucan {\""O}zg{\""u}r","The RELX Dataset and Matching the Multilingual Blanks for Cross-Lingual Relation Classification","","","","10.18653/v1/2020.findings-emnlp.32","https://aclanthology.org/2020.findings-emnlp.32","Relation classification is one of the key topics in information extraction, which can be used to construct knowledge bases or to provide useful information for question answering. Current approaches for relation classification are mainly focused on the English language and require lots of training data with human annotations. Creating and annotating a large amount of training data for low-resource languages is impractical and expensive. To overcome this issue, we propose two cross-lingual relation classification models: a baseline model based on Multilingual BERT and a new multilingual pretraining setup, which significantly improves the baseline with distant supervision. For evaluation, we introduce a new public benchmark dataset for cross-lingual relation classification in English, French, German, Spanish, and Turkish, called RELX. We also provide the RELX-Distant dataset, which includes hundreds of thousands of sentences with relations from Wikipedia and Wikidata collected by distant supervision for these languages. Our code and data are available at: https://github.com/boun-tabi/RELX","2020-11-01","2023-05-03 16:11:01","2023-10-17 16:36:23","","NA","","","NA","","","RELX","","","","","ACL","","","True","","https://paperswithcode.com/paper/the-relx-dataset-and-matching-the-1","https://github.com/boun-tabi/RELX","","","","","","","SAT_model:BERT; SAT_oldTag:CHECKED0923; SAT_task:QA; SAT_granularity:sentence; SAT_task:RC; SAT_lang:multi; SAT_task:NER; SAT_source:Wikidata; SAT_source:Wikipedia; SAT_lang:english; SAT_lang:french; SAT_lang:german; SAT_lang:spanish; SAT_method_selection:Distant; SAT_lang:turkish; SAT_extend: KBP-37; SAT_nbtypes_relations:37; SAT_nbtypes_relations:24; SAT_nbSent:2575582; havecode; SAT_task:Classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings of the Association for Computational Linguistics 2020","","","","","","","","","","","","","","",""
"JVN3E77S","conferencePaper","2021",", Natalia Loukachevitch; , Ekaterina Artemova; , Tatiana Batura; , Pavel Braslavski; , Ilia Denisov; , Vladimir Ivanov; , Suresh Manandhar; , Alexander Pugachev; , Elena Tutubalina","NEREL: A Russian Dataset with Nested Named Entities, Relations and Events","","","","10.26615/978-954-452-072-4_100","https://arxiv.org/abs/2108.13112v2","In this paper, we present NEREL, a Russian dataset for named entity recognition and relation extraction. NEREL is significantly larger than existing Russian datasets: to date it contains 56K annotated named entities and 39K annotated relations. Its important difference from previous datasets is annotation of nested named entities, as well as relations within nested entities and at the discourse level. NEREL can facilitate development of novel models that can extract relations between nested named entities, as well as relations on both sentence and document levels. NEREL also contains the annotation of events involving named entities and their roles in the events. The NEREL collection is available via https://github.com/nerel-ds/NEREL.","2021-08-30","2023-05-03 16:11:37","2023-10-17 16:23:41","","NA","","","NA","","","NEREL","","","","","Incoma Ltd","","","True","","https://paperswithcode.com/paper/nerel-a-russian-dataset-with-nested-named","https://github.com/nerel-ds/NEREL","","","","","/root/snap/zotero-snap/common/Zotero/storage/SEE9MRQN/ et al. - 2021 - NEREL A Russian Dataset with Nested Named Entitie.pdf","","SAT_granularity:Cross-sentence; SAT_oldTag:CHECKED0923; SAT_rel_type:Cross-sentence; SAT_task:RE; SAT_task:NER; SAT_rel_type:event; SAT_rel_type:nested; SAT_lang:russian; SAT_source:Wikinews; SAT_nbtypes_entity:29; SAT_nbtypes_relations:49; SAT_NbEntity:56000; SAT_nbTriples:39000; havecode","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","RANLP 2021 9","","","","","","","","","","","","","","",""
"7UJNX6EE","conferencePaper","2021",", Yuan YAO; , Jiaju Du; , Yankai Lin; , Peng Li; , Zhiyuan Liu; , Jie zhou; , Maosong Sun","CodRED: A Cross-Document Relation Extraction Dataset for Acquiring Knowledge in the Wild","","","","10.18653/v1/2021.emnlp-main.366","https://aclanthology.org/2021.emnlp-main.366","Existing relation extraction (RE) methods typically focus on extracting relational facts between entity pairs within single sentences or documents. However, a large quantity of relational facts in knowledge bases can only be inferred across documents in practice. In this work, we present the problem of cross-document RE, making an initial step towards knowledge acquisition in the wild. To facilitate the research, we construct the first human-annotated cross-document RE dataset CodRED. Compared to existing RE datasets, CodRED presents two key challenges: Given two entities, (1) it requires finding the relevant documents that can provide clues for identifying their relations; (2) it requires reasoning over multiple documents to extract the relational facts. We conduct comprehensive experiments to show that CodRED is challenging to existing RE methods including strong BERT-based models.","2021-11-01","2023-05-03 16:14:14","2023-10-17 15:47:19","","NA","","","NA","","","CodRED","","","","","ACL","","","True","","https://paperswithcode.com/paper/codred-a-cross-document-relation-extraction","https://github.com/thunlp/CodRED","","","","","","","SAT_granularity:Cross-sentence; SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_task:NER; SAT_task:Retrieval; SAT_focus:Evidence; SAT_source:Wikidata; SAT_method_selection:Human; SAT_source:Wikipedia; SAT_method_selection:Distant; SAT_negativeExamples:True; SAT_granularity:cross-document; SAT_focus:hardNAinstance; SAT_focus:ReasoningPath; SAT_nbtypes_relations:276; SAT_nbTriples:4755; havecode","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2021 11","","","","","","","","","","","","","","",""
"M59VT7SX","conferencePaper","2020",", Chris van der Lee; , Chris Emmery; , Sander Wubben; , Emiel Krahmer","The CACAPO Dataset: A Multilingual, Multi-Domain Dataset for Neural Pipeline and End-to-End Data-to-Text Generation","","","","not found","https://aclanthology.org/2020.inlg-1.10","This paper describes the CACAPO dataset, built for training both neural pipeline and end-to-end data-to-text language generation systems. The dataset is multilingual (Dutch and English), and contains almost 10,000 sentences from human-written news texts in the sports, weather, stocks, and incidents domain, together with aligned attribute-value paired data. The dataset is unique in that the linguistic variation and indirect ways of expressing data in these texts reflect the challenges of real world NLG tasks.","2020-12-01","2023-05-03 16:14:43","2023-10-17 16:31:47","","NA","","","NA","","","CACAPO","","","","","ACL","","","TRUE","","https://paperswithcode.com/paper/the-cacapo-dataset-a-multilingual-multi","https://github.com/TallChris91/CACAPO-Dataset","","","","","","","SAT_oldTag:CHECKED0923; SAT_granularity:sentence; SAT_lang:multi; SAT_task:TextGeneration; SAT_domain:multi; SAT_method_selection:Human; SAT_domain:finance; SAT_lang:english; SAT_All_checked:True; SAT_lang:dutch; SAT_domain:sport; SAT_domain:weather; SAT_method_selection:MultiHuman; SAT_focus:indirectRephrasing; SAT_nbSent:10000; SAT_task:Data-to-text","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","INLG (ACL) 2020 12","","","","","","","","","","","","","","",""
"8NPMRMBH","conferencePaper","2022",", Siffi Singh; , Alham Fikri Aji; , Gaurav Singh; , Christos Christodoulopoulos","A Relation Extraction Dataset for Knowledge Extraction from Web Tables","","","","not found","https://aclanthology.org/2022.coling-1.203","Relational web-tables are significant sources of structural information that are widely used for relation extraction and population of facts into knowledge graphs. To transform the web-table data into knowledge, we need to identify the relations that exist between column pairs. Currently, there are only a handful of publicly available datasets with relations annotated against natural web-tables. Most datasets are constructed using synthetic tables that lack valuable metadata information, or are limited in size to be considered as a challenging evaluation set. In this paper, we present REDTab, the largest natural-table relation extraction dataset. We have annotated ~9K tables and ~22K column pairs using crowd sourced annotators from MTurk, which has 50x larger number of column pairs than the existing human-annotated benchmark. Our test set is specially designed to be challenging as observed in our experiment results using TaBERT. We publicly release REDTab as a benchmark for the evaluation process in relation extraction.","2022-10-01","2023-05-03 16:19:30","2023-10-17 16:16:48","","NA","","","NA","","","REDTab","","","","","ACL","","","True","","https://paperswithcode.com/paper/a-relation-extraction-dataset-for-knowledge","https://github.com/alexa/alexa-dataset-redtab","","","","","","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_method_selection:Human; SAT_context:Table; SAT_nbtypes_relations:23; SAT_nbTables:9149; SAT_source:WebDataCommon; havecode; SAT_task:GraphGeneration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","COLING 2022 10","","","","","","","","","","","","","","",""
"VXW9K8TD","conferencePaper","2022",", Aryeh Tiktinsky; , Vijay Viswanathan; , Danna Niezni; , Dana Meron Azagury; , Yosi Shamay; , Hillel Taub-Tabib; , Tom Hope; , Yoav Goldberg","A Dataset for N-ary Relation Extraction of Drug Combinations","","","","10.18653/v1/2022.naacl-main.233","https://arxiv.org/abs/2205.02289v1","Combination therapies have become the standard of care for diseases such as cancer, tuberculosis, malaria and HIV. However, the combinatorial set of available multi-drug treatments creates a challenge in identifying effective combination therapies available in a situation. To assist medical professionals in identifying beneficial drug-combinations, we construct an expert-annotated dataset for extracting information about the efficacy of drug combinations from the scientific literature. Beyond its practical utility, the dataset also presents a unique NLP challenge, as the first relation extraction dataset consisting of variable-length relations. Furthermore, the relations in this dataset predominantly require language understanding beyond the sentence level, adding to the challenge of this task. We provide a promising baseline model and identify clear areas for further improvement. We release our dataset, code, and baseline models publicly to encourage the NLP community to participate in this task.","2022-05-04","2023-05-03 16:17:24","2023-10-17 16:40:05","","NA","","","NA","","","BioNaryRE","","","","","ACL","","","True","","https://paperswithcode.com/paper/a-dataset-for-n-ary-relation-extraction-of-1","https://github.com/allenai/drug-combo-extraction","","","{'citing': ['10.4018/ijswis.307908', '10.1101/2022.05.03.490286'], 'cited': []}","","","","SAT_oldTag:CHECKED0923; SAT_rel_type:Cross-sentence; SAT_task:RE; SAT_domain:biomedical; SAT_granularity:paragraph; SAT_rel_type:nary; SAT_method_selection:Human; SAT_method_selection:MultiHuman; SAT_nbtypes_relations:2; SAT_nbTriples:1248; SAT_nbParagraph:1634; havecode","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL","","","","","","","","","","","","","","",""
"SIDHAUZ7","conferencePaper","2016",", Teresa Martin; , Fiete Botschen; , Ajay Nagesh; , Andrew McCallum","Call for Discussion: Building a New Standard Dataset for Relation Extraction Tasks","Proceedings of the 5th Workshop on Automated Knowledge Base Construction","","","10.18653/v1/w16-1317","https://aclanthology.org/W16-1317","NA","2016-06-01","2023-05-03 15:54:20","2023-10-17 14:56:56","","NA","","","NA","","","","","","","","ACL","","","NA","","https://paperswithcode.com/paper/call-for-discussion-building-a-new-standard","NA","","","{'citing': ['10.1109/tnnls.2019.2955597'], 'cited': []}","","","","SAT_task:RE; SAT_focus:datasets; donthavecode; notbenchmarked","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AKBC","","","","","","","","","","","","","","",""
"F78972LP","conferencePaper","2021","Huguet Cabot, Pere-Lluís; Navigli, Roberto","REBEL: Relation Extraction By End-to-end Language generation","Findings of the Association for Computational Linguistics: EMNLP 2021","","","10.18653/v1/2021.findings-emnlp.204","https://aclanthology.org/2021.findings-emnlp.204","Extracting relation triplets from raw text is a crucial task in Information Extraction, enabling multiple applications such as populating or validating knowledge bases, factchecking, and other downstream tasks. However, it usually involves multiple-step pipelines that propagate errors or are limited to a small number of relation types. To overcome these issues, we propose the use of autoregressive seq2seq models. Such models have previously been shown to perform well not only in language generation, but also in NLU tasks such as Entity Linking, thanks to their framing as seq2seq tasks. In this paper, we show how Relation Extraction can be simplified by expressing triplets as a sequence of text and we present REBEL, a seq2seq model based on BART that performs end-to-end relation extraction for more than 200 different relation types. We show our model’s flexibility by fine-tuning it on an array of Relation Extraction and Relation Classification benchmarks, with it attaining state-of-the-art performance in most of them.","2021","2023-02-27 14:10:56","2023-10-17 16:48:03","2023-02-27 14:10:56","2370-2381","","","","","","REBEL","","","","","Association for Computational Linguistics","Punta Cana, Dominican Republic","en","True","","https://paperswithcode.com/paper/rebel-relation-extraction-by-end-to-end","https://github.com/Babelscape/rebel/","DOI.org (Crossref)","","{'citing': ['10.1093/bib/bbac409', '10.1007/978-3-031-19433-7_37', '10.1145/3511808.3557323', '10.1016/j.jksuci.2022.08.038', '10.1093/bib/bbac409', '10.1007/978-3-031-19433-7_37', '10.1145/3511808.3557323', '10.1016/j.jksuci.2022.08.038'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/22FNBJLK/Huguet Cabot and Navigli - 2021 - REBEL Relation Extraction By End-to-end Language .pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_task:RC; SAT_source:Wikidata; SAT_source:Wikipedia; SAT_method_selection:Distant; SAT_nbtypes_entity:220; SAT_nbtypes_entity:1146; SAT_nbTrainEx:878555; SAT_nbTrainEx:92822837; SAT_nbTestEx:48852; SAT_NbEntity:513270; SAT_NbEntity:48514; SAT_nbEvalEx:48514; SAT_nbEvalEx:513270; SAT_method_selection:NLI; SAT_nbTestEx:515186","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings of the Association for Computational Linguistics: EMNLP 2021","","","","","","","","","","","","","","",""
"8BIEU5K8","conferencePaper","2022","Amaral, Gabriel; Rodrigues, Odinaldo; Simperl, Elena","WDV: A Broad Data Verbalisation Dataset Built from Wikidata","The Semantic Web – ISWC 2022","978-3-031-19433-7","","10.1007/978-3-031-19433-7_32","","Data verbalisation is a task of great importance in the current field of natural language processing, as there is a clear benefit in the transformation of our abundant structured and semi-structured data into human-readable formats. Verbalising Knowledge Graph (KG) data focuses on converting interconnected triple-based claims, formed of subject, predicate, and object, into text. Although KG verbalisation datasets exist for some KGs, there are still limitations in their applicability to many scenarios. This is especially true for Wikidata, where available datasets either loosely couple claim sets with textual information or heavily focus on predicates around biographies, cities, and countries. To address these gaps, we propose WDV, a large KG claim verbalisation dataset built from Wikidata, with a tight coupling between triples and text, covering a wide variety of entities and predicates. We also evaluate the quality of our verbalisations through a reusable workflow for measuring human-centred fluency and adequacy scores. Our data (https://doi.org/10.6084/m9.figshare.17159045.v1) and code (https://github.com/gabrielmaia7/WDV) are openly available in the hopes of furthering research towards KG verbalisation.","2022","2023-03-06 19:37:18","2023-10-17 16:37:42","","556-574","","","","","","WDV","Lecture Notes in Computer Science","","","","Springer","Cham","en","True","","https://paperswithcode.com/paper/wdv-a-broad-data-verbalisation-dataset-built","https://github.com/gabrielmaia7/wdv","Springer Link","","{'citing': [], 'cited': ['10.1007/978-3-319-11964-9_4', '10.1007/978-3-319-18818-8_20', '10.1016/j.csl.2020.101151', '10.1016/j.websem.2018.07.002', '10.1080/13674676.2018.1486394', '10.1080/19312450709336664', '10.1145/1743384.1743478', '10.1145/2872427.2874809', '10.1145/3159652.3159661', '10.1145/3479531', '10.1145/3484828', '10.1162/coli_a_00322', '10.1177/2053168015604648', '10.18653/v1/2020.acl-main.224', '10.18653/v1/2020.coling-main.218', '10.18653/v1/2020.emnlp-main.628', '10.18653/v1/2021.findings-emnlp.90', '10.18653/v1/2021.nlp4convai-1.20', '10.18653/v1/d15-1312', '10.18653/v1/d17-1004', '10.18653/v1/d17-1238', '10.18653/v1/d18-1081', '10.18653/v1/p17-1017', '10.18653/v1/p18-1151', '10.18653/v1/w15-4007', '10.2307/2529310', '10.24963/ijcai.2020/419', '10.24963/ijcai.2020/711', '10.3115/1073083.1073135', '10.3115/1690219.1690287', '10.5281/zenodo.3828935']}","","","","SAT_oldTag:CHECKED0923; SAT_granularity:sentence; SAT_task:DataAugmentation; SAT_source:Wikidata; SAT_focus:verbalization; SAT_method_selection:Human; SAT_nbtypes_relations:439; SAT_nbDoc:7.6K; SAT_nbTriples:7.6K; SAT_nbtypes_entity:20; SAT_method_selection:Tight; SAT_method_selection:MultiHuman; SAT_task:Data-to-text","","Sattler, Ulrike; Hogan, Aidan; Keet, Maria; Presutti, Valentina; Almeida, João Paulo A.; Takeda, Hideaki; Monnin, Pierre; Pirrò, Giuseppe; d’Amato, Claudia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QAM6IPW5","conferencePaper","2019","Mesquita, Filipe; Cannaviccio, Matteo; Schmidek, Jordan; Mirza, Paramita; Barbosa, Denilson","KnowledgeNet: A Benchmark Dataset for Knowledge Base Population","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","10.18653/v1/d19-1069","https://www.aclweb.org/anthology/D19-1069","","2019","2023-02-27 15:22:13","2023-10-17 16:38:12","2023-02-27 15:22:13","749-758","","","","","","KnowledgeNet","","","","","Association for Computational Linguistics","Hong Kong, China","en","True","","https://paperswithcode.com/paper/knowledgenet-a-benchmark-dataset-for","https://github.com/diffbot/knowledge-net","DOI.org (Crossref)","","{'citing': ['10.14778/3384345.3384352', '10.1007/s10115-020-01502-y', '10.1145/3340531.3412164', '10.1007/978-3-030-62419-4_11', '10.1016/j.websem.2021.100638', '10.1007/978-3-030-75015-2_15', '10.1007/978-3-030-86549-8_33', '10.1111/lnc3.12438', '10.1007/s11280-021-00972-6', '10.3233/sw-212865', '10.1007/978-3-031-11609-4_35', '10.3390/s22155765', '10.1007/978-3-031-19433-7_47', '10.3390/info13110510', '10.1109/access.2022.3208666'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/NTCIUE5W/Mesquita et al. - 2019 - KnowledgeNet A Benchmark Dataset for Knowledge Ba.pdf","","SAT_granularity:Cross-sentence; SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_task:RC; SAT_task:CorefReso; SAT_task:EntityLinking; SAT_task:NER; SAT_source:Wikidata; SAT_method_selection:Human; SAT_source:Wikipedia; SAT_All_checked:True; SAT_source:DBpedia; SAT_negativeExamples:True; SAT_nbSent:9000; SAT_nbtypes_relations:15; SAT_nbTriples:13000; SAT_extend:T-REX; SAT_method_selection:MultiHuman; SAT_method_generation:Pipeline; SAT_rel_type:qualified; SAT_task:GraphGeneration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","","","","","","","","","","","","",""
"CEEENS4M","conferencePaper","2020","Jain, Sarthak; van Zuylen, Madeleine; Hajishirzi, Hannaneh; Beltagy, Iz","SciREX: A Challenge Dataset for Document-Level Information Extraction","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/2020.acl-main.670","https://aclanthology.org/2020.acl-main.670","Extracting information from full documents is an important problem in many domains, but most previous work focus on identifying relationships within a sentence or a paragraph. It is challenging to create a large-scale information extraction (IE) dataset at the document level since it requires an understanding of the whole document to annotate entities and their document-level relationships that usually span beyond sentences or even sections. In this paper, we introduce SciREX, a document level IE dataset that encompasses multiple IE tasks, including salient entity identification and document level N-ary relation identification from scientific articles. We annotate our dataset by integrating automatic and human annotations, leveraging existing scientific knowledge resources. We develop a neural model as a strong baseline that extends previous state-of-the-art IE models to document-level IE. Analyzing the model performance shows a significant gap between human performance and current baselines, inviting the community to use our dataset as a challenge to develop document-level IE models. Our data and code are publicly available at https://github.com/allenai/SciREX .","2020-07","2023-02-28 16:23:56","2023-10-17 16:43:46","2023-02-28 16:23:56","7506–7516","","","","","","SciREX","","","","","Association for Computational Linguistics","Online","","True","","https://paperswithcode.com/paper/scirex-a-challenge-dataset-for-document-level","https: //github.com/allenai/SciREX","ACLWeb","","{'citing': ['10.1145/3340531.3412878', '10.1007/978-3-030-82322-1_5', '10.1007/s00799-021-00306-x', '10.1016/j.jbi.2021.103893', '10.3233/jifs-210982', '10.1007/s12559-021-09917-7', '10.1007/978-3-030-91669-5_35', '10.1007/s11192-022-04332-7', '10.3390/su14052802', '10.1109/jcdl52503.2021.00068', '10.1109/isi53945.2021.9624840', '10.1109/ijcnn52387.2021.9533869', '10.1145/3487553.3524637', '10.1145/3487553.3524654', '10.1007/s40747-022-00806-6', '10.1016/j.neucom.2022.11.064'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/A2J2XV3D/Jain et al. - 2020 - SciREX A Challenge Dataset for Document-Level Inf.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_task:CorefReso; SAT_task:NER; SAT_rel_type:nary; SAT_method_selection:Human; SAT_domain:science; SAT_method_selection:NLI; SAT_source:PWC; SAT_nbDoc:438","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2020","","","","","","","","","","","","","","",""
"T9KHGDML","webpage","","","A deep learning based method for extracting semantic information from patent documents | SpringerLink","","","","","https://link.springer.com/article/10.1007/s11192-020-03634-y","","","2023-03-22 11:26:11","2023-03-22 11:26:11","2023-03-22 11:26:11","","","","","","","","","","","","","","","","","","","","","","","/root/snap/zotero-snap/common/Zotero/storage/YK9LNYY6/s11192-020-03634-y.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S8M8EZM6","conferencePaper","2002","Ohta, Tomoko; Tateisi, Yuka; Kim, Jin-Dong","The GENIA corpus: an annotated research abstract corpus in molecular biology domain","Proceedings of the second international conference on Human Language Technology Research","","","","","With the information overload in genome-related field, there is an increasing need for natural language processing technology to extract information from literature and various attempts of information extraction using NLP has been being made. We are developing the necessary resources including domain ontology and annotated corpus from research abstracts in MEDLINE database (GENIA corpus). We are building the ontology and the corpus simultaneously, using each other. In this paper we report on our new corpus, its ontological basis, annotation scheme, and statistics of annotated objects. We also describe the tools used for corpus annotation and management.","2002-03-24","2023-02-28 16:29:47","2023-02-28 16:29:47","2023-02-28","82–86","","","","","","The GENIA corpus","HLT '02","","","","Morgan Kaufmann Publishers Inc.","San Francisco, CA, USA","","","","","","ACM Digital Library","","","","/root/snap/zotero-snap/common/Zotero/storage/BJV4MLE8/Ohta et al. - 2002 - The GENIA corpus an annotated research abstract c.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2LNDD7VC","preprint","2018","Rajpurkar, Pranav; Jia, Robin; Liang, Percy","Know What You Don't Know: Unanswerable Questions for SQuAD","","","","10.48550/arXiv.1806.03822","http://arxiv.org/abs/1806.03822","Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD 1.1 achieves only 66% F1 on SQuAD 2.0.","2018-06-11","2023-02-28 16:26:03","2023-02-28 16:26:03","2023-02-28 16:26:03","","","","","","","Know What You Don't Know","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1806.03822 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/5ZLXPBEY/Rajpurkar et al. - 2018 - Know What You Don't Know Unanswerable Questions f.pdf; /root/snap/zotero-snap/common/Zotero/storage/IEFSQESK/1806.html","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:1806.03822","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ILMJ6YXX","preprint","2019","Jaume, Guillaume; Ekenel, Hazim Kemal; Thiran, Jean-Philippe","FUNSD: A Dataset for Form Understanding in Noisy Scanned Documents","","","","","http://arxiv.org/abs/1905.13538","We present a new dataset for form understanding in noisy scanned documents (FUNSD) that aims at extracting and structuring the textual content of forms. The dataset comprises 199 real, fully annotated, scanned forms. The documents are noisy and vary widely in appearance, making form understanding (FoUn) a challenging task. The proposed dataset can be used for various tasks, including text detection, optical character recognition, spatial layout analysis, and entity labeling/linking. To the best of our knowledge, this is the ﬁrst publicly available dataset with comprehensive annotations to address FoUn task. We also present a set of baselines and introduce metrics to evaluate performance on the FUNSD dataset, which can be downloaded at https://guillaumejaume. github.io/FUNSD/.","2019-10-29","2023-02-28 16:25:34","2023-02-28 16:25:34","2023-02-28 16:25:34","","","","","","","FUNSD","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1905.13538 [cs, stat]","","/root/snap/zotero-snap/common/Zotero/storage/F6JGWIQA/Jaume et al. - 2019 - FUNSD A Dataset for Form Understanding in Noisy S.pdf","","","Computer Science - Machine Learning; Computer Science - Information Retrieval; Statistics - Machine Learning; Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:1905.13538","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CHJBQPFE","conferencePaper","2022","Xu, Yiheng; Lv, Tengchao; Cui, Lei; Wang, Guoxin; Lu, Yijuan; Florencio, Dinei; Zhang, Cha; Wei, Furu","XFUND: A Benchmark Dataset for Multilingual Visually Rich Form Understanding","Findings of the Association for Computational Linguistics: ACL 2022","","","10.18653/v1/2022.findings-acl.253","https://aclanthology.org/2022.findings-acl.253","Multimodal pre-training with text, layout, and image has achieved SOTA performance for visually rich document understanding tasks recently, which demonstrates the great potential for joint learning across different modalities. However, the existed research work has focused only on the English domain while neglecting the importance of multilingual generalization. In this paper, we introduce a human-annotated multilingual form understanding benchmark dataset named XFUND, which includes form understanding samples in 7 languages (Chinese, Japanese, Spanish, French, Italian, German, Portuguese). Meanwhile, we present LayoutXLM, a multimodal pre-trained model for multilingual document understanding, which aims to bridge the language barriers for visually rich document understanding. Experimental results show that the LayoutXLM model has significantly outperformed the existing SOTA cross-lingual pre-trained models on the XFUND dataset. The XFUND dataset and the pre-trained LayoutXLM model have been publicly available at https://aka.ms/layoutxlm.","2022-05","2023-03-22 11:27:11","2023-04-05 12:46:01","2023-03-22 11:27:11","3214–3224","","","","","","XFUND","","","","","Association for Computational Linguistics","Dublin, Ireland","","","","","","ACLWeb","","{'citing': ['10.1007/s10032-022-00406-7'], 'cited': ['10.18653/v1/2022.findings-acl.253']}","","/root/snap/zotero-snap/common/Zotero/storage/LRADBTTW/Xu et al. - 2022 - XFUND A Benchmark Dataset for Multilingual Visual.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings 2022","","","","","","","","","","","","","","",""
"VFCIUHHG","conferencePaper","2017","","TAC KBP 2017 Cold Start Track","","","","not found","https://tac.nist.gov/2017/KBP/ColdStart/index.html","","2017","2023-02-27 14:09:40","2023-10-17 16:07:18","2023-02-27 14:09:40","","","","","","","TAC","","","","","","","","False","","","","","","","","/root/snap/zotero-snap/common/Zotero/storage/NKRWXIVW/index.html","","SAT_oldTag:CHECKED0923; SAT_granularity:sentence; SAT_method_selection:Human; SAT_All_checked:True; SAT_nbTriples:84000; SAT_nbtypes_relations:41","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W28ZESZY","webpage","","","BioRED: a rich biomedical relation extraction dataset | Briefings in Bioinformatics | Oxford Academic","","","","","https://academic.oup.com/bib/article/23/5/bbac282/6645993","","","2023-03-22 11:26:55","2023-03-22 11:26:55","2023-03-22 11:26:55","","","","","","","","","","","","","","","","","","","","","","","/root/snap/zotero-snap/common/Zotero/storage/8ZXIGY33/6645993.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"836DG7JB","preprint","2021","Arviv, Ofir; Nikolaev, Dmitry; Karidi, Taelin; Abend, Omri","On the Relation between Syntactic Divergence and Zero-Shot Performance","","","","10.48550/arXiv.2110.04644","http://arxiv.org/abs/2110.04644","We explore the link between the extent to which syntactic relations are preserved in translation and the ease of correctly constructing a parse tree in a zero-shot setting. While previous work suggests such a relation, it tends to focus on the macro level and not on the level of individual edges-a gap we aim to address. As a test case, we take the transfer of Universal Dependencies (UD) parsing from English to a diverse set of languages and conduct two sets of experiments. In one, we analyze zero-shot performance based on the extent to which English source edges are preserved in translation. In another, we apply three linguistically motivated transformations to UD, creating more cross-lingually stable versions of it, and assess their zero-shot parsability. In order to compare parsing performance across different schemes, we perform extrinsic evaluation on the downstream task of cross-lingual relation extraction (RE) using a subset of a popular English RE benchmark translated to Russian and Korean. In both sets of experiments, our results suggest a strong relation between cross-lingual stability and zero-shot parsing performance.","2021-10-09","2023-03-22 11:26:31","2023-03-22 11:26:31","2023-03-22 11:26:31","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2110.04644 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/CCI45NA4/Arviv et al. - 2021 - On the Relation between Syntactic Divergence and Z.pdf; /root/snap/zotero-snap/common/Zotero/storage/AMD59SVH/2110.html","","","Computer Science - Computation and Language; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2110.04644","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J2Y87PS2","conferencePaper","2013","Mesquita, Filipe; Schmidek, Jordan; Barbosa, Denilson","Effectiveness and Efficiency of Open Relation Extraction","Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing","","","not found","https://aclanthology.org/D13-1043","","2013-10","2023-03-22 11:26:41","2023-04-14 22:28:34","2023-03-22 11:26:41","447–457","","","","","","","","","","","Association for Computational Linguistics","Seattle, Washington, USA","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/8K35LRJF/Mesquita et al. - 2013 - Effectiveness and Efficiency of Open Relation Extr.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2013","","","","","","","","","","","","","","",""
"98867W25","preprint","2021","Park, Sungjoon; Moon, Jihyung; Kim, Sungdong; Cho, Won Ik; Han, Jiyoon; Park, Jangwon; Song, Chisung; Kim, Junseong; Song, Yongsook; Oh, Taehwan; Lee, Joohong; Oh, Juhyun; Lyu, Sungwon; Jeong, Younghoon; Lee, Inkwon; Seo, Sangwoo; Lee, Dongjun; Kim, Hyunwoo; Lee, Myeonghwa; Jang, Seongbo; Do, Seungwon; Kim, Sunkyoung; Lim, Kyungtae; Lee, Jongwon; Park, Kyumin; Shin, Jamin; Kim, Seonghyun; Park, Lucy; Oh, Alice; Ha, Jung-Woo; Cho, Kyunghyun","KLUE: Korean Language Understanding Evaluation","","","","not found","http://arxiv.org/abs/2105.09680","We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE is a collection of 8 Korean natural language understanding (NLU) tasks, including Topic Classiﬁcation, Semantic Textual Similarity, Natural Language Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing, Machine Reading Comprehension, and Dialogue State Tracking. We build all of the tasks from scratch from diverse source corpora while respecting copyrights, to ensure accessibility for anyone without any restrictions. With ethical considerations in mind, we carefully design annotation protocols. Along with the benchmark tasks and data, we provide suitable evaluation metrics and ﬁne-tuning recipes for pretrained language models for each task. We furthermore release the pretrained language models (PLM), KLUE-BERT and KLUE-RoBERTa, to help reproducing baseline models on KLUE and thereby facilitate future research. We make a few interesting observations from the preliminary experiments using the proposed KLUE benchmark suite, already demonstrating the usefulness of this new benchmark suite. First, we ﬁnd KLUE-RoBERTaLARGE outperforms other baselines, including multilingual PLMs and existing open-source Korean PLMs. Second, we see minimal degradation in performance even when we replace personally identiﬁable information from the pretraining corpus, suggesting that privacy and NLU capability are not at odds with each other. Lastly, we ﬁnd that using BPE tokenization in combination with morpheme-level pre-tokenization is effective in tasks involving morpheme-level tagging, detection and generation. In addition to accelerating Korean NLP research, our comprehensive documentation on creating KLUE will facilitate creating similar resources for other languages in the future. KLUE is available at https://klue-benchmark.com/.","2021-11-02","2023-02-28 16:23:39","2023-04-14 22:21:44","2023-02-28 16:23:39","","","","","","","KLUE","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2105.09680 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/AZG8WFSU/Park et al. - 2021 - KLUE Korean Language Understanding Evaluation.pdf","","Pwc_task:Reading Comprehension; Pwc_task:Relation Extraction; Pwc_task:Named Entity Recognition (NER); Pwc_task:Dependency Parsing; Pwc_task:Natural Language Inference; Pwc_task:Natural Language Understanding; Pwc_task:Named Entity Recognition; Pwc_task:named-entity-recognition; Pwc_task:Text Classification; Pwc_task:Semantic Textual Similarity; Pwc_task:Machine Reading Comprehension; Pwc_task:Dialogue State Tracking; Pwc_task:Topic Classification","⚠️ Invalid DOI; Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2105.09680","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XXNVHUGB","preprint","2022","Hennig, Leonhard; Truong, Phuc Tran; Gabryszak, Aleksandra","MobIE: A German Dataset for Named Entity Recognition, Entity Linking and Relation Extraction in the Mobility Domain","","","","not found","http://arxiv.org/abs/2108.06955","We present MobIE, a German-language dataset, which is human-annotated with 20 coarse- and ﬁne-grained entity types and entity linking information for geographically linkable entities. The dataset consists of 3,232 social media texts and trafﬁc reports with 91K tokens, and contains 20.5K annotated entities, 13.1K of which are linked to a knowledge base. A subset of the dataset is humanannotated with seven mobility-related, n-ary relation types, while the remaining documents are annotated using a weakly-supervised labeling approach implemented with the Snorkel framework. To the best of our knowledge, this is the ﬁrst German-language dataset that combines annotations for NER, EL and RE, and thus can be used for joint and multi-task learning of these fundamental information extraction tasks. We make MobIE public at https: //github.com/dfki-nlp/mobie.","2022-03-28","2023-03-22 11:23:59","2023-04-14 22:21:34","2023-03-22 11:23:59","","","","","","","MobIE","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2108.06955 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/BUGBACGD/Hennig et al. - 2022 - MobIE A German Dataset for Named Entity Recogniti.pdf","","Pwc_task:Relation Extraction; Pwc_task:Named Entity Recognition (NER); Pwc_task:Multi-Task Learning; Pwc_task:Entity Linking; Pwc_task:Named Entity Recognition; Pwc_task:named-entity-recognition; Pwc_task:NER","⚠️ Invalid DOI; Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2108.06955","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7XJ3H263","preprint","2020","Schulz, Sarah; Ševa, Jurica; Rodriguez, Samuel; Ostendorff, Malte; Rehm, Georg","Named Entities in Medical Case Reports: Corpus and Experiments","","","","not found","http://arxiv.org/abs/2003.13032","We present a new corpus comprising annotations of medical entities in case reports, originating from PubMed Central’s open access library. In the case reports, we annotate cases, conditions, ﬁndings, factors and negation modiﬁers. Moreover, where applicable, we annotate relations between these entities. As such, this is the ﬁrst corpus of this kind made available to the scientiﬁc community in English. It enables the initial investigation of automatic information extraction from case reports through tasks like Named Entity Recognition, Relation Extraction and (sentence/paragraph) relevance detection. Additionally, we present four strong baseline systems for the detection of medical entities made available through the annotated dataset.","2020-03-29","2023-03-22 11:23:48","2023-04-14 22:21:25","2023-03-22 11:23:48","","","","","","","Named Entities in Medical Case Reports","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2003.13032 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/9M8GV298/Schulz et al. - 2020 - Named Entities in Medical Case Reports Corpus and.pdf","","Pwc_task:Relation Extraction; Pwc_task:Named Entity Recognition (NER); Pwc_task:Named Entity Recognition; Pwc_task:named-entity-recognition","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2003.13032","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZCDC6EFB","preprint","2020","Asgari-Bidhendi, Majid; Nasser, Mehrdad; Janfada, Behrooz; Minaei-Bidgoli, Behrouz","PERLEX: A Bilingual Persian-English Gold Dataset for Relation Extraction","","","","10.1155/2021/8893270","http://arxiv.org/abs/2005.06588","Relation extraction is the task of extracting semantic relations between entities in a sentence. It is an essential part of some natural language processing tasks such as information extraction, knowledge extraction, and knowledge base population. The main motivations of this research stem from a lack of a dataset for relation extraction in the Persian language as well as the necessity of extracting knowledge from the growing big-data in the Persian language for different applications. In this paper, we present “PERLEX” as the ﬁrst Persian dataset for relation extraction, which is an experttranslated version of the “Semeval-2010-Task-8” dataset. Moreover, this paper addresses Persian relation extraction utilizing state-of-the-art language-agnostic algorithms. We employ six different models for relation extraction on the proposed bilingual dataset, including a non-neural model (as the baseline), three neural models, and two deep learning models fed by multilingual-BERT contextual word representations. The experiments result in the maximum f-score 77.66% (provided by BERTEM-MTB method) as the state-of-the-art of relation extraction in the Persian language.","2020-05-13","2023-03-22 11:25:16","2023-04-14 22:21:17","2023-03-22 11:25:16","","","","","","","PERLEX","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2005.06588 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/IRV5TWHG/Asgari-Bidhendi et al. - 2020 - PERLEX A Bilingual Persian-English Gold Dataset f.pdf","","Pwc_task:Relation Extraction; Pwc_task:Knowledge Base Population","⚠️ Invalid DOI; Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2005.06588","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WPQPUPZR","preprint","2021","Jain, Saahil; Agrawal, Ashwin; Saporta, Adriel; Truong, Steven QH; Duong, Du Nguyen; Bui, Tan; Chambon, Pierre; Zhang, Yuhao; Lungren, Matthew P.; Ng, Andrew Y.; Langlotz, Curtis P.; Rajpurkar, Pranav","RadGraph: Extracting Clinical Entities and Relations from Radiology Reports","","","","not found","http://arxiv.org/abs/2106.14463","Extracting structured clinical information from free-text radiology reports can enable the use of radiology report information for a variety of critical healthcare applications. In our work, we present RadGraph, a dataset of entities and relations in full-text chest X-ray radiology reports based on a novel information extraction schema we designed to structure radiology reports. We release a development dataset, which contains board-certiﬁed radiologist annotations for 500 radiology reports from the MIMIC-CXR dataset (14,579 entities and 10,889 relations), and a test dataset, which contains two independent sets of board-certiﬁed radiologist annotations for 100 radiology reports split equally across the MIMIC-CXR and CheXpert datasets. Using these datasets, we train and test a deep learning model, RadGraph Benchmark, that achieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR and CheXpert test sets respectively. Additionally, we release an inference dataset, which contains annotations automatically generated by RadGraph Benchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4 million relations) and 500 CheXpert reports (13,783 entities and 9,908 relations) with mappings to associated chest radiographs. Our freely available dataset can facilitate a wide range of research in medical natural language processing, as well as computer vision and multi-modal learning when linked to chest radiographs.","2021-08-29","2023-02-28 16:23:43","2023-04-14 22:21:03","2023-02-28 16:23:43","","","","","","","RadGraph","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2106.14463 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/YBMMYPNB/Jain et al. - 2021 - RadGraph Extracting Clinical Entities and Relatio.pdf","","Pwc_task:Relation Extraction","⚠️ Invalid DOI; Computer Science - Computation and Language; Computer Science - Artificial Intelligence; Computer Science - Machine Learning; Computer Science - Information Retrieval","","","","","","","","","","","","","","","","","","","arXiv:2106.14463","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KWA4D2T","journalArticle","2020","Agarwal, Oshin; Kale, Mihir; Ge, Heming; Shakeri, Siamak; Al-Rfou, Rami","Machine Translation Aided Bilingual Data-to-Text Generation and Semantic Parsing","","","","not found","","We present a system for bilingual Data-ToText Generation and Semantic Parsing. We use a text-to-text generator to learn a single model that works for both languages on each of the tasks. The model is aided by machine translation during both pre-training and ﬁne-tuning. We evaluate the system on WebNLG 2020 data1, which consists of RDF triples in English and natural language sentences in English and Russian for both the tasks. We achieve considerable gains over monolingual models, especially on unseen relations and Russian.","2020","2023-02-28 16:30:06","2023-04-14 22:19:50","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/5TX74ESK/Agarwal et al. - Machine Translation Aided Bilingual Data-to-Text G.pdf","","","⛔ No DOI found","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PAT2D5W2","journalArticle","2014","Doğan, Rezarta Islamaj; Leaman, Robert; Lu, Zhiyong","NCBI disease corpus: a resource for disease name recognition and concept normalization","Journal of Biomedical Informatics","","1532-0480","10.1016/j.jbi.2013.12.006","","Information encoded in natural language in biomedical literature publications is only useful if efficient and reliable ways of accessing and analyzing that information are available. Natural language processing and text mining tools are therefore essential for extracting valuable information, however, the development of powerful, highly effective tools to automatically detect central biomedical concepts such as diseases is conditional on the availability of annotated corpora. This paper presents the disease name and concept annotations of the NCBI disease corpus, a collection of 793 PubMed abstracts fully annotated at the mention and concept level to serve as a research resource for the biomedical natural language processing community. Each PubMed abstract was manually annotated by two annotators with disease mentions and their corresponding concepts in Medical Subject Headings (MeSH®) or Online Mendelian Inheritance in Man (OMIM®). Manual curation was performed using PubTator, which allowed the use of pre-annotations as a pre-step to manual annotations. Fourteen annotators were randomly paired and differing annotations were discussed for reaching a consensus in two annotation phases. In this setting, a high inter-annotator agreement was observed. Finally, all results were checked against annotations of the rest of the corpus to assure corpus-wide consistency. The public release of the NCBI disease corpus contains 6892 disease mentions, which are mapped to 790 unique disease concepts. Of these, 88% link to a MeSH identifier, while the rest contain an OMIM identifier. We were able to link 91% of the mentions to a single disease concept, while the rest are described as a combination of concepts. In order to help researchers use the corpus to design and test disease identification methods, we have prepared the corpus as training, testing and development sets. To demonstrate its utility, we conducted a benchmarking experiment where we compared three different knowledge-based disease normalization methods with a best performance in F-measure of 63.7%. These results show that the NCBI disease corpus has the potential to significantly improve the state-of-the-art in disease name recognition and normalization research, by providing a high-quality gold standard thus enabling the development of machine-learning based approaches for such tasks. The NCBI disease corpus, guidelines and other associated resources are available at: http://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/.","2014-02","2023-03-22 11:24:19","2023-04-15 14:14:50","","1-10","","","47","","J Biomed Inform","NCBI disease corpus","","","","","","","eng","","","","","PubMed","","{'citing': ['10.1155/2020/8894760', '10.1007/s10115-022-01779-1', '10.1088/1742-6596/1646/1/012072', '10.1093/jamia/ocw177', '10.1016/j.cosrev.2018.06.001', '10.1007/978-3-031-13643-6_22', '10.1109/icassp43922.2022.9746482', '10.1186/s12859-019-2813-6', '10.1093/database/bau053', '10.1186/s12859-018-2045-1', '10.1109/ijcnn52387.2021.9533687', '10.1038/s41540-021-00200-x', '10.1007/s10462-022-10197-2', '10.1007/s11859-016-1200-7', '10.1186/s12859-020-03834-6', '10.3390/app122312012', '10.1093/bioinformatics/btx228', '10.3389/fphar.2019.00839', '10.3390/app12063191', '10.1007/978-3-030-45385-5_56', '10.1109/access.2018.2826224', '10.2196/24020', '10.1038/s41597-021-00875-1', '10.1101/2022.02.02.22270107', '10.1186/s13326-017-0173-6', '10.1016/j.patrec.2017.06.009', '10.1016/b978-0-12-819061-6.00001-x', '10.1155/2022/3212370', '10.1007/s10994-020-05897-1', '10.1186/s12888-022-03713-9', '10.1186/s12859-017-1805-7', '10.1186/s13326-015-0004-6', '10.3389/frai.2021.711467', '10.1038/s41598-021-93018-w', '10.1093/bib/bbv024', '10.1007/978-94-024-0881-2_53', '10.1093/database/bau074', '10.1016/j.jbi.2015.07.010', '10.1016/j.jbi.2021.103880', '10.1093/database/baw066', '10.3390/app12199781', '10.1186/s13321-018-0290-y', '10.3389/frma.2021.674205', '10.1101/038083', '10.3390/app11031090', '10.1186/s12859-017-1857-8', '10.1109/icassp43922.2022.9747858', '10.2196/preprints.12159', '10.1147/jrd.2018.2888975', '10.1101/2020.05.20.107003', '10.1093/bib/bbab282', '10.1101/262790', '10.1007/978-3-030-15719-7_15', '10.1109/icoice48418.2019.9035170', '10.1016/j.jbi.2016.09.009', '10.21203/rs.3.rs-2032932/v1', '10.3390/app122111084', '10.1038/s41597-020-00620-0', '10.1093/database/baw032', '10.1093/database/bau073', '10.1101/2021.05.10.443343', '10.1007/s00521-022-07228-y', '10.1055/s-0040-1702001', '10.1093/nar/gky428', '10.3389/frai.2021.732381', '10.1093/jamiaopen/ooz009', '10.1186/s12889-019-7630-3', '10.1145/3445965', '10.1093/bioinformatics/btw343', '10.1108/el-11-2020-0320', '10.3233/jifs-212495', '10.3389/fcell.2020.00673', '10.1007/978-3-319-71084-6_61', '10.1109/bibm.2017.8217723', '10.1007/978-3-031-18315-7_16', '10.1016/j.jbi.2021.103684', '10.1145/3465221', '10.1007/978-3-319-59888-8_15', '10.1093/database/baw068', '10.1145/3502223.3502228', '10.1075/term.00015.tho', '10.1371/journal.pone.0221582', '10.1186/s12859-017-1776-8', '10.1109/access.2019.2920708', '10.1093/bib/bbaa057', '10.1007/978-3-319-49004-5_5', '10.2196/preprints.35649', '10.1007/s10115-020-01532-6', '10.2196/14830', '10.1007/978-3-319-99344-7_11', '10.1145/3458754', '10.1007/978-3-031-15034-0_5', '10.1186/s13321-018-0317-4', '10.1007/978-3-030-66046-8_16', '10.1007/978-3-030-89657-7_29', '10.1016/j.jbi.2015.03.010', '10.1101/2021.11.29.470486', '10.1093/bioinformatics/btx815', '10.1016/j.jbi.2020.103381', '10.1016/j.jbi.2022.104080', '10.1109/access.2021.3108445', '10.1093/jamia/ocaa269', '10.1248/yakushi.21-00178-4', '10.1186/s12859-021-04200-w', '10.1093/bioinformatics/btab702', '10.1016/j.jbi.2017.05.016', '10.1186/s12859-020-3393-1', '10.1038/s41597-020-0543-2', '10.1093/bioinformatics/btac598', '10.1007/978-3-319-73618-1_13', '10.1093/bioinformatics/bty449', '10.1186/s13326-022-00272-6', '10.1145/3507524.3507525', '10.1016/j.ins.2022.04.037', '10.1109/icpr56361.2022.9956656', '10.1007/978-981-16-6471-7_5', '10.1109/ijcnn55064.2022.9892324', '10.1186/s13326-022-00269-1', '10.1093/bib/bbac282', '10.1021/acs.jcim.9b00164', '10.1016/j.knosys.2022.108825', '10.1016/j.joi.2016.01.003', '10.1016/j.jbi.2021.103799', '10.1093/bioinformatics/btz528', '10.1186/s12859-021-04397-w', '10.1109/bigdata50022.2020.9378052', '10.1097/scs.0000000000004583', '10.1038/s41598-021-83966-8', '10.1007/978-3-319-73830-7_27', '10.1093/nar/gkaa333', '10.1101/2022.10.11.511776', '10.1093/bib/bbv021', '10.1007/978-3-030-72240-1_81', '10.1007/s13748-021-00230-w', '10.1145/3508230.3508252', '10.1093/bioinformatics/btab042', '10.1093/database/baw112', '10.1016/j.jbi.2021.103779', '10.1371/journal.pone.0149621', '10.1007/978-3-319-91947-8_34', '10.1109/bibm.2017.8217678', '10.1093/jamia/ocy020', '10.2196/12159', '10.1145/2649387.2649420', '10.1093/jamia/ocaa106', '10.1109/bibm47256.2019.8983212', '10.1016/j.jbi.2022.104238', '10.3390/app112311251', '10.1109/ubmk52708.2021.9558986', '10.1109/bibm52615.2021.9669749', '10.1101/2020.11.05.368969', '10.1093/jamia/ocab090', '10.1016/j.jmb.2022.167568', '10.2196/preprints.19612', '10.1088/1742-6596/1693/1/012087', '10.1016/b978-0-12-800453-1.00004-x', '10.1093/database/baac047', '10.3390/biology11081221', '10.1007/s13721-019-0216-2', '10.1007/978-3-319-46349-0_17', '10.2196/preprints.24020', '10.1186/s12911-021-01614-7', '10.1038/sdata.2018.258', '10.1186/s13326-019-0218-0', '10.1093/bioinformatics/bty845', '10.1186/s13326-017-0153-x', '10.1093/database/baw036', '10.1093/bioinformatics/btz682', '10.1093/jamia/ocaa109', '10.1093/nar/gkz389', '10.1101/2021.09.15.460567', '10.3233/idt-200048', '10.1038/srep10021', '10.1016/j.jbi.2022.104185', '10.1093/database/bau056', '10.1007/978-3-031-08530-7_29', '10.1109/access.2022.3157854', '10.1142/s0219720020500158', '10.1109/icbk50248.2020.00050', '10.1093/bioinformatics/btac422', '10.1007/978-3-030-33966-1_3', '10.1155/2015/913489', '10.1109/bibm52615.2021.9669475', '10.1007/978-3-031-17189-5_5', '10.1109/tcbb.2021.3079339', '10.1016/j.health.2022.100078', '10.1038/s41597-022-01350-1', '10.1093/jamiaopen/ooab070', '10.1186/s12911-018-0690-y', '10.1007/978-3-030-33966-1_2', '10.3390/ijms232314934', '10.1093/bioinformatics/btx172', '10.1007/s40264-022-01170-7', '10.1109/bibm.2016.7822625', '10.1109/jbhi.2015.2422651', '10.1093/bioinformatics/bty356', '10.1016/j.jbi.2021.103982', '10.1109/bibm.2016.7822672', '10.1016/j.jbi.2021.103961', '10.1007/978-981-15-5679-1_54', '10.1186/s12911-021-01706-4', '10.1109/inista55318.2022.9894270', '10.1109/icgi.2017.31', '10.2196/27434', '10.1186/s12859-022-05035-9', '10.1186/s12859-021-04551-4', '10.1101/2022.09.22.22280246', '10.1089/omi.2015.0151', '10.1016/j.jbi.2017.06.013', '10.1007/978-3-030-79150-6_4', '10.3390/biochem1020007', '10.1186/s12859-015-0487-2', '10.1007/s00607-021-01000-1', '10.1186/s12859-022-05051-9', '10.1186/s12920-017-0316-8', '10.1016/b978-0-12-819314-3.00005-7', '10.1007/978-3-030-60450-9_65', '10.1109/access.2019.2932842', '10.1007/978-3-319-42706-5_15', '10.2196/14502', '10.1093/bioinformatics/btab019', '10.3390/app11209648', '10.1016/j.jbi.2022.104137', '10.1093/database/bau064', '10.1109/ijcnn52387.2021.9533884', '10.1186/s12859-019-3321-4', '10.1109/ijcnn48605.2020.9206808', '10.1093/database/baw096', '10.1109/jcdl52503.2021.00014', '10.1109/bibm47256.2019.8983421', '10.1016/j.ins.2022.06.089', '10.3390/data3040053', '10.1021/acs.chemrev.6b00851', '10.1007/s10579-022-09596-2', '10.1007/s00799-021-00306-x', '10.1186/s12859-015-0844-1', '10.5334/cstp.56', '10.1093/database/baw091', '10.2196/19612', '10.1371/journal.pone.0162287', '10.1016/j.jbi.2015.08.008', '10.1371/journal.pone.0144717', '10.1093/jamiaopen/ooz057', '10.1093/bioinformatics/btv760', '10.1016/j.compbiomed.2019.04.002', '10.1186/s40168-019-0742-2', '10.1371/journal.pone.0179488', '10.1145/3487553.3524701', '10.1109/bibm52615.2021.9669753', '10.1007/978-3-030-68763-2_48', '10.1108/ec-03-2017-0073', '10.1016/j.cmpb.2014.11.005', '10.1186/s40708-022-00174-4'], 'cited': ['10.1016/j.jbi.2013.12.006']}","","/root/snap/zotero-snap/common/Zotero/storage/I7ZMIZDA/Doğan et al. - 2014 - NCBI disease corpus a resource for disease name r.pdf; ","http://www.ncbi.nlm.nih.gov/pubmed/24393765","","Natural Language Processing; Semantics; Named entity recognition; Artificial Intelligence; Computational Biology; Corpus annotation; Data Mining; Disease name corpus; Disease name normalization; Disease name recognition; Genetic Diseases, Inborn; Humans; Information Storage and Retrieval; Knowledge Bases; Medical Subject Headings; National Institutes of Health (U.S.); PubMed; Terminology as Topic; United States; Vocabulary, Controlled","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WQHGJ9PV","journalArticle","2004","Becker, Kevin G.; Barnes, Kathleen C.; Bright, Tiffani J.; Wang, S. Alex","The genetic association database","Nature Genetics","","1061-4036","10.1038/ng0504-431","","","2004-05","2023-03-22 11:22:10","2023-04-15 14:14:49","","431-432","","5","36","","Nat Genet","","","","","","","","eng","","","","","PubMed","","{'citing': ['10.1007/978-1-4939-0709-0_12', '10.1109/bmei.2014.7002870', '10.1186/1755-8794-2-17', '10.1016/j.jpba.2020.113535', '10.1586/1744666x.2.6.901', '10.1093/bioinformatics/btw503', '10.1186/1752-0509-5-6', '10.1038/srep15340', '10.1186/s12859-017-1852-0', '10.1186/1755-8794-3-1', '10.1093/bioinformatics/btk031', '10.1038/srep02147', '10.1111/j.1556-4029.2006.00361.x', '10.1042/bsr20180519', '10.1093/nar/gkq472', '10.1194/jlr.m800232-jlr200', '10.1371/journal.pone.0139245', '10.1371/journal.pone.0135024', '10.1186/s13059-020-01990-9', '10.1016/j.ygeno.2011.01.004', '10.1186/1471-2105-7-291', '10.1093/database/bav028', '10.1093/bib/bbw042', '10.1186/s12967-020-02597-1', '10.1186/s13062-015-0088-z', '10.1186/s12859-022-04788-7', '10.1016/j.gene.2015.11.023', '10.1155/2020/2914579', '10.1093/nar/gkx895', '10.1093/hmg/ddr599', '10.1016/j.jbi.2018.02.013', '10.1371/journal.pone.0216948', '10.1093/nar/gks389', '10.1186/s12859-015-0591-3', '10.1007/s11033-021-06780-5', '10.1007/978-1-4614-7931-4_3', '10.1016/j.tig.2005.02.011', '10.1371/journal.pone.0099415', '10.3109/19396368.2014.955896', '10.1101/gr.6554007', '10.1109/bibm.2017.8217651', '10.1101/2021.05.26.445910', '10.3892/ijmm.2017.2853', '10.1007/978-3-030-93733-1_28', '10.1371/journal.pone.0036694', '10.1093/bioinformatics/btp166', '10.1093/nar/gkx934', '10.1093/bib/bbq026', '10.1093/nar/gkv1257', '10.1007/s11255-018-1976-9', '10.4081/nr.2012.e12', '10.18632/oncotarget.14361', '10.5772/intechopen.85030', '10.1089/cmb.2009.0040', '10.1186/1471-2105-8-348', '10.1186/s12920-018-0427-x', '10.1093/nar/gkw1082', '10.1371/journal.pone.0085093', '10.1136/amiajnl-2011-000658', '10.1093/nar/gkq813', '10.5812/ircmj.16659', '10.1371/journal.pone.0048336', '10.1136/amiajnl-2011-000480', '10.1089/cmb.2015.0202', '10.1016/j.ymeth.2014.10.003', '10.1080/19396368.2017.1330368', '10.1002/0471142905.hg1806s71', '10.1093/database/baz014', '10.1186/s12859-015-0519-y', '10.1016/s1875-5364(19)30031-7', '10.1007/978-1-62703-514-9_8', '10.1093/nar/gks364', '10.3389/fphar.2019.01065', '10.1186/s12859-015-0550-z', '10.1186/1472-6947-15-s1-s7', '10.1108/lht-10-2016-0107', '10.2139/ssrn.3293682', '10.3389/fonc.2019.00395', '10.1021/pr500009j', '10.1109/bsb.2016.7552151', '10.3389/fbioe.2014.00088', '10.1371/journal.pgen.1005111', '10.1002/minf.201700017', '10.1042/bsr20191247', '10.5392/jkca.2013.13.08.466', '10.1371/journal.pone.0022859', '10.1038/ejhg.2009.38', '10.2217/pgs-2020-0039', '10.1038/srep09463', '10.1093/database/baw141', '10.1093/nar/gkv1317', '10.1007/978-94-017-7408-6_5', '10.1186/1471-2105-11-74', '10.1088/1367-2630/17/8/085009', '10.1093/gbe/evq064', '10.1093/nar/gkt161', '10.1021/acs.jproteome.7b00772', '10.3389/fphar.2020.00519', '10.1093/nar/gkm895', '10.3389/frma.2018.00007', '10.1109/fgcn.2008.212', '10.1038/s41386-021-01027-0', '10.15406/mojcsr.2017.04.00085', '10.1002/ijc.29035', '10.1186/s12918-015-0253-0', '10.1093/database/bau090', '10.1007/s13670-012-0023-4', '10.1101/743781', '10.1111/jcmm.13928', '10.1145/3271553.3271562', '10.3390/biom11081245', '10.1002/9783527634613.ch14', '10.1186/1752-0509-4-158', '10.3389/fphar.2021.656115', '10.1371/journal.pone.0049686', '10.1038/s41598-022-07035-4', '10.1038/ejhg.2011.30', '10.1093/bioinformatics/btm001', '10.1093/bioinformatics/btr154', '10.1186/1756-0500-6-511', '10.1371/journal.pbio.1001427', '10.1016/j.ijmedinf.2013.05.003', '10.1371/journal.pcbi.1000641', '10.1038/srep11435', '10.1016/j.ins.2015.01.036', '10.1038/mp.2008.131', '10.1371/journal.pgen.1002240', '10.1101/532929', '10.1038/msb.2011.29', '10.1016/j.patter.2022.100524', '10.1371/journal.pcbi.1002902', '10.1093/nar/gkx1107', '10.1016/j.oraloncology.2018.09.029', '10.1039/c5ra01920f', '10.1101/2020.11.24.396317', '10.1016/j.schres.2006.05.023', '10.1186/1471-2164-10-s1-s6', '10.1186/s12859-021-04342-x', '10.1093/nar/gkr483', '10.1161/circgenetics.108.843946', '10.1186/1471-2105-10-s2-s14', '10.1093/bioinformatics/btv265', '10.1093/nar/gku434', '10.1186/1471-2105-10-s15-s9', '10.1093/nar/gkaa1037', '10.1109/tcbb.2019.2927310', '10.1186/1471-2105-15-13', '10.1371/journal.pcbi.1006042', '10.1093/nar/gkw943', '10.18632/oncotarget.18473', '10.1186/s12906-021-03210-8', '10.1093/nar/gkt1166', '10.1109/bibm.2016.7822765', '10.1126/science.1224344', '10.1109/ems.2017.20', '10.1016/j.jep.2010.08.022', '10.1186/s12859-022-04954-x', '10.1371/journal.pone.0078896', '10.1038/nrg2483', '10.1007/978-981-19-4771-1_7', '10.1093/bib/bbab438', '10.3389/fgene.2014.00312', '10.1093/bioinformatics/btr389', '10.1093/bioinformatics/bts581', '10.1186/1471-2288-7-31', '10.18632/oncotarget.9353', '10.1186/1755-8794-3-50', '10.1186/1471-2148-11-16', '10.1186/1752-0509-3-46', '10.1136/jmedgenet-2014-102535', '10.1093/bioinformatics/btw358', '10.1007/s11427-014-4692-4', '10.1016/j.mrrev.2010.04.001', '10.1097/01.bor.0000134407.48586.b0', '10.23919/ccc50068.2020.9188803', '10.1186/1471-2105-12-266', '10.1371/journal.pone.0001262', '10.1186/1471-2105-16-s6-s4', '10.1371/journal.pone.0076666', '10.1007/s12026-021-09217-0', '10.1002/jcb.26301', '10.1016/j.compbiolchem.2015.06.003', '10.1080/17474124.2017.1271323', '10.1155/2014/290325', '10.1186/1471-2164-14-129', '10.1371/journal.pone.0140888', '10.1093/gbe/evu220', '10.1007/978-3-319-06269-3_7', '10.1111/j.1528-1167.2009.02423.x', '10.1038/nn.4353', '10.1371/journal.pone.0105393', '10.1093/database/bav015', '10.1007/s12539-020-00359-7', '10.1016/j.biomaterials.2009.02.016', '10.1093/bioinformatics/btu766', '10.18632/oncotarget.9030', '10.2217/bmm.15.67', '10.2217/14622416.8.6.623', '10.1016/j.sna.2012.07.025', '10.1007/978-981-33-4084-8_16', '10.1371/journal.pone.0116815', '10.1016/j.canep.2011.01.007', '10.1002/prca.201400127', '10.18632/oncotarget.14675', '10.1186/1471-2164-13-s8-s20', '10.3389/fpubh.2016.00193', '10.1089/neu.2012.2631', '10.1016/j.ebiom.2018.08.050', '10.1007/978-3-319-59575-7_3', '10.1142/s0219720014500176', '10.1101/2020.12.01.406215', '10.1186/1471-2105-7-325', '10.1039/c5ra10761j', '10.1101/434803', '10.1186/1471-2105-10-s8-i1', '10.1038/srep39433', '10.1186/1752-0509-3-109', '10.1093/bioinformatics/btq645', '10.1186/s12929-019-0581-2', '10.1093/gbe/evt066', '10.1186/1471-2105-6-s4-s18', '10.1080/08927022.2022.2045015', '10.1101/2022.05.03.490380', '10.1039/c4mb00099d', '10.1016/j.mgene.2020.100771', '10.1007/978-94-017-7408-6_6', '10.1007/978-3-540-37654-5_44', '10.1016/j.jbi.2016.01.004', '10.1080/13506129.2017.1353966', '10.1016/j.gene.2017.11.028', '10.1007/978-1-61737-954-3_16', '10.1142/s0219720007003090', '10.1186/2040-2392-5-48', '10.1002/sim.3695', '10.3109/9781420067064-12', '10.3390/ncrna3020020', '10.1080/19396368.2016.1197982', '10.1186/s12859-017-1467-5', '10.1016/j.ymeth.2013.07.031', '10.1101/2021.06.03.446973', '10.1101/2021.05.23.445314', '10.1186/s12920-016-0194-5', '10.1093/gigascience/giy035', '10.1016/j.biopsych.2012.09.028', '10.3892/ijo.2014.2501', '10.1038/s41598-017-13723-3', '10.1002/oby.23303', '10.1073/pnas.0907112106', '10.3892/etm.2017.5185', '10.1016/j.jgg.2016.04.006', '10.1186/s12920-016-0173-x', '10.1080/01635581.2018.1540715', '10.1111/jth.14290', '10.1016/j.ymeth.2018.06.002', '10.1159/000089011', '10.1371/journal.pone.0080170', '10.1016/j.jhep.2014.10.036', '10.1016/j.jbi.2017.11.009', '10.1093/nar/gkac960', '10.1093/bib/bbz176', '10.1093/nar/gkq949', '10.1177/2040622319899300', '10.1016/j.jaci.2016.01.006', '10.1093/bioinformatics/btn653', '10.1155/2021/8874296', '10.1016/j.jep.2022.115450', '10.1074/mcp.m111.010629', '10.1089/omi.2014.0135', '10.1016/j.websem.2022.100756', '10.1093/molbev/msw127', '10.1038/s41598-017-01791-4', '10.1109/tcbb.2019.2907536', '10.1016/j.jpba.2017.04.012', '10.1007/978-1-4471-4474-8_25', '10.1186/s12918-016-0280-5', '10.1093/database/bat063', '10.1371/journal.pone.0094303', '10.1186/1471-2105-16-s5-s1', '10.7717/peerj.8685', '10.1371/journal.pone.0126283', '10.1038/s41397-022-00289-1', '10.1016/j.gene.2019.02.056', '10.1186/1471-2105-15-152', '10.1007/s11192-016-2196-7', '10.3389/fphar.2021.806829', '10.1007/s12539-014-0241-x', '10.1007/978-3-319-97310-4_30', '10.1186/s12859-020-03583-6', '10.1093/nar/gkv905', '10.1109/icsc.2017.65', '10.3389/fphar.2018.01433', '10.1186/1471-2202-15-11', '10.1038/tp.2013.38', '10.1093/database/baw100', '10.1016/j.drudis.2011.12.005', '10.1111/iji.12236', '10.1038/nature11690', '10.1186/s12918-014-0108-0', '10.1142/s0219720011005392', '10.1186/1471-2105-9-s12-s19', '10.1371/journal.pone.0063308', '10.1136/amiajnl-2011-000745', '10.1186/s12920-017-0315-9', '10.1002/advs.201801384', '10.1002/humu.22950', '10.1186/s12859-016-1095-5', '10.1186/1752-0509-4-97', '10.1371/journal.pone.0019240', '10.1093/bioinformatics/btu269', '10.1093/nar/gkq1094', '10.1186/s12865-014-0061-0', '10.1002/imt2.47', '10.1002/humu.20584', '10.4161/15548627.2014.994346', '10.18632/oncotarget.10891', '10.1093/carcin/bgq287', '10.1039/c4mb00573b', '10.1093/nar/gks937', '10.1101/2020.08.25.266924', '10.4137/cin.s13874', '10.1371/journal.pone.0135339', '10.1371/journal.pone.0134693', '10.1007/s00432-016-2332-z', '10.3389/fgene.2022.1010048', '10.1126/sciadv.aaw0946', '10.1186/1752-0509-7-s5-s10', '10.1016/j.cmet.2015.11.004', '10.1093/database/baz062', '10.1038/srep22602', '10.1038/srep30024', '10.1371/journal.pcbi.1002180', '10.1186/s12911-017-0449-x', '10.1039/c5mb00095e', '10.1038/srep10204', '10.1038/s41380-022-01529-3', '10.1002/cphy.c190047', '10.1186/1471-2105-7-30', '10.1371/journal.pone.0200717', '10.1021/acsomega.1c04440', '10.1111/cea.12883', '10.1093/nar/gkab950', '10.1038/ng1433', '10.1155/2019/2675287', '10.1109/tetci.2020.3014923', '10.1016/j.chembiol.2021.02.015', '10.1016/s1674-6384(15)60015-6', '10.1016/j.jprot.2013.11.008', '10.1097/ypg.0000000000000191', '10.1371/journal.pone.0079564', '10.1093/nar/gkq362', '10.1371/journal.pone.0089123', '10.3390/molecules23040736', '10.1016/j.omtn.2019.09.019', '10.1016/j.ygeno.2008.10.009', '10.1016/j.cell.2012.08.011', '10.1371/journal.pgen.1001375', '10.1007/978-3-642-38036-5_18', '10.1186/s40364-022-00431-y', '10.1186/1471-2105-13-s15-s2', '10.1371/journal.pbio.1000247', '10.1186/s12885-020-06869-3', '10.1016/j.jep.2012.01.041', '10.1093/bioinformatics/btac230', '10.1007/s40618-021-01693-3', '10.1038/srep03538', '10.1007/978-1-59745-439-1_8', '10.1016/j.jtbi.2016.05.020', '10.1155/2016/3594517', '10.1186/s13148-015-0123-z', '10.1016/b978-0-08-046884-6.01419-6', '10.1186/1471-230x-11-5', '10.1101/763672', '10.3389/fgene.2020.00005', '10.1038/srep11459', '10.1038/srep30624', '10.1007/s12253-014-9848-9', '10.1093/jmcb/mjv008', '10.1016/j.ymgme.2018.09.003', '10.1186/1471-2164-10-s3-s32', '10.3389/fphar.2022.893231', '10.1042/bsr20204247', '10.1186/s13073-018-0565-y', '10.1109/hibit.2012.6209052', '10.3390/v13112117', '10.1186/1755-8794-4-63', '10.1039/c3mb70496c', '10.1109/bibm47256.2019.8983031', '10.1007/978-3-7091-0947-2_1', '10.1002/gepi.21629', '10.1098/rstb.2014.0069', '10.1109/bibm.2016.7822487', '10.1021/acs.jproteome.9b00366', '10.1038/nrm3769', '10.1002/9780470015902.a0020763', '10.1038/ncomms4584', '10.3389/fneur.2018.01158', '10.1093/bfgp/els032', '10.4161/sysb.22816', '10.1093/nar/gkx1040', '10.1371/journal.pone.0142624', '10.1093/bfgp/elab002', '10.1038/nature12511', '10.1002/advs.201800640', '10.1186/s13229-015-0009-0', '10.1038/srep14955', '10.1038/ijo.2009.152', '10.1128/iai.00207-11', '10.1089/omi.2012.0084', '10.1371/journal.pone.0149257', '10.1007/s00251-005-0075-0', '10.1093/database/bap008', '10.1038/s41419-019-1638-6', '10.1016/b978-0-12-420226-9.00008-5', '10.1371/journal.pcbi.1000662', '10.2174/1389450120666190923162203', '10.1186/s12918-017-0451-z', '10.1007/978-981-16-3993-7_13', '10.1038/ng.466', '10.1093/bioinformatics/bty002', '10.1093/carcin/bgq092', '10.1186/1752-0509-6-80', '10.1371/journal.pone.0114903', '10.1161/circgenetics.114.000640', '10.3390/biomedicines10061225', '10.1093/nar/gkv1036', '10.1007/978-3-319-54472-4_21', '10.1016/j.jbi.2016.06.009', '10.1016/j.jep.2021.114109', '10.1007/978-1-60327-411-1_16', '10.1109/bibm.2017.8217726', '10.1111/j.1601-183x.2011.00721.x', '10.1002/0471250953.bi0808s45', '10.1093/bib/bbac006', '10.1093/nar/gkn296', '10.1186/s12862-015-0534-7', '10.1002/ajmg.b.32189', '10.1182/blood-2008-02-140434', '10.1101/2020.06.13.150201', '10.1007/978-94-024-0951-2_15', '10.1145/3107411.3107483', '10.1109/iccse.2013.6554016', '10.1371/journal.pone.0021131', '10.1021/pr5007685', '10.1111/j.1399-0039.2004.00327.x', '10.1101/2020.06.05.136754', '10.1007/s00251-005-0025-x', '10.1371/journal.pone.0124632', '10.1093/database/bas061', '10.1021/pr501148q', '10.1093/gigascience/giy014', '10.1093/nar/gku1026', '10.1093/nar/gkw945', '10.1186/s12885-019-6209-9', '10.1007/978-1-4939-0847-9_17', '10.1158/0008-5472.can-07-2608', '10.1186/1756-0500-5-212', '10.1093/bib/bbx103', '10.1093/nar/gkv074', '10.1242/dmm.010322', '10.1093/nar/gku948', '10.1091/mbc.e13-10-0602', '10.1007/978-3-319-42007-3_19', '10.1039/c4mb00478g', '10.1186/s12920-020-00730-z', '10.1016/j.fsigen.2021.102637', '10.1101/2020.08.13.20173666', '10.1242/dmm.026021', '10.1016/j.jaci.2011.03.050', '10.1016/j.jep.2019.01.019', '10.1007/s12539-015-0276-7', '10.1101/2021.03.31.437823', '10.1038/s41598-017-03039-7', '10.1101/2020.09.01.277277', '10.1186/s12859-022-04646-6', '10.1371/journal.pgen.1004237', '10.1016/j.compbiomed.2021.104243', '10.1016/j.jbi.2009.12.005', '10.1016/b978-0-12-800453-1.00004-x', '10.1016/j.jneumeth.2014.12.008', '10.1038/cddis.2015.414', '10.1007/978-1-4939-7868-7_11', '10.1371/journal.pone.0084639', '10.1093/g3journal/jkab112', '10.1371/journal.pone.0200699', '10.1038/clpt.2012.51', '10.4258/hir.2013.19.1.50', '10.1093/nar/gkq957', '10.12688/f1000research.10788.1', '10.1039/c6mb00359a', '10.1007/978-1-4471-4282-9_9', '10.1093/bib/bbr070', '10.1007/s13721-020-00278-z', '10.1002/ptr.7012', '10.1093/nar/gkr1145', '10.18632/aging.102667', '10.1186/s12864-015-1481-9', '10.15406/mojpb.2014.01.00020', '10.1016/j.jaci.2012.02.040', '10.1074/mcp.m114.047159', '10.1155/2015/432012', '10.1002/0471250953.bi0104s40', '10.1039/c9mo00129h', '10.1038/s41398-022-02015-8', '10.1007/s00251-006-0093-6', '10.1089/omi.2018.0205', '10.1093/gbe/evv228', '10.3892/or.2021.8180', '10.1186/1471-2148-12-10', '10.1093/nar/gkt401', '10.1016/j.schres.2010.08.022', '10.1186/s13041-014-0083-9', '10.1038/srep15478', '10.1186/1471-2105-7-166', '10.1002/prot.21846', '10.1002/0471250953.bi0104s28', '10.3389/fncel.2014.00080', '10.1101/2020.12.14.421529', '10.1002/humu.22077', '10.1101/2020.10.05.327155', '10.1016/b978-0-12-812744-5.00004-7', '10.1038/s41598-017-05224-0', '10.1101/711754', '10.1371/journal.pgen.1000592', '10.1146/annurev.med.58.071105.111738', '10.1152/physiolgenomics.00008.2010', '10.1186/1755-8794-8-s2-s7', '10.1002/jcp.26174', '10.1186/1471-2105-12-s1-s25', '10.1186/1472-6947-13-s1-s3', '10.1093/nar/gkw519', '10.1016/j.molcel.2015.07.019', '10.1016/j.jmb.2021.167149', '10.1002/0471250953.bi0113s39', '10.1186/s12859-021-04479-9', '10.1016/j.biopsych.2014.06.016', '10.1371/journal.pgen.1004122', '10.1016/b978-0-12-384978-6.00010-8', '10.1186/2047-2501-2-7', '10.1093/nar/gkr1182', '10.1186/1471-2105-14-47', '10.1371/journal.pcbi.1000910', '10.1093/bioinformatics/btl593', '10.1142/s0219720020500079', '10.1007/s10792-021-02055-x', '10.1016/j.trim.2005.03.001', '10.1093/bioinformatics/bty289', '10.1038/srep03426', '10.1101/2020.08.15.250282', '10.1007/s11427-013-4573-2', '10.1093/nar/gkw1087', '10.1101/057828', '10.1007/s00221-016-4669-6', '10.1186/1756-0381-3-5', '10.3389/fgene.2019.00670', '10.1093/genetics/iyac005', '10.1097/01.wco.0000218232.66054.46', '10.1093/bioinformatics/btu487', '10.1093/infdis/jix633', '10.1093/bib/bbt004', '10.1038/s41467-019-11874-7', '10.1517/14728222.8.6.587', '10.1039/c5mb00061k', '10.1161/hypertensionaha.107.090316', '10.1109/titb.2006.884367', '10.1093/ijnp/pyaa097', '10.1165/rcmb.2007-0151oc', '10.1016/j.gene.2017.08.010', '10.1002/em.21798', '10.1002/humu.22079', '10.1038/srep14941', '10.1016/b978-0-12-801238-3.65251-0', '10.1186/s12859-016-1205-4', '10.1016/j.prp.2015.07.007', '10.1155/2013/245357', '10.1371/journal.pgen.0030196', '10.1186/1755-8794-3-17', '10.1016/j.jprot.2017.08.011', '10.3389/fgene.2019.00474', '10.1631/jzus.b1800631', '10.1109/access.2022.3154820', '10.1101/053793', '10.2217/pgs.12.76', '10.1007/978-3-030-58721-5_26', '10.1186/1752-0509-7-122', '10.1093/gbe/evp013', '10.1093/bioinformatics/btr380', '10.1101/2020.06.01.20119081', '10.1093/nar/gkaa922', '10.1038/srep43258', '10.1371/journal.pone.0171512', '10.1016/j.bbadis.2020.165714', '10.1002/humu.20972', '10.1109/tcbb.2018.2817624', '10.5665/sleep.1376', '10.1186/s13073-014-0094-2', '10.1152/physiolgenomics.90247.2008', '10.1080/15548627.2020.1796015', '10.1152/physiolgenomics.00063.2018', '10.1038/srep23167', '10.1155/2020/7193832', '10.1371/journal.pone.0153006', '10.1371/journal.pone.0084408', '10.1007/978-981-13-2354-6_39', '10.1186/s12859-019-3317-0', '10.1093/bioinformatics/btv301', '10.1186/1755-8794-7-s1-s3', '10.3389/fnhum.2014.00283', '10.1371/journal.pone.0024495', '10.1186/1471-2105-10-73', '10.1080/14712598.2018.1474198', '10.1038/s41525-020-00166-5', '10.1371/journal.pone.0125876', '10.1002/ajmg.b.32565', '10.1155/2014/170289', '10.1186/s12920-019-0609-1', '10.1002/gepi.20531', '10.1371/journal.pone.0075504', '10.1111/j.1463-1326.2012.01651.x', '10.3389/fphys.2019.00917', '10.1155/2013/637424', '10.1038/nm.3933', '10.1186/1471-2350-11-14', '10.1016/j.ejogrb.2005.10.002', '10.1101/gr.203059.115', '10.1186/1471-2164-11-189', '10.1186/s13326-017-0140-2', '10.1002/widm.1383', '10.1007/978-1-4939-7717-8_12', '10.1375/twin.10.6.861', '10.1093/nar/gks538', '10.1155/2019/5804710', '10.1016/j.gene.2015.07.068', '10.1038/s41366-021-00896-1', '10.1093/nar/gkw973', '10.1186/1471-2202-14-147', '10.1016/j.jep.2012.01.055', '10.1186/s12864-022-08491-y', '10.1016/j.dnarep.2014.01.004', '10.1093/bioinformatics/btq310', '10.1007/978-1-4614-8778-4_4', '10.1038/s12276-019-0351-y', '10.1007/978-3-540-78839-3_4', '10.1002/gepi.20476', '10.1186/1750-1326-6-83', '10.1186/1471-2105-15-304', '10.3389/fnbeh.2014.00388', '10.1016/j.dib.2020.105439', '10.4103/wjtcm.wjtcm_25_21', '10.1186/1471-2105-10-278', '10.1093/nar/gkaa811', '10.1016/j.gene.2012.03.054', '10.3389/fphar.2022.858345', '10.1007/3-540-27272-0_4', '10.1186/s12967-016-0921-x', '10.1038/ng.3621', '10.1152/ajpgi.90237.2008', '10.3389/fphar.2019.00123', '10.3390/nu11010143', '10.1038/nrg3253', '10.1016/j.compbiolchem.2015.08.005', '10.1039/c5mb00264h', '10.3389/fnbeh.2014.00110', '10.3390/genes10020154', '10.1039/c4mb00169a', '10.1038/ejhg.2012.218', '10.1186/1471-2164-12-55', '10.1371/journal.pone.0104650', '10.1242/dmm.002790', '10.4137/cin.s17641', '10.1093/bib/bbaa298', '10.1371/journal.pone.0243127', '10.1016/j.jbi.2017.09.006', '10.1186/s12859-017-1672-2', '10.3389/fgene.2021.758041', '10.1371/journal.pone.0214857', '10.1016/j.atherosclerosis.2009.10.026', '10.1002/ajmg.b.31078', '10.1371/journal.pcbi.1002488', '10.1093/nar/gks1244', '10.3390/genes13040683', '10.1002/ajmg.b.31062', '10.1080/10245332.2016.1235673', '10.1002/2211-5463.12984', '10.1186/1753-6561-3-s7-s93', '10.1101/459172', '10.1145/3307339.3343479', '10.1371/journal.pone.0116095', '10.1093/aje/kws394', '10.1093/bib/bbv033', '10.1093/bioinformatics/btz887', '10.1186/1471-2105-10-s12-s5', '10.18632/oncotarget.19933', '10.1007/978-3-319-70474-6_9', '10.1109/gensips.2012.6507738', '10.1016/j.ygeno.2015.11.001', '10.1016/j.jmb.2020.166788', '10.1145/3018896.3018966', '10.1038/s41598-021-03357-x', '10.1155/2019/3171420', '10.1093/database/baq016', '10.18632/oncotarget.20256', '10.1007/s00439-009-0655-4', '10.1038/srep00757', '10.1016/j.compbiolchem.2015.08.010', '10.1021/pr300829r', '10.1016/j.jgg.2015.11.002', '10.1016/j.gene.2016.05.044', '10.1371/journal.pone.0143045', '10.1039/c3mb25432a', '10.1152/physiolgenomics.90403.2008', '10.1016/j.jbi.2015.08.008', '10.1093/bioinformatics/btm376', '10.1007/978-3-642-10238-7_10', '10.1109/bibe.2016.71', '10.1038/srep16401', '10.1371/journal.pone.0104827', '10.1371/journal.pone.0002907', '10.2147/dddt.s297683', '10.1093/database/baw034'], 'cited': ['10.1038/ng0504-431']}","","/root/snap/zotero-snap/common/Zotero/storage/YN6ZU8KB/Becker et al. - 2004 - The genetic association database.pdf; ","http://www.ncbi.nlm.nih.gov/pubmed/15118671","","Genetic Diseases, Inborn; Humans; Databases, Genetic; Genetics, Population; Mutation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C75NMDNL","conferencePaper","2013","Bing, Lidong; Lam, Wai; Wong, Tak-Lam","Wikipedia entity expansion and attribute extraction from the web using semi-supervised learning","Proceedings of the sixth ACM international conference on Web search and data mining","978-1-4503-1869-3","","10.1145/2433396.2433468","https://doi.org/10.1145/2433396.2433468","We develop a new framework to achieve the goal of Wikipedia entity expansion and attribute extraction from the Web. Our framework takes a few existing entities that are automatically collected from a particular Wikipedia category as seed input and explores their attribute infoboxes to obtain clues for the discovery of more entities for this category and the attribute content of the newly discovered entities. One characteristic of our framework is to conduct discovery and extraction from desirable semi-structured data record sets which are automatically collected from the Web. A semi-supervised learning model with Conditional Random Fields is developed to deal with the issues of extraction learning and limited number of labeled examples derived from the seed entities. We make use of a proximate record graph to guide the semi-supervised learning process. The graph captures alignment similarity among data records. Then the semi-supervised learning process can leverage the unlabeled data in the record set by controlling the label regularization under the guidance of the proximate record graph. Extensive experiments on different domains have been conducted to demonstrate its superiority for discovering new entities and extracting attribute content.","2013-02-04","2023-03-22 11:20:33","2023-10-17 13:58:23","2023-03-22","567–576","","","","","","","WSDM '13","","","","ACM","New York, NY, USA","","","","","","ACM Digital Library","","{'citing': ['10.1007/978-3-662-49521-6_4', '10.1061/(asce)cp.1943-5487.0000346', '10.1145/2857054', '10.1145/3269206.3269245', '10.1007/s10489-018-1208-0', '10.1007/s10489-019-01499-0', '10.1007/978-3-319-64468-4_24', '10.1007/978-3-319-91455-8_21', '10.1109/icws.2017.85', '10.1109/compsac.2017.202', '10.1145/3377713.3377755', '10.1007/978-981-13-2206-8_20', '10.1007/s11704-020-9240-8', '10.1145/2508434', '10.1145/2600428.2609630', '10.2139/ssrn.3254297', '10.1016/j.knosys.2014.10.003', '10.1007/s10489-021-02220-w', '10.1109/tbdata.2018.2805366', '10.1007/978-3-031-10983-6_45'], 'cited': []}","","","","SAT_context:Graph; SAT_learning:distant; SAT_task:InformationExtraction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U4RMTXCQ","conferencePaper","2018","Phi, Van-Thuy; Santoso, Joan; Shimbo, Masashi; Matsumoto, Yuji","Ranking-Based Automatic Seed Selection and Noise Reduction for Weakly Supervised Relation Extraction","Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)","","","10.18653/v1/p18-2015","http://aclweb.org/anthology/P18-2015","This paper addresses the tasks of automatic seed selection for bootstrapping relation extraction, and noise reduction for distantly supervised relation extraction. We ﬁrst point out that these tasks are related. Then, inspired by ranking relation instances and patterns computed by the HITS algorithm, and selecting cluster centroids using the K-means, LSA, or NMF method, we propose methods for selecting the initial seeds from an existing resource, or reducing the level of noise in the distantly labeled data. Experiments show that our proposed methods achieve a better performance than the baseline systems in both tasks.","2018","2023-03-22 11:25:00","2023-04-15 14:14:43","2023-03-22 11:25:00","89-95","","","","","","","","","","","Association for Computational Linguistics","Melbourne, Australia","en","","","","","DOI.org (Crossref)","","{'citing': ['10.1007/s00521-021-06667-3', '10.1007/978-981-16-8052-6_269', '10.1007/978-981-15-0118-0_27'], 'cited': ['10.18653/v1/p18-2015']}","","/root/snap/zotero-snap/common/Zotero/storage/H92ZA8VL/Phi et al. - 2018 - Ranking-Based Automatic Seed Selection and Noise R.pdf","","Pwc_task:Relation Extraction; Pwc_task:Word Sense Disambiguation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)","","","","","","","","","","","","","","",""
"GNQRFR3D","conferencePaper","2017","Perez-Beltrachini, Laura; Gardent, Claire","Analysing Data-To-Text Generation Benchmarks","Proceedings of the 10th International Conference on Natural Language Generation","","","10.18653/v1/w17-3537","http://aclweb.org/anthology/W17-3537","A generation system can only be as good as the data it is trained on. In this short paper, we propose a methodology for analysing data-to-text corpora used for training microplanner i.e., systems which given some input must produce a text verbalising exactly this input. We apply this methodology to three existing benchmarks and we elicite a set of criteria for the creation of a data-to-text benchmark which could help better support the development, evaluation and comparison of linguistically sophisticated data-to-text generators.","2017","2023-02-27 14:08:58","2023-04-15 14:14:42","2023-02-27 14:08:58","238-242","","","","","","","","","","","Association for Computational Linguistics","Santiago de Compostela, Spain","en","","","","","DOI.org (Crossref)","","{'citing': ['10.1007/s10618-021-00801-4', '10.1016/j.csl.2022.101433', '10.1109/bigcomp.2019.8679486'], 'cited': ['10.18653/v1/w17-3537']}","","/root/snap/zotero-snap/common/Zotero/storage/CG3QG6Y8/Perez-Beltrachini and Gardent - 2017 - Analysing Data-To-Text Generation Benchmarks.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 10th International Conference on Natural Language Generation","","","","","","","","","","","","","","",""
"E6NHUKA4","conferencePaper","2011","Agarwal, Oshin; Ge, Heming; Shakeri, Siamak; Al-Rfou, Rami","Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2021.naacl-main.278","https://aclanthology.org/2021.naacl-main.278","Many Knowledge Bases (KBs) are now readily available and encompass colossal quantities of information thanks to either a long-term funding effort (e.g. WordNet, OpenCyc) or a collaborative process (e.g. Freebase, DBpedia). However, each of them is based on a different rigid symbolic framework which makes it hard to use their data in other systems. It is unfortunate because such rich structured knowledge might lead to a huge leap forward in many other areas of AI like natural language processing (word-sense disambiguation, natural language understanding, ...), vision (scene classification, image semantic annotation, ...) or collaborative filtering. In this paper, we present a learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more flexible continuous vector space in which the original knowledge is kept and enhanced. These learnt embeddings would allow data from any KB to be easily used in recent machine learning methods for prediction and information retrieval. We illustrate our method on WordNet and Freebase and also present a way to adapt it to knowledge extraction from raw text.","2011","2023-02-28 16:23:49","2023-10-17 13:58:26","2023-02-28 16:23:49","3554-3565","","","","","","","","","","","ACL","Online","en","","","","","DOI.org (Crossref)","","{'citing': ['10.2200/s0113ed1v01y202109icr076', '10.1145/3460210.3493580', '10.1007/978-3-030-96623-2_14', '10.1109/access.2021.3130956', '10.1162/tacl_a_00476', '10.1145/3487553.3524265', '10.3233/sw-222974', '10.1007/978-3-031-21422-6_17'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/T2UWPZJA/Agarwal et al. - 2021 - Knowledge Graph Based Synthetic Corpus Generation .pdf","","SAT_context:Graph; SAT_granularity:edge; SAT_task:TextGeneration; SAT_task:Retrieval; SAT_task:DataToText","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","","","","","","","","","","","","",""
"3533B2VD","conferencePaper","2019","Trisedya, Bayu Distiawan; Weikum, Gerhard; Qi, Jianzhong; Zhang, Rui","Neural Relation Extraction for Knowledge Base Enrichment","Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/p19-1023","https://aclanthology.org/P19-1023","We study relation extraction for knowledge base (KB) enrichment. Specifically, we aim to extract entities and their relationships from sentences in the form of triples and map the elements of the extracted triples to an existing KB in an end-to-end manner. Previous studies focus on the extraction itself and rely on Named Entity Disambiguation (NED) to map triples into the KB space. This way, NED errors may cause extraction errors that affect the overall precision and recall.To address this problem, we propose an end-to-end relation extraction model for KB enrichment based on a neural encoder-decoder model. We collect high-quality training data by distant supervision with co-reference resolution and paraphrase detection. We propose an n-gram based attention model that captures multi-word entity names in a sentence. Our model employs jointly learned word and entity embeddings to support named entity disambiguation. Finally, our model uses a modified beam search and a triple classifier to help generate high-quality triples. Our model outperforms state-of-the-art baselines by 15.51% and 8.38% in terms of F1 score on two real-world datasets.","2019-07","2023-02-28 16:25:00","2023-10-17 13:57:05","2023-02-28 16:25:00","229–240","","","","","","","","","","","Association for Computational Linguistics","Florence, Italy","","","","","","ACLWeb","","{'citing': ['10.1007/978-3-030-62419-4_17', '10.6339/21-jds1012', '10.1007/s13748-021-00230-w', '10.1007/978-981-33-6981-8_48', '10.1007/s13748-021-00263-1', '10.1007/s12559-021-09917-7', '10.4218/etrij.2020-0460', '10.1145/3459637.3482268', '10.3233/sw-212838', '10.1109/jcdl52503.2021.00014', '10.1109/icde48307.2020.00106', '10.1007/s10489-022-03596-z', '10.1109/tetci.2021.3136598', '10.1007/978-3-031-11609-4_35', '10.1109/icccs52626.2021.9449230', '10.1007/s00778-022-00747-z', '10.1109/ijcnn52387.2021.9533807', '10.1109/tpami.2021.3118703', '10.1007/978-3-030-62419-4_17', '10.6339/21-jds1012', '10.1007/s13748-021-00230-w', '10.1007/978-981-33-6981-8_48', '10.1007/s13748-021-00263-1', '10.1007/s12559-021-09917-7', '10.4218/etrij.2020-0460', '10.1145/3459637.3482268', '10.3233/sw-212838', '10.1109/jcdl52503.2021.00014', '10.1109/icde48307.2020.00106', '10.1007/s10489-022-03596-z', '10.1109/tetci.2021.3136598', '10.1007/978-3-031-11609-4_35', '10.1109/icccs52626.2021.9449230', '10.1007/s00778-022-00747-z', '10.1109/ijcnn52387.2021.9533807', '10.1109/tpami.2021.3118703'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/P88VJP8W/Trisedya et al. - 2019 - Neural Relation Extraction for Knowledge Base Enri.pdf","","SAT_context:Graph; SAT_granularity:edge; FOCUS_STUDY_OCT; FOCUS_STUDY_FINAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2019","","","","","","","","","","","","","","",""
"UTJA666L","conferencePaper","2016","Wen, Tsung-Hsien; Gašić, Milica; Mrkšić, Nikola; Rojas-Barahona, Lina M.; Su, Pei-Hao; Vandyke, David; Young, Steve","Multi-domain Neural Network Language Generation for Spoken Dialogue Systems","Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/n16-1015","https://aclanthology.org/N16-1015","Moving from limited-domain natural lan- guage generation (NLG) to open domain is difficult because the number of semantic in- put combinations grows exponentially with the number of domains. Therefore, it is im- portant to leverage existing resources and ex- ploit similarities between domains to facilitate domain adaptation. In this paper, we propose a procedure to train multi-domain, Recurrent Neural Network-based (RNN) language gen- erators via multiple adaptation steps. In this procedure, a model is first trained on counter- feited data synthesised from an out-of-domain dataset, and then fine tuned on a small set of in-domain utterances with a discriminative ob- jective function. Corpus-based evaluation re- sults show that the proposed procedure can achieve competitive performance in terms of BLEU score and slot error rate while signifi- cantly reducing the data needed to train gen- erators in new, unseen domains. In subjective testing, human judges confirm that the proce- dure greatly improves generator performance when only a small amount of data is available in the domain.","2016-06","2023-02-28 16:27:22","2023-04-15 14:14:34","2023-02-28 16:27:22","120–129","","","","","","","","","","","Association for Computational Linguistics","San Diego, California","","","","","","ACLWeb","","{'citing': ['10.1007/s10462-020-09866-x', '10.1007/978-981-10-8438-6_6', '10.1007/s10462-022-10248-8', '10.1007/s10489-020-02077-5', '10.1017/9781139061773.010', '10.1109/taslp.2018.2856625', '10.1145/3166054.3166058', '10.1145/3203422.3203431', '10.1017/9781139061773.003', '10.1017/9781139061773.004', '10.1017/9781139061773.001', '10.1017/9781139061773.008', '10.1017/9781139061773.024', '10.1109/icaibd55127.2022.9820437', '10.1017/9781139061773.015', '10.1017/9781139061773.016', '10.1017/9781139061773.023', '10.1007/s40593-020-00235-x', '10.1007/978-3-319-92537-0_55', '10.20965/jaciii.2018.p0777', '10.1017/9781139061773.014', '10.1007/s11280-018-0598-6', '10.1007/978-3-030-60290-1_24', '10.2139/ssrn.3248712', '10.1109/icmla51294.2020.00163', '10.1017/9781139061773.006', '10.1017/9781139061773.027', '10.1007/s10489-022-04190-z', '10.1017/9781139061773.012', '10.1017/9781139061773.009', '10.1007/978-3-030-24409-5_11', '10.1017/9781139061773.018', '10.1017/9781139061773.022', '10.1109/icassp43922.2022.9747600', '10.1017/9781139061773.007', '10.1007/978-981-15-8395-7_21', '10.1016/j.csl.2020.101120', '10.1017/9781139061773.019', '10.1017/9781139061773.005', '10.1109/access.2020.2976816', '10.1145/3186729', '10.1017/9781139061773.020', '10.1017/9781139061773.011', '10.1017/9781139061773.026', '10.1017/9781139061773.025', '10.1109/access.2022.3174108', '10.1109/slt.2018.8639576', '10.1007/978-3-319-91947-8_15', '10.1109/mci.2017.2708558', '10.1017/9781139061773', '10.1109/cdke46621.2019.00012', '10.1017/9781139061773.013', '10.1017/9781139061773.021', '10.1007/978-981-33-4370-2_17'], 'cited': ['10.18653/v1/n16-1015']}","","/root/snap/zotero-snap/common/Zotero/storage/24UW296U/Wen et al. - 2016 - Multi-domain Neural Network Language Generation fo.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL-HLT 2016","","","","","","","","","","","","","","",""
"UELPYECD","journalArticle","2012","Harsha Gurulingappa, Abdul Mateen Rajput, Angus Roberts, Juliane Fluck, Martin Hofmann-Apitius, Luca Toldo","Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports - PubMed","","","","10.1016/j.jbi.2012.04.008","https://www.sciencedirect.com/science/article/pii/S1532046412000615","","2012","2023-02-28 16:27:41","2023-04-15 14:14:33","2023-02-28 16:27:41","","","","","","","","","","","","","","","","","","","","","{'citing': ['10.1016/j.ymeth.2015.01.015', '10.1016/j.knosys.2021.107298', '10.2196/preprints.18417', '10.1038/s41467-022-29763-x', '10.1016/j.jbi.2021.103960', '10.2196/37201', '10.3414/me17-01-0024', '10.1007/978-3-319-47674-2_21', '10.1016/j.jbi.2014.11.002', '10.1007/s10115-022-01665-w', '10.1007/978-3-319-78503-5_10', '10.1007/s12559-021-09917-7', '10.1109/ickg52313.2021.00048', '10.1007/978-94-024-0881-2_53', '10.1007/978-1-4939-0709-0_13', '10.1016/j.eswa.2022.119216', '10.2196/preprints.22661', '10.1186/s13321-018-0290-y', '10.2196/18417', '10.1007/978-3-030-36664-3_3', '10.2196/preprints.41100', '10.1109/access.2021.3130956', '10.2196/preprints.12159', '10.1088/1742-6596/1848/1/012110', '10.1109/ccwc51732.2021.9376004', '10.1016/j.cmpb.2018.07.007', '10.1162/tacl_a_00021', '10.1093/jamia/ocz101', '10.1016/j.ipm.2020.102473', '10.1093/database/baw032', '10.1134/s0361768819080024', '10.1007/s40264-014-0218-z', '10.1016/j.jbi.2015.06.016', '10.3390/info6040790', '10.1093/jamiaopen/ooz009', '10.1109/bigdata52589.2021.9671514', '10.2196/preprints.40456', '10.1016/j.jbi.2018.12.005', '10.1093/nar/gkx462', '10.1186/s12859-021-04249-7', '10.1109/itaic54216.2022.9836511', '10.1016/bs.pmch.2017.12.003', '10.1093/database/baw068', '10.1007/978-3-319-44564-9_13', '10.1016/j.jbi.2021.103896', '10.1080/14740338.2018.1458838', '10.1007/978-3-030-80119-9_64', '10.1007/978-981-15-2407-3_17', '10.1109/iccse.2018.8468701', '10.2196/27527', '10.1002/pds.3493', '10.1371/journal.pone.0226272', '10.1007/978-3-030-77967-2_52', '10.1145/3442381.3449895', '10.1007/s00521-022-07747-8', '10.1016/j.jbi.2015.03.010', '10.32628/cseit21743', '10.1186/s12859-019-3053-5', '10.1007/978-3-030-23281-8_14', '10.1007/978-3-030-75762-5_21', '10.3233/jifs-201017', '10.1145/3038912.3052671', '10.19053/0121053x.n39.2022.13436', '10.1145/2719920', '10.2200/s01078ed2v01y202002hlt049', '10.1016/j.ijinfomgt.2018.12.007', '10.1186/1471-2105-15-64', '10.1007/978-981-19-5391-0_4', '10.1186/s13326-022-00272-6', '10.1093/bioinformatics/btaa993', '10.1016/j.neucom.2021.05.007', '10.1093/jamia/ocu041', '10.1371/journal.pcbi.1010144', '10.1007/978-3-030-34387-3_56', '10.1016/j.knosys.2022.108825', '10.1007/978-981-33-4355-9_19', '10.1186/1472-6947-15-s2-s6', '10.1109/iccc54389.2021.9674535', '10.1109/ichi.2017.59', '10.1016/j.asoc.2021.107358', '10.1007/978-981-16-8885-0_29', '10.1016/j.jbi.2015.01.011', '10.1016/j.imu.2019.100190', '10.2196/26770', '10.2196/12159', '10.1016/j.jbi.2019.103295', '10.1093/jamia/ocz018', '10.1016/j.jbi.2013.07.011', '10.1016/j.jbi.2018.10.002', '10.1007/s10115-022-01663-y', '10.1007/s41666-022-00116-z', '10.1109/smc.2017.8122680', '10.1007/978-3-030-93733-1_35', '10.1109/bibm.2015.7359750', '10.1093/database/baw046', '10.1186/s12859-017-1609-9', '10.1007/978-981-16-5157-1_33', '10.3390/app12126231', '10.1080/09540091.2022.2026295', '10.1109/bibm52615.2021.9669650', '10.1186/1472-6947-14-13', '10.1007/978-3-319-98932-7_10', '10.1016/j.jbi.2020.103437', '10.1016/j.eswa.2018.07.032', '10.1186/2041-1480-3-15', '10.3390/electronics11203336', '10.21203/rs.3.rs-2182156/v1', '10.1016/j.cmpb.2019.04.029', '10.3390/app112110064', '10.1016/j.artmed.2018.03.006', '10.1093/bib/bbaa110', '10.1007/978-3-031-14771-5_26', '10.1109/access.2018.2882443', '10.2196/22661', '10.1007/978-3-319-73013-4_1', '10.22430/22565337.1483', '10.1093/jamia/ocv037', '10.1109/icst46399.2020.00040', '10.1007/978-3-319-77113-7_36', '10.1038/s41597-019-0342-9', '10.2196/40456', '10.1145/3530190.3534850', '10.1155/2021/5589829', '10.1016/j.jbi.2020.103392', '10.2196/preprints.27527', '10.1186/s12911-022-01977-5', '10.1101/534388', '10.4018/jitr.2015040101', '10.1145/3374217', '10.1016/j.jbi.2021.103961', '10.1007/978-3-319-93417-4_8', '10.1145/3387634', '10.1016/j.ins.2021.09.028', '10.1145/3498537', '10.1016/j.jbi.2017.06.013', '10.1016/j.jbi.2012.08.001', '10.1007/s40264-018-0762-z', '10.1186/s13321-016-0165-z', '10.1109/bibm52615.2021.9669427', '10.1016/j.artmed.2021.102086', '10.3390/ijerph15061291', '10.1007/978-3-030-93733-1_37', '10.1007/978-3-031-17120-8_21', '10.7763/ijimt.2014.v5.512', '10.1016/j.jbi.2018.09.018', '10.1021/acs.chemrev.6b00851', '10.3390/bdcc6010010', '10.1007/978-3-031-16075-2_59', '10.1109/aiiot54504.2022.9817231', '10.1109/access.2019.2952154', '10.1109/icaica.2019.8873466', '10.2196/publichealth.6396', '10.1093/bib/bbac342'], 'cited': ['10.1016/j.jbi.2012.04.008']}","","/root/snap/zotero-snap/common/Zotero/storage/NY82FNZE/22554702.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WM9SRQVU","conferencePaper","2009","Hendrickx, Iris; Kim, Su Nam; Kozareva, Zornitsa; Nakov, Preslav; Ó Séaghdha, Diarmuid; Padó, Sebastian; Pennacchiotti, Marco; Romano, Lorenza; Szpakowicz, Stan","SemEval-2010 task 8: multi-way classification of semantic relations between pairs of nominals","Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions - DEW '09","978-1-932432-31-2","","10.3115/1621969.1621986","http://portal.acm.org/citation.cfm?doid=1621969.1621986","SemEval-2 Task 8 focuses on Multi-way classiﬁcation of semantic relations between pairs of nominals. The task was designed to compare different approaches to semantic relation classiﬁcation and to provide a standard testbed for future research. This paper deﬁnes the task, describes the training and test data and the process of their creation, lists the participating systems (10 teams, 28 runs), and discusses their results.","2009","2023-02-28 16:28:16","2023-10-17 16:42:07","2023-02-28 16:28:16","94","","","","","","SemEval-2010 task 8","","","","","Association for Computational Linguistics","Boulder, Colorado","en","True","","","https://drive.google.com/file/d/0B_jQiLugGTAkMDQ5ZjZiMTUtMzQ1Yy00YWNmLWJlZDYtOWY1ZDMwY2U4YjFk/view?sort=name&layout=list&num=50","DOI.org (Crossref)","","{'citing': ['10.1186/s13638-020-01720-6', '10.1016/j.oregeorev.2021.104200', '10.1007/978-3-030-80119-9_64', '10.1007/978-981-16-1964-9_8', '10.1007/978-3-030-75762-5_28', '10.1007/s11704-020-9420-6', '10.1016/j.knosys.2021.106888', '10.1007/978-3-030-79725-6_5', '10.1061/(asce)cp.1943-5487.0000977', '10.2196/preprints.27527', '10.1007/s11390-020-9713-0', '10.1007/978-3-030-72240-1_82', '10.1007/978-3-030-81007-8_72', '10.1016/j.ipm.2021.102563', '10.1007/s42521-020-00023-1', '10.1007/978-3-030-80599-9_10', '10.1007/s10489-021-02492-2', '10.1007/s10489-021-02596-9', '10.1016/j.neucom.2021.03.066', '10.1145/3451471.3451506', '10.1016/j.jbi.2021.103820', '10.1007/s12559-021-09917-7', '10.1007/s11431-020-1673-6', '10.1016/j.neucom.2021.12.044', '10.4018/ijitwe.2020070102', '10.1007/978-981-16-8062-5_33', '10.1007/s00799-021-00310-1', '10.1111/exsy.12873', '10.48084/etasr.4300', '10.1016/j.neucom.2021.10.002', '10.1016/j.jbi.2021.103932', '10.1145/3502223.3502229', '10.1017/s135132492100036x', '10.1007/978-981-16-8885-0_29', '10.1007/s00521-021-06667-3', '10.1007/s10115-022-01665-w', '10.1007/978-981-16-9573-5_25', '10.1007/s10115-022-01663-y', '10.1016/j.eswa.2022.117113', '10.1016/j.eswa.2022.117113', '10.1109/icccbda49378.2020.9095628', '10.1109/access.2020.2966303', '10.1109/mlhpc49564.2019.00010', '10.1109/ssci50451.2021.9660108', '10.1109/itaic.2019.8785831', '10.1109/access.2020.3048088', '10.1109/ijcnn48605.2020.9207554', '10.1109/ijcnn48605.2020.9207662', '10.1007/s10489-022-03596-z', '10.1109/access.2019.2948155', '10.1007/s10115-022-01687-4', '10.1109/icosc.2019.8665497', '10.1109/access.2021.3086480', '10.1109/bibm.2018.8621228', '10.1016/j.neucom.2015.12.091', '10.1109/access.2018.2888508', '10.1109/cds52072.2021.00022', '10.1109/tai.2021.3068697', '10.1109/tetci.2021.3136598', '10.1109/access.2019.2932041', '10.1109/ithings-greencom-cpscom-smartdata-cybermatics50389.2020.00094', '10.1109/s.a.i.ence50533.2020.9303196', '10.1109/tetci.2020.3040444', '10.1109/access.2020.3034907', '10.1109/gucon48875.2020.9231227', '10.1109/taslp.2018.2852502', '10.1109/icme51207.2021.9428274', '10.1109/icdm.2019.00204', '10.1109/icdm.2019.00205', '10.1109/iucc/dsci/smartcns.2019.00071', '10.1109/taslp.2021.3082295', '10.1109/iaeac47372.2019.8997966', '10.1109/ictai.2019.00227', '10.1007/s10489-022-03731-w', '10.1109/access.2018.2877934', '10.1109/cis.2019.00032', '10.1109/gncc42960.2018.9018722', '10.1109/taslp.2019.2921726', '10.1109/access.2019.2955977', '10.1109/cset.2019.8904905', '10.1109/iccse51940.2021.9569695', '10.1109/ijcnn.2019.8852408', '10.1109/nics.2018.8606824', '10.1007/s41666-022-00116-z', '10.1007/978-3-031-16075-2_59', '10.1007/s10462-022-10239-9', '10.1007/978-3-031-17288-5_8', '10.1109/inista55318.2022.9894216', '10.1007/978-3-031-16078-3_49', '10.1145/3543174.3547117', '10.1007/978-3-031-19433-7_37', '10.1007/978-3-031-19496-2_8', '10.1016/b978-0-323-89931-4.00005-5', '10.1007/978-3-030-40223-5_2', '10.12677/csa.2022.1210245', '10.1007/s11859-017-1278-6', '10.1007/s12559-016-9425-5', '10.1017/s1351324913000041', '10.1017/s1351324913000065', '10.1017/s1351324913000107', '10.1017/s135132491900024x', '10.1093/bioinformatics/btw486', '10.1007/978-981-10-8438-6_5', '10.1007/978-981-13-3146-6_8', '10.1002/sam.10135', '10.4018/ijdwm.2019100104', '10.1162/coli_a_00301', '10.1007/s00521-016-2603-2', '10.1007/s00521-016-2680-2', '10.1186/s12859-018-2584-5', '10.1186/s12859-019-2808-3', '10.1007/978-3-030-01716-3_12', '10.1007/978-3-030-04015-4_43', '10.1007/978-3-030-14596-5_1', '10.1007/978-3-030-14799-0_12', '10.1007/978-3-030-22744-9_23', '10.1007/978-3-030-23584-0_10', '10.1007/978-3-030-30490-4_4', '10.1007/978-3-030-31964-9_6', '10.1007/978-3-030-32236-6_21', '10.1007/978-3-030-32236-6_29', '10.1007/978-3-030-32236-6_65', '10.1007/978-3-030-32236-6_72', '10.1007/978-3-319-23135-8_13', '10.1371/journal.pone.0221582', '10.1007/978-3-319-45814-4_34', '10.1007/978-3-319-46128-1_28', '10.1007/978-3-319-46349-0_21', '10.1007/978-3-319-47674-2_24', '10.1007/978-3-319-50496-4_60', '10.1007/978-3-319-56535-4_11', '10.1007/978-3-319-59569-6_13', '10.1007/978-3-319-59569-6_49', '10.1007/978-3-319-70096-0_15', '10.1007/978-3-319-73618-1_31', '10.1007/978-3-319-73618-1_38', '10.1007/978-3-319-73618-1_39', '10.1007/978-3-319-73618-1_81', '10.1007/978-3-319-93701-4_15', '10.1007/978-3-319-93803-5_35', '10.1527/tjsai.ai30-l', '10.1527/tjsai.d-g96', '10.2200/s00489ed1v01y201303hlt019', '10.1007/978-3-642-19400-9_23', '10.1007/978-3-642-25261-7_25', '10.1007/978-3-642-28604-9_32', '10.1007/978-3-642-33185-5_2', '10.1007/978-3-642-41154-0_16', '10.1109/iaeac.2017.8054150', '10.1109/iciibms.2015.7439518', '10.1109/icsc.2010.73', '10.1109/ie.2017.18', '10.1109/ie.2017.28', '10.1109/ijcnn.2017.7966407', '10.1109/spc.2013.6735129', '10.1109/taslp.2016.2573050', '10.1109/access.2017.2785229', '10.1145/3041021.3054266', '10.1145/3377713.3377784', '10.1145/3184558.3191546', '10.1145/3357384.3357997', '10.1145/3357384.3358003', '10.1145/3357384.3358003', '10.1145/3357384.3358119', '10.1145/3018896.3036386', '10.1587/nolta.10.28', '10.1007/978-3-030-00665-5_90', '10.1007/978-3-319-70087-8_16', '10.1007/978-3-030-35445-9_50', '10.1007/978-981-15-1925-3_19', '10.1007/978-3-319-93037-4_29', '10.22430/22565337.1483', '10.1145/3159652.3159709', '10.1007/978-3-030-51310-8_15', '10.1145/3402885', '10.1145/3405962.3405985', '10.1145/3340531.3411858', '10.1145/3340531.3412763', '10.1007/978-3-030-32233-5_15', '10.1007/978-3-030-63799-6_5', '10.1007/978-3-030-65218-0_16', '10.1016/j.neucom.2020.08.078', '10.1016/j.neucom.2020.08.078', '10.1016/j.neucom.2020.08.078', '10.1016/j.neucom.2020.08.078', '10.1016/j.engappai.2016.01.027', '10.1016/j.neucom.2015.11.028', '10.1016/j.jbi.2016.11.004', '10.1016/j.procs.2018.04.221', '10.1016/j.procs.2018.10.475', '10.1007/978-3-030-73539-5_1', '10.1007/978-3-030-75768-7_26', '10.2196/27527', '10.1016/j.csl.2021.101265', '10.1007/s00521-020-05087-z'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/G9C8CG7Z/Hendrickx et al. - 2009 - SemEval-2010 task 8 multi-way classification of s.pdf","","SAT_oldTag:CHECKED0923; SAT_granularity:sentence; SAT_task:RC; SAT_task:NER; SAT_rel_type:Common-sense; SAT_method_selection:Human; SAT_All_checked:True; SAT_source:Web; SAT_method_selection:MultiHuman; SAT_nbtypes_relations:10; SAT_nbSent:10 000; SAT_focus:Relation between nominals","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","the Workshop","","","","","","","","","","","","","","",""
"TNU8YTME","conferencePaper","2010","Riedel, Sebastian; Yao, Limin; McCallum, Andrew","Modeling Relations and Their Mentions without Labeled Text","Machine Learning and Knowledge Discovery in Databases","978-3-642-15939-8","","10.1007/978-3-642-15939-8_10","","Several recent works on relation extraction have been applying the distant supervision paradigm: instead of relying on annotated text to learn how to predict relations, they employ existing knowledge bases (KBs) as source of supervision. Crucially, these approaches are trained based on the assumption that each sentence which mentions the two related entities is an expression of the given relation. Here we argue that this leads to noisy patterns that hurt precision, in particular if the knowledge base is not directly related to the text we are working with. We present a novel approach to distant supervision that can alleviate this problem based on the following two ideas: First, we use a factor graph to explicitly model the decision whether two entities are related, and the decision whether this relation is mentioned in a given sentence; second, we apply constraint-driven semi-supervision to train this model without any knowledge about which sentences express the relations in our training KB. We apply our approach to extract relations from the New York Times corpus and use Freebase as knowledge base. When compared to a state-of-the-art approach for relation extraction under distant supervision, we achieve 31% error reduction.","2010","2023-02-28 16:28:21","2023-10-02 05:47:26","","148-163","","","","","","","Lecture Notes in Computer Science","","","","Springer","Berlin, Heidelberg","en","","","","","Springer Link","","{'citing': ['10.1007/978-3-319-90596-9_3', '10.1007/978-3-030-32233-5_26', '10.1007/978-3-030-60450-9_41', '10.1007/978-3-030-72240-1_47', '10.1016/j.knosys.2020.105912', '10.1007/978-3-030-49461-2_6', '10.1109/icde53745.2022.00018', '10.1155/2021/7466114', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00096', '10.1109/compcomm.2018.8780970', '10.1109/icaaid51067.2022.9799502', '10.1109/access.2022.3164688', '10.1007/978-3-031-07472-1_16', '10.1007/s00778-019-00552-1', '10.1007/978-3-031-10986-7_7', '10.1016/j.jbi.2021.103956', '10.1016/j.jbi.2020.103425', '10.1016/j.neucom.2020.06.061', '10.1145/3404835.3463103', '10.1109/icde48307.2020.00093', '10.1016/j.eswa.2021.114922', '10.1145/3241741', '10.1109/tkde.2017.2754499', '10.1007/978-3-319-70139-4_22', '10.1145/3340531.3412164', '10.1007/978-3-319-69005-6_16', '10.1145/2983323.2983725', '10.1109/compcomm.2017.8322795', '10.1109/access.2019.2925502', '10.1145/3554734', '10.2200/s01078ed2v01y202002hlt049', '10.1007/s10462-022-10239-9', '10.1007/978-3-030-55130-8_13', '10.1109/access.2019.2932041', '10.1007/978-3-030-32381-3_20', '10.1007/978-3-030-04618-7_2', '10.1007/978-3-030-79463-7_52', '10.1007/978-3-030-00072-1_5', '10.1109/cds52072.2021.00022', '10.1007/s00799-021-00313-y', '10.1007/978-3-319-13704-9_3', '10.1007/978-3-319-99495-6_18', '10.1145/3038912.3052708', '10.1109/bigdata.2017.8258168', '10.1109/access.2019.2892724', '10.1109/ictai.2019.00210', '10.1109/taslp.2021.3110126', '10.1016/j.neucom.2022.04.067', '10.1109/bibm47256.2019.8983057', '10.3389/fnbot.2022.914705', '10.1016/j.knosys.2020.105548', '10.1145/3402885', '10.1109/cscwd54268.2022.9776118', '10.1007/978-3-319-77525-8_285', '10.1109/taslp.2022.3153254', '10.1007/978-3-031-00123-9_9', '10.1093/bib/bbz087', '10.1162/tacl_a_00456', '10.1007/978-981-10-8438-6_5', '10.1007/s10115-013-0675-1', '10.1109/ivs.2019.8814147', '10.1007/s10489-021-02699-3', '10.1007/s10489-021-02632-8', '10.1145/3459637.3482045', '10.1186/s12859-020-03889-5', '10.3233/ida-194476', '10.1007/s11280-021-00982-4', '10.1109/access.2020.2980859', '10.1145/3357384.3357997', '10.1145/3209978.3210031', '10.23919/eusipco47968.2020.9287502', '10.3233/sw-180333', '10.1145/3335656.3335694', '10.1007/978-3-031-19496-2_8', '10.1109/aiiot54504.2022.9817231', '10.1007/978-3-319-77113-7_33', '10.1109/cvpr52688.2022.01348', '10.1109/tvcg.2020.3030443', '10.1007/978-3-030-75762-5_64', '10.1007/s10115-019-01351-4', '10.1007/978-3-319-11382-1_12', '10.1007/978-3-030-02922-7_28', '10.1007/s00521-020-05642-8', '10.1007/978-3-319-70096-0_57', '10.1007/978-3-319-12277-9_15', '10.1007/978-3-030-41407-8_12', '10.1007/978-3-030-30793-6_25', '10.1007/978-3-030-21348-0_19', '10.1007/978-3-030-71590-8_5', '10.1007/s12559-021-09917-7', '10.1109/icbk50248.2020.00042', '10.1145/3340531.3411858', '10.1109/iccse49874.2020.9201713', '10.1007/978-981-16-0100-2_10', '10.1007/978-3-030-04284-4_5', '10.1016/j.jksuci.2014.06.004', '10.1007/978-3-319-98812-2_7', '10.1007/978-3-031-20865-2_13', '10.1007/s10489-022-03677-z', '10.1016/j.websem.2021.100656', '10.1007/s11280-019-00765-y', '10.1007/978-3-030-22744-9_23', '10.1109/access.2019.2938986', '10.1007/978-3-030-32236-6_9', '10.1007/978-981-19-5391-0_5', '10.1007/978-981-10-2993-6_6', '10.1109/itaic54216.2022.9836511', '10.1007/978-3-030-36808-1_10', '10.1145/3077136.3080666', '10.1109/qr2mse46217.2019.9021234', '10.1145/3357384.3357986', '10.1007/978-981-16-2540-4_1', '10.1109/icbk.2018.00022', '10.1101/2020.03.11.986836', '10.1007/s11280-020-00816-9', '10.1007/978-3-319-12277-9_14', '10.1162/dint_a_00103', '10.1038/s41392-021-00568-6', '10.1007/978-3-030-16142-2_16', '10.1007/978-3-319-26535-3_29', '10.1007/978-3-030-26072-9_6', '10.1109/iccsmt51754.2020.00082', '10.1145/3495162', '10.1109/cvpr.2018.00168', '10.1007/s12559-016-9425-5', '10.1038/s42256-020-0189-y', '10.1145/3451471.3451506', '10.1007/s00521-021-06667-3', '10.1007/978-3-030-89698-0_64', '10.1007/978-981-15-1956-7_6', '10.1145/3159652.3159709', '10.1186/s13638-020-01720-6', '10.1007/978-3-319-23708-4_7', '10.1007/978-3-030-55130-8_11', '10.1007/978-3-030-18590-9_75', '10.1007/978-3-030-75768-7_33', '10.1007/s11633-022-1323-6', '10.1101/626226', '10.4018/ijswis.2020040101', '10.1007/978-3-030-29908-8_12', '10.1007/978-3-030-14596-5_1', '10.3390/app12136361', '10.1007/978-3-319-25816-4_21', '10.1007/s11280-021-00979-z', '10.1109/iceca52323.2021.9675884', '10.1145/3488560.3498409', '10.1109/bibm.2018.8621136', '10.1007/978-3-030-32381-3_19', '10.1007/978-3-030-32236-6_2', '10.1109/ijcnn48605.2020.9206648', '10.1109/ijcnn.2019.8852408', '10.3233/ida-194492', '10.1109/dsc50466.2020.00021', '10.1109/tkde.2020.2964747', '10.1007/978-3-319-78583-7_2', '10.1051/matecconf/201818903025', '10.1109/smds49396.2020.00015', '10.1007/978-3-030-01421-6_26', '10.1177/0165551515610989', '10.1109/taslp.2021.3082295', '10.1109/icarm.2017.8273158', '10.1109/bsb.2016.7552135', '10.1109/idsta53674.2021.9660801', '10.1007/978-3-319-93935-3_6', '10.1016/j.neunet.2018.01.006', '10.1007/978-3-319-48740-3_42', '10.1007/978-3-319-63962-8_285-1', '10.1109/icmcce.2017.14', '10.1007/s00778-016-0437-2', '10.1007/s10489-021-02596-9', '10.1007/s10489-021-03002-0', '10.1109/citsm47753.2019.8965423', '10.1109/icassp43922.2022.9746958', '10.37882/2223-2966.2021.05.15', '10.1371/journal.pone.0171929', '10.1016/j.procs.2017.08.208', '10.1049/cit2.12033', '10.1109/ijcnn.2019.8851951', '10.1109/access.2021.3073428', '10.1016/j.knosys.2019.03.025', '10.1109/icbda.2016.7509818', '10.1016/j.ins.2020.10.030', '10.1007/978-3-031-10983-6_31', '10.1007/978-3-030-32233-5_15', '10.1007/978-3-030-32381-3_24', '10.1016/j.asoc.2022.108604', '10.1007/978-3-319-93417-4_17', '10.1007/978-3-319-16354-3_46', '10.1007/978-3-031-06794-5_12', '10.1007/978-981-15-8101-4_10', '10.1145/3436369.3437431', '10.1145/3289600.3291004', '10.1007/978-3-030-73197-7_32', '10.1186/s12859-022-04646-6', '10.1109/access.2020.2970119', '10.1109/taslp.2022.3199655', '10.3233/jcm-193723', '10.1145/3394486.3403047', '10.1145/3457682.3457765', '10.4218/etrij.2020-0460', '10.1007/978-3-642-45068-6_30', '10.1145/3477495.3531876', '10.1109/icsess52187.2021.9522255', '10.5715/jnlp.28.965', '10.1371/journal.pone.0216913', '10.1007/978-3-319-11915-1_32', '10.1145/3474198.3478487', '10.1007/978-3-030-79463-7_21', '10.1007/978-3-030-00671-6_11', '10.1007/978-3-030-75768-7_29', '10.1007/978-3-642-37186-8_9', '10.2200/s00860ed1v01y201806dmk015', '10.1007/s13042-021-01491-6', '10.1109/icccs52626.2021.9449230', '10.3233/sw-150180', '10.1109/ijcnn.2019.8852286', '10.1007/978-3-030-82147-0_13', '10.3390/app12178821', '10.1007/978-3-030-60450-9_22', '10.1007/978-3-319-26832-3_55', '10.3233/idt-180352', '10.1007/978-3-319-59858-1_5', '10.1007/978-3-030-32236-6_72', '10.1007/978-3-642-53917-6_37', '10.1007/978-981-16-5188-5_2', '10.1088/1742-6596/1550/3/032065', '10.1007/978-3-030-89363-7_23', '10.1049/cit2.12008', '10.1007/978-3-319-45880-9_12', '10.1007/s11431-020-1673-6', '10.1109/ijcnn52387.2021.9533807', '10.1145/3384544.3384582', '10.1109/access.2018.2888508', '10.1007/978-981-10-0515-2_12', '10.1007/978-3-319-50496-4_44', '10.5715/jnlp.28.183', '10.1007/978-3-030-18590-9_29', '10.1109/icnidc.2016.7974612', '10.1186/s12859-020-3457-2', '10.1007/978-3-030-23551-2_3', '10.1145/3077136.3080735', '10.1007/978-3-031-00129-1_29', '10.1145/3210713.3210728', '10.1007/978-3-319-41706-6_18', '10.1371/journal.pone.0260426', '10.1155/2019/6789520', '10.1007/s00521-019-04430-3', '10.1007/s10032-022-00399-3', '10.1007/s10489-021-02492-2', '10.1007/s10115-020-01502-y', '10.1109/ijcnn.2019.8852378', '10.1145/3488560.3498377', '10.1007/s10489-022-03547-8', '10.1007/978-3-642-40585-3_25', '10.1145/3510030', '10.1007/978-981-19-1742-4_40', '10.1145/3366424.3383757', '10.1109/ijcnn55064.2022.9892310', '10.1007/978-3-031-19433-7_37', '10.1007/978-981-10-7877-4_30', '10.1109/iceiec49280.2020.9152287', '10.1002/cae.22122', '10.1007/s00799-015-0139-1', '10.1007/978-3-030-00671-6_3', '10.1007/978-3-030-34223-4_20', '10.1587/transinf.2020edp7249', '10.1007/978-3-030-41407-8_18', '10.1007/978-3-030-03667-6_27', '10.1109/bigdata50022.2020.9378317', '10.1016/j.asoc.2021.107080', '10.1109/access.2017.2785229', '10.1109/ictai.2019.00040', '10.1145/3207677.3278063', '10.1007/s11432-018-9721-7', '10.1007/978-3-030-43887-6_6', '10.1016/j.neucom.2020.07.077', '10.1109/iciea48937.2020.9248138', '10.1007/978-3-030-00671-6_12', '10.1007/978-3-030-21348-0_3', '10.1109/iccst50977.2020.00059', '10.1007/s11837-021-04902-9', '10.1007/978-981-19-6142-7_10', '10.1145/3511808.3557323', '10.1145/2882903.2904442', '10.1109/imcec51613.2021.9482001', '10.1145/2783258.2788580', '10.3233/ida-184238', '10.1007/978-3-030-88480-2_24', '10.1007/978-3-319-12580-0_2', '10.1109/icosc.2015.7050814', '10.1007/978-981-16-9492-9_302', '10.1007/978-3-030-03667-6_12', '10.1007/978-3-030-32236-6_8', '10.1093/bioinformatics/btaa430', '10.1155/2021/6110885', '10.1145/3374217', '10.1145/3486622.3494010', '10.1109/icsp54964.2022.9778528', '10.1145/3055167.3055184', '10.1109/taslp.2016.2573050', '10.1016/j.ipm.2021.102563', '10.1109/ijcnn.2018.8489631', '10.1109/tbdata.2022.3144151', '10.1007/s00521-022-07312-3', '10.1145/2641730.2641735', '10.1007/978-3-319-63962-8_285-2', '10.1007/s11063-021-10548-0', '10.1109/ijcnn52387.2021.9534215', '10.1007/978-981-10-7359-5_6', '10.1016/j.neunet.2021.03.030', '10.1109/ichi.2019.8904821'], 'cited': ['10.1007/978-3-642-15939-8_10']}","","/root/snap/zotero-snap/common/Zotero/storage/IUJ6MVZ2/Riedel et al. - 2010 - Modeling Relations and Their Mentions without Labe.pdf","","SAT_source:FreeBase","Relation Extraction; Computational Linguistics; Factor Graph; Related Entity; Relation Type","Balcázar, José Luis; Bonchi, Francesco; Gionis, Aristides; Sebag, Michèle","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D7BU8ZW9","preprint","2021","Schindler, David; Bensmann, Felix; Dietze, Stefan; Krüger, Frank","SoMeSci- A 5 Star Open Data Gold Standard Knowledge Graph of Software Mentions in Scientific Articles","","","","10.1145/3459637.3482017","http://arxiv.org/abs/2108.09070","Knowledge about software used in scientific investigations is important for several reasons, for instance, to enable an understanding of provenance and methods involved in data handling. However, software is usually not formally cited, but rather mentioned informally within the scholarly description of the investigation, raising the need for automatic information extraction and disambiguation. Given the lack of reliable ground truth data, we present SoMeSci—Software Mentions in Science—a gold standard knowledge graph of software mentions in scientific articles. It contains high quality annotations (IRR: 𝜅=.82) of 3756 software mentions in 1367 PubMed Central articles. Besides the plain mention of the software, we also provide relation labels for additional information, such as the version, the developer, a URL or citations. Moreover, we distinguish between different types, such as application, plugin or programming environment, as well as different types of mentions, such as usage or creation. To the best of our knowledge, SoMeSci is the most comprehensive corpus about software mentions in scientific articles, providing training samples for Named Entity Recognition, Relation Extraction, Entity Disambiguation, and Entity Linking. Finally, we sketch potential use cases and provide baseline results.","2021-08-20","2023-03-22 11:25:57","2023-04-15 14:14:26","2023-03-22 11:25:57","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","{'citing': ['10.7717/peerj-cs.835', '10.1109/percomworkshops53856.2022.9767387'], 'cited': ['10.1145/3459637.3482017']}","","/root/snap/zotero-snap/common/Zotero/storage/EZTZ8ZI3/Schindler et al. - 2021 - SoMeSci- A 5 Star Open Data Gold Standard Knowledg.pdf","","Pwc_task:Relation Extraction; Pwc_task:Named Entity Recognition (NER); Pwc_task:Entity Linking; Pwc_task:Named Entity Recognition; Pwc_task:named-entity-recognition; Pwc_task:Entity Disambiguation","⚠️ Invalid DOI; Computer Science - Computation and Language; Computer Science - Information Retrieval","","","","","","","","","","","","","","","","","","","arXiv:2108.09070","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9V2F9QDT","preprint","2020","Kruiper, Ruben; Vincent, Julian F. V.; Chen-Burger, Jessica; Desmulliez, Marc P. Y.; Konstas, Ioannis","In Layman's Terms: Semi-Open Relation Extraction from Scientific Texts","","","","10.18653/v1/2020.acl-main.137","http://arxiv.org/abs/2005.07751","Information Extraction (IE) from scientific texts can be used to guide readers to the central information in scientific documents. But narrow IE systems extract only a fraction of the information captured, and Open IE systems do not perform well on the long and complex sentences encountered in scientific texts. In this work we combine the output of both types of systems to achieve Semi-Open Relation Extraction, a new task that we explore in the Biology domain. First, we present the Focused Open Biological Information Extraction (FOBIE) dataset and use FOBIE to train a state-of-the-art narrow scientific IE system to extract trade-off relations and arguments that are central to biology texts. We then run both the narrow IE system and a state-of-the-art Open IE system on a corpus of 10k open-access scientific biological texts. We show that a significant amount (65%) of erroneous and uninformative Open IE extractions can be filtered using narrow IE extractions. Furthermore, we show that the retained extractions are significantly more often informative to a reader.","2020-05-26","2023-03-22 11:21:38","2023-04-15 14:14:23","2023-03-22 11:21:38","","","","","","","In Layman's Terms","","","","","arXiv","","en","","","","","arXiv.org","","{'citing': ['10.1145/3529372.3530924', '10.3390/info13100466', '10.1109/access.2021.3056927', '10.1115/1.4051681', '10.1007/978-3-031-17288-5_6', '10.1016/j.procs.2021.02.087'], 'cited': ['10.18653/v1/2020.acl-main.137']}","","/root/snap/zotero-snap/common/Zotero/storage/2L96K4G7/Kruiper et al. - 2020 - In Layman's Terms Semi-Open Relation Extraction f.pdf","","Pwc_task:Relation Extraction","⚠️ Invalid DOI; Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2005.07751","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"46VTXRGJ","conferencePaper","2018","Han, Xu; Zhu, Hao; Yu, Pengfei; Wang, Ziyun; Yao, Yuan; Liu, Zhiyuan; Sun, Maosong","FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation","Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/d18-1514","https://aclanthology.org/D18-1514","We present a Few-Shot Relation Classification Dataset (dataset), consisting of 70, 000 sentences on 100 relations derived from Wikipedia and annotated by crowdworkers. The relation of each sentence is first recognized by distant supervision methods, and then filtered by crowdworkers. We adapt the most recent state-of-the-art few-shot learning methods for relation classification and conduct thorough evaluation of these methods. Empirical results show that even the most competitive few-shot learning models struggle on this task, especially as compared with humans. We also show that a range of different reasoning skills are needed to solve our task. These results indicate that few-shot relation classification remains an open problem and still requires further research. Our detailed analysis points multiple directions for future research.","2018-10","2023-02-28 16:26:30","2023-10-17 16:53:59","2023-02-28 16:26:30","4803–4809","","","","","","FewRel","","","","","Association for Computational Linguistics","Brussels, Belgium","","True","","https://paperswithcode.com/paper/fewrel-a-large-scale-supervised-few-shot","https://github.com/thunlp/FewRel","ACLWeb","","{'citing': ['10.1007/978-3-030-32236-6_72', '10.1007/978-3-030-41964-6_37', '10.1145/3371158.3371186', '10.1093/bib/bbz087', '10.1007/978-981-15-3341-9_13', '10.1145/3357384.3358100', '10.1186/s13638-020-01720-6', '10.1007/978-981-15-5573-2_11', '10.1007/978-981-15-5573-2_4', '10.3389/fnbot.2020.584192', '10.1145/3340531.3411858', '10.1145/3340531.3411910', '10.1145/3340531.3412011', '10.1145/3340531.3412153', '10.1145/3419972', '10.1145/3419972', '10.1145/3419972', '10.1145/3419972', '10.1007/978-3-030-60457-8_15', '10.1145/3394486.3403244', '10.1007/s11431-020-1673-6', '10.1007/978-3-030-62419-4_11', '10.3390/rs12244046', '10.1016/j.eswa.2020.113819', '10.1016/j.ipm.2021.102563', '10.1007/s10489-021-02596-9', '10.1016/j.ipm.2021.102596', '10.1016/j.aiopen.2021.06.004', '10.1007/978-3-030-73200-4_38', '10.1016/j.neunet.2021.03.030', '10.1145/3453483.3454047', '10.1007/978-3-030-87571-8_29', '10.1007/978-981-16-5943-0_10', '10.1007/978-3-030-82136-4_9', '10.1587/transinf.2020bdp0021', '10.3233/jifs-210795', '10.1145/3447548.3467438', '10.1007/978-3-030-84186-7_21', '10.1162/tacl_a_00392', '10.1007/978-3-030-84186-7_13', '10.1145/3459637.3482403', '10.1016/j.neucom.2021.10.002', '10.1145/3459637.3482436', '10.1016/j.jii.2021.100301', '10.1007/978-3-030-88480-2_23', '10.1145/3484729', '10.1145/3459637.3482280', '10.1007/978-981-16-6471-7_4', '10.1145/3459637.3482268', '10.1007/s00521-021-06667-3', '10.1007/978-3-030-88132-0_4', '10.1007/s44196-021-00053-6', '10.1145/3529954', '10.1145/3485447.3511998', '10.1007/s10489-022-03210-2', '10.1016/j.neucom.2022.04.067', '10.1007/s11432-020-3055-1', '10.1109/ssci50451.2021.9660108', '10.1016/j.csl.2022.101432', '10.1145/3510030', '10.1007/s10489-022-03596-z', '10.1109/taslp.2022.3153254', '10.1109/ictai52525.2021.00191', '10.1109/icsess52187.2021.9522191', '10.1117/12.2631869', '10.1109/s.a.i.ence50533.2020.9303192', '10.3390/s22134911', '10.1109/cbd54617.2021.00026', '10.1109/ickg52313.2021.00040', '10.1109/aiea53260.2021.00069', '10.1109/icccs52626.2021.9449297', '10.1109/icme51207.2021.9428274', '10.1109/bibm47256.2019.8983057', '10.1109/iccv48922.2021.01603', '10.1109/icassp39728.2021.9413437', '10.1145/3477495.3531831', '10.1109/icarm52023.2021.9536124', '10.1109/access.2019.2955977', '10.1109/access.2022.3164688', '10.1016/j.compind.2022.103753', '10.1007/978-3-031-12423-5_2', '10.1109/taslp.2022.3199655', '10.1145/3534678.3539340', '10.1109/cvprw56347.2022.00447', '10.1007/s10489-022-03880-y', '10.3390/electronics11152423', '10.1109/tkde.2020.3038670', '10.1109/itaic54216.2022.9836511', '10.1007/s10489-022-03677-z', '10.1007/978-3-031-19433-7_37', '10.1145/3511808.3557323', '10.1145/3511808.3557422', '10.1109/asiancon55314.2022.9909125', '10.1109/tcss.2022.3178416', '10.1145/3563766.3564109', '10.1007/978-3-031-18315-7_7', '10.1007/978-3-031-18315-7_6', '10.3390/math10224378', '10.1016/b978-0-323-89931-4.00005-5'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/5L5BC9UD/Han et al. - 2018 - FewRel A Large-Scale Supervised Few-Shot Relation.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_task:RC; SAT_task:CorefReso; SAT_task:EntityLinking; SAT_task:NER; SAT_learning:FewShot; SAT_task:OpenIE; SAT_source:Wikidata; SAT_method_selection:Human; SAT_source:Wikipedia; SAT_All_checked:False; SAT_method_selection:Distant; SAT_nbTriples:56000; SAT_nbtypes_relations:100; SAT_task:Classification; SAT_task:FewShot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2018","","","","","","","","","","","","","","",""
"FB7VPGIU","conferencePaper","2021","Cheng, Qiao; Liu, Juntao; Qu, Xiaoye; Zhao, Jin; Liang, Jiaqing; Wang, Zhefeng; Huai, Baoxing; Yuan, Nicholas Jing; Xiao, Yanghua","HacRED: A Large-Scale Relation Extraction Dataset Toward Hard Cases in Practical Applications","Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021","","","10.18653/v1/2021.findings-acl.249","https://aclanthology.org/2021.findings-acl.249","","2021-08","2023-03-22 11:25:40","2023-10-17 16:40:45","2023-03-22 11:25:40","2819–2831","","","","","","HacRED","","","","","Association for Computational Linguistics","Online","","True","","https://paperswithcode.com/paper/hacred-a-large-scale-relation-extraction","https://github. com/qiaojiim/HacRED","ACLWeb","","{'citing': ['10.3390/app12031599'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/V6IWFSJX/Cheng et al. - 2021 - HacRED A Large-Scale Relation Extraction Dataset .pdf","","SAT_oldTag:CHECKED0923; SAT_granularity:document; SAT_task:RC; SAT_task:EntityLinking; SAT_task:NER; SAT_lang:chinese; SAT_rel_type:overlapping; SAT_method_selection:Human; SAT_source:Wikipedia; SAT_source:DBpedia; SAT_rel_type:LongTailRelation; SAT_rel_type:MultipleTriples; SAT_nbtypes_relations:26; SAT_nbTriples:67047; SAT_nbDoc:9231; SAT_focus:ComplexRelations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings 2021","","","","","","","","","","","","","","",""
"HLU2QW43","preprint","2018","Luan, Yi; He, Luheng; Ostendorf, Mari; Hajishirzi, Hannaneh","Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction","","","","10.18653/v1/d18-1360","http://arxiv.org/abs/1808.09602","We introduce a multi-task setup of identifying and classifying entities, relations, and coreference clusters in scientific articles. We create SciERC, a dataset that includes annotations for all three tasks and develop a unified framework called Scientific Information Extractor (SciIE) for with shared span representations. The multi-task setup reduces cascading errors between tasks and leverages cross-sentence relations through coreference links. Experiments show that our multi-task model outperforms previous models in scientific information extraction without using any domain-specific features. We further show that the framework supports construction of a scientific knowledge graph, which we use to analyze information in scientific literature.","2018-08-28","2023-02-28 16:26:18","2023-05-04 08:10:30","2023-02-28 16:26:18","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","{'citing': ['10.6339/21-jds1012', '10.1109/access.2020.3034894', '10.1145/3511808.3557459', '10.1007/978-3-030-62466-8_9', '10.1007/978-3-030-64452-9_1', '10.1145/3336191.3371878', '10.1007/978-3-031-12285-9_15', '10.1145/3383583.3398504', '10.1109/icsess49938.2020.9237741', '10.1146/annurev-biodatasci-010820-091627', '10.1145/3404835.3462792', '10.1145/3397271.3401289', '10.1007/s00799-021-00306-x', '10.1007/978-981-16-0479-9_5', '10.1162/tacl_a_00515', '10.1109/trustcom50675.2020.00083', '10.1145/3377325.3377503', '10.1109/taslp.2021.3105013', '10.1109/icicn52636.2021.9673905', '10.1007/978-3-030-54956-5_1', '10.1007/978-3-031-12423-5_5', '10.1109/iccc54389.2021.9674535', '10.3390/app12136361', '10.1109/icassp43922.2022.9747455', '10.1007/s11192-022-04332-7', '10.1016/j.jbi.2021.103761', '10.1109/ijcnn48605.2020.9207021', '10.3389/fnbot.2021.635492', '10.1016/j.knosys.2022.109129', '10.1007/978-3-031-19433-7_39', '10.1109/ijcnn52387.2021.9533951', '10.1007/s00521-022-07747-8', '10.1007/978-3-030-91669-5_35', '10.1007/978-981-16-6471-7_7', '10.1515/auto-2021-0050', '10.1145/3442381.3449895', '10.1007/978-981-16-8885-0_29', '10.1007/978-3-030-89363-7_6', '10.1145/3394486.3406465', '10.1007/978-3-030-73197-7_13', '10.1007/978-3-031-17120-8_21', '10.1186/s12911-022-01862-1', '10.1007/978-3-030-62327-2_37', '10.2478/jdis-2021-0023', '10.1016/j.commatsci.2021.110325', '10.1162/tacl_a_00389', '10.1007/978-3-031-18315-7_11', '10.1109/access.2019.2930340', '10.1109/ickg52313.2021.00048', '10.1145/3487553.3524654', '10.1162/dint_a_00116', '10.1016/j.knosys.2022.109945', '10.1145/3485447.3512182', '10.1145/3529372.3530922', '10.1016/j.rcradv.2021.200057', '10.1016/j.compag.2022.107127', '10.1007/978-3-031-15428-7_22', '10.1007/978-3-030-60450-9_65', '10.1016/j.jbi.2020.103631', '10.1109/ictai.2019.00064', '10.1145/3491102.3502087', '10.1016/j.ipm.2021.102563', '10.1007/978-3-030-93733-1_23', '10.1145/3491102.3501905', '10.1007/978-3-030-32327-1_2', '10.1007/978-3-030-72113-8_6', '10.1007/978-3-030-45439-5_17', '10.1109/icoice48418.2019.9035170', '10.1145/3292500.3330942', '10.1007/s00799-021-00313-y', '10.1145/3511808.3557169', '10.1109/jsac.2022.3191112', '10.1016/j.future.2020.10.026', '10.1007/s11276-022-03077-8', '10.1002/pra2.303', '10.1007/s40747-022-00806-6', '10.1109/access.2022.3180830', '10.1162/tacl_a_00404', '10.3233/sw-212955', '10.1007/978-3-030-49461-2_16', '10.1162/qss_a_00183', '10.1007/978-3-031-16802-4_3', '10.1016/j.eswa.2022.118936', '10.1109/tns.2022.3162216', '10.1007/978-3-030-91669-5_31', '10.1515/comp-2020-0209', '10.1109/isi53945.2021.9624840', '10.1007/978-3-030-59028-4_10', '10.3390/app122311971', '10.1109/access.2022.3177752', '10.1145/3340531.3412011', '10.1007/978-3-030-86324-1_4', '10.1109/dtpi52967.2021.9540098', '10.1007/978-3-030-84529-2_39', '10.3390/app12126231', '10.1145/3508546.3508639', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00090', '10.1527/tjsai.dsi-h', '10.1109/icceai55464.2022.00094', '10.1145/3529372.3530917', '10.1007/s11265-022-01778-z', '10.1007/978-3-031-19433-7_37', '10.1109/icbk50248.2020.00050', '10.1145/3340531.3412783'], 'cited': ['10.18653/v1/d18-1360']}","","/root/snap/zotero-snap/common/Zotero/storage/ZPBLXZPL/Luan et al. - 2018 - Multi-Task Identification of Entities, Relations, .pdf","","crit:OutOfDomain","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:1808.09602","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A24JGTQ5","conferencePaper","2019","Gao, Tianyu; Han, Xu; Zhu, Hao; Liu, Zhiyuan; Li, Peng; Sun, Maosong; Zhou, Jie","FewRel 2.0: Towards More Challenging Few-Shot Relation Classification","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","10.18653/v1/d19-1649","https://aclanthology.org/D19-1649","We present FewRel 2.0, a more challenging task to investigate two aspects of few-shot relation classification models: (1) Can they adapt to a new domain with only a handful of instances? (2) Can they detect none-of-the-above (NOTA) relations? To construct FewRel 2.0, we build upon the FewRel dataset by adding a new test set in a quite different domain, and a NOTA relation choice. With the new dataset and extensive experimental analysis, we found (1) that the state-of-the-art few-shot relation classification models struggle on these two aspects, and (2) that the commonly-used techniques for domain adaptation and NOTA detection still cannot handle the two challenges well. Our research calls for more attention and further efforts to these two real-world issues. All details and resources about the dataset and baselines are released at https://github.com/thunlp/fewrel.","2019-11","2023-02-28 16:25:14","2023-10-17 16:44:04","2023-02-28 16:25:14","6250–6255","","","","","","FewRel 2.0","","","","","Association for Computational Linguistics","Hong Kong, China","","True","","https://paperswithcode.com/paper/fewrel-20-towards-more-challenging-few-shot","https://github.com/thunlp/fewrel","ACLWeb","","{'citing': ['10.1145/3340531.3411858', '10.1145/3340531.3412153', '10.1007/978-3-030-67661-2_37', '10.2196/25670', '10.2196/preprints.25670', '10.1016/j.ipm.2021.102596', '10.1162/tacl_a_00392', '10.1145/3447548.3467438', '10.1007/s12559-021-09917-7', '10.1007/978-3-030-82136-4_9', '10.1007/978-3-030-84186-7_13', '10.1016/j.jii.2021.100301', '10.1007/978-3-030-88480-2_56', '10.1145/3459637.3482268', '10.1145/3459637.3482280', '10.1016/j.ipm.2021.102863', '10.1007/s00521-021-06667-3', '10.1016/j.neucom.2022.04.067', '10.1109/ssci50451.2021.9660108', '10.1007/978-3-030-93119-3_8', '10.1016/j.csl.2022.101432', '10.1007/s13042-022-01604-9', '10.1145/3510030', '10.1007/s10489-022-03596-z', '10.1109/taslp.2022.3153254', '10.1117/12.2631869', '10.1109/s.a.i.ence50533.2020.9303192', '10.1109/icccs52626.2021.9449297', '10.1109/iv51561.2020.00051', '10.1109/cvprw56347.2022.00447', '10.3390/electronics11152423', '10.1145/3511808.3557323', '10.1145/3511808.3557422', '10.1109/taffc.2022.3205358', '10.3390/math10224378'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/25GFZVNA/Gao et al. - 2019 - FewRel 2.0 Towards More Challenging Few-Shot Rela.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RC; SAT_focus:TransferLearning; SAT_learning:FewShot; SAT_domain:biomedical; SAT_source:Wikidata; SAT_source:Wikipedia; SAT_extend:FewRel; SAT_source:PubMed; SAT_source:UMLS; SAT_task:Classification; SAT_task:FewShot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP-IJCNLP 2019","","","","","","","","","","","","","","",""
"SNEAIYCA","conferencePaper","2019","Sousa, Diana; Lamurias, Andre; Couto, Francisco M.","A Silver Standard Corpus of Human Phenotype-Gene Relations","Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)","","","10.18653/v1/n19-1152","https://aclanthology.org/N19-1152","Human phenotype-gene relations are fundamental to fully understand the origin of some phenotypic abnormalities and their associated diseases. Biomedical literature is the most comprehensive source of these relations, however, we need Relation Extraction tools to automatically recognize them. Most of these tools require an annotated corpus and to the best of our knowledge, there is no corpus available annotated with human phenotype-gene relations. This paper presents the Phenotype-Gene Relations (PGR) corpus, a silver standard corpus of human phenotype and gene annotations and their relations. The corpus consists of 1712 abstracts, 5676 human phenotype annotations, 13835 gene annotations, and 4283 relations. We generated this corpus using Named-Entity Recognition tools, whose results were partially evaluated by eight curators, obtaining a precision of 87.01%. By using the corpus we were able to obtain promising results with two state-of-the-art deep learning tools, namely 78.05% of precision. The PGR corpus was made publicly available to the research community.","2019-06","2023-03-22 11:25:21","2023-10-17 16:53:24","2023-03-22 11:25:21","1487–1492","","","","","","PGR","","","","","Association for Computational Linguistics","Minneapolis, Minnesota","","True","","https://paperswithcode.com/paper/a-silver-standard-corpus-of-human-phenotype","https://github.com/lasigeBioTM/PGR","ACLWeb","","{'citing': ['10.1007/978-3-030-45442-5_46', '10.1007/978-1-0716-0826-5_14', '10.5808/gi.2020.18.2.e20', '10.1007/978-3-030-72240-1_82', '10.1007/s12559-021-09917-7', '10.1007/978-3-030-88189-4_15', '10.2196/preprints.37817', '10.2196/37817', '10.1109/jbhi.2022.3173558'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/RMCHQXX6/Sousa et al. - 2019 - A Silver Standard Corpus of Human Phenotype-Gene R.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_task:NER; SAT_domain:biomedical; SAT_granularity:paragraph; SAT_lang:english; SAT_method_selection:Distant; SAT_source:PubMed; SAT_nbtypes_relations:2","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL-HLT 2019","","","","","","","","","","","","","","",""
"GQBSL2QX","conferencePaper","2017","Gardent, Claire; Shimorina, Anastasia; Narayan, Shashi; Perez-Beltrachini, Laura","Creating Training Corpora for NLG Micro-Planners","Proceedings of the 55th Annual Meeting of the Association for           Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/p17-1017","http://aclweb.org/anthology/P17-1017","In this paper, we present a novel framework for semi-automatically creating linguistically challenging microplanning data-to-text corpora from existing Knowledge Bases. Because our method pairs data of varying size and shape with texts ranging from simple clauses to short texts, a dataset created using this framework provides a challenging benchmark for microplanning. Another feature of this framework is that it can be applied to any large scale knowledge base and can therefore be used to train and learn KB verbalisers. We apply our framework to DBpedia data and compare the resulting dataset with Wen et al. (2016)’s. We show that while Wen et al.’s dataset is more than twice larger than ours, it is less diverse both in terms of input and in terms of text. We thus propose our corpus generation framework as a novel method for creating challenging data sets from which NLG models can be learned which are capable of handling the complex interactions occurring during in micro-planning between lexicalisation, aggregation, surface realisation, referring expression generation and sentence segmentation. To encourage researchers to take up this challenge, we recently made available a dataset created using this framework in the context of the WEBNLG shared task.","2017","2023-02-28 16:26:50","2023-10-17 16:45:19","2023-02-28 16:26:50","179-188","","","","","","WebNLG","","","","","Association for Computational Linguistics","Vancouver, Canada","en","True","","https://paperswithcode.com/paper/creating-training-corpora-for-nlg-micro","https://gitlab.com/shimorina/webnlg-dataset","DOI.org (Crossref)","","{'citing': ['10.1145/3297280.3297571', '10.1007/978-3-030-30793-6_22', '10.1162/coli_a_00363', '10.1162/coli_a_00370', '10.1007/978-3-030-33274-7_5', '10.1145/3209978.3210031', '10.1088/1742-6596/1487/1/012009', '10.1145/3383652.3423884', '10.1007/978-3-030-60450-9_22', '10.1007/978-3-030-54832-2_13', '10.1007/978-3-030-62419-4_24', '10.2139/ssrn.3248712', '10.1007/978-3-030-73197-7_32', '10.1007/978-3-030-74296-6_19', '10.1016/j.neucom.2020.12.083', '10.3233/jifs-210281', '10.1016/j.asoc.2021.107080', '10.1007/978-3-030-75762-5_64', '10.1016/j.knosys.2021.106888', '10.1162/tacl_a_00381', '10.1007/s12559-021-09917-7', '10.1007/978-3-030-86523-8_34', '10.1007/s10618-021-00801-4', '10.5715/jnlp.28.965', '10.1145/3459637.3482045', '10.1145/3485766', '10.1145/3488560.3498409', '10.1016/j.asoc.2022.108604', '10.1007/s10489-021-03002-0', '10.1007/s10489-021-02699-3', '10.1371/journal.pone.0260426', '10.3233/sw-222925', '10.47164/ijngc.v13i1.377', '10.1007/978-981-19-1742-4_40', '10.1007/978-981-16-9492-9_302', '10.1109/icassp43922.2022.9746958', '10.1007/978-3-031-10986-7_7', '10.1162/tacl_a_00484', '10.1007/978-3-031-07472-1_16', '10.1109/icdm51629.2021.00165', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00090', '10.1109/icpr48806.2021.9413232', '10.1109/icmla51294.2020.00163', '10.1109/icbk50248.2020.00060', '10.1145/3462757.3466148', '10.3390/electronics11142161', '10.1007/978-981-19-2456-9_66', '10.1109/iccse49874.2020.9201713', '10.3390/app12136361', '10.1145/3487553.3524637', '10.1007/978-3-031-19433-7_32', '10.1007/978-3-031-19433-7_37', '10.1145/3511808.3557459', '10.1007/978-3-031-20865-2_13', '10.1109/ijcnn55064.2022.9892310', '10.1109/tpami.2021.3118703', '10.1007/978-981-19-5538-9_7', '10.1007/978-981-19-6142-7_10'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/JZPRSLQK/Gardent et al. - 2017 - Creating Training Corpora for NLG Micro-Planners.pdf","","SAT_oldTag:CHECKED0923; SAT_granularity:sentence; SAT_task:TextGeneration; SAT_task:Retrieval; SAT_lang:english; SAT_source:DBpedia; SAT_nbtypes_entity:6; SAT_rel_type:MultipleTriples; SAT_method_selection:MultiHuman; SAT_task:Spanning; SAT_nbtypes_relations:172; SAT_NbEntity:962; SAT_nbTriples:5068; SAT_nbDoc:13339; SAT_task:Data-to-text; SAT_focus:AnnotationQuality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 55th Annual Meeting of the Association for           Computational Linguistics (Volume 1: Long Papers)","","","","","","","","","","","","","","",""
"AT5BZGU8","conferencePaper","2017","Zhang, Yuhao; Zhong, Victor; Chen, Danqi; Angeli, Gabor; Manning, Christopher D.","Position-aware Attention and Supervised Data Improve Slot Filling","Proceedings of the 2017 Conference on Empirical Methods in Natural           Language Processing","","","10.18653/v1/d17-1004","http://aclweb.org/anthology/D17-1004","Organized relational knowledge in the form of “knowledge graphs” is important for many applications. However, the ability to populate knowledge bases with facts automatically extracted from documents has improved frustratingly slowly. This paper simultaneously addresses two issues that have held back prior work. We ﬁrst propose an effective new model, which combines an LSTM sequence model with a form of entity position-aware attention that is better suited to relation extraction. Then we build TACRED, a large (119,474 examples) supervised relation extraction dataset, obtained via crowdsourcing and targeted towards TAC KBP relations. The combination of better supervised data and a more appropriate high-capacity model enables much better relation extraction performance. When the model trained on this new dataset replaces the previous relation extraction component of the best TAC KBP 2015 slot ﬁlling system, its F1 score increases markedly from 22.2% to 26.7%.","2017","2023-02-28 16:25:47","2023-10-17 14:56:12","2023-02-28 16:25:47","35-45","","","","","","TACRED","","","","","Association for Computational Linguistics","Copenhagen, Denmark","en","False","","https://paperswithcode.com/paper/position-aware-attention-and-supervised-data","","DOI.org (Crossref)","","{'citing': ['10.1109/icassp39728.2021.9414755', '10.1145/3477495.3531746', '10.1109/access.2018.2890390', '10.1109/slt.2018.8639671', '10.1007/s10462-022-10239-9', '10.1109/inista55318.2022.9894216', '10.1109/taslp.2022.3199655', '10.1016/j.eswa.2022.117678', '10.1016/j.knosys.2022.109471', '10.1093/database/baac070', '10.1162/dint_a_00147', '10.1007/978-3-031-19433-7_32', '10.1007/978-3-031-19433-7_37', '10.1145/3511808.3557251', '10.1145/3511808.3557459', '10.1145/3511808.3557615', '10.3390/info13080364', '10.3390/math10203831', '10.3390/app12199781', '10.1109/tii.2022.3159710', '10.1145/3563766.3564109', '10.1109/tbdata.2022.3144151', '10.1007/978-3-031-18315-7_7', '10.1007/978-3-031-18315-7_6', '10.1007/s10489-022-03731-w', '10.1017/s1351324918000451', '10.1145/3308558.3313573', '10.1007/978-3-030-30490-4_12', '10.1007/978-3-319-91947-8_18', '10.1145/3377713.3377784', '10.2196/preprints.18417', '10.1145/3371158.3371186', '10.1007/978-3-030-32381-3_19', '10.1145/3366423.3380282', '10.2196/18417', '10.1007/s00521-020-05087-z', '10.1007/978-981-15-6168-9_2', '10.1007/s10115-020-01502-y', '10.1007/978-3-030-55130-8_11', '10.1145/3340531.3412011', '10.12677/hjdm.2020.104030', '10.1007/978-3-030-62419-4_11', '10.1007/978-3-030-63031-7_9', '10.1016/j.knosys.2020.106321', '10.1016/j.asoc.2019.105913', '10.1016/j.datak.2019.101764', '10.1007/s10489-021-02596-9', '10.1007/s10489-021-02632-8', '10.1016/j.oregeorev.2021.104200', '10.14778/3407790.3407804', '10.1016/j.aiopen.2021.06.004', '10.1007/978-3-030-80599-9_10', '10.1371/journal.pone.0248299', '10.1007/978-3-030-73216-5_22', '10.1145/3412841.3441977', '10.1016/j.ipm.2021.102636', '10.1007/978-3-030-75768-7_26', '10.1007/978-3-030-75768-7_30', '10.1007/978-3-030-75015-2_15', '10.1016/j.ipm.2021.102563', '10.1007/978-3-030-77867-5_10', '10.1007/978-3-030-82322-1_5', '10.1162/tacl_a_00392', '10.1007/978-3-030-86523-8_35', '10.1007/978-3-030-85896-4_23', '10.1007/s10489-021-02667-x', '10.1007/978-3-658-31938-0_6', '10.1007/978-3-030-84529-2_39', '10.1007/s12559-021-09917-7', '10.1007/978-3-030-87571-8_29', '10.1145/3491056', '10.1007/978-981-16-6471-7_4', '10.52547/jipm.37.1.255', '10.1016/j.jii.2021.100301', '10.1145/3436369.3437431', '10.1016/j.knosys.2021.107565', '10.1145/3503917', '10.1007/978-981-16-8885-0_29', '10.1007/s00521-021-06667-3', '10.1142/s0218194021400222', '10.1145/3503047.3503060', '10.1007/978-981-16-6963-7_85', '10.1007/s10462-022-10148-x', '10.1007/s10115-022-01665-w', '10.1007/978-3-031-01333-1_2', '10.1145/3485447.3511998', '10.1007/s11633-022-1323-6', '10.1007/s00521-022-07223-3', '10.1016/j.eswa.2022.117113', '10.1016/j.eswa.2022.117113', '10.1162/tacl_a_00456', '10.1527/tjsai.37-3_ids-d', '10.1109/icccbda49378.2020.9095628', '10.1109/ijcnn48605.2020.9207515', '10.1109/ijcnn48605.2020.9207706', '10.1109/dsc53577.2021.00017', '10.1109/icassp43922.2022.9747486', '10.1145/3495162', '10.1109/trustcom50675.2020.00083', '10.1109/cis52066.2020.00028', '10.1145/3510030', '10.1007/978-3-031-03948-5_11', '10.1109/cscwd54268.2022.9776127', '10.1109/access.2019.2917302', '10.1007/978-3-031-07472-1_16', '10.1007/s10115-022-01687-4', '10.1109/taslp.2022.3153254', '10.1109/ijcnn52387.2021.9534434', '10.1109/ijcnn52387.2021.9534473', '10.1109/ijcnn52387.2021.9534183', '10.1109/ijcnn52387.2021.9534398', '10.1109/access.2021.3086480', '10.1109/access.2019.2930407', '10.1109/tai.2021.3068697', '10.1109/tetci.2021.3136598', '10.1109/s.a.i.ence50533.2020.9303196', '10.3390/s22134911', '10.1109/icicn52636.2021.9673905', '10.1109/tetci.2020.3040444', '10.1109/bibm47256.2019.8982966', '10.1109/iccst50977.2020.00059', '10.1109/icme51207.2021.9428274', '10.1109/bibm47256.2019.8983057', '10.1109/ictai.2019.00210', '10.1016/j.knosys.2022.109146'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/ZUHR7NT3/Zhang et al. - 2017 - Position-aware Attention and Supervised Data Impro.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:sentence; SAT_task:EntityTyping; SAT_task:NER; SAT_task:SlotFilling; SAT_method_selection:Human; SAT_All_checked:True; SAT_negativeExamples:True; SAT_extend:TAC; SAT_nbtypes_relations:42; SAT_nbTrainEx:75000; SAT_nbEvalEx:25764; SAT_nbExNegative:93189; SAT_nbExPositive:26285; SAT_nbDoc:106K; SAT_nbTriples:22000; SAT_task:GraphGeneration; SAT_nbTestEx:18660","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2017 Conference on Empirical Methods in Natural           Language Processing","","","","","","","","","","","","","","",""
"ACI9PMBV","conferencePaper","2021","Zheng, Changmeng; Wu, Zhiwei; Feng, Junhao; Fu, Ze; Cai, Yi","MNRE: A Challenge Multimodal Dataset for Neural Relation Extraction with Visual Evidence in Social Media Posts","2021 IEEE International Conference on Multimedia and Expo (ICME)","978-1-6654-3864-3","","10.1109/icme51207.2021.9428274","https://ieeexplore.ieee.org/document/9428274/","","2021-07-05","2023-05-11 14:17:37","2023-10-17 16:43:13","2023-05-11 14:17:37","1-6","","","","","","MNRE","","","","","IEEE","Shenzhen, China","","True","","","https://github.com/thecharm/MNRE","DOI.org (Crossref)","","{'citing': ['10.1145/3477495.3531992', '10.1109/icme52920.2022.9859972', '10.3390/app12199691'], 'cited': ['10.1007/s00500-020-04742-w', '10.1109/cvpr.2017.670', '10.18653/v1/d15-1203', '10.18653/v1/d15-1205', '10.18653/v1/d17-1004', '10.18653/v1/d17-1115', '10.18653/v1/d18-1514', '10.18653/v1/p18-1185', '10.18653/v1/p18-1208', '10.18653/v1/p19-1074', '10.18653/v1/p19-1279', '10.3115/1220175.1220279', '10.3115/1621969.1621986', '10.3115/v1/w15-1506']}","","","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_task:NER; SAT_context:MultiModal; SAT_source:Twitter; SAT_nbtypes_relations:23; SAT_NbEntity:30970; SAT_NbImages:9201; SAT_nbSent:9201; SAT_nbTriples:15485","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021 IEEE International Conference on Multimedia and Expo (ICME)","","","","","","","","","","","","","","",""
"3RBI2END","conferencePaper","2020","Xu Han, Tianyu Gao; , Yankai Lin; , Hao Peng; , Yaoliang Yang; , Chaojun Xiao; , Zhiyuan Liu; , Peng Li; , Maosong Sun; , Jie Zhou","More Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction","AACL","","","not found","https://aclanthology.org/2020.aacl-main.75/","Relational facts are an important component of human knowledge, which are hidden in vast amounts of text. In order to extract these facts from text, people have been working on relation extraction (RE) for years. From early pattern matching to current neural networks, existing RE methods have achieved significant progress. Yet with explosion of Web text and emergence of new relations, human knowledge is increasing drastically, and we thus require “more” from RE: a more powerful RE system that can robustly utilize more data, efficiently learn more relations, easily handle more complicated context, and flexibly generalize to more open domains. In this paper, we look back at existing RE methods, analyze key challenges we are facing nowadays, and show promising directions towards more powerful RE. We hope our view can advance this field and inspire more efforts in the community.","2020-04-07","2023-02-03 15:59:23","2025-02-04 17:20:33","","745-758","","","nan","","","","","","","","ACL","","","FALSE","","SemanticScholar","15e0a71bd655d7c6c7a1b1a9e9eb7a4f650531cd","","","","","/root/snap/zotero-snap/common/Zotero/storage/WG7QLNDJ/Xu Han et al. - 2020 - More Data, More Relations, More Context and More O.pdf","","star; automatic; SAT_focus:OpenIE; SAT_model:BERT; SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_task:Retrieval; SAT_focus:Denoising; SAT_archi:PCNN; SAT_focus:Context; SAT_focus:FewSHot; SAT_type:Review; SAT_focus:GraphNN; SAT_typology_dim:Architecture; FOCUS_STUDY_OCT; CHECKED1023; SAT_nbModel:3; SAT_dataset:NYT; SAT_benchmark_type:Quantitative; SAT_dataset:SemEval; SAT_dataset:TACRED; SAT_interest:10; SAT_focus:Generation; SAT_nbDataset:4; SAT_model:PCNN; SAT_focus_period:1995-2020; SAT_dataset:WikiDistant; SAT_dataset:Wiki80","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P38DB89B","journalArticle","2015","Bravo, Àlex; Piñero, Janet; Queralt-Rosinach, Núria; Rautschka, Michael; Furlong, Laura I.","Extraction of relations between genes and diseases from text and large-scale data analysis: implications for translational research","BMC Bioinformatics","","1471-2105","10.1186/s12859-015-0472-9","https://doi.org/10.1186/s12859-015-0472-9","Current biomedical research needs to leverage and exploit the large amount of information reported in scientific publications. Automated text mining approaches, in particular those aimed at finding relationships between entities, are key for identification of actionable knowledge from free text repositories. We present the BeFree system aimed at identifying relationships between biomedical entities with a special focus on genes and their associated diseases.","2015-02-21","2023-03-22 11:22:34","2023-10-17 14:25:33","2023-03-22 11:22:34","55","","1","16","","BMC Bioinformatics","","","","","","","","","","","","","BioMed Central","","{'citing': ['10.1093/jamiaopen/ooac043', '10.1038/s41597-022-01350-1', '10.1093/bioinformatics/btac578', '10.1038/s41597-022-01654-2', '10.3897/bdj.10.e89481', '10.1016/j.ins.2022.10.063', '10.1093/nar/gkac1017', '10.1186/s13040-022-00311-z', '10.3390/app122312012', '10.1016/j.jbi.2022.104135', '10.1109/bibm47256.2019.8983350', '10.1101/2022.05.27.493696', '10.1007/s40484-019-0167-8', '10.1002/asi.23876', '10.1038/s41573-019-0024-5', '10.1038/srep43258', '10.1093/bioinformatics/btv301', '10.1093/bioinformatics/btw214', '10.1093/bioinformatics/btw503', '10.1093/bioinformatics/btx506', '10.1093/bioinformatics/bty933', '10.1093/bioinformatics/btz490', '10.1093/database/baw051', '10.1093/database/baw094', '10.1093/database/baw143', '10.1093/nar/gkw943', '10.1101/403667', '10.1101/730085', '10.1145/3079452.3079472', '10.1155/2018/3928080', '10.1177/026119291804600208', '10.1007/s00439-019-01970-5', '10.1186/s12859-016-0998-5', '10.1186/s12911-018-0639-1', '10.1007/978-3-030-17083-7_17', '10.1371/journal.pone.0149621', '10.1371/journal.pone.0155811', '10.1371/journal.pone.0200699', '10.2217/pme-2016-0100', '10.3233/jad-150769', '10.3233/sw-150189', '10.3389/frma.2018.00007', '10.3390/molecules23051028', '10.1109/ichi-w.2018.00013', '10.1109/spices.2017.8091326', '10.1109/codit.2016.7593578', '10.1186/s12859-019-3317-0', '10.1101/839704', '10.1093/nar/gkz1021', '10.1007/978-3-030-38021-2_2', '10.1093/database/bay020', '10.1186/s40537-019-0254-8', '10.1093/bioinformatics/btz682', '10.1093/bioinformatics/btz857', '10.1101/2020.04.23.057117', '10.1371/journal.pone.0231728', '10.1145/3307339.3343479', '10.1093/bib/bbaa110', '10.1038/s41598-020-71418-8', '10.1007/978-3-030-60470-7_5', '10.1093/bib/bbaa157', '10.1002/ggn2.10023', '10.1002/med.21764', '10.1093/bib/bbaa296', '10.1093/bib/bbaa296', '10.1093/bib/bbaa296', '10.1093/bib/bbaa296', '10.1093/bioinformatics/btaa577', '10.1093/bioinformatics/btaa721', '10.1186/s12911-020-01274-z', '10.1007/978-3-030-66046-8_16', '10.1016/j.imu.2019.100181', '10.1016/j.jtbi.2019.110112', '10.1016/b978-0-12-819314-3.00005-7', '10.1016/j.jbi.2018.08.005', '10.1016/j.procs.2018.05.016', '10.1016/j.imu.2020.100492', '10.1016/j.compbiolchem.2015.10.002', '10.1016/j.engappai.2020.104130', '10.1016/j.mad.2019.111194', '10.1016/bs.apcsb.2015.07.005', '10.1016/j.csbj.2020.05.017', '10.1101/2021.06.03.446973', '10.1088/1742-6596/1963/1/012173', '10.1101/2021.01.28.428707', '10.1088/1757-899x/1022/1/012055', '10.1016/j.addr.2021.05.015', '10.1136/archdischild-2020-321023', '10.1016/b978-0-12-820045-2.00005-2', '10.1002/ajmg.c.31900', '10.1101/2021.03.18.436005', '10.1093/nargab/lqab062', '10.1155/2021/9958410', '10.1016/j.jmb.2021.167149', '10.1016/j.imu.2021.100680', '10.1021/acs.chemrev.6b00851', '10.1007/s10462-021-10058-4', '10.1007/978-981-16-0753-0_3', '10.1186/s13326-021-00248-y', '10.3390/biom11101430', '10.1093/bioinformatics/btab671', '10.1016/j.bbagrm.2021.194778', '10.1016/j.neucom.2021.10.100', '10.1145/3458754', '10.1101/2022.01.08.475476', '10.1016/j.fmre.2022.01.037', '10.1093/database/baab057', '10.1186/s12859-022-04646-6', '10.1186/s12859-022-04688-w', '10.1109/tcbb.2020.3020016', '10.1016/j.health.2022.100078', '10.1098/rspb.2021.2721'], 'cited': ['10.1016/j.ijmedinf.2009.04.010', '10.1016/j.jbi.2003.11.003', '10.1016/j.jbi.2008.10.002', '10.1016/j.jbi.2011.04.005', '10.1016/j.jbi.2012.04.004', '10.1016/j.jbi.2012.04.006', '10.1016/j.jbi.2012.04.007', '10.1016/j.jbi.2012.04.011', '10.1038/ng0411-281', '10.1038/nrg3337', '10.1093/bfgp/elu015', '10.1093/bib/bbs018', '10.1093/bioinformatics/bti1142', '10.1093/bioinformatics/btl616', '10.1093/bioinformatics/btm544', '10.1093/bioinformatics/btn182', '10.1093/bioinformatics/btq538', '10.1093/bioinformatics/btt333', '10.1093/database/bau039', '10.1098/rstb.2012.0190', '10.1111/joim.12105', '10.1136/amiajnl-2012-001173', '10.1142/s0219720007003144', '10.1145/1882992.1883096', '10.1155/2014/253128', '10.1186/1471-2105-11-107', '10.1186/1471-2105-13-s11-s9', '10.1186/1471-2105-14-14', '10.1186/1471-2105-14-181', '10.1186/1471-2105-15-64', '10.1186/1471-2105-9-207', '10.1186/1471-2105-9-s11-s10', '10.1186/1471-2105-9-s11-s9', '10.1186/2041-1480-3-15', '10.1186/gb-2003-4-5-p3', '10.1186/gb-2008-9-s2-s2', '10.1197/jamia.m3028', '10.1371/journal.pone.0060954', '10.3115/1218955.1219009']}","","/root/snap/zotero-snap/common/Zotero/storage/DD728RSY/Bravo et al. - 2015 - Extraction of relations between genes and diseases.pdf; /root/snap/zotero-snap/common/Zotero/storage/W3VL68V2/s12859-015-0472-9.html","","SAT_domain:medical; SAT_domain:bio","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4K5HZU4Z","conferencePaper","2022",", Tushar Abhishek; , Shivprasad Sagare; , Bhavyajeet Singh; , Anubhav Sharma; , Manish Gupta; , Vasudeva Varma","XAlign: Cross-lingual Fact-to-Text Alignment and Generation for Low-Resource Languages","Proceedings of the Web Conference 2022","","","10.1145/3487553.3524265","https://arxiv.org/abs/2202.00291v2","Multiple critical scenarios (like Wikipedia text generation given English Infoboxes) need automated generation of descriptive text in low resource (LR) languages from English fact triples. Previous work has focused on English fact-to-text (F2T) generation. To the best of our knowledge, there has been no previous attempt on cross-lingual alignment or generation for LR languages. Building an effective cross-lingual F2T (XF2T) system requires alignment between English structured facts and LR sentences. We propose two unsupervised methods for cross-lingual alignment. We contribute XALIGN, an XF2T dataset with 0.45M pairs across 8 languages, of which 5402 pairs have been manually annotated. We also train strong baseline XF2T generation models on the XAlign dataset.","2022-02-01","2023-04-05 15:11:28","2023-10-17 16:36:54","","","","","","","","XAlign","","","","","ACM","","","True","","https://paperswithcode.com/paper/xalign-cross-lingual-fact-to-text-alignment","https://github.com/tushar117/XAlign","","","{'citing': [], 'cited': ['10.18653/v1/2020.acl-main.224', '10.18653/v1/2020.acl-main.747', '10.18653/v1/2020.emnlp-main.630', '10.18653/v1/2021.naacl-main.278', '10.18653/v1/2021.naacl-main.41', '10.18653/v1/d16-1128', '10.18653/v1/n18-1139', '10.18653/v1/w17-3518']}","","/root/snap/zotero-snap/common/Zotero/storage/PQFWJSR4/ et al. - 2022 - XAlign Cross-lingual Fact-to-Text Alignment and G.pdf","","SAT_oldTag:CHECKED0923; SAT_lang:multi; SAT_task:TextGeneration; SAT_source:Wikidata; SAT_method_generation:mT5; SAT_NbEntity:85K; SAT_task:Data-to-text; SAT_nbTriples:0.91M","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WWW '22","","","","","","","","","","","","","","",""
"CJ82MU55","conferencePaper","2020",", Tong Zhu; , Haitao Wang; , Junjie Yu; , Xiabing Zhou; , Wenliang Chen; , Wei zhang; , Min Zhang","Towards Accurate and Consistent Evaluation: A Dataset for Distantly-Supervised Relation Extraction","Proceedings of the 28th International Conference on Computational Linguistics","","","10.18653/v1/2020.coling-main.566","https://arxiv.org/abs/2010.16275v1","In recent years, distantly-supervised relation extraction has achieved a certain success by using deep neural networks. Distant Supervision (DS) can automatically generate large-scale annotated data by aligning entity pairs from Knowledge Bases (KB) to sentences. However, these DS-generated datasets inevitably have wrong labels that result in incorrect evaluation scores during testing, which may mislead the researchers. To solve this problem, we build a new dataset NYTH, where we use the DS-generated data as training data and hire annotators to label test data. Compared with the previous datasets, NYT-H has a much larger test set and then we can perform more accurate and consistent evaluation. Finally, we present the experimental results of several widely used systems on NYT-H. The experimental results show that the ranking lists of the comparison systems on the DS-labelled test data and human-annotated test data are different. This indicates that our human-annotated data is necessary for evaluation of distantly-supervised relation extraction.","2020-10-30","2023-04-05 15:11:08","2023-10-17 16:52:18","","","","","","","","NYT-H","","","","","ACL","","","True","","https://paperswithcode.com/paper/towards-accurate-and-consistent-evaluation-a","https://github.com/Spico197/NYT-H","","","{'citing': ['10.1007/978-3-030-75768-7_29', '10.1007/s12559-021-09917-7', '10.1162/dint_a_00108', '10.1007/978-3-030-89363-7_23', '10.1186/s12859-022-04646-6', '10.1007/s10462-022-10239-9', '10.1016/j.neunet.2022.10.008'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/V84E85A8/ et al. - 2020 - Towards Accurate and Consistent Evaluation A Data.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:sentence; SAT_method_selection:Distant; SAT_negativeExamples:True; SAT_task:Spanning; SAT_extend:NYT10; SAT_nbTriples:377393; SAT_nbtypes_relations:22; SAT_NbEntity:69063","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9EE3TK2R","conferencePaper","2022",", Tobias Deußer; , Syed Musharraf Ali; , Lars Hillebrand; , Desiana Nurchalifah; , Basil Jacob; , Christian Bauckhage; , Rafet Sifa","KPI-EDGAR: A Novel Dataset and Accompanying Metric for Relation Extraction from Financial Documents","2022 21st IEEE International Conference on Machine Learning and Applications","","","10.1109/icmla55696.2022.00254","https://arxiv.org/abs/2210.09163v1","We introduce KPI-EDGAR, a novel dataset for Joint Named Entity Recognition and Relation Extraction building on financial reports uploaded to the Electronic Data Gathering, Analysis, and Retrieval (EDGAR) system, where the main objective is to extract Key Performance Indicators (KPIs) from financial documents and link them to their numerical values and other attributes. We further provide four accompanying baselines for benchmarking potential future research. Additionally, we propose a new way of measuring the success of said extraction process by incorporating a word-level weighting scheme into the conventional F1 score to better model the inherently fuzzy borders of the entity pairs of a relation in this domain.","2022-10-17","2023-05-03 16:19:48","2023-10-17 15:51:20","","","","","","","","KPI-EDGAR","","","","","IEEE","","","Registration","","https://paperswithcode.com/paper/kpi-edgar-a-novel-dataset-and-accompanying","https://www.sec.gov/edgar","","","","","/root/snap/zotero-snap/common/Zotero/storage/3L9KL45H/ et al. - 2022 - KPI-EDGAR A Novel Dataset and Accompanying Metric.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_task:NER; SAT_task:Retrieval; SAT_method_selection:Human; SAT_domain:finance; SAT_method_selection:MultiHuman; SAT_nbTriples:3841; SAT_nbSent:1355; SAT_nbDoc:10K; SAT_NbEntity:4522; SAT_source:EDGAR_db; havecode; SAT_task:JoinRE; isbenchmarked","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICMLA","","","","","","","","","","","","","","",""
"4AG8UPZQ","conferencePaper","2018","Takanobu, Ryuichi; Zhang, Tianyang; Liu, Jiexi; Huang, Minlie","A Hierarchical Framework for Relation Extraction with Reinforcement Learning","The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19)","","","10.1609/aaai.v33i01.33017072","http://arxiv.org/abs/1811.03925","Most existing methods determine relation types only after all the entities have been recognized, thus the interaction between relation types and entity mentions is not fully modeled. This paper presents a novel paradigm to deal with relation extraction by regarding the related entities as the arguments of a relation. We apply a hierarchical reinforcement learning (HRL) framework in this paradigm to enhance the interaction between entity mentions and relation types. The whole extraction process is decomposed into a hierarchy of two-level RL policies for relation detection and entity extraction respectively, so that it is more feasible and natural to deal with overlapping relations. Our model was evaluated on public datasets collected via distant supervision, and results show that it gains better performance than existing methods and is more powerful for extracting overlapping relations1.","2018-11-09","2023-02-28 16:26:24","2023-10-08 16:39:34","2023-02-28 16:26:24","","","","","","","NYT11-HRL","","","","","AAAI","","en","","","https://paperswithcode.com/paper/a-hierarchical-framework-for-relation","","arXiv.org","","{'citing': ['10.1016/j.compbiolchem.2021.107508', '10.1016/j.neucom.2021.06.071', '10.1007/978-3-030-32236-6_71', '10.1007/s10032-022-00399-3', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00090', '10.1016/j.knosys.2020.105912', '10.1109/tnnls.2021.3070843', '10.1007/s13042-021-01491-6', '10.1016/j.knosys.2020.106172', '10.1007/978-3-030-73197-7_32', '10.3390/info11010031', '10.3390/app12178493', '10.1109/taslp.2021.3110126', '10.1016/j.neucom.2020.12.037', '10.1007/s11192-022-04340-7', '10.1007/978-3-030-89363-7_6', '10.1108/idd-01-2020-0005', '10.1109/access.2020.2980859', '10.1109/hpcc-dss-smartcity-dependsys53884.2021.00167', '10.1145/3402885', '10.1145/3442381.3449895', '10.1007/s12559-021-09917-7', '10.1007/s10489-021-02667-x', '10.1109/iaeac50856.2021.9390651', '10.1109/tbdata.2022.3144151', '10.1016/j.ipm.2020.102311', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00096', '10.3233/jifs-210281', '10.1007/978-3-030-93733-1_23', '10.1109/tim.2022.3200429', '10.1109/tkde.2021.3070317', '10.1007/978-3-030-82147-0_13', '10.1109/access.2021.3062231', '10.3390/app12126231', '10.1145/3308558.3313455', '10.1007/s11432-020-3307-3', '10.1093/bioinformatics/btaa491', '10.1007/978-3-031-20891-1_30', '10.1109/qrs54544.2021.00052', '10.1109/aiea53260.2021.00060', '10.1109/ijcnn55064.2022.9892140', '10.1007/978-3-030-60239-0_35', '10.1145/3459637.3482058', '10.1007/s10489-021-02600-2', '10.1109/dtpi52967.2021.9540098', '10.1145/3437963.3441738', '10.1145/3459637.3482491', '10.1109/iccc54389.2021.9674630', '10.1109/access.2019.2938986', '10.1016/j.neunet.2021.03.030', '10.1109/icassp43922.2022.9746958', '10.1007/978-3-030-32236-6_72', '10.1007/978-981-16-9492-9_302', '10.1155/2022/2146236'], 'cited': ['10.1609/aaai.v33i01.33017072']}","","/root/snap/zotero-snap/common/Zotero/storage/RJHU5L3Z/Takanobu et al. - 2018 - A Hierarchical Framework for Relation Extraction w.pdf","","Pwc_task:Relation Extraction; Pwc_task:Entity Extraction using GAN; Pwc_task:Reinforcement Learning (RL); Pwc_task:reinforcement-learning; Pwc_task:Hierarchical Reinforcement Learning; SAT_task:RE; SAT_task:EntityExtraction; SAT_learning:reinforcement","⚠️ Invalid DOI; Computer Science - Computation and Language; Computer Science - Information Retrieval","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"D8X8N45F","conferencePaper","2022",", Shuyang Cao; , Lu Wang","Time-aware Prompting for Text Generation","Findings of the Association for Computational Linguistics: EMNLP 2022","","","10.18653/v1/2022.findings-emnlp.535","https://arxiv.org/abs/2211.02162v1","In this paper, we study the effects of incorporating timestamps, such as document creation dates, into generation systems. Two types of time-aware prompts are investigated: (1) textual prompts that encode document timestamps in natural language sentences; and (2) linear prompts that convert timestamps into continuous vectors. To explore extrapolation to future data points, we further introduce a new data-to-text generation dataset, TempWikiBio, containing more than 4 millions of chronologically ordered revisions of biographical articles from English Wikipedia, each paired with structured personal profiles. Through data-to-text generation on TempWikiBio, text-to-text generation on the content transfer dataset, and summarization on XSum, we show that linear prompts on encoder and textual prompts improve the generation quality on all datasets. Despite having less performance drop when testing on data drawn from a later time, linear prompts focus more on non-temporal information and are less sensitive to the given timestamps, according to human evaluations and sensitivity analyses. Meanwhile, textual prompts establish the association between the given timestamps and the output dates, yielding more factual temporal information in the output.","2022-11-03","2023-04-05 15:11:41","2023-10-17 16:17:46","","","","","","","","TEMPWIKIBIO","","","","","ACL","","","False","","https://paperswithcode.com/paper/time-aware-prompting-for-text-generation","","","","","","/root/snap/zotero-snap/common/Zotero/storage/XJNV4UZI/ and  - 2022 - Time-aware Prompting for Text Generation.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_task:TextGeneration; SAT_task:SlotFilling; SAT_task:Event; SAT_learning:FewShot; SAT_context:Text; SAT_source:Wikipedia; SAT_context:Table; SAT_focus:FewSHot; SAT_NbEntity:695929; SAT_nbDoc:625000; SAT_method_generation:BART; SAT_task:Data-to-text","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP","","","","","","","","","","","","","","",""
"E6I7WPKI","conferencePaper","2021","Stoica, George; Platanios, Emmanouil Antonios; Póczos, Barnabás","Re-TACRED: Addressing Shortcomings of the TACRED Dataset","The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)","","","10.48550/arXiv.2104.08398","http://arxiv.org/abs/2104.08398","TACRED is one of the largest and most widely used sentence-level relation extraction datasets. Proposed models that are evaluated using this dataset consistently set new state-of-the-art performance. However, they still exhibit large error rates despite leveraging external knowledge and unsupervised pretraining on large text corpora. A recent study suggested that this may be due to poor dataset quality. The study observed that over 50% of the most challenging sentences from the development and test sets are incorrectly labeled and account for an average drop of 8% f1-score in model performance. However, this study was limited to a small biased sample of 5k (out of a total of 106k) sentences, substantially restricting the generalizability and broader implications of its findings. In this paper, we address these shortcomings by: (i) performing a comprehensive study over the whole TACRED dataset, (ii) proposing an improved crowdsourcing strategy and deploying it to re-annotate the whole dataset, and (iii) performing a thorough analysis to understand how correcting the TACRED annotations affects previously published results. After verification, we observed that 23.9% of TACRED labels are incorrect. Moreover, evaluating several models on our revised dataset yields an average f1-score improvement of 14.3% and helps uncover significant relationships between the different models (rather than simply offsetting or scaling their scores by a constant factor). Finally, aside from our analysis we also release Re-TACRED, a new completely re-annotated version of the TACRED dataset that can be used to perform reliable evaluation of relation extraction models.","2021-04-16","2023-02-27 14:11:26","2023-10-05 09:08:30","2023-02-27 14:11:26","","","","","","","Re-TACRED","","","","","AAAI","","","FALSE","","https://paperswithcode.com/paper/re-tacred-addressing-shortcomings-of-the","https://github.com/gstoica27/Re-TACRED","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/D7DT5XVZ/Stoica et al. - 2021 - Re-TACRED Addressing Shortcomings of the TACRED D.pdf; /root/snap/zotero-snap/common/Zotero/storage/IPL5B9FT/2104.html","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:sentence; SAT_extend:TACRED; SAT_method_selection:Human; SAT_nbtypes_entity:17; SAT_nbtypes_relations:40; SAT_nbTrainEx:58465; SAT_nbEvalEx:19584; SAT_focus:WrongTypign; SAT_nbSent:91467; SAT_focus:AnnotationQuality; SAT_nbTestEx:13418","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"Z8GN4R6W","conferencePaper","2022","Popovic, Nicholas; Färber, Michael","Few-Shot Document-Level Relation Extraction","Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2022.naacl-main.421","http://arxiv.org/abs/2205.02048","We present FREDo, a few-shot document-level relation extraction (FSDLRE) benchmark. As opposed to existing benchmarks which are built on sentence-level relation extraction corpora, we argue that document-level corpora provide more realism, particularly regarding none-ofthe-above (NOTA) distributions. Therefore, we propose a set of FSDLRE tasks and construct a benchmark based on two existing supervised learning data sets, DocRED and sciERC. We adapt the state-of-the-art sentence-level method MNAV to the document-level and develop it further for improved domain adaptation. We ﬁnd FSDLRE to be a challenging setting with interesting new characteristics such as the ability to sample NOTA instances from the support set. The data, code, and trained models are available online1.","2022-07-01","2023-02-28 16:22:52","2023-10-02 05:45:33","2023-02-28 16:22:52","","","","","","","FREDo","","","","","ACL","","en","","","https://paperswithcode.com/paper/few-shot-document-level-relation-extraction","","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/HMF9ZTF7/Popovic and Färber - 2022 - Few-Shot Document-Level Relation Extraction.pdf","","Pwc_task:Relation Extraction; Pwc_task:Relation Classification; Pwc_task:Document-level Relation Extraction; Pwc_task:Domain Adaptation; Pwc_task:Few-Shot Learning; Pwc_task:Few-Shot Relation Classification; SAT_granularity:document; SAT_learning:FewShot","⚠️ Invalid DOI; Computer Science - Computation and Language; Computer Science - Artificial Intelligence; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL","","","","","","","","","","","","","","",""
"88BAH4U4","conferencePaper","2019",", Mostafa Abdou; , Cezar Sas; , Rahul Aralikatte; , Isabelle Augenstein; , Anders Søgaard","X-WikiRE: A Large, Multilingual Resource for Relation Extraction as Machine Comprehension","Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019)","","","10.18653/v1/d19-6130","https://arxiv.org/abs/1908.05111v2","Although the vast majority of knowledge bases KBs are heavily biased towards English, Wikipedias do cover very different topics in different languages. Exploiting this, we introduce a new multilingual dataset (X-WikiRE), framing relation extraction as a multilingual machine reading problem. We show that by leveraging this resource it is possible to robustly transfer models cross-lingually and that multilingual support significantly improves (zero-shot) relation extraction, enabling the population of low-resourced KBs from their well-populated counterparts.","2019-08-14","2023-04-05 15:10:44","2023-10-17 16:24:26","","","","","","","","X-WikiRE","","","","","ACL","","","True","","https://paperswithcode.com/paper/x-wikire-a-large-multilingual-resource-for","https://github.com/mhany90/Multi-WikiRE","","","","","","","SAT_oldTag:CHECKED0923; SAT_task:NLU; SAT_task:QA; SAT_task:RE; SAT_lang:multi; SAT_task:SlotFilling; SAT_focus:Evidence; SAT_source:Wikidata; SAT_method_selection:Human; SAT_source:Wikipedia; SAT_lang:english; SAT_All_checked:False; SAT_lang:french; SAT_lang:german; SAT_lang:spanish; SAT_negativeExamples:True; SAT_method_generation:LSTM; SAT_nbExPositive:13000000; SAT_nbtypes_relations:120; SAT_method_generation:mBERT; SAT_focus:UnseenRelation; SAT_focus:unseenEntity; SAT_focus:ZeroShot; SAT_focus:AnnotationQuality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","DeepLo","","","","","","","","","","","","","","",""
"FC2UNT4J","conferencePaper","2020",", Mingda Chen; , Sam Wiseman; , Kevin Gimpel","WikiTableT: A Large-Scale Data-to-Text Dataset for Generating Wikipedia Article Sections","Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021","","","10.18653/v1/2021.findings-acl.17","https://arxiv.org/abs/2012.14919v2","Datasets for data-to-text generation typically focus either on multi-domain, single-sentence generation or on single-domain, long-form generation. In this work, we cast generating Wikipedia sections as a data-to-text generation task and create a large-scale dataset, WikiTableT, that pairs Wikipedia sections with their corresponding tabular data and various metadata. WikiTableT contains millions of instances, covering a broad range of topics, as well as a variety of flavors of generation tasks with different levels of flexibility. We benchmark several training and decoding strategies on WikiTableT. Our qualitative analysis shows that the best approaches can generate fluent and high quality texts but they struggle with coherence and factuality, showing the potential for our dataset to inspire future work on long-form generation.","2020-12-29","2023-04-05 15:11:10","2023-10-17 16:24:51","","","","","","","","WikiTableT","","","","","ACL","","","True","","https://paperswithcode.com/paper/generating-wikipedia-article-sections-from","https://github.com/mingdachen/WikiTableT","","","","","","","SAT_oldTag:CHECKED0923; SAT_granularity:document; SAT_task:TextGeneration; SAT_task:EntityLinking; SAT_task:NER; SAT_context:Text; SAT_granularity:paragraph; SAT_domain:encyclo; SAT_source:Wikidata; SAT_source:Wikipedia; SAT_method_selection:Distant; SAT_NbEntity:1500000; SAT_context:Table; SAT_task:Data-to-text","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL-IJCNLP","","","","","","","","","","","","","","",""
"N33QQQ9T","conferencePaper","2021",", Luyu Wang; , Yujia Li; , Ozlem Aslan; , Oriol Vinyals","WikiGraphs: A Wikipedia Text - Knowledge Graph Paired Dataset","Proceedings of the Fifteenth Workshop on Graph-Based Methods for Natural Language Processing (TextGraphs-15)","","","10.18653/v1/11.textgraphs-1.7","https://arxiv.org/abs/2107.09556v1","We present a new dataset of Wikipedia articles each paired with a knowledge graph, to facilitate the research in conditional text generation, graph generation and graph representation learning. Existing graph-text paired datasets typically contain small graphs and short text (1 or few sentences), thus limiting the capabilities of the models that can be learned on the data. Our new dataset WikiGraphs is collected by pairing each Wikipedia article from the established WikiText-103 benchmark (Merity et al., 2016) with a subgraph from the Freebase knowledge graph (Bollacker et al., 2008). This makes it easy to benchmark against other state-of-the-art text generative models that are capable of generating long paragraphs of coherent text. Both the graphs and the text data are of significantly larger scale compared to prior graph-text paired datasets. We present baseline graph neural network and transformer model results on our dataset for 3 tasks: graph -> text generation, graph -> text retrieval and text -> graph retrieval. We show that better conditioning on the graph provides gains in generation and retrieval quality but there is still large room for improvement.","2021-07-20","2023-04-05 15:11:23","2023-10-17 16:26:36","","","","","","","","WikiGraphs","","","","","ACL","","","True","","https://paperswithcode.com/paper/wikigraphs-a-wikipedia-text-knowledge-graph","https://github.com/google-deepmind/deepmind-research/tree/master/wikigraphs","","","","","","","SAT_oldTag:CHECKED0923; SAT_task:DataAugmentation; SAT_task:TextGeneration; SAT_task:Retrieval; SAT_source:Wikipedia; SAT_source:FreeBase; SAT_nbDoc:23000; SAT_task:Data-to-text; SAT_task:GraphGeneration; SAT_task:RepresentationLearning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","TextGraph","","","","","","","","","","","","","","",""
"DGBFMST9","conferencePaper","2020",", Liying Cheng; , Dekun Wu; , Lidong Bing; , Yan Zhang; , Zhanming Jie; , Wei Lu; , Luo Si","ENT-DESC: Entity Description Generation by Exploring Knowledge Graph","Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","","","10.18653/v1/2020.emnlp-main.90","https://arxiv.org/abs/2004.14813v2","Previous works on knowledge-to-text generation take as input a few RDF triples or key-value pairs conveying the knowledge of some entities to generate a natural language description. Existing datasets, such as WIKIBIO, WebNLG, and E2E, basically have a good alignment between an input triple/pair set and its output text. However, in practice, the input knowledge could be more than enough, since the output description may only cover the most significant knowledge. In this paper, we introduce a large-scale and challenging dataset to facilitate the study of such a practical scenario in KG-to-text. Our dataset involves retrieving abundant knowledge of various types of main entities from a large knowledge graph (KG), which makes the current graph-to-sequence models severely suffer from the problems of information loss and parameter explosion while generating the descriptions. We address these challenges by proposing a multi-graph structure that is able to represent the original graph information more comprehensively. Furthermore, we also incorporate aggregation methods that learn to extract the rich graph information. Extensive experiments demonstrate the effectiveness of our model architecture.","2020-04-30","2023-04-05 15:10:56","2023-10-17 16:50:13","","","","","","","","ENT-DESC","","","","","ACL","","","True","","https://paperswithcode.com/paper/knowledge-graph-empowered-entity-description","https://github.com/LiyingCheng95/EntityDescriptionGeneration","","","{'citing': ['10.1007/978-3-031-17120-8_63'], 'cited': []}","","","","SAT_oldTag:CHECKED0923; SAT_task:TextGeneration; SAT_granularity:paragraph; SAT_focus:MultipleRelations; SAT_source:Wikidata; SAT_source:Wikipedia; SAT_method_generation:LSTM; SAT_method_generation:GCN; SAT_focus:EntityDesc; SAT_method_selection:PageRankBAsed; SAT_nbtypes_entity:90; SAT_nbTriples:3000000; SAT_nbDoc:110k; SAT_nbtypes_relations:957; SAT_NbEntity:691; SAT_task:Data-to-text; SAT_task:GraphGeneration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP","","","","","","","","","","","","","","",""
"RD83MSVU","conferencePaper","2023",", Hongbo Wang; , Weimin Xiong; , YiFan Song; , Dawei Zhu; , Yu Xia; , Sujian Li","DocRED-FE: A Document-Level Fine-Grained Entity And Relation Extraction Dataset","2023 IEEE International Conference on Acoustics, Speech and Signal Processing","","","10.1109/ICASSP49357.2023.10095786","https://arxiv.org/abs/2303.11141v2","Joint entity and relation extraction (JERE) is one of the most important tasks in information extraction. However, most existing works focus on sentence-level coarse-grained JERE, which have limitations in real-world scenarios. In this paper, we construct a large-scale document-level fine-grained JERE dataset DocRED-FE, which improves DocRED with Fine-Grained Entity Type. Specifically, we redesign a hierarchical entity type schema including 11 coarse-grained types and 119 fine-grained types, and then re-annotate DocRED manually according to this schema. Through comprehensive experiments we find that: (1) DocRED-FE is challenging to existing JERE models; (2) Our fine-grained entity types promote relation classification. We make DocRED-FE with instruction and the code for our baselines publicly available at https://github.com/PKU-TANGENT/DOCRED-FE.","2023-03-20","2023-05-03 16:20:40","2023-10-05 09:03:28","","","","","","","","DocRED-FE","","","","","IEEE","","","NA","","https://paperswithcode.com/paper/docred-fe-a-document-level-fine-grained","https://github.com/PKU-TANGENT/DOCRED-FE","","","","","","","SAT_oldTag:CHECKED0923; SAT_oldTag:havecode; SAT_task:RE; SAT_granularity:document; SAT_task:RC; SAT_source:Wikidata; SAT_method_selection:Human; SAT_source:Wikipedia; SAT_extend:DocRED; SAT_nbtypes_relations:96; SAT_nbDoc:2593; SAT_nbtypes_entity:119; SAT_nbTriples:32000; havecode; SAT_task:JoinRE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICASSP 2023","","","","","","","","","","","","","","",""
"S32JE2KQ","conferencePaper","2022",", Elisa Bassignana; , Barbara Plank","CrossRE: A Cross-Domain Dataset for Relation Extraction","Findings of the Association for Computational Linguistics: EMNLP 2022","","","10.18653/v1/2022.findings-emnlp.263","https://arxiv.org/abs/2210.09345v1","Relation Extraction (RE) has attracted increasing attention, but current RE evaluation is limited to in-domain evaluation setups. Little is known on how well a RE system fares in challenging, but realistic out-of-distribution evaluation setups. To address this gap, we propose CrossRE, a new, freely-available cross-domain benchmark for RE, which comprises six distinct text domains and includes multi-label annotations. An additional innovation is that we release meta-data collected during annotation, to include explanations and flags of difficult instances. We provide an empirical evaluation with a state-of-the-art model for relation classification. As the meta-data enables us to shed new light on the state-of-the-art model, we provide a comprehensive analysis on the impact of difficult cases and find correlations between model and human annotations. Overall, our empirical investigation highlights the difficulty of cross-domain RE. We release our dataset, to spur more research in this direction.","2022-10-17","2023-04-05 15:11:37","2023-10-17 16:27:58","","","","","","","","CrossRE","","","","","ACL","","","True","","https://paperswithcode.com/paper/crossre-a-cross-domain-dataset-for-relation","https://github.com/mainlp/CrossRE","","","","","","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_task:RC; SAT_domain:multi; SAT_method_selection:Human; SAT_source:Wikipedia; SAT_domain:science; SAT_domain:politic; SAT_domain:literature; SAT_domain:music; SAT_domain:naturalSci; SAT_source:Reuters; SAT_nbtypes_relations:17; SAT_nbSent:5265; SAT_nbTriples:18608","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP","","","","","","","","","","","","","","",""
"G9EFPZI5","conferencePaper","2022","Amaral, Gabriel; Rodrigues, Odinaldo; Simperl, Elena","WDV: A Broad Data Verbalisation Dataset Built from Wikidata","The Semantic Web – ISWC 2022","","","10.1007/978-3-031-19433-7_32","https://arxiv.org/abs/2205.02627v1","Data verbalisation is a task of great importance in the current field of natural language processing, as there is great benefit in the transformation of our abundant structured and semi-structured data into human-readable formats. Verbalising Knowledge Graph (KG) data focuses on converting interconnected triple-based claims, formed of subject, predicate, and object, into text. Although KG verbalisation datasets exist for some KGs, there are still gaps in their fitness for use in many scenarios. This is especially true for Wikidata, where available datasets either loosely couple claim sets with textual information or heavily focus on predicates around biographies, cities, and countries. To address these gaps, we propose WDV, a large KG claim verbalisation dataset built from Wikidata, with a tight coupling between triples and text, covering a wide variety of entities and predicates. We also evaluate the quality of our verbalisations through a reusable workflow for measuring human-centred fluency and adequacy scores. Our data and code are openly available in the hopes of furthering research towards KG verbalisation.","2022-05-05","2023-03-28 08:29:23","2023-06-01 14:19:25","2023-03-23 16:04:54","","","","","","","WDV","","","","","Springer","","en","","","https://paperswithcode.com/paper/wdv-a-broad-data-verbalisation-dataset-built","","","","","","/root/snap/zotero-snap/common/Zotero/storage/4TGZZNX8/Amaral 2022- WDV A Broad Data Verbalisation Dataset Built from Wikidata.pdf; /root/snap/zotero-snap/common/Zotero/storage/7XKZ2TMI/Amaral et al. - 2022 - WDV A Broad Data Verbalisation Dataset Built from.pdf","","TODO","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ISWC","","","","","","","","","","","","","","",""
"LCN9K2BH","conferencePaper","2019","Yao, Yuan; Ye, Deming; Li, Peng; Han, Xu; Lin, Yankai; Liu, Zhenghao; Liu, Zhiyuan; Huang, Lixin; Zhou, Jie; Sun, Maosong","DocRED: A Large-Scale Document-Level Relation Extraction Dataset","Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/p19-1074","http://arxiv.org/abs/1906.06127","Multiple entities in a document generally exhibit complex inter-sentence relations, and cannot be well handled by existing relation extraction (RE) methods that typically focus on extracting intra-sentence relations for single entity pairs. In order to accelerate the research on document-level RE, we introduce DocRED, a new dataset constructed from Wikipedia and Wikidata with three features: (1) DocRED annotates both named entities and relations, and is the largest humanannotated dataset for document-level RE from plain text; (2) DocRED requires reading multiple sentences in a document to extract entities and infer their relations by synthesizing all information of the document; (3) along with the human-annotated data, we also offer large-scale distantly supervised data, which enables DocRED to be adopted for both supervised and weakly supervised scenarios. In order to verify the challenges of documentlevel RE, we implement recent state-of-the-art methods for RE and conduct a thorough evaluation of these methods on DocRED. Empirical results show that DocRED is challenging for existing RE methods, which indicates that document-level RE remains an open problem and requires further efforts. Based on the detailed analysis on the experiments, we discuss multiple promising directions for future research. We make DocRED and the code for our baselines publicly available at https: //github.com/thunlp/DocRED.","2019-08-09","2023-02-27 14:10:16","2023-10-17 16:52:56","2023-02-27 14:10:16","","","","","","","DocRED","","","","","Association for Computational Linguistics","","en","True","","https://paperswithcode.com/paper/docred-a-large-scale-document-level-relation","https://github.com/thunlp/DocRED","arXiv.org","","{'citing': ['10.1007/978-3-030-47426-3_16', '10.1007/978-981-15-5573-2_4', '10.1145/3340531.3412011', '10.1145/3340531.3412133', '10.1145/3340531.3412878', '10.1007/s11431-020-1673-6', '10.1007/978-3-030-75765-6_22', '10.1007/978-3-030-82322-1_5', '10.1145/3404835.3463070', '10.1007/s10489-021-02596-9', '10.1016/j.ipm.2021.102563', '10.1007/978-3-030-79463-7_21', '10.1007/978-3-030-75768-7_30', '10.1016/j.neunet.2021.03.030', '10.1016/j.jbi.2021.103893', '10.1007/s12559-021-09917-7', '10.1162/tacl_a_00392', '10.1007/978-3-030-86549-8_33', '10.1162/dint_a_00108', '10.1007/978-3-030-86523-8_35', '10.1007/978-3-030-88480-2_6', '10.1016/j.jii.2021.100301', '10.1007/978-3-030-91560-5_25', '10.1007/978-3-030-88480-2_26', '10.1145/3508546.3508633', '10.1007/s10115-022-01665-w', '10.1007/s00521-022-07223-3', '10.1162/tacl_a_00456', '10.1109/access.2020.2996642', '10.1109/icicta51737.2020.00077', '10.1109/bibm52615.2021.9669319', '10.1109/icbk50248.2020.00051', '10.1109/icme51207.2021.9428274', '10.1109/taslp.2021.3082295', '10.1007/s10489-022-03731-w', '10.1109/icassp39728.2021.9414755', '10.1007/978-3-031-17120-8_13', '10.1016/j.eswa.2022.117678', '10.1145/3534678.3539233', '10.1145/3534678.3539304', '10.1109/itaic54216.2022.9836511', '10.1109/jsac.2022.3191112', '10.1109/icme52920.2022.9859653', '10.1007/978-3-031-19433-7_3', '10.1007/978-3-031-19433-7_37', '10.1145/3511808.3557313', '10.1145/3511808.3557615', '10.1016/j.eswa.2022.119369', '10.1007/s10115-022-01781-7', '10.1109/ijcnn55064.2022.9892647', '10.1109/ijcnn55064.2022.9892914', '10.1007/978-981-19-5391-0_6', '10.1109/icpr56361.2022.9956376', '10.1016/j.neucom.2022.11.064', '10.3390/app12031599', '10.1007/s11227-022-04875-9'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/PMVK8RBJ/Yao et al. - 2019 - DocRED A Large-Scale Document-Level Relation Extr.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_task:CorefReso; SAT_task:NER; SAT_source:Wikidata; SAT_method_selection:Human; SAT_source:Wikipedia; SAT_All_checked:False; SAT_nbtypes_entity:6; SAT_nbtypes_relations:96; SAT_nbDoc:5053; SAT_nbDoc:101873; SAT_nbSent:40000; SAT_nbSent:826115; SAT_nbTriples:56000; SAT_nbTriples:881298; SAT_NbEntity:132000; SAT_NBEntity:2558000; SAT_nbTrainEx:37486; SAT_nbEvalEx:3678; SAT_focus:ReasoningPath; SAT_nbTestEx:8787","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9PS6VQTX","conferencePaper","2020","Alt, Christoph; Gabryszak, Aleksandra; Hennig, Leonhard","TACRED Revisited: A Thorough Evaluation of the TACRED Relation Extraction Task","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.48550/arXiv.2004.14855","http://arxiv.org/abs/2004.14855","TACRED (Zhang et al., 2017) is one of the largest, most widely used crowdsourced datasets in Relation Extraction (RE). But, even with recent advances in unsupervised pre-training and knowledge enhanced neural RE, models still show a high error rate. In this paper, we investigate the questions: Have we reached a performance ceiling or is there still room for improvement? And how do crowd annotations, dataset, and models contribute to this error rate? To answer these questions, we first validate the most challenging 5K examples in the development and test sets using trained annotators. We find that label errors account for 8% absolute F1 test error, and that more than 50% of the examples need to be relabeled. On the relabeled test set the average F1 score of a large baseline model set improves from 62.1 to 70.1. After validation, we analyze misclassifications on the challenging instances, categorize them into linguistically motivated error groups, and verify the resulting error hypotheses on three state-of-the-art RE models. We show that two groups of ambiguous relations are responsible for most of the remaining errors and that models may adopt shallow heuristics on the dataset when entities are not masked.","2020-04-30","2023-03-06 14:47:11","2023-10-17 16:35:12","2023-03-06 14:47:11","","","","","","","TACREV","","","","","Association for Computational Linguistics","","","False","","https://paperswithcode.com/paper/tacred-revisited-a-thorough-evaluation-of-the","https://github.com/DFKI-NLP/tacrev","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/MRMFVDAI/Alt et al. - 2020 - TACRED Revisited A Thorough Evaluation of the TAC.pdf; /root/snap/zotero-snap/common/Zotero/storage/HUG2WN6I/2004.html","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:sentence; SAT_focus:Denoising; SAT_extend:TACRED; SAT_method_selection:Human; SAT_negativeExamples:True","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XQ2FRKVB","conferencePaper","2022","Tan, Qingyu; Xu, Lu; Bing, Lidong; Ng, Hwee Tou; Aljunied, Sharifah Mahani","Revisiting DocRED -- Addressing the False Negative Problem in Relation Extraction","Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","","","10.48550/arxiv.2205.12696","http://arxiv.org/abs/2205.12696","The DocRED dataset is one of the most popular and widely used benchmarks for document-level relation extraction (RE). It adopts a recommend-revise annotation scheme so as to have a large-scale annotated dataset. However, we find that the annotation of DocRED is incomplete, i.e., false negative samples are prevalent. We analyze the causes and effects of the overwhelming false negative problem in the DocRED dataset. To address the shortcoming, we re-annotate 4,053 documents in the DocRED dataset by adding the missed relation triples back to the original DocRED. We name our revised DocRED dataset Re-DocRED. We conduct extensive experiments with state-of-the-art neural models on both datasets, and the experimental results show that the models trained and evaluated on our Re-DocRED achieve performance improvements of around 13 F1 points. Moreover, we conduct a comprehensive analysis to identify the potential areas for further improvement. Our dataset is publicly available at https://github.com/tonytan48/Re-DocRED.","2022-10-25","2023-03-22 11:23:39","2023-10-17 16:12:08","2023-03-22 11:23:39","8472--8487","","","","","","Re-DocRED","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates","en","True","","https://paperswithcode.com/paper/revisiting-docred-addressing-the-overlooked","https://github.com/tonytan48/Re-DocRED","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/NH6BENTC/Tan et al. - 2022 - Revisiting DocRED -- Addressing the False Negative.pdf","","SAT_oldTag:CHECKED0923; SAT_oldTag:havecode; SAT_task:RE; SAT_granularity:document; SAT_task:CorefReso; SAT_task:Retrieval; SAT_method_selection:Human; SAT_extend:DocRED; SAT_nbtypes_entity:6; SAT_nbtypes_relations:96; SAT_focus:FalseNegative; SAT_nbTriples:120664; SAT_nbTrainEx:3053; SAT_nbEvalEx:500; SAT_method_selection:PositiveRelationClassif; SAT_method_selection:ScoringTriples; SAT_nbTestEx:500","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NJVFLJYL","conferencePaper","2013","Pradhan, Sameer; Moschitti, Alessandro; Xue, Nianwen; Ng, Hwee Tou; Björkelund, Anders; Uryupina, Olga; Zhang, Yuchen; Zhong, Zhi","Towards Robust Linguistic Analysis using OntoNotes","Proceedings of the Seventeenth Conference on Computational Natural Language Learning","","","not found","https://aclanthology.org/W13-3516","Large-scale linguistically annotated cor- pora have played a crucial role in advanc- ing the state of the art of key natural lan- guage technologies such as syntactic, se- mantic and discourse analyzers, and they serve as training data as well as evaluation benchmarks. Up till now, however, most of the evaluation has been done on mono- lithic corpora such as the Penn Treebank, the Proposition Bank. As a result, it is still unclear how the state-of-the-art analyzers perform in general on data from a vari- ety of genres or domains. The completion of the OntoNotes corpus, a large-scale, multi-genre, multilingual corpus manually annotated with syntactic, semantic and discourse information, makes it possible to perform such an evaluation. This paper presents an analysis of the performance of publicly available, state-of-the-art tools on all layers and languages in the OntoNotes v5.0 corpus. This should set the bench- mark for future development of various NLP components in syntax and semantics, and possibly encourage research towards an integrated system that makes use of the various layers jointly to improve overall performance.","2013-08","2023-02-28 16:27:30","2023-10-09 17:21:18","2023-02-28 16:27:30","143–152","","","","","","","","","","","Association for Computational Linguistics","Sofia, Bulgaria","","","","https://paperswithcode.com/paper/towards-robust-linguistic-analysis-using","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/6QIM3K2A/Pradhan et al. - 2013 - Towards Robust Linguistic Analysis using OntoNotes.pdf","","SAT_lang:multi; SAT_task:CorefReso; SAT_lang:chinese; SAT_lang:english; SAT_lang:arabic; SAT_nbDoc:10568","⚠️ Invalid DOI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CoNLL 2013","","","","","","","","","","","","","","",""
"UH2HSVR7","conferencePaper","2011","Hoffmann, Raphael; Zhang, Congle; Ling, Xiao; Zettlemoyer, Luke; Weld, Daniel S.","Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations","Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies","","","not found","https://aclanthology.org/P11-1055","nformation extraction (IE) holds the promise of generating a large-scale knowledge base from the Web’s natural language text. Knowledge-based weak supervision, using structured data to heuristically label a training corpus, works towards this goal by enabling the automated learning of a potentially unbounded number of relation extractors. Recently, researchers have developed multi- instance learning algorithms to combat the noisy training data that can come from heuristic labeling, but their models assume relations are disjoint — for example they cannot extract the pair Founded(Jobs, Apple) and CEO-of(Jobs, Apple). This paper presents a novel approach for multi-instance learning with overlapping re- lations that combines a sentence-level extrac- tion model with a simple, corpus-level compo- nent for aggregating the individual facts. We apply our model to learn extractors for NY Times text using weak supervision from Free- base. Experiments show that the approach runs quickly and yields surprising gains in accuracy, at both the aggregate and sentence level.","2011-06","2023-02-28 16:28:04","2023-10-02 05:38:11","2023-02-28 16:28:04","541–550","","","","","","","","","","","Association for Computational Linguistics","Portland, Oregon, USA","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/CP4662VS/Hoffmann et al. - 2011 - Knowledge-Based Weak Supervision for Information E.pdf","","SAT_learning:weaklySupervised; SAT_rel_type:overlapping","⚠️ Invalid DOI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL-HLT 2011","","","","","","","","","","","","","","",""
"M9CKB29S","conferencePaper","2022","Chia, Yew Ken; Bing, Lidong; Aljunied, Sharifah Mahani; Si, Luo; Poria, Soujanya","A Dataset for Hyper-Relational Extraction and a Cube-Filling Approach","Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","","","not found","http://arxiv.org/abs/2211.10018","Relation extraction has the potential for largescale knowledge graph construction, but current methods do not consider the qualiﬁer attributes for each relation triplet, such as time, quantity or location. The qualiﬁers form hyperrelational facts which better capture the rich and complex knowledge graph structure. For example, the relation triplet (Leonard Parker, Educated At, Harvard University) can be factually enriched by including the qualiﬁer (End Time, 1967). Hence, we propose the task of hyper-relational extraction to extract more speciﬁc and complete facts from text. To support the task, we construct HyperRED, a largescale and general-purpose dataset. Existing models cannot perform hyper-relational extraction as it requires a model to consider the interaction between three entities. Hence, we propose CubeRE, a cube-ﬁlling model inspired by table-ﬁlling approaches and explicitly considers the interaction between relation triplets and qualiﬁers. To improve model scalability and reduce negative class imbalance, we further propose a cube-pruning method. Our experiments show that CubeRE outperforms strong baselines and reveal possible directions for future research. Our code and data are available at github.com/declare-lab/HyperRED.","2022-11-17","2023-02-28 16:22:58","2023-10-17 16:32:22","2023-02-28 16:22:58","10114--10133","","","","","","HyperRED","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates","en","TRUE","","https://paperswithcode.com/paper/a-dataset-for-hyper-relational-extraction-and","https://github.com/declare-lab/HyperRED","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/4U7DYE48/Chia et al. - 2022 - A Dataset for Hyper-Relational Extraction and a Cu.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:sentence; SAT_source:Wikidata; SAT_rel_type:nary; SAT_source:Wikipedia; SAT_method_selection:Distant; SAT_method_selection:NLI; SAT_method_selection:MultiHuman; SAT_nbtypes_entity:62; SAT_nbTrainEx:39840; SAT_nbEvalEx:1000; SAT_nbTriples:44372; SAT_rel_type:qualified; SAT_task:GraphGeneration; SAT_nbTestEx:4000","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","","","","","","","","","","","","","","",""
"T4FMGPAN","conferencePaper","2018","Elsahar, Hady; Vougiouklis, Pavlos; Remaci, Arslen; Gravier, Christophe; Hare, Jonathon; Simperl, Elena; Laforest, Frederique","T-REx: A Large Scale Alignment of Natural Language with Knowledge Base Triples","LREC2018","","","not found","https://aclanthology.org/L18-1544","Alignments between natural language and Knowledge Base (KB) triples are an essential prerequisite for training machine learning approaches employed in a variety of Natural Language Processing problems. These include Relation Extraction, KB Population, Question Answering and Natural Language Generation from KB triples. Available datasets that provide those alignments are plagued by signiﬁcant shortcomings – they are of limited size, they exhibit a restricted predicate coverage, and/or they are of unreported quality. To alleviate these shortcomings, we present T-REx, a dataset of large scale alignments between Wikipedia abstracts and Wikidata triples. T-REx consists of 11 million triples aligned with 3.09 million Wikipedia abstracts (6.2 million sentences). T-REx is two orders of magnitude larger than the largest available alignments dataset and covers 2.5 times more predicates. Additionally, we stress the quality of this language resource thanks to an extensive crowdsourcing evaluation. T-REx is publicly available at https://w3id.org/t-rex.","2018","2023-02-27 14:10:46","2023-10-17 16:27:31","","","","","","","","T-REx","","","","","European Language Resources Association (ELRA)","","en","True","","https://paperswithcode.com/paper/t-rex-a-large-scale-alignment-of-natural","https://github.com/hadyelsahar/RE-NLG-Dataset","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/ICIUCWWS/Elsahar et al. - T-REx A Large Scale Alignment of Natural Language.pdf","","SAT_oldTag:CHECKED0923; SAT_task:QA; SAT_task:RE; SAT_granularity:sentence; SAT_task:TextGeneration; SAT_task:CorefReso; SAT_task:EntityLinking; SAT_task:NER; SAT_source:Wikidata; SAT_source:Wikipedia; SAT_source:DBpedia; SAT_method_selection:Distant; SAT_nbSent:11000; SAT_nbtypes_relations:633; SAT_nbDoc:3090; SAT_task:GraphGeneration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FHC8RXUX","preprint","2021","Zaporojets, Klim; Deleu, Johannes; Develder, Chris; Demeester, Thomas","DWIE: an entity-centric dataset for multi-task document-level information extraction","","","","10.48550/arXiv.2009.12626","http://arxiv.org/abs/2009.12626","This paper presents DWIE, the 'Deutsche Welle corpus for Information Extraction', a newly created multi-task dataset that combines four main Information Extraction (IE) annotation subtasks: (i) Named Entity Recognition (NER), (ii) Coreference Resolution, (iii) Relation Extraction (RE), and (iv) Entity Linking. DWIE is conceived as an entity-centric dataset that describes interactions and properties of conceptual entities on the level of the complete document. This contrasts with currently dominant mention-driven approaches that start from the detection and classification of named entity mentions in individual sentences. Further, DWIE presented two main challenges when building and evaluating IE models for it. First, the use of traditional mention-level evaluation metrics for NER and RE tasks on entity-centric DWIE dataset can result in measurements dominated by predictions on more frequently mentioned entities. We tackle this issue by proposing a new entity-driven metric that takes into account the number of mentions that compose each of the predicted and ground truth entities. Second, the document-level multi-task annotations require the models to transfer information between entity mentions located in different parts of the document, as well as between different tasks, in a joint learning setting. To realize this, we propose to use graph-based neural message passing techniques between document-level mention spans. Our experiments show an improvement of up to 5.5 F1 percentage points when incorporating neural graph propagation into our joint model. This demonstrates DWIE's potential to stimulate further research in graph neural networks for representation learning in multi-task IE. We make DWIE publicly available at https://github.com/klimzaporojets/DWIE.","2021-03-09","2023-02-28 16:24:13","2023-05-10 09:57:32","2023-02-28 16:24:13","","","","","","","DWIE","","","","","arXiv","","","","","https://paperswithcode.com/paper/dwie-an-entity-centric-dataset-for-multi-task","","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/V8SUDUNA/Zaporojets et al. - 2021 - DWIE an entity-centric dataset for multi-task doc.pdf; /root/snap/zotero-snap/common/Zotero/storage/USG83MU9/2009.html","","Pwc_task:Relation Extraction; Pwc_task:Named Entity Recognition (NER); Pwc_task:Coreference Resolution; Pwc_task:Representation Learning; Pwc_task:Entity Linking; Pwc_task:Named Entity Recognition; Pwc_task:named-entity-recognition; Pwc_task:NER; Pwc_task:coreference-resolution","⚠️ Invalid DOI; Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2009.12626","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NVSTQ44D","journalArticle","2021","Zaporojets, Klim; Deleu, Johannes; Develder, Chris; Demeester, Thomas","DWIE: An entity-centric dataset for multi-task document-level information extraction","Elsevier","","0306-4573","10.1016/j.ipm.2021.102563","https://www.sciencedirect.com/science/article/pii/S0306457321000662","This paper presents DWIE, the ‘Deutsche Welle corpus for Information Extraction’, a newly created multi-task dataset that combines four main Information Extraction (IE) annotation subtasks: (i) Named Entity Recognition (NER), (ii) Coreference Resolution, (iii) Relation Extraction (RE), and (iv) Entity Linking. DWIE is conceived as an entity-centric dataset that describes interactions and properties of conceptual entities on the level of the complete document. This contrasts with currently dominant mention-driven approaches that start from the detection and classification of named entity mentions in individual sentences. Further, DWIE presented two main challenges when building and evaluating IE models for it. First, the use of traditional mention-level evaluation metrics for NER and RE tasks on entity-centric DWIE dataset can result in measurements dominated by predictions on more frequently mentioned entities. We tackle this issue by proposing a new entity-driven metric that takes into account the number of mentions that compose each of the predicted and ground truth entities. Second, the document-level multi-task annotations require the models to transfer information between entity mentions located in different parts of the document, as well as between different tasks, in a joint learning setting. To realize this, we propose to use graph-based neural message passing techniques between document-level mention spans. Our experiments show an improvement of up to 5.5 F1 percentage points when incorporating neural graph propagation into our joint model. This demonstrates DWIE’s potential to stimulate further research in graph neural networks for representation learning in multi-task IE. We make DWIE publicly available at https://github.com/klimzaporojets/DWIE.","2021-07-01","2023-03-06 19:28:21","2023-10-17 16:49:49","2023-03-06 19:28:21","102563","","4","58","","Information Processing & Management","DWIE","","","","","","","en","True","","https://arxiv.org/abs/2009.12626","https://github.com/klimzaporojets/DWIE","ScienceDirect","","{'citing': ['10.1016/j.ipm.2021.102836', '10.1016/j.ipm.2022.102902', '10.1007/s11227-022-04476-6', '10.1007/978-3-031-19433-7_37', '10.1145/3511808.3557313'], 'cited': ['10.1016/j.eswa.2018.07.032', '10.1016/j.inffus.2016.10.004', '10.1016/j.is.2018.12.003', '10.1086/266577', '10.1145/3357384.3358119', '10.18653/v1/d17-1182', '10.18653/v1/d18-1514', '10.18653/v1/d19-1005', '10.18653/v1/k17-1008', '10.18653/v1/n18-2016', '10.18653/v1/n19-1078', '10.18653/v1/p16-1101', '10.18653/v1/p19-1066', '10.3115/v1/p14-1038', '10.1109/iccv.2019.01039', '10.1145/1557019.1557073', '10.1145/3178876.3186175', '10.1162/tacl_a_00104', '10.18653/v1/e17-2044', '10.18653/v1/n18-2108', '10.18653/v1/p17-1053', '10.18653/v1/p19-1024', '10.18653/v1/p19-1279', '10.18653/v1/p19-1525', '10.3115/1220575.1220579', '10.3115/v1/p14-2006', '10.1016/j.ipm.2019.03.004', '10.1016/j.ipm.2020.102344', '10.1093/bioinformatics/btg1023', '10.1109/tnn.2008.2005605', '10.1162/tacl_a_00240', '10.1177/001316446002000104', '10.18653/v1/d17-1018', '10.18653/v1/k19-1063', '10.18653/v1/n19-1308', '10.18653/v1/p19-1480', '10.18653/v1/s17-2091', '10.3115/v1/d14-1162', '10.3115/v1/w15-0812', '10.1016/j.ipm.2018.04.008', '10.1145/3178876.3186023', '10.11613/bm.2012.031', '10.18653/v1/d17-1004', '10.18653/v1/d18-1360', '10.18653/v1/d19-1539', '10.18653/v1/d19-1585', '10.18653/v1/e17-1110', '10.18653/v1/n16-1030', '10.18653/v1/p17-1171', '10.18653/v1/p19-1074', '10.18653/v1/p19-1136', '10.18653/v1/w17-4418', '10.3115/1621969.1621986', '10.1007/978-3-642-15939-8_10', '10.1016/j.ipm.2020.102311', '10.1162/tacl_a_00049', '10.18653/v1/d17-1279', '10.18653/v1/d17-1283', '10.18653/v1/d18-1217', '10.18653/v1/d18-1244', '10.18653/v1/d18-1307', '10.18653/v1/n18-1079', '10.2307/2529310', '10.3115/1614049.1614064', '10.3115/v1/p15-1137', '10.3115/v1/w14-2907', '10.1109/tnnls.2020.3004626']}","","/root/snap/zotero-snap/common/Zotero/storage/UMSBC4VS/Zaporojets et al. - 2021 - DWIE An entity-centric dataset for multi-task doc.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_task:CorefReso; SAT_task:EntityLinking; SAT_task:NER; SAT_task:OpenIE; SAT_archi:GNN; SAT_task:KeywordExtraction; SAT_task:MultiLabelLearning; SAT_method_selection:Human; SAT_lang:english; SAT_method_selection:MultiHuman; SAT_nbtypes_entity:311; SAT_nbtypes_relations:65; SAT_NbEntity:43373; SAT_source:DeutscheWelle; SAT_nbTriples:21749; SAT_nbDoc:802; SAT_focus:EntityCentric; SAT_task:JoinRE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B5GV4G6W","conferencePaper","2021","Bhartiya, Abhyuday; Badola, Kartikeya; Mausam","DiS-ReX: A Multilingual Dataset for Distantly Supervised Relation Extraction","","","","10.18653/v1/2022.acl-short.95","http://arxiv.org/abs/2104.08655","Distant supervision (DS) is a well established technique for creating large-scale datasets for relation extraction (RE) without using human annotations. However, research in DS-RE has been mostly limited to the English language. Constraining RE to a single language inhibits utilization of large amounts of data in other languages which could allow extraction of more diverse facts. Very recently, a dataset for multilingual DS-RE has been released. However, our analysis reveals that the proposed dataset exhibits unrealistic characteristics such as 1) lack of sentences that do not express any relation, and 2) all sentences for a given entity pair expressing exactly one relation. We show that these characteristics lead to a gross overestimation of the model performance. In response, we propose a new dataset, DiS-ReX, which alleviates these issues. Our dataset has more than 1.5 million sentences, spanning across 4 languages with 36 relation classes + 1 no relation (NA) class. We also modify the widely used bag attention models by encoding sentences using mBERT and provide the ﬁrst benchmark results on multilingual DS-RE. Unlike the competing dataset, we show that our dataset is challenging and leaves enough room for future research to take place in this ﬁeld.","2021-04-17","2023-02-28 16:23:06","2023-10-17 16:36:33","2023-02-28 16:23:06","","","","","","","DiS-ReX","","","","","ACL","","en","True","","https://paperswithcode.com/paper/dis-rex-a-multilingual-dataset-for-distantly","https://github.com/dair-iitd/DiS-ReX","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/PEGS8G4P/Bhartiya et al. - 2021 - DiS-ReX A Multilingual Dataset for Distantly Supe.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:sentence; SAT_task:RC; SAT_lang:multi; SAT_source:Wikidata; SAT_lang:english; SAT_lang:french; SAT_lang:german; SAT_lang:spanish; SAT_source:DBpedia; SAT_method_selection:Distant; SAT_nbtypes_relations:36; SAT_negativeExamples:True; SAT_nbExPositive:1835000; SAT_nbExNegative:274000","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL ARR September 2021 9","","","","","","","","","","","","","","",""
"Q2GD88DZ","conferencePaper","2004","Roth, Dan; Yih, Wen-tau","A Linear Programming Formulation for Global Inference in Natural Language Tasks","Proceedings of the Eighth Conference on Computational Natural Language Learning (CoNLL-2004) at HLT-NAACL 2004","","","not found","","Given a collection of discrete random variables representing outcomes of learned local predictors in natural language, e.g., named entities and relations, we seek an optimal global assignment to the variables in the presence of general (non-sequential) constraints. Examples of these constraints include the type of arguments a relation can take, and the mutual activity of different relations, etc. We develop a linear programming formulation for this problem and evaluate it in the context of simultaneously learning named entities and relations. Our approach allows us to efﬁciently incorporate domain and task speciﬁc constraints at decision time, resulting in signiﬁcant improvements in the accuracy and the “human-like” quality of the inferences.","2004","2023-02-28 16:29:14","2023-10-02 05:48:01","","","","","","","","","","","","","ACL","","en","","","","","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/ZHVNIX6R/Roth and Yih - A Linear Programming Formulation for Global Infere.pdf","","?","⚠️ Invalid DOI; ⛔ No DOI found","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","HLT-NAACL","","","","","","","","","","","","","","",""
"6U8QVKWS","conferencePaper","2004","Doddington, George; Mitchell, Alexis; Przybocki, Mark; Ramshaw, Lance; Strassel, Stephanie; Weischedel, Ralph","The Automatic Content Extraction (ACE) Program Tasks, Data, and Evaluation","Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC’04)","","","10.35111/mwxc-vh88","http://www.lrec-conf.org/proceedings/lrec2004/pdf/5.pdf","The objective of the ACE program is to develop technology to automatically infer from human language data the entities being mentioned, the relations among these entities that are directly expressed, and the events in which these entities participate. Data sources include audio and image data in addition to pure text, and Arabic and Chinese in addition to English. The effort involves defining the research tasks in detail, collecting and annotating data needed for training, development, and evaluation, and supporting the research with evaluation tools and research workshops. This program began with a pilot study in 1999. The next evaluation is scheduled for September 2004.","2004","2023-02-28 16:30:14","2023-10-17 16:30:57","","","","","Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC’04)","","","ACE","","","","","ELRA","","en","False","","","","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/NIZQJZW7/Doddington et al. - The Automatic Content Extraction (ACE) Program Tas.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_lang:multi; SAT_task:NER; SAT_lang:chinese; SAT_rel_type:nested; SAT_method_selection:Human; SAT_lang:english; SAT_All_checked:True; SAT_lang:arabic; SAT_nbtypes_entity:7; SAT_nbtypes_relations:5; SAT_nbTrainEx:300000; SAT_nbEvalEx:50000; SAT_nbSent:11000; SAT_nbTriples:8000; SAT_granularity:cross-document; SAT_rel_type:spatial; SAT_rel_type:part","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LREC","","","","","","","","","","","","","","",""
"MWZWG8DH","conferencePaper","2020","Zhang, Ningyu; Deng, Shumin; Sun, Zhanlin; Chen, Jiaoayan; Zhang, Wei; Chen, Huajun","Relation Adversarial Network for Low Resource Knowledge Graph Completion","WWW '20","","","10.1145/3366423.3380089","http://arxiv.org/abs/1911.03091","Knowledge Graph Completion (KGC) has been proposed to improve Knowledge Graphs by filling in missing connections via link prediction or relation extraction. One of the main difficulties for KGC is a low resource problem. Previous approaches assume sufficient training triples to learn versatile vectors for entities and relations, or a satisfactory number of labeled sentences to train a competent relation extraction model. However, low resource relations are very common in KGs, and those newly added relations often do not have many known samples for training. In this work, we aim at predicting new facts under a challenging setting where only limited training instances are available. We propose a general framework called Weighted Relation Adversarial Network, which utilizes an adversarial procedure to help adapt knowledge/features learned from high resource relations to different but related low resource relations. Specifically, the framework takes advantage of a relation discriminator to distinguish between samples from different relations, and help learn relation-invariant features more transferable from source relations to target relations. Experimental results show that the proposed approach outperforms previous methods regarding low resource settings for both link prediction and relation extraction.","2020-06-22","2023-03-22 11:21:12","2023-06-07 08:15:52","2023-03-22 11:21:12","","","","","","","FB1.5M","","","","","Association for Computing Machinery","","en","","","https://paperswithcode.com/paper/relation-adversarial-network-for-low-resource","","arXiv.org","","{'citing': ['10.1145/3442381.3449898', '10.1145/3487553.3524238', '10.1016/j.knosys.2022.109721', '10.1631/fitee.2040000', '10.1007/978-981-16-6471-7_3', '10.1145/3510030', '10.1016/j.knosys.2022.109459', '10.1007/978-981-16-6471-7_4', '10.1109/cost57098.2022.00026', '10.1145/3447548.3467057', '10.1145/3477495.3531757', '10.1007/s44196-022-00097-2', '10.1007/978-3-030-73194-6_20', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00096'], 'cited': ['10.1145/3366423.3380089']}","","/root/snap/zotero-snap/common/Zotero/storage/MUBRXBGY/Zhang et al. - 2020 - Relation Adversarial Network for Low Resource Know.pdf","","Pwc_task:Relation Extraction; Pwc_task:Knowledge Graphs; Pwc_task:Link Prediction; Pwc_task:Domain Adaptation; Pwc_task:Knowledge Graph Completion; Pwc_task:Partial Domain Adaptation","⚠️ Invalid DOI; Computer Science - Computation and Language; Computer Science - Artificial Intelligence; Computer Science - Machine Learning; Computer Science - Information Retrieval; Computer Science - Databases","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WWW","","","","","","","","","","","","","","",""
"CQ7MJN87","journalArticle","2022","Lin, Yucong; Xiao, Hongming; Liu, Jiani; Lin, Zichao; Lu, Keming; Wang, Feifei; Wei, Wei","Knowledge Graph Enhanced Relation Extraction Datasets","SSRN","","","10.2139/ssrn.4291794","http://arxiv.org/abs/2210.11231","Knowledge-enhanced methods that take advantage of auxiliary knowledge graphs have recently emerged in relation extraction, and they surpass traditional textbased relation extraction methods. However, there are no public datasets that contain both evidence sentences and knowledge graphs for knowledge-enhanced relation extraction. To solve this issue, we propose a knowledge-graph-enhanced relation extraction dataset (KGRED) based on widely used distantly supervised relation extraction datasets. We reﬁned these datasets to improve the data quality and constructed auxiliary knowledge graphs for these datasets through entity linking to support knowledge-enhanced relation extraction tasks. We built baselines in two popular relation extraction settings, sentence-level and bag-level relation extraction, and made comparisons between the latest knowledge-enhanced relation extraction methods using the new datasets we curated. KGRED provided high-quality relation extraction datasets with auxiliary knowledge graphs for evaluating the performance of knowledge-enhanced relation extraction methods. Experiments on KGRED reveal the inﬂuence of knowledge graph information on relation extraction tasks.","2022-11-11","2023-03-22 11:23:29","2023-10-17 12:26:42","2023-03-22 11:23:29","","","","","","Information Systems eJournal","","","","","","","","en","","","","","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/4CQD7UR7/Lin et al. - 2022 - Knowledge Graph Enhanced Relation Extraction Datas.pdf","","SAT_task:RE; SAT_context:Graph; SAT_granularity:edge; SAT_granularity:sentence; SAT_task:EntityLinking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KYTNAWUU","journalArticle","2018","Welbl, Johannes; Stenetorp, Pontus; Riedel, Sebastian","Constructing Datasets for Multi-hop Reading Comprehension Across Documents","MIT Press","","","10.1162/tacl_a_00021","https://aclanthology.org/Q18-1021","Most Reading Comprehension methods limit themselves to queries which can be answered using a single sentence, paragraph, or document. Enabling models to combine disjoint pieces of textual evidence would extend the scope of machine comprehension methods, but currently no resources exist to train and test this capability. We propose a novel task to encourage the development of models for text understanding across multiple documents and to investigate the limits of existing methods. In our task, a model learns to seek and combine evidence — effectively performing multihop, alias multi-step, inference. We devise a methodology to produce datasets for this task, given a collection of query-answer pairs and thematically linked documents. Two datasets from different domains are induced, and we identify potential pitfalls and devise circumvention strategies. We evaluate two previously proposed competitive models and find that one can integrate information across documents. However, both models struggle to select relevant information; and providing documents guaranteed to be relevant greatly improves their performance. While the models outperform several strong baselines, their best accuracy reaches 54.5% on an annotated test set, compared to human performance at 85.0%, leaving ample room for improvement.","2018","2023-03-22 11:26:21","2023-10-17 16:42:44","2023-03-22 11:26:21","287–302","","","6","","Transactions of the Association for Computational Linguistics","WikiHop/MedHop","","","","","","","","True","","https://paperswithcode.com/paper/constructing-datasets-for-multi-hop-reading","http://qangaroo.cs.ucl.ac.uk/","ACLWeb","","{'citing': ['10.1162/tacl_a_00266', '10.1017/s1351324920000017', '10.1162/tacl_a_00305', '10.1145/3366423.3380197', '10.1162/tacl_a_00309', '10.1162/tacl_a_00317', '10.3390/electronics9091472', '10.3390/app10217640', '10.1007/978-3-030-60259-8_40', '10.1007/978-3-030-60457-8_33', '10.1080/24751839.2020.1833136', '10.1145/3430984.3431007', '10.1162/tacl_a_00338', '10.1162/tacl_a_00342', '10.1007/978-3-030-32233-5_6', '10.1007/978-3-030-52167-7_7', '10.1016/j.neucom.2020.01.056', '10.1007/s11042-021-11197-0', '10.1016/j.procs.2021.05.024', '10.1145/3442381.3449806', '10.1162/tacl_a_00370', '10.1007/s10844-021-00645-w', '10.1016/j.knosys.2021.106936', '10.1007/s11280-021-00911-5', '10.1145/3442381.3449993', '10.17671/gazibtd.810362', '10.1016/b978-0-323-90118-5.00001-1', '10.1007/978-3-030-86523-8_35', '10.1145/3464377', '10.1017/9781108924184.012', '10.1017/9781108924184.014', '10.1017/9781108924184.015', '10.1017/9781108924184.018', '10.1017/9781108924184.002', '10.1017/9781108924184.004', '10.1017/9781108924184.005', '10.1017/9781108924184.017', '10.1017/9781108924184.019', '10.1017/9781108924184.009', '10.1017/9781108924184.003', '10.1017/9781108924184.006', '10.1017/9781108924184.011', '10.1017/9781108924184.016', '10.1017/9781108924184.020', '10.1017/9781108924184', '10.1017/9781108924184.001', '10.1017/9781108924184.023', '10.1017/9781108924184.007', '10.1017/9781108924184.013', '10.1017/9781108924184.021', '10.1017/9781108924184.010', '10.1017/9781108924184.008', '10.1017/9781108924184.022', '10.1007/s12559-021-09917-7', '10.1007/s11280-021-00980-6', '10.1016/j.knosys.2021.107612', '10.1017/s1351324921000395', '10.1145/3490238', '10.3390/math10040646', '10.1007/s10579-022-09577-5', '10.1017/s1351324922000171', '10.1007/s00521-022-07072-0', '10.1016/j.eswa.2022.118271', '10.1016/j.eswa.2022.118271', '10.1016/j.eswa.2022.118271', '10.1016/j.eswa.2022.118271', '10.1109/access.2020.2981134', '10.1109/ialp48816.2019.9037718', '10.1109/access.2020.3035701', '10.1109/bigdia53151.2021.9619690', '10.1109/ijcnn52387.2021.9534370', '10.1162/tacl_a_00475', '10.1007/978-981-16-9113-3_1', '10.1109/tkde.2020.2982894', '10.1109/iccmc53470.2022.9754070', '10.1145/3477495.3532048', '10.1109/access.2022.3157289', '10.1109/icdm.2019.00046', '10.1109/access.2020.3025957', '10.1109/iciccs53718.2022.9788276', '10.1109/taslp.2021.3138679', '10.1007/s00799-022-00329-y', '10.1145/3477495.3531731', '10.1109/taslp.2021.3120643', '10.1109/taslp.2022.3164218', '10.1007/s10489-022-04052-8', '10.1109/icde53745.2022.00095', '10.1007/978-3-031-12423-5_2', '10.1109/cvpr52688.2022.01600', '10.1007/978-3-031-17105-5_4', '10.1117/12.2635359', '10.1007/978-3-031-22137-8_4', '10.1007/978-3-031-22321-1_11', '10.1145/3502720', '10.1007/978-981-19-3148-2_3'], 'cited': ['10.1007/s10994-006-5833-1', '10.1016/j.jbi.2012.04.008', '10.1017/s1351324901002765', '10.1038/75556', '10.1086/601720', '10.1093/bib/5.1.39', '10.1145/2071389.2071390', '10.1162/coli_a_00287', '10.1162/tacl_a_00049', '10.1162/tacl_a_00133']}","","/root/snap/zotero-snap/common/Zotero/storage/N9435PMN/Welbl et al. - 2018 - Constructing Datasets for Multi-hop Reading Compre.pdf","","SAT_oldTag:CHECKED0923; SAT_task:QA; SAT_task:RE; SAT_source:Wikidata; SAT_source:Wikipedia; SAT_granularity:cross-document; SAT_task:ReadingComprehesion; SAT_focus:bias; SAT_nbDoc:51318; SAT_nbDoc:2508","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z55RH5U4","conferencePaper","2020",", Fabio Petroni; , Aleksandra Piktus; , Angela Fan; , Patrick Lewis; , Majid Yazdani; , Nicola De Cao; , James Thorne; , Yacine Jernite; , Vladimir Karpukhin; , Jean Maillard; , Vassilis Plachouras; , Tim Rocktäschel; , Sebastian Riedel","KILT: a Benchmark for Knowledge Intensive Language Tasks","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2021.naacl-main.200","https://arxiv.org/abs/2009.02252v4","Challenging problems such as open-domain question answering, fact checking, slot filling and entity linking require access to large, external knowledge sources. While some models do well on individual tasks, developing general models is difficult as each task might require computationally expensive indexing of custom knowledge sources, in addition to dedicated infrastructure. To catalyze research on models that condition on specific information in large textual resources, we present a benchmark for knowledge-intensive language tasks (KILT). All tasks in KILT are grounded in the same snapshot of Wikipedia, reducing engineering turnaround through the re-use of components, as well as accelerating research into task-agnostic memory architectures. We test both task-specific and general baselines, evaluating downstream performance in addition to the ability of the models to provide provenance. We find that a shared dense vector index coupled with a seq2seq model is a strong baseline, outperforming more tailor-made approaches for fact checking, open-domain question answering and dialogue, and yielding competitive results on entity linking and slot filling, by generating disambiguated text. KILT data and code are available at https://github.com/facebookresearch/KILT.","2020-09-04","2023-04-05 15:10:59","2023-10-17 16:38:46","","NA","","","NA","","","KILT","","","","","ACL","","","True","","https://paperswithcode.com/paper/kilt-a-benchmark-for-knowledge-intensive","https://github.com/facebookresearch/KILT","","","{'citing': ['10.7238/artnodes.v0i28.385735', '10.1186/s40537-021-00492-0', '10.1162/tacl_a_00407', '10.1007/978-3-030-88361-4_19', '10.1162/tacl_a_00446', '10.3233/sw-212865', '10.1162/tacl_a_00460', '10.1145/3477314.3506999', '10.1162/tacl_a_00475', '10.1109/access.2022.3190408', '10.1145/3477495.3531712', '10.1007/978-3-031-14756-2_9', '10.1007/978-3-031-17189-5_19', '10.1145/3543829.3543830', '10.1145/3511808.3557388', '10.1016/b978-0-323-89931-4.00005-5'], 'cited': []}","","","","SAT_oldTag:CHECKED0923; SAT_task:QA; SAT_task:EntityLinking; SAT_task:FactChecking; SAT_task:SlotFilling; SAT_source:Wikipedia; SAT_extend:T-REX; SAT_extend:zsRE; SAT_task:Dialog","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL","","","","","","","","","","","","","","",""
"B5KFGWZG","conferencePaper","2020",", Jeniya Tabassum; , Sydney Lee; , Wei Xu; , Alan Ritter","WNUT-2020 Task 1 Overview: Extracting Entities and Relations from Wet Lab Protocols","Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020)","","","10.18653/v1/2020.wnut-1.33","https://arxiv.org/abs/2010.14576v3","This paper presents the results of the wet lab information extraction task at WNUT 2020. This task consisted of two sub tasks: (1) a Named Entity Recognition (NER) task with 13 participants and (2) a Relation Extraction (RE) task with 2 participants. We outline the task, data annotation process, corpus statistics, and provide a high-level overview of the participating systems for each sub task.","2020-10-27","2023-04-05 15:11:07","2023-10-17 16:47:41","","NA","","","NA","","","WNUT-2020","","","","","ACL","","","True","","https://paperswithcode.com/paper/wnut-2020-task-1-overview-extracting-entities","https://github.com/jeniyat/WNUT_2020_NER","","","{'citing': ['10.1101/2021.04.26.21256038', '10.3389/frma.2021.689803', '10.1109/gcce53005.2021.9621966', '10.1109/bigdata52589.2021.9671781', '10.1155/2022/1222692'], 'cited': []}","","","","SAT_granularity:Cross-sentence; SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_task:NER; SAT_domain:bio; SAT_nbtypes_relations:15; SAT_nbtypes_entity:18; SAT_nbDoc:726; SAT_nbSent:17658; SAT_NbEntity:185313; SAT_nbTriples:124803","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WNUT","","","","","","","","","","","","","","",""
"9GVF8WUP","conferencePaper","2020",", Zhijing Jin; , Qipeng Guo; , Xipeng Qiu; , Zheng Zhang","GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation","","","","10.18653/v1/2020.coling-main.217","https://aclanthology.org/2020.coling-main.217/","Data collection for the knowledge graph-to-text generation is expensive. As a result, research on unsupervised models has emerged as an active field recently. However, most unsupervised models have to use non-parallel versions of existing small supervised datasets, which largely constrain their potential. In this paper, we propose a large-scale, general-domain dataset, GenWiki. Our unsupervised dataset has 1.3M text and graph examples, respectively. With a human-annotated test set, we provide this new benchmark dataset for future research on unsupervised text generation from knowledge graphs.","2020-12-01","2023-04-05 15:11:24","2023-10-17 16:47:09","","NA","","","NA","","","GenWiki","","","","","ACL","","","True","","https://paperswithcode.com/paper/genwiki-a-dataset-of-1-3-million-content","https://github.com/zhijing-jin/genwiki","","","{'citing': ['10.1109/access.2022.3146405'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/ED64AAIJ/ et al. - 2020 - GenWiki A Dataset of 1.3 Million Content-Sharing .pdf","","SAT_oldTag:CHECKED0923; SAT_task:TextGeneration; SAT_task:NER; SAT_granularity:paragraph; SAT_source:Wikipedia; SAT_All_checked:False; SAT_source:DBpedia; SAT_method_selection:Distant; SAT_NbEntity:1230920; SAT_NbEntity:1950664; SAT_nbTriples:2000636; SAT_nbTriples:2607997; SAT_nbtypes_relations:287; SAT_nbtypes_relations:290; SAT_task:Data-to-text; SAT_task:GraphGeneration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J35UEX3X","conferencePaper","2022","Yang, Li; Wang, Qifan; Yu, Zac; Kulkarni, Anand; Sanghai, Sumit; Shu, Bin; Elsas, Jon; Kanagal, Bhargav","MAVE: A Product Dataset for Multi-source Attribute Value Extraction","Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining","978-1-4503-9132-0","","10.1145/3488560.3498377","https://doi.org/10.1145/3488560.3498377","Attribute value extraction refers to the task of identifying values of an attribute of interest from product information. Product attribute values are essential in many e-commerce scenarios, such as customer service robots, product ranking, retrieval and recommendations. While in the real world, the attribute values of a product are usually incomplete and vary over time, which greatly hinders the practical applications. In this paper, we introduce MAVE, a new dataset to better facilitate research on product attribute value extraction. MAVE is composed of a curated set of 2.2 million products from Amazon pages, with 3 million attribute-value annotations across 1257 unique categories. MAVE has four main and unique advantages: First, MAVE is the largest product attribute value extraction dataset by the number of attribute-value examples. Second, MAVE includes multi-source representations from the product, which captures the full product information with high attribute coverage. Third, MAVE represents a more diverse set of attributes and values relative to what previous datasets cover. Lastly, MAVE provides a very challenging zero-shot test set, as we empirically illustrate in the experiments. We further propose a novel approach that effectively extracts the attribute value from the multi-source product information. We conduct extensive experiments with several baselines and show that MAVE is an effective dataset for attribute value extraction task. It is also a very challenging task on zero-shot attribute extraction. Data is available at \urlhttps://github.com/google-research-datasets/MAVE .","2022-02-15","2023-03-06 19:18:34","2023-10-09 12:12:35","2023-03-06","1256–1265","","","","","","MAVE","WSDM '22","","","","ACM","New York, NY, USA","","","","","","ACM Digital Library","","{'citing': ['10.1145/3511808.3557161', '10.1145/3485447.3512032', '10.1145/3487553.3524717'], 'cited': ['10.1145/3488560.3498377']}","","/root/snap/zotero-snap/common/Zotero/storage/CWRFLMC4/Yang et al. - 2022 - MAVE A Product Dataset for Multi-source Attribute.pdf","","new_models; SAT_context:Text; SAT_context:Image; SAT_context:MultiModal","attribute value extraction; open tag extraction; zero-shot learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C92MPZCH","conferencePaper","2023","Whitehouse, Chenxi; Vania, Clara; Aji, Alham Fikri; Christodoulopoulos, Christos; Pierleoni, A.","WebIE: Faithful and Robust Information Extraction on the Web","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2023.acl-long.428","https://www.semanticscholar.org/paper/WebIE%3A-Faithful-and-Robust-Information-Extraction-Whitehouse-Vania/49848674fd5e498a340e5632c151789ef76ae523","Extracting structured and grounded fact triples from raw text is a fundamental task in Information Extraction (IE). Existing IE datasets are typically collected from Wikipedia articles, using hyperlinks to link entities to the Wikidata knowledge base. However, models trained only on Wikipedia have limitations when applied to web domains, which often contain noisy text or text that does not have any factual information. We present WebIE, the first large-scale, entity-linked closed IE dataset consisting of 1.6M sentences automatically collected from the English Common Crawl corpus. WebIE also includes negative examples, i.e. sentences without fact triples, to better reflect the data on the web. We annotate ~25K triples from WebIE through crowdsourcing and introduce mWebIE, a translation of the annotated set in four other languages: French, Spanish, Portuguese, and Hindi. We evaluate the in-domain, out-of-domain, and zero-shot cross-lingual performance of generative IE models and find models trained on WebIE show better generalisability. We also propose three training strategies that use entity linking as an auxiliary task. Our experiments show that adding Entity-Linking objectives improves the faithfulness of our generative IE models.","2023-05-23","2023-06-01 12:19:58","2023-10-17 15:50:26","2023-06-01 12:19:58","","","","","","","WebIE","","","","","ACL","","","True","","","https://github.com/amazon-science/WebIE","Semantic Scholar","","","","/root/snap/zotero-snap/common/Zotero/storage/ZLWGQD22/Whitehouse et al. - 2023 - WebIE Faithful and Robust Information Extraction .pdf; ","https://www.semanticscholar.org/paper/WebIE%3A-Faithful-and-Robust-Information-Extraction-Whitehouse-Vania/49848674fd5e498a340e5632c151789ef76ae523","SAT_oldTag:CHECKED0923; SAT_lang:multi; SAT_learning:prompt; SAT_task:NER; SAT_model:BART; SAT_source:Wikidata; SAT_method_selection:Human; SAT_All_checked:False; SAT_negativeExamples:True; SAT_method_selection:NLI; SAT_nbtypes_entity:661; SAT_nbSent:1649657; SAT_nbTriples:1905205; SAT_nbTrainEx:1480223; SAT_nbEvalEx:86030; SAT_source:Web; SAT_source:C4; SAT_model:mBART; SAT_nbTestEx:86030","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Annual Meeting of ACL","","","","","","","","","","","","","","",""
"XQMT85ZZ","conferencePaper","2021","Ormándi, Róbert; Saleh, Mohammad; Winter, Erin; Rao, Vinay","WebRED: Effective Pretraining And Finetuning For Relation Extraction On The Web","Findings of the Association for Computational Linguistics: EACL 2023","","","10.18653/v1/2023.findings-eacl.195","https://www.semanticscholar.org/paper/WebRED%3A-Effective-Pretraining-And-Finetuning-For-On-Orm%C3%A1ndi-Saleh/085c4ca05bfb9e02ea9e534d931d5ce6f35811a6","Relation extraction is used to populate knowledge bases that are important to many applications. Prior datasets used to train relation extraction models either suffer from noisy labels due to distant supervision, are limited to certain domains or are too small to train highcapacity models. This constrains downstream applications of relation extraction. We therefore introduce: WebRED (Web Relation Extraction Dataset), a strongly-supervised human annotated dataset for extracting relationships from a variety of text found on the World Wide Web, consisting of ∼110K examples. We also describe the methods we used to collect ∼200M examples as pre-training data for this task. We show that combining pre-training on a large weakly supervised dataset with finetuning on a small strongly-supervised dataset leads to better relation extraction performance. We provide baselines for this new dataset and present a case for the importance of human annotation in improving the performance of relation extraction from text found on the web.","2021-02-18","2023-06-01 12:13:40","2023-10-17 16:21:27","2023-06-01 12:13:40","","","","","","","WebRED","","","","","ACL","","","True","","","https://github.com/ google-research-datasets/WebRED.","Semantic Scholar","","","","","https://www.semanticscholar.org/paper/WebRED%3A-Effective-Pretraining-And-Finetuning-For-On-Orm%C3%A1ndi-Saleh/085c4ca05bfb9e02ea9e534d931d5ce6f35811a6","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_task:CorefReso; SAT_task:NER; SAT_source:Wikidata; SAT_method_selection:Distant; SAT_negativeExamples:True; SAT_nbtypes_relations:100; SAT_source:Web; SAT_nbtypes_relations:523; SAT_nbDoc:117717; SAT_nbDoc:199786781","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EACL 2023","","","","","","","","","","","","","","",""
"VM2L25UP","conferencePaper","2023","Ali, Manzoor; Saleem, Muhammad; Moussallem, Diego; Sherif, Mohamed Ahmed; Ngonga Ngomo, Axel-Cyrille","RELD: A Knowledge Graph of Relation Extraction Datasets","The Semantic Web","978-3-031-33454-2 978-3-031-33455-9","","10.1007/978-3-031-33455-9_20","https://link.springer.com/10.1007/978-3-031-33455-9_20","Relation extraction plays an important role in natural language processing. There is a wide range of available datasets that benchmark existing relation extraction approaches. However, most benchmarking datasets are provided in different formats containing specific annotation rules, thus making it difficult to conduct experiments on different types of relation extraction approaches. We present RELD, an RDF knowledge graph of eight open-licensed and publicly available relation extraction datasets. We modeled the benchmarking datasets into a single ontology that provides a unified format for data access, along with annotations required for training different types of relation extraction systems. Moreover, RELD abides by the Linked Data principles. To the best of our knowledge, RELD is the largest RDF knowledge graph of entities and relations from text, containing ∼1230 million triples describing 1034 relations, 2 million sentences, 3 million abstracts and 4013 documents. RELD contributes to a variety of uses in the natural language processing community, and distinctly provides unified and easy modeling of data for benchmarking relation extraction and named entity recognition models.","2023","2023-05-30 18:18:10","2023-10-17 16:35:49","2023-05-30 18:18:10","337-353","","","13870","","","RELD","","","","","Springer Nature Switzerland","Cham","en","True","","","https://github.com/dice-group/RELD","DOI.org (Crossref)","","","","/root/snap/zotero-snap/common/Zotero/storage/IEGR2GYK/Ali et al. - 2023 - RELD A Knowledge Graph of Relation Extraction Dat.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_granularity:sentence; SAT_task:NER; SAT_granularity:paragraph; SAT_extend:DocRED; SAT_extend:FewRel; SAT_extend:T-REX; SAT_extend:GoogleRE; SAT_extend:WebNLG; SAT_extend:NYT-FB; SAT_extend:SemEval2010; SAT_nbDoc:4013; SAT_nbSent:2000000; SAT_nbTriples:1230000000; SAT_nbParagraph:3000000; SAT_extend:Wikidata-Wikipedia","","Pesquita, Catia; Jimenez-Ruiz, Ernesto; McCusker, Jamie; Faria, Daniel; Dragoni, Mauro; Dimou, Anastasia; Troncy, Raphael; Hertling, Sven","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"69D2VBCP","conferencePaper","2017","Levy, Omer; Seo, Minjoon; Choi, Eunsol; Zettlemoyer, Luke","Zero-Shot Relation Extraction via Reading Comprehension","Proceedings of the 21st Conference on Computational Natural Language           Learning (CoNLL 2017)","","","10.18653/v1/k17-1034","http://aclweb.org/anthology/K17-1034","We show that relation extraction can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot. This reduction has several advantages: we can (1) learn relationextraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-speciﬁc crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only speciﬁed at test-time, for which we have no labeled training examples. Experiments on a Wikipedia slot-ﬁlling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task.","2017","2023-02-28 16:26:43","2023-10-11 10:38:53","2023-02-28 16:26:43","333-342","","","","","","","","","","","ACL","Vancouver, Canada","en","","","","","DOI.org (Crossref)","","{'citing': ['10.1007/978-3-030-62466-8_7', '10.1162/tacl_a_00392', '10.1007/978-3-030-86159-9_33', '10.3233/sw-210435', '10.1145/3459637.3482403', '10.1109/tr.2020.3001918', '10.1162/tacl_a_00485', '10.14778/3476311.3476393', '10.1145/3488560.3498377', '10.1007/978-3-319-99495-6_8', '10.1017/s1351324918000451', '10.1109/access.2020.2970119', '10.1109/access.2022.3173355', '10.1016/j.inffus.2022.11.025', '10.1145/3510030', '10.1007/978-3-031-00129-1_21', '10.1016/j.jii.2021.100301', '10.1145/3560260', '10.1145/3293318', '10.1162/tacl_a_00475', '10.1007/s12559-021-09917-7', '10.1007/978-3-030-29894-4_10', '10.1145/3394486.3403047', '10.1145/3511808.3557271', '10.1007/978-3-031-18315-7_6', '10.1109/cecit53797.2021.00071', '10.1007/978-3-030-00671-6_12', '10.1162/tacl_a_00302', '10.1145/3485447.3512032', '10.1145/3308558.3313511', '10.2200/s01078ed2v01y202002hlt049', '10.1109/bigdata52589.2021.9672080', '10.1109/taslp.2022.3210442', '10.1145/3501399', '10.1007/978-3-030-86380-7_9', '10.1186/s12859-021-04534-5', '10.1109/access.2020.2985126', '10.1007/978-3-031-17105-5_4', '10.1016/j.ins.2022.03.075', '10.1109/access.2021.3130956', '10.1016/j.neucom.2022.03.016', '10.1007/978-3-030-44689-5_6', '10.1145/3430895.3460131', '10.1007/s11633-022-1331-6', '10.1007/s10489-022-03596-z', '10.1007/978-3-030-73200-4_38', '10.1016/j.neucom.2022.04.059', '10.1162/dint_a_00103', '10.1016/j.ijmedinf.2021.104628', '10.1007/978-981-15-5573-2_4', '10.1007/s12559-021-09925-7', '10.1145/3290353'], 'cited': ['10.18653/v1/k17-1034']}","","/root/snap/zotero-snap/common/Zotero/storage/FWI9ZRLD/Levy et al. - 2017 - Zero-Shot Relation Extraction via Reading Comprehe.pdf","","slot_filling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 21st Conference on Computational Natural Language           Learning (CoNLL 2017)","","","","","","","","","","","","","","",""
"UM67W6X6","conferencePaper","2019","Spala, Sasha; Miller, Nicholas A.; Yang, Yiming; Dernoncourt, Franck; Dockhorn, Carl","DEFT: A corpus for definition extraction in free- and semi-structured text","Proceedings of the 13th Linguistic Annotation Workshop","","","10.18653/v1/W19-4015","https://www.aclweb.org/anthology/W19-4015","","2019","2023-02-28 16:25:39","2023-10-17 16:51:08","2023-02-28 16:25:39","124-131","","","","","","DEFT","","","","","Association for Computational Linguistics","Florence, Italy","en","True","","https://paperswithcode.com/paper/deft-a-corpus-for-definition-extraction-in","https://github.com/adobe-research/deft_corpus","DOI.org (Crossref)","","{'citing': ['10.1007/978-3-030-96957-8_25', '10.3389/frai.2022.900304'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/GTTBLG2I/Spala et al. - 2019 - DEFT A corpus for definition extraction in free- .pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_task:TextGeneration; SAT_method_selection:Human; SAT_nbtypes_relations:5; SAT_negativeExamples:True; SAT_domain:politic; SAT_method_selection:MultiHuman; SAT_task:Spanning; SAT_focus:DefinitionGeneration; SAT_nbSent:23746; SAT_source:legal; SAT_source:textBook; SAT_domain:justice; SAT_domain:biology; SAT_domain:psychology; SAT_domain:economy; SAT_domain:sociology; SAT_rel_type:definition; SAT_rel_type:qualified; SAT_task:Data-to-text","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 13th Linguistic Annotation Workshop","","","","","","","","","","","","","","",""
"JAI2H3PD","conferencePaper","2022",", Xiaozhi Wang; , Yulin Chen; , Ning Ding; , Hao Peng; , Zimu Wang; , Yankai Lin; , Xu Han; , Lei Hou; , Juanzi Li; , Zhiyuan Liu; , Peng Li; , Jie zhou","MAVEN-ERE: A Unified Large-scale Dataset for Event Coreference, Temporal, Causal, and Subevent Relation Extraction","Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","","","not found","https://arxiv.org/abs/2211.07342v1","The diverse relationships among real-world events, including coreference, temporal, causal, and subevent relations, are fundamental to understanding natural languages. However, two drawbacks of existing datasets limit event relation extraction (ERE) tasks: (1) Small scale. Due to the annotation complexity, the data scale of existing datasets is limited, which cannot well train and evaluate data-hungry models. (2) Absence of unified annotation. Different types of event relations naturally interact with each other, but existing datasets only cover limited relation types at once, which prevents models from taking full advantage of relation interactions. To address these issues, we construct a unified large-scale human-annotated ERE dataset MAVEN-ERE with improved annotation schemes. It contains 103,193 event coreference chains, 1,216,217 temporal relations, 57,992 causal relations, and 15,841 subevent relations, which is larger than existing datasets of all the ERE tasks by at least an order of magnitude. Experiments show that ERE on MAVEN-ERE is quite challenging, and considering relation interactions with joint learning can improve performances. The dataset and source codes can be obtained from https://github.com/THU-KEG/MAVEN-ERE.","2022-11-14","2023-04-05 15:11:42","2023-10-17 16:07:22","","926--941","","","","","","MAVEN-ERE","","","","","Association for Computational Linguistics","","","True","","https://paperswithcode.com/paper/maven-ere-a-unified-large-scale-dataset-for","https://github.com/THU-KEG/MAVEN-ERE","","","","","/root/snap/zotero-snap/common/Zotero/storage/IELIEXU2/ et al. - 2022 - MAVEN-ERE A Unified Large-scale Dataset for Event.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:document; SAT_task:CorefReso; SAT_rel_type:temporal; SAT_task:Event; SAT_rel_type:causal; SAT_focus:ReasoningPath; SAT_nbtypes_relations:12; SAT_nbDoc:4480; SAT_nbSent:49873; SAT_nbtypes_entity:168; SAT_NbEntity:112276; SAT_focus:Subevent; SAT_nbtypes_entity:3","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP","","","","","","","","","","","","","","",""
"NYKQEMXZ","journalArticle","2022","Sharma, Soumya; Nayak, Tapas; Bose, Arusarka; Meena, Ajay Kumar; Dasgupta, Koustuv; Ganguly, Niloy; Goyal, Pawan","FinRED: A Dataset for Relation Extraction in Financial Domain","","","","10.1145/3487553.3524637","","Relation extraction models trained on a source domain cannot be applied on a different target domain due to the mismatch between relation sets. In the current literature, there is no extensive opensource relation extraction dataset specific to the finance domain. In this paper, we release FinRED, a relation extraction dataset curated from financial news and earning call transcripts containing relations from the finance domain. FinRED has been created by mapping Wikidata triplets using distance supervision method. We manually annotate the test data to ensure proper evaluation. We also experiment with various state-of-the-art relation extraction models on this dataset to create the benchmark. We see a significant drop in their performance on FinRED compared to the general relation extraction datasets which tells that we need better models for financial relation extraction.","2022","2022-05-02 09:33:35","2023-06-07 12:17:22","","3","","","","","","","","","","","","","en","Close","","","","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/KQ7MCQ8Y/Sharma et al. - FinRED A Dataset for Relation Extraction in Finan.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ICXL9387","preprint","2021","Perkins, Hugh","TexRel: a Green Family of Datasets for Emergent Communications on Relations","","","","10.48550/arXiv.2105.12804","http://arxiv.org/abs/2105.12804","We propose a new dataset TexRel as a playground for the study of emergent communications, in particular for relations. By comparison with other relations datasets, TexRel provides rapid training and experimentation, whilst being sufficiently large to avoid overfitting in the context of emergent communications. By comparison with using symbolic inputs, TexRel provides a more realistic alternative whilst remaining efficient and fast to learn. We compare the performance of TexRel with a related relations dataset Shapeworld. We provide baseline performance results on TexRel for sender architectures, receiver architectures and end-to-end architectures. We examine the effect of multitask learning in the context of shapes, colors and relations on accuracy, topological similarity and clustering precision. We investigate whether increasing the size of the latent meaning space improves metrics of compositionality. We carry out a case-study on using TexRel to reproduce the results of an experiment in a recent paper that used symbolic inputs, but using our own non-symbolic inputs, from TexRel, instead.","2021-05-26","2023-03-22 11:26:03","2023-06-07 12:15:27","2023-03-22 11:26:03","","","","","","","TexRel","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2105.12804 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/2ZFCM9LF/Perkins - 2021 - TexRel a Green Family of Datasets for Emergent Co.pdf; /root/snap/zotero-snap/common/Zotero/storage/95G4KCHV/2105.html","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2105.12804","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R3HSD4G5","conferencePaper","2021","Gao, Tianyu; Han, Xu; Bai, Yuzhuo; Qiu, Keyue; Xie, Zhiyu; Lin, Yankai; Liu, Zhiyuan; Li, Peng; Sun, Maosong; Zhou, Jie","Manual Evaluation Matters: Reviewing Test Protocols of Distantly Supervised Relation Extraction","Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021","","","10.18653/v1/2021.findings-acl.112","https://aclanthology.org/2021.findings-acl.112","","2021","2023-03-22 11:24:46","2023-10-20 13:05:38","2023-03-22 11:24:46","1306-1318","","","","","","","","","","","ACL","Online","en","","","https://paperswithcode.com/paper/manual-evaluation-matters-reviewing-test","","DOI.org (Crossref)","","{'citing': ['10.1186/s12859-022-04646-6', '10.3390/s22134911', '10.1186/s12859-022-04646-6', '10.3390/s22134911', '10.1186/s12859-022-04646-6', '10.3390/s22134911'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/6PBLV8P2/Gao et al. - 2021 - Manual Evaluation Matters Reviewing Test Protocol.pdf","","star; NOT A SURVEY ?; SAT_model:BERT; SAT_task:RE; SAT_granularity:sentence; SAT_archi:CNN; SAT_archi:PCNN; SAT_type:Benchmark; SAT_focus:distant; CHECKED1023; SAT_dataset:NYT; SAT_dataset:Wiki20; SAT_granularity:bag; SAT_nbModel:4; SAT_focus_period:2015-2021; SAT_interest:8; SAT_focus:EVAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL-IJCNLP","","","","","","","","","","","","","","",""
"IBPVBBUM","conferencePaper","2003","Tjong Kim Sang, Erik F.; De Meulder, Fien","Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition","Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003","","","10.3115/1119176.1119195","https://aclanthology.org/W03-0419","We describe the CoNLL-2003 shared task: language-independent named entity recog- nition. We give background information on the data sets (English and German) and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their perfor- mance.","2003","2023-02-28 16:29:37","2023-10-17 16:45:57","2023-02-28 16:29:37","142–147","","","","","","CoNLL","","","","","ACL","","","False","","https://paperswithcode.com/paper/introduction-to-the-conll-2003-shared-task","http://lcg-www.uia.ac.be/conll2003/ner/","ACLWeb","","{'citing': ['10.1109/iceet48479.2020.9048203', '10.1109/access.2020.2984582', '10.1109/icmla.2019.00298', '10.1109/tbdata.2020.2998770', '10.1007/978-981-15-4828-4_14', '10.1109/icawst.2018.8517195', '10.1371/journal.pone.0270904', '10.1109/icmla51294.2020.00094', '10.1109/icphys.2019.8780184', '10.1109/gucon.2018.8674901', '10.1007/978-3-031-10525-8_3', '10.1109/icsc50631.2021.00007', '10.1109/bibm52615.2021.9669766', '10.1016/j.eswa.2020.113765', '10.1109/tpami.2020.3046683', '10.1109/ebbt.2019.8741631', '10.1371/journal.pone.0267812', '10.5715/jnlp.29.294', '10.1109/bibm47256.2019.8983247', '10.1109/cic48465.2019.00031', '10.1007/s10489-022-03511-6', '10.1109/icassp43922.2022.9746913', '10.1109/iaeac50856.2021.9390956', '10.1109/icassp39728.2021.9414304', '10.1049/cit2.12107', '10.1109/infrkm.2018.8464820', '10.1200/cci.21.00136', '10.1109/asonam49781.2020.9381292', '10.1109/slt48900.2021.9383493', '10.1109/ubmk.2019.8907039', '10.1109/asyu52992.2021.9598971', '10.1109/bigdata52589.2021.9671435', '10.1109/slt.2018.8639043', '10.3390/app12136391', '10.1001/jamanetworkopen.2022.27109', '10.1016/j.neucom.2022.09.081', '10.1016/j.neucom.2022.09.081', '10.1039/d2sc04322j', '10.3233/sw-223177', '10.1162/tacl_a_00500', '10.1016/j.ipm.2022.103065', '10.1101/2022.09.22.22280246', '10.1007/978-3-031-17601-2_28', '10.1007/978-3-031-16270-1_12', '10.1145/3301275.3302276', '10.1109/fuzz-ieee55066.2022.9882595', '10.1007/978-3-031-16078-3_49', '10.3390/info13080367', '10.1162/tacl_a_00501', '10.1007/s10618-022-00854-z', '10.1016/j.eswa.2022.119274', '10.1080/13658816.2022.2133125', '10.1109/icacte55855.2022.9943631', '10.12677/csa.2022.1211257', '10.21203/rs.3.rs-2169841/v1', '10.1007/978-3-031-21689-3_38', '10.1109/icpr56361.2022.9956120', '10.21203/rs.3.rs-2163664/v1', '10.1007/s11280-019-00736-3', '10.1186/s13326-019-0211-7', '10.1007/978-3-030-43823-4_41', '10.1007/s42044-018-0014-5', '10.1007/978-3-319-99495-6_19', '10.1007/978-981-15-0751-9_14', '10.1007/978-3-030-00671-6_12', '10.1007/s10916-020-1542-8', '10.1080/14754835.2019.1671173', '10.1631/fitee.1800743', '10.1002/9781119419686.biblio', '10.1145/3368555.3384467', '10.14778/1920841.1920916', '10.14778/2536222.2536237', '10.1007/978-3-030-36708-4_25', '10.1007/978-981-15-1081-6_18', '10.1007/978-3-030-03596-9_35', '10.1007/978-3-319-75477-2_30', '10.1145/3159652.3159695', '10.1007/978-3-030-03192-3_20', '10.2200/s00999ed3v01y202003hlt046', '10.1145/2499955.2499958', '10.1007/11562214_78', '10.1145/1328964.1328989', '10.1145/3366424.3383527', '10.1145/3329710', '10.1145/3331184.3331646', '10.1007/978-3-030-44584-3_37', '10.1145/3297280.3297379', '10.1145/3357384.3358024', '10.1145/3357384.3358109', '10.1101/786921', '10.1145/3308560.3317704', '10.1007/978-3-030-52683-2_1', '10.1162/coli_a_00376', '10.1007/s40998-020-00352-2', '10.1162/tacl_a_00316', '10.1093/bioinformatics/btaa531', '10.1007/978-981-15-5573-2_7', '10.1002/asi.24399', '10.1111/jbfa.12378', '10.1145/2047296.2047298', '10.1145/1967293.1967296', '10.1145/2483691.2483695', '10.1007/s00521-020-05351-2', '10.1007/978-3-030-58323-1_11', '10.1007/978-3-030-58323-1_29', '10.1007/978-3-030-54956-5_7', '10.1080/13658816.2018.1458986', '10.1145/1322391.1322393', '10.1162/tacl_a_00334', '10.1145/3394486.3403149', '10.4018/ijghpc.2020070101', '10.1145/1089815.1089817', '10.1145/2414425.2414428', '10.1051/itmconf/20171204002', '10.1145/3281354.3281363', '10.1145/3368089.3417067', '10.1016/j.websem.2015.12.004', '10.1007/978-3-030-62327-2_23', '10.1007/978-3-030-63007-2_61', '10.1007/978-3-030-63031-7_10', '10.1007/978-3-030-64452-9_3', '10.1007/978-3-030-65218-0_16', '10.1007/978-3-319-59834-5_8', '10.2139/ssrn.2940564', '10.2200/s00994ed1v01y202002hlt045', '10.1016/j.eswa.2011.05.004', '10.1016/j.ins.2008.05.002', '10.1016/j.ipm.2014.04.005', '10.1016/j.patcog.2008.02.010', '10.1016/j.artint.2012.03.006', '10.1016/j.artint.2012.04.005', '10.1016/j.future.2018.03.035', '10.1016/j.jbi.2011.10.007', '10.1016/j.knosys.2020.105842', '10.1016/b978-0-12-809633-8.20463-9', '10.5715/jnlp.27.499', '10.1016/j.datak.2020.101796', '10.1016/j.ipm.2012.05.006', '10.1016/j.jbi.2017.05.009', '10.1016/j.jbi.2004.08.008', '10.1016/j.knosys.2013.02.008', '10.1016/j.artint.2012.10.002', '10.1016/j.csl.2007.12.001', '10.1016/j.datak.2006.06.014', '10.1016/j.drudis.2013.10.006', '10.1016/j.engappai.2016.01.011', '10.1016/j.ipm.2014.10.006', '10.1016/j.neucom.2015.07.046', '10.1016/j.sbspro.2011.10.596', '10.3390/ijgi10030155', '10.1007/s10462-021-09983-1', '10.1002/asi.24032', '10.1016/j.neucom.2021.05.103', '10.1007/s10664-020-09918-4', '10.2196/preprints.31223', '10.1007/978-3-030-72610-2_2', '10.1038/s41598-021-82338-6', '10.1145/3459930.3469533', '10.1002/9781119268567.biblio', '10.1007/s11302-018-9614-7', '10.1007/s11390-017-1762-7', '10.1007/s12204-018-1954-5', '10.1007/s13042-014-0268-7', '10.1007/s13042-014-0275-8', '10.1002/9781444324044.refs', '10.1002/asi.24282', '10.1017/atsip.2019.12', '10.1017/s1351324908004968', '10.1038/sdata.2018.258', '10.1075/term.21.2.04gai', '10.1080/18756891.2012.747661', '10.1093/bioinformatics/bts125', '10.1007/978-94-024-0881-2_31', '10.1007/978-94-024-0881-2_32', '10.1007/978-981-10-8438-6_19', '10.1007/978-981-13-1135-2_4', '10.1111/coin.12214', '10.1007/11683568_8', '10.1007/11893318_27', '10.1145/2328967.2328972', '10.1145/2736277.2741626', '10.1145/2736277.2741633', '10.1145/2740908.2743039', '10.1145/2948649.2948651', '10.1145/2963100', '10.1145/2993901.2993907', '10.1145/3018661.3018724', '10.1145/3038912.3052600', '10.1145/3077136.3080668', '10.1145/3106668.3106672', '10.1145/3148011.3148021', '10.1145/3148011.3148024', '10.1145/3148011.3154478', '10.1145/3205977.3205984', '10.1145/3238797', '10.1145/3273931', '10.1007/978-1-4471-2978-3_1', '10.1177/1464884917716699', '10.1002/9781118617151.ch37', '10.1007/s00500-012-0885-6', '10.1007/s00500-017-2963-2', '10.1007/s10032-011-0155-7', '10.1007/s10115-012-0502-0', '10.1007/s10115-018-1265-z', '10.1007/s10462-019-09688-6', '10.1007/s10506-018-9225-1', '10.1007/s10515-011-0099-7', '10.1007/s10579-013-9255-y', '10.1007/s10579-019-09461-9', '10.1007/s10579-019-09471-7', '10.1007/s10590-017-9208-0', '10.1007/s10664-016-9430-z', '10.1007/s10994-013-5411-2', '10.1007/s11168-010-9071-0', '10.1186/1471-2105-14-281', '10.1186/1758-2946-7-s1-s4', '10.1186/1758-2946-7-s1-s8', '10.1186/s12911-019-0865-1', '10.1186/s12938-018-0573-6', '10.1186/s42400-018-0019-2', '10.1007/978-3-030-01129-1_10', '10.1007/978-3-030-03146-6_116', '10.1007/978-3-030-04179-3_8', '10.1007/978-3-030-14596-5_1', '10.1007/978-3-030-17083-7_2', '10.1007/978-3-030-18305-9_46', '10.1007/978-3-030-22312-0_8', '10.1007/978-3-030-22999-3_65', '10.1007/978-3-030-26072-9_25', '10.1007/978-3-030-29894-4_13', '10.1007/978-3-030-29908-8_26', '10.1007/978-3-030-30241-2_29', '10.1007/978-3-030-30639-7_2', '10.1007/978-3-030-31624-2_7', '10.1007/978-3-030-32236-6_14', '10.1007/978-3-319-06569-4_19', '10.1007/978-3-319-07064-3_26', '10.1007/978-3-319-08958-4_16', '10.1007/978-3-319-08976-8_2', '10.1007/978-3-319-12655-5_6', '10.1007/978-3-319-13647-9_6', '10.1007/978-3-319-14120-6_16', '10.1007/978-3-319-15563-0_3', '10.1007/978-3-319-24033-6_7', '10.1007/978-3-319-27000-5_23', '10.1007/978-3-319-27433-1_15', '10.1007/978-3-319-29009-6_1', '10.1007/978-3-319-45510-5_20', '10.1007/978-3-319-46565-4_2', '10.1007/978-3-319-48674-1_54', '10.1007/978-3-319-50478-0_11', '10.1007/978-3-319-50496-4_22', '10.1007/978-3-319-52920-2_18', '10.1007/978-3-319-56288-9_71', '10.1007/978-3-319-59888-8_23', '10.1007/978-3-319-68723-0_9', '10.1007/978-3-319-68786-5_18', '10.1007/978-3-319-71078-5_12', '10.1007/978-3-319-76348-4_11', '10.1007/978-3-319-90165-7_6', '10.1007/978-3-319-91452-7_53', '10.1007/978-3-319-93417-4_8', '10.1007/978-3-319-93782-3_20', '10.1007/978-3-319-99722-3_32', '10.1587/transinf.2017kbl0001', '10.1007/978-3-540-24581-0_78', '10.1007/978-3-540-24630-5_19', '10.1007/978-3-540-77018-3_18', '10.1007/978-3-540-78246-9_65', '10.1007/978-3-540-89704-0_29', '10.21923/jesd.448251', '10.2200/s00491ed1v01y201303dtm034', '10.2200/s00509ed1v01y201305hlt023', '10.1007/978-3-642-00958-7_50', '10.2200/s00676ed1v01y201509dtm042', '10.2200/s00809ed2v01y201710hlt038', '10.2200/s00866ed1v01y201807dtm049', '10.2200/s00920ed2v01y201904hlt042', '10.1007/978-3-642-04125-9_27', '10.1007/978-3-642-04930-9_66', '10.1007/978-3-642-13840-9_16', '10.1007/978-3-642-13881-2_27', '10.1007/978-3-642-15246-7_8', '10.1007/978-3-642-15998-5_12', '10.1007/978-3-642-22327-3_5', '10.1007/978-3-642-23538-2_26', '10.1007/978-3-642-23708-9_3', '10.1007/978-3-642-23780-5_36', '10.1007/978-3-642-23808-6_18', '10.1007/978-3-642-27172-4_52', '10.1007/978-3-642-28249-2_6', '10.1007/978-3-642-28604-9_26', '10.1007/978-3-642-32790-2_28', '10.1007/978-3-642-37247-6_25', '10.1007/978-3-642-37247-6_27', '10.1007/978-3-642-37453-1_31', '10.1007/978-3-642-39200-9_39', '10.1007/978-3-642-40585-3_10', '10.1007/978-3-642-40585-3_20', '10.1007/978-3-642-41464-0_10', '10.1007/978-3-642-41464-0_16', '10.1007/978-3-642-41644-6_3', '10.1007/978-3-642-45185-0_50', '10.1007/978-3-642-45358-8_7', '10.29252/jsdp.14.3.127', '10.3103/s0005105517030049', '10.3233/ao-190215', '10.3233/ds-190021', '10.3233/sw-170253', '10.3233/sw-170282', '10.3233/sw-170286', '10.3897/bdj.7.e29626', '10.1109/hsi.2016.7529634', '10.1109/ialp.2015.7451557', '10.1109/icaict.2013.6722801', '10.1109/icassp.2011.5947449', '10.1109/icassp.2012.6289004', '10.1109/iccnc.2015.7069416', '10.1109/iccp.2013.6646077', '10.1109/icices.2014.7033948', '10.1109/icpr.2010.477', '10.1109/ictai.2010.54', '10.1109/ijcnn.2017.7966181', '10.1109/isise.2012.107', '10.1109/mercon.2016.7480111', '10.1109/mipro.2014.6859768', '10.1109/mis.2009.32', '10.1109/rivf.2012.6169818', '10.1109/scis-isis.2012.6505254', '10.1109/skg.2012.2', '10.1109/smap.2014.27', '10.1109/sose.2014.30', '10.1109/tkde.2011.178', '10.1109/tsc.2015.2474861', '10.1109/tvcg.2017.2744158', '10.1109/wict.2013.7113096', '10.1109/wi-iat.2010.314', '10.1109/ams.2013.33', '10.1109/asonam.2012.97', '10.1109/asru.2011.6163967', '10.1109/ceec.2012.6375385', '10.1109/civts.2014.7009471', '10.1109/cloudcom-asia.2013.102', '10.1109/compsac.2016.109', '10.1109/eit.2016.7535297', '10.1109/etcm.2017.8247537', '10.1109/fruct.2016.7584769', '10.1109/hicss.2015.190', '10.5715/jnlp.24.655', '10.1145/3377325.3377503', '10.1111/tgis.12579', '10.1007/s11192-019-03274-x', '10.1007/s10664-019-09788-5', '10.1145/3178876.3185997', '10.3233/ida-184238', '10.1145/3453892.3461321', '10.1016/j.ipm.2020.102473', '10.1145/3437963.3441777', '10.1016/j.procs.2021.06.082', '10.2478/popets-2021-0019', '10.1016/j.neucom.2020.10.010', '10.2196/24020', '10.1007/978-3-030-72113-8_28', '10.1007/978-3-030-77442-4_51', '10.1007/s11042-021-11253-9', '10.1007/s10579-020-09516-2', '10.1007/978-3-030-80599-9_7', '10.1186/s13634-021-00736-4', '10.1007/978-3-030-73050-5_34', '10.1145/3442381.3449995', '10.1162/coli_a_00397', '10.1162/tacl_a_00386', '10.1007/s00521-020-05268-w', '10.1021/acs.jcim.9b00470', '10.1007/978-3-030-87839-9_3', '10.1145/3404835.3463071', '10.1007/978-3-030-83527-9_19', '10.1016/j.eswa.2021.114855', '10.1007/978-3-030-86331-9_48', '10.1145/3404835.3462873', '10.1145/3404835.3463113', '10.3103/s1066530720020027', '10.1007/978-3-030-84186-7_24', '10.1145/3442381.3449870', '10.5715/jnlp.28.847', '10.1016/j.artmed.2021.102153', '10.1162/tacl_a_00404', '10.1007/978-3-030-86549-8_36', '10.1186/s12859-021-04247-9', '10.1145/3442442.3451894', '10.1007/s00799-021-00319-6', '10.1162/tacl_a_00425', '10.1162/tacl_a_00416', '10.1007/s41060-021-00285-x', '10.1016/j.procs.2021.08.030', '10.1162/tacl_a_00429', '10.1162/tacl_a_00438', '10.1145/3474124.3474160', '10.1007/978-3-030-91669-5_21', '10.1145/3297280.3297378', '10.1007/978-3-030-88304-1_28', '10.1145/3487057', '10.1007/978-3-030-91699-2_42', '10.1016/j.psep.2021.11.004', '10.2196/preprints.34400', '10.48084/etasr.4300', '10.1162/tacl_a_00448', '10.1021/acs.jcim.1c01199', '10.2196/preprints.36119', '10.1017/s1351324921000486', '10.1108/ijwis-05-2013-0016', '10.1007/s41060-022-00310-7', '10.1007/s11063-021-10737-x', '10.1007/s41666-021-00111-w', '10.2196/36119', '10.54856/jiswa.201912084', '10.1145/3487664.3487677', '10.1017/s1351324922000080', '10.1007/s00521-022-07164-x', '10.1145/3498324', '10.1007/s11192-022-04332-7', '10.1101/2022.04.14.488416', '10.1017/s1351324922000122', '10.1145/3485447.3512242', '10.1016/j.neucom.2022.04.027', '10.1145/3523150.3523176', '10.1162/tacl_a_00459', '10.2196/preprints.37816', '10.1109/ast52587.2021.00017', '10.1109/icctec.2017.00113', '10.1109/sp46214.2022.9833641', '10.1109/icassp43922.2022.9747433', '10.1109/icbats54253.2022.9759051', '10.1109/csci51800.2020.00099', '10.1109/hpca51647.2021.00018', '10.1109/escience.2019.00021', '10.1109/icoice48418.2019.9035170', '10.1109/tkde.2020.2981314', '10.1109/tkde.2020.2981329', '10.1109/rivf.2019.8713710', '10.1109/ivmem.2019.00016', '10.1109/iac3t.2018.8674025', '10.1109/ic-aiai.2018.8674438', '10.1109/ispras.2018.00015', '10.1109/bigcomp.2019.8679473', '10.1109/icosc.2019.8665500', '10.1109/istel.2018.8661067', '10.1109/ijcnn52387.2021.9534328', '10.1145/3531146.3533233', '10.1007/978-3-658-35969-0_3', '10.1109/dicta.2018.8615844', '10.1109/icmla.2018.00104', '10.1109/icmla.2018.00149', '10.1109/snams.2018.8554623', '10.1109/icbaie52039.2021.9389994'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/M2QSTVMZ/Tjong Kim Sang and De Meulder - 2003 - Introduction to the CoNLL-2003 Shared Task Langua.pdf","","SAT_oldTag:CHECKED0923; SAT_lang:multi; SAT_task:NER; SAT_task:OpenIE; SAT_lang:german","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CoNLL-HLT 2003","","","","","","","","","","","","","","",""
"ESM84JX4","preprint","2021",", Anonymous","RelO: An Overlapping Relation Extraction Dataset and Model","","","","not found","https://openreview.net/forum?id=3rxgHBM48gw","We introduce an overlapping relation extraction dataset(RelO) constructed from Wikipedia and Wikidata. RelO consists of 308,579 sentences, representing 40 relations and three different overlapping types. We evaluate the state-of-the-art relation extraction methods on RelO and results show that RelO is challenging for these relation extraction methods. We also use RelO as a transfer learning resources and the fine-tuned two models achieve state-of-the-art results on other related datasets. To handle the overlapping relation extraction task, We extend a pipeline framework by utilizing overlapping type information and semantic distance information of relation representations. Through careful experiments, we validate the importance of these information for overlapping relation extraction. All details and resources about the dataset and baselines are released on https://github.com/disquietBookShare/Relo.","2021-09-17","2023-05-03 16:15:55","2023-06-07 09:59:57","","","","","","","","RelO","","","","","ACL","","","NA","","https://paperswithcode.com/paper/relo-an-overlapping-relation-extraction","NA","","","","","","","Pwc_task:Relation Extraction; PWC:notbenchmarked; PWC:havecode; Pwc_task:Transfer Learning","⚠️ Invalid DOI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MZFT8DRU","conferencePaper","2019",", Hrant Khachatrian; , Lilit Nersisyan; , Karen Hambardzumyan; , Tigran Galstyan; , Anna Hakobyan; , Arsen Arakelyan; , Andrey Rzhetsky; , Aram Galstyan","BioRelEx 1.0: Biological Relation Extraction Benchmark","","","","10.18653/v1/w19-5019","https://aclanthology.org/W19-5019","Automatic extraction of relations and interactions between biological entities from scientific literature remains an extremely challenging problem in biomedical information extraction and natural language processing in general. One of the reasons for slow progress is the relative scarcity of standardized and publicly available benchmarks. In this paper we introduce BioRelEx, a new dataset of fully annotated sentences from biomedical literature that capture \textit{binding} interactions between proteins and/or biomolecules. To foster reproducible research on the interaction extraction task, we define a precise and transparent evaluation process, tools for error analysis and significance tests. Finally, we conduct extensive experiments to evaluate several baselines, including SciIE, a recently introduced neural multi-task architecture that has demonstrated state-of-the-art performance on several tasks.","2019-08-01","2023-05-03 16:04:21","2023-10-17 16:47:15","","NA","","","NA","","","BioRelEx","","","","","ACL","","","True","","https://paperswithcode.com/paper/biorelex-10-biological-relation-extraction","https://github.com/YerevaNN/BioRelEx","","","{'citing': ['10.1101/2021.10.28.466262', '10.1109/access.2021.3130956', '10.1093/bib/bbac342', '10.1109/itaic54216.2022.9836511', '10.3897/bdj.10.e89481'], 'cited': []}","","","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:sentence; SAT_task:CorefReso; SAT_task:EntityLinking; SAT_task:NER; SAT_domain:bio; SAT_method_selection:Human; SAT_nbtypes_entity:33; SAT_nbSent:2010; SAT_nbTriples:3235; SAT_NbEntity:9871; havecode","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WS 2019 8","","","","","","","","","","","","","","",""
"VM8FDWJB","conferencePaper","2023","Cabot, Pere-Lluís Huguet; Tedeschi, Simone; Ngomo, Axel-Cyrille Ngonga; Navigli, Roberto","RED$^{\rm FM}$: a Filtered and Multilingual Relation Extraction Dataset","","","","10.18653/v1/2023.acl-long.237","https://aclanthology.org/2023.acl-long.237/","Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English.","2023-06-19","2023-07-21 16:01:56","2023-10-17 16:32:59","2023-07-21 16:01:56","","","","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","REDfm","","","","","ACL","","en","True","","","https://github.com/babelscape/rebel","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/RR6PEZDG/Cabot et al. - 2023 - RED$^{rm FM}$ a Filtered and Multilingual Relati.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:sentence; SAT_lang:multi; SAT_task:EntityTyping; SAT_model:BART; SAT_lang:chinese; SAT_source:Wikidata; SAT_focus:Filtering; SAT_method_selection:Human; SAT_source:Wikipedia; SAT_lang:english; SAT_lang:arabic; SAT_lang:french; SAT_lang:german; SAT_lang:spanish; SAT_method_selection:NLI; SAT_lang:italian; SAT_method_selection:TripletCritic; SAT_nbtypes_relations:400; SAT_nbtypes_relations:32; SAT_nbDoc:15.4K; SAT_nbDoc:12.3M; SAT_nbSent:46.6M; SAT_nbSent:43.7K; SAT_nbtypes_entity:13; SAT_extend:Rebel; FOCUS_STUDY_FINAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"STWUICVQ","conferencePaper","2021","Seganti, Alessandro; Firląg, Klaudia; Skowronska, Helena; Satława, Michał; Andruszkiewicz, Piotr","Multilingual Entity and Relation Extraction Dataset and Model","Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume","","","10.18653/v1/2021.eacl-main.166","https://aclanthology.org/2021.eacl-main.166","We present a novel dataset and model for a multilingual setting to approach the task of Joint Entity and Relation Extraction. The SMiLER dataset consists of 1.1 M annotated sentences, representing 36 relations, and 14 languages. To the best of our knowledge, this is currently both the largest and the most comprehensive dataset of this type. We introduce HERBERTa, a pipeline that combines two independent BERT models: one for sequence classiﬁcation, and the other for entity tagging. The model achieves micro F1 81.49 for English on this dataset, which is close to the current SOTA on CoNLL, SpERT.","2021","2023-08-22 09:20:04","2023-10-17 16:18:14","2023-08-22 09:20:04","1946-1955","","","","","","Smiler","","","","","Association for Computational Linguistics","Online","en","True","","","https://github.com/samsungnlp/smiler/","DOI.org (Crossref)","","","","/root/snap/zotero-snap/common/Zotero/storage/H57TV4MN/Seganti et al. - 2021 - Multilingual Entity and Relation Extraction Datase.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_granularity:sentence; SAT_lang:multi; SAT_task:NER; SAT_method_selection:Human; SAT_source:Wikipedia; SAT_lang:russian; SAT_lang:english; SAT_lang:arabic; SAT_lang:french; SAT_lang:german; SAT_lang:spanish; SAT_source:DBpedia; SAT_method_selection:Distant; SAT_nbtypes_relations:36; SAT_negativeExamples:True; SAT_lang:italian; SAT_lang:dutch; SAT_nbtypes_entity:9; SAT_lang:portuguese; SAT_lang:sv; SAT_lang:polish; SAT_lang:uk; SAT_lang:fa; SAT_nbSent:1.1M","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume","","","","","","","","","","","","","","",""
"ZTWFSXZJ","journalArticle","2022","Luo, Ling; Lai, Po-Ting; Wei, Chih-Hsuan; Arighi, Cecilia N; Lu, Zhiyong","BioRED: a rich biomedical relation extraction dataset","Briefings in Bioinformatics","","1477-4054","10.1093/bib/bbac282","https://doi.org/10.1093/bib/bbac282","Automated relation extraction (RE) from biomedical literature is critical for many downstream text mining applications in both research and real-world settings. However, most existing benchmarking datasets for biomedical RE only focus on relations of a single type (e.g. protein–protein interactions) at the sentence level, greatly limiting the development of RE systems in biomedicine. In this work, we first review commonly used named entity recognition (NER) and RE datasets. Then, we present a first-of-its-kind biomedical relation extraction dataset (BioRED) with multiple entity types (e.g. gene/protein, disease, chemical) and relation pairs (e.g. gene–disease; chemical–chemical) at the document level, on a set of 600 PubMed abstracts. Furthermore, we label each relation as describing either a novel finding or previously known background knowledge, enabling automated algorithms to differentiate between novel and background information. We assess the utility of BioRED by benchmarking several existing state-of-the-art methods, including Bidirectional Encoder Representations from Transformers (BERT)-based models, on the NER and RE tasks. Our results show that while existing approaches can reach high performance on the NER task (F-score of 89.3%), there is much room for improvement for the RE task, especially when extracting novel relations (F-score of 47.7%). Our experiments also demonstrate that such a rich dataset can successfully facilitate the development of more accurate, efficient and robust RE systems for biomedicine.Availability: The BioRED dataset and annotation guidelines are freely available at https://ftp.ncbi.nlm.nih.gov/pub/lu/BioRED/.","2022-09-01","2023-10-09 16:08:56","2023-10-17 16:48:35","2023-10-09 16:08:56","bbac282","","5","23","","Briefings in Bioinformatics","BioRED","","","","","","","","True","","","https://ftp.ncbi.nlm.nih.gov/pub/lu/BioRED/","Silverchair","","{'citing': ['10.1016/j.websem.2022.100756', '10.3390/ijms232314934'], 'cited': ['10.1016/j.artmed.2004.07.016', '10.1016/j.jbi.2013.07.011', '10.1016/j.jbi.2013.12.006', '10.1016/j.jbi.2020.103384', '10.1016/j.jbi.2021.103779', '10.1016/j.jbi.2021.103931', '10.1016/j.knosys.2018.11.020', '10.1093/bib/bbz171', '10.1093/bioinformatics/btaa1087', '10.1093/bioinformatics/btg1023', '10.1093/bioinformatics/btl616', '10.1093/bioinformatics/btm235', '10.1093/bioinformatics/btq667', '10.1093/bioinformatics/btt156', '10.1093/bioinformatics/btw343', '10.1093/bioinformatics/btx541', '10.1093/database/baw032', '10.1093/database/baw043', '10.1093/database/baw068', '10.1093/database/bay073', '10.1093/jamia/ocz166', '10.1093/nar/29.1.239', '10.1093/nar/gkaa333', '10.1093/nar/gks563', '10.1093/nar/gky355', '10.1093/nar/gkz389', '10.1142/9789812799623_0031', '10.1145/3458754', '10.1155/2015/918710', '10.1162/neco.1997.9.8.1735', '10.1162/tacl_a_00049', '10.1186/1471-2105-11-85', '10.1186/1471-2105-13-161', '10.1186/1471-2105-6-s1-s11', '10.1186/1471-2105-8-50', '10.1186/gb-2008-9-s2-s1', '10.1186/s12859-019-3000-5', '10.1371/journal.pcbi.1005017', '10.1371/journal.pone.0065390']}","","/root/snap/zotero-snap/common/Zotero/storage/MD63KSV5/Luo et al. - 2022 - BioRED a rich biomedical relation extraction data.pdf","","SAT_oldTag:CHECKED0923; SAT_task:NER; SAT_domain:biomedical; SAT_method_selection:Human; SAT_All_checked:False; SAT_negativeExamples:True; SAT_source:PubMed; SAT_NbEntity:20419; SAT_nbtypes_entity:3869; SAT_nbTriples:6503; SAT_source:NCBI; SAT_source:NLM-Gene; SAT_source:GNormPlus; SAT_source:tmVar; SAT_source:BC5CDR; SAT_nbDoc:600; SAT_focus:BackgroundKnowledge","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IW9QTWK2","conferencePaper","2022","Popovic, Nicholas; Färber, Michael","Few-Shot Document-Level Relation Extraction","Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2022.naacl-main.421","https://aclanthology.org/2022.naacl-main.421","We present FREDo, a few-shot document-level relation extraction (FSDLRE) benchmark. As opposed to existing benchmarks which are built on sentence-level relation extraction corpora, we argue that document-level corpora provide more realism, particularly regarding none-of-the-above (NOTA) distributions. Therefore, we propose a set of FSDLRE tasks and construct a benchmark based on two existing supervised learning data sets, DocRED and sciERC. We adapt the state-of-the-art sentence-level method MNAV to the document-level and develop it further for improved domain adaptation. We find FSDLRE to be a challenging setting with interesting new characteristics such as the ability to sample NOTA instances from the support set. The data, code, and trained models are available online (https://github.com/nicpopovic/FREDo).","2022-07","2023-10-09 16:09:43","2023-10-17 16:20:46","2023-10-09 16:09:43","5733–5746","","","","","","FREDo","","","","","Association for Computational Linguistics","Seattle, United States","","True","","","https://github.com/nicpopovic/FREDo","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/ST7MU4LD/Popovic and Färber - 2022 - Few-Shot Document-Level Relation Extraction.pdf","","SAT_oldTag:CHECKED0923; SAT_granularity:document; SAT_focus:TransferLearning; SAT_method_selection:Human; SAT_domain:science; SAT_extend:DocRED; SAT_All_checked:True; SAT_granularity:cross-document; SAT_extend:SciERC; SAT_focus:FewSHot; SAT_domain:general","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL-HLT 2022","","","","","","","","","","","","","","",""
"VUVXXBGH","conferencePaper","2023","Bassignana, Elisa; Ginter, Filip; Pyysalo, Sampo; van der Goot, Rob; Plank, Barbara","Multi-CrossRE A Multi-Lingual Multi-Domain Dataset for Relation Extraction","Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa)","","","not found","https://aclanthology.org/2023.nodalida-1.9","Most research in Relation Extraction (RE) involves the English language, mainly due to the lack of multi-lingual resources. We propose Multi-CrossRE, the broadest multi-lingual dataset for RE, including 26 languages in addition to English, and covering six text domains. Multi-CrossRE is a machine translated version of CrossRE (Bassignana and Plank, 2022), with a sub-portion including more than 200 sentences in seven diverse languages checked by native speakers. We run a baseline model over the 26 new datasets and–as sanity check–over the 26 back-translations to English. Results on the back-translated data are consistent with the ones on the original English CrossRE, indicating high quality of the translation and the resulting dataset.","2023-05","2023-10-09 16:10:11","2025-01-15 08:51:43","2023-10-09 16:10:11","80–85","","","","","","MultiCrossRE","","","","","University of Tartu Library","Tórshavn, Faroe Islands","","True","","","https://github.com/mainlp/CrossRE","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/L65TY7P4/Bassignana et al. - 2023 - Multi-CrossRE A Multi-Lingual Multi-Domain Dataset.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_lang:multi; SAT_focus:TransferLearning; SAT_task:NER; SAT_method_selection:Human; SAT_source:Wikipedia; SAT_domain:science; SAT_All_checked:True; SAT_source:DBpedia; SAT_domain:politic; SAT_domain:literature; SAT_domain:naturalSci; SAT_nbSent:5265; SAT_nbTriples:18608; SAT_method_selection:MultiHuman; SAT_domain:news; SAT_method_generation:translation","⚠️ Invalid DOI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NoDaLiDa 2023","","","","","","","","","","","","","","",""
"IVYY82DP","conferencePaper","2021","Nayak, Tapas; Ng, Hwee Tou","A Hierarchical Entity Graph Convolutional Network for Relation Extraction across Documents","Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)","","","10.26615/978-954-452-072-4_115","https://aclanthology.org/2021.ranlp-1.115","Distantly supervised datasets for relation extraction mostly focus on sentence-level extraction, and they cover very few relations. In this work, we propose cross-document relation extraction, where the two entities of a relation tuple appear in two different documents that are connected via a chain of common entities. Following this idea, we create a dataset for two-hop relation extraction, where each chain contains exactly two documents. Our proposed dataset covers a higher number of relations than the publicly available sentence-level datasets. We also propose a hierarchical entity graph convolutional network (HEGCN) model for this task that improves performance by 1.1% F1 score on our two-hop relation extraction dataset, compared to some strong neural baselines.","2021-09","2023-10-09 16:10:39","2023-10-17 16:23:06","2023-10-09 16:10:39","1022–1030","","","","","","THRED","","","","","INCOMA Ltd.","Held Online","","True","","","https://github.com/nusnlp/MHRE.git","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/LMXAPWUX/Nayak and Ng - 2021 - A Hierarchical Entity Graph Convolutional Network .pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_source:Wikidata; SAT_source:Wikipedia; SAT_negativeExamples:True; SAT_granularity:cross-document; SAT_focus:ReasoningPath; SAT_extend:WikiHop; SAT_nbtypes_relations:218; SAT_nbDoc:149226","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","RANLP 2021","","","","","","","","","","","","","","",""
"BTWBPNLJ","conferencePaper","2019","Takanobu, Ryuichi; Zhang, Tianyang; Liu, Jiexi; Huang, Minlie","A hierarchical framework for relation extraction with reinforcement learning","Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence","978-1-57735-809-1","","10.1609/aaai.v33i01.33017072","https://dl.acm.org/doi/10.1609/aaai.v33i01.33017072","Most existing methods determine relation types only after all the entities have been recognized, thus the interaction between relation types and entity mentions is not fully modeled. This paper presents a novel paradigm to deal with relation extraction by regarding the related entities as the arguments of a relation. We apply a hierarchical reinforcement learning (HRL) framework in this paradigm to enhance the interaction between entity mentions and relation types. The whole extraction process is decomposed into a hierarchy of two-level RL policies for relation detection and entity extraction respectively, so that it is more feasible and natural to deal with overlapping relations. Our model was evaluated on public datasets collected via distant supervision, and results show that it gains better performance than existing methods and is more powerful for extracting overlapping relations.","2019-01-27","2023-10-09 16:11:30","2023-10-17 16:54:34","2023-10-09","7072–7079","","","","","","HRL-RE","AAAI'19/IAAI'19/EAAI'19","","","","AAAI Press","Honolulu, Hawaii, USA","","True","","","https://github.com/truthless11/HRL-RE","ACM Digital Library","","{'citing': ['10.1007/978-3-030-32236-6_71', '10.1145/3308558.3313455', '10.3390/info11010031', '10.1108/idd-01-2020-0005', '10.1145/3402885', '10.1007/978-3-030-60239-0_35', '10.1093/bioinformatics/btaa491', '10.1016/j.neucom.2020.12.037', '10.1016/j.knosys.2020.105912', '10.1016/j.knosys.2020.106172', '10.1016/j.neunet.2021.03.030', '10.1016/j.compbiolchem.2021.107508', '10.1145/3437963.3441738', '10.1145/3442381.3449895', '10.1007/978-3-030-73197-7_32', '10.1007/s10489-021-02600-2', '10.1016/j.neucom.2021.06.071', '10.3233/jifs-210281', '10.1007/s12559-021-09917-7', '10.1007/978-3-030-82147-0_13', '10.1007/s10489-021-02667-x', '10.1007/978-3-030-89363-7_6', '10.1145/3459637.3482058', '10.1145/3459637.3482491', '10.1007/978-3-030-93733-1_23', '10.1007/s13042-021-01491-6', '10.1007/s10032-022-00399-3', '10.1007/s11192-022-04340-7', '10.1007/978-981-16-9492-9_302', '10.1155/2022/2146236', '10.1109/icassp43922.2022.9746958', '10.1109/tnnls.2021.3070843', '10.1109/access.2020.2980859', '10.1109/hpcc-dss-smartcity-dependsys53884.2021.00167', '10.1109/dtpi52967.2021.9540098', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00090', '10.1109/ispa-bdcloud-socialcom-sustaincom51426.2020.00096', '10.1109/access.2021.3062231', '10.1109/iccc54389.2021.9674630', '10.1109/aiea53260.2021.00060', '10.3390/app12126231', '10.1109/qrs54544.2021.00052', '10.1109/access.2019.2938986', '10.1109/taslp.2021.3110126', '10.1109/iaeac50856.2021.9390651', '10.1016/j.ipm.2020.102311', '10.1007/978-3-030-32236-6_72', '10.3390/app12178493', '10.1109/tim.2022.3200429', '10.1109/tkde.2021.3070317', '10.1007/978-3-031-20891-1_30', '10.1109/tbdata.2022.3144151', '10.1109/ijcnn55064.2022.9892140', '10.1007/s11432-020-3307-3'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/TV2YWV6F/Takanobu et al. - 2019 - A hierarchical framework for relation extraction w.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_learning:reinforcement; SAT_method_selection:Human; SAT_source:FreeBase; SAT_All_checked:False; SAT_method_selection:Distant; SAT_nbtypes_relations:29; SAT_nbtypes_relations:12; SAT_nbSent:74345; SAT_nbSent:63017; SAT_nbTriples:93598; SAT_nbTriples:74682; SAT_source:NYT; SAT_focus:NAdeletion; SAT_focus:RelDeletion; SAT_extend:NYT10; SAT_extend:NYT11","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EEC67CS8","conferencePaper","2021","Kassner, Nora; Dufter, Philipp; Schütze, Hinrich","Multilingual LAMA: Investigating Knowledge in Multilingual Pretrained Language Models","Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume","","","10.18653/v1/2021.eacl-main.284","https://aclanthology.org/2021.eacl-main.284","Recently, it has been found that monolingual English language models can be used as knowledge bases. Instead of structural knowledge base queries, masked sentences such as “Paris is the capital of [MASK]” are used as probes. We translate the established benchmarks TREx and GoogleRE into 53 languages. Working with mBERT, we investigate three questions. (i) Can mBERT be used as a multilingual knowledge base? Most prior work only considers English. Extending research to multiple languages is important for diversity and accessibility. (ii) Is mBERT's performance as knowledge base language-independent or does it vary from language to language? (iii) A multilingual model is trained on more text, e.g., mBERT is trained on 104 Wikipedias. Can mBERT leverage this for better performance? We find that using mBERT as a knowledge base yields varying performance across languages and pooling predictions across languages improves performance. Conversely, mBERT exhibits a language bias; e.g., when queried in Italian, it tends to predict Italy as the country of origin.","2021-04","2023-10-10 12:09:18","2023-10-17 16:49:01","2023-10-10 12:09:18","3250–3258","","","","","","Multilingual LAMA","","","","","Association for Computational Linguistics","Online","","True","","","https://github.com/norakassner/mlama","ACLWeb","","{'citing': ['10.1016/j.jbi.2021.103982', '10.1162/tacl_a_00410', '10.1162/tacl_a_00459', '10.1007/978-3-031-16500-9_11'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/C6RBWZB5/Kassner et al. - 2021 - Multilingual LAMA Investigating Knowledge in Mult.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EACL 2021","","","","","","","","","","","","","","",""
"6XQZPCYI","journalArticle","2021","Sabo, Ofer; Elazar, Yanai; Goldberg, Yoav; Dagan, Ido","Revisiting Few-shot Relation Classification: Evaluation Data and Classification Schemes","Transactions of the Association for Computational Linguistics","","","10.1162/tacl_a_00392","https://aclanthology.org/2021.tacl-1.42","We explore few-shot learning (FSL) for relation classification (RC). Focusing on the realistic scenario of FSL, in which a test instance might not belong to any of the target categories (none-of-the-above, [NOTA]), we first revisit the recent popular dataset structure for FSL, pointing out its unrealistic data distribution. To remedy this, we propose a novel methodology for deriving more realistic few-shot test data from available datasets for supervised RC, and apply it to the TACRED dataset. This yields a new challenging benchmark for FSL-RC, on which state of the art models show poor performance. Next, we analyze classification schemes within the popular embedding-based nearest-neighbor approach for FSL, with respect to constraints they impose on the embedding space. Triggered by this analysis, we propose a novel classification scheme in which the NOTA category is represented as learned vectors, shown empirically to be an appealing option for FSL.","2021","2023-10-10 12:10:18","2023-10-17 16:40:26","2023-10-10 12:10:18","691–706","","","9","","","FSL TACRED","","","","","","","","False","","","","ACLWeb","","{'citing': ['10.3390/app12042185', '10.2196/preprints.41100', '10.3390/app12042185', '10.2196/preprints.41100'], 'cited': ['10.18653/v1/d17-1004', '10.18653/v1/d19-1364', '10.18653/v1/d19-1649', '10.18653/v1/p16-1105', '10.18653/v1/k17-1034', '10.18653/v1/p16-1123', '10.18653/v1/w18-5511', '10.1007/978-3-319-24261-3_7', '10.18653/v1/p19-1074', '10.18653/v1/p19-1589', '10.1109/tnn.2010.2052630', '10.18653/v1/d18-1244', '10.18653/v1/d18-1514', '10.3115/1690219.1690287', '10.1109/cvpr.2015.7298682', '10.1109/iccvw.2017.194', '10.18653/v1/n18-1109', '10.18653/v1/p19-1279', '10.18653/v1/d17-1004', '10.18653/v1/d19-1364', '10.18653/v1/d19-1649', '10.18653/v1/p16-1105', '10.18653/v1/k17-1034', '10.18653/v1/p16-1123', '10.18653/v1/w18-5511', '10.1007/978-3-319-24261-3_7', '10.18653/v1/p19-1074', '10.18653/v1/p19-1589', '10.1109/tnn.2010.2052630', '10.18653/v1/d18-1244', '10.18653/v1/d18-1514', '10.3115/1690219.1690287', '10.1109/cvpr.2015.7298682', '10.1109/iccvw.2017.194', '10.18653/v1/n18-1109', '10.18653/v1/p19-1279']}","","/root/snap/zotero-snap/common/Zotero/storage/33R53KFI/Sabo et al. - 2021 - Revisiting Few-shot Relation Classification Evalu.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MF3NPQFP","journalArticle","2019","Sun, Kai; Yu, Dian; Chen, Jianshu; Yu, Dong; Choi, Yejin; Cardie, Claire","DREAM: A Challenge Data Set and Models for Dialogue-Based Reading Comprehension","Transactions of the Association for Computational Linguistics","","2307-387X","10.1162/tacl_a_00264","https://direct.mit.edu/tacl/article/43501","We present DREAM, the first dialogue-based multiple-choice reading comprehension data set. Collected from English as a Foreign Language examinations designed by human experts to evaluate the comprehension level of Chinese learners of English, our data set contains 10,197 multiple-choice questions for 6,444 dialogues. In contrast to existing reading comprehension data sets, DREAM is the first to focus on in-depth multi-turn multi-party dialogue understanding. DREAM is likely to present significant challenges for existing reading comprehension systems: 84% of answers are non-extractive, 85% of questions require reasoning beyond a single sentence, and 34% of questions also involve commonsense knowledge.","2019-11","2023-10-18 07:47:56","2023-10-30 13:49:26","2023-10-18 07:47:56","217-231","","","7","","Transactions of the Association for Computational Linguistics","DREAM","","","","","","","en","","","","","DOI.org (Crossref)","","{'citing': ['10.1162/tacl_a_00305', '10.1145/3340531.3412013', '10.3390/app10217640', '10.1007/978-3-030-60450-9_5', '10.3233/jifs-189386', '10.1080/24751839.2020.1833136', '10.1016/j.neucom.2020.10.107', '10.1007/s11042-021-11197-0', '10.1016/j.knosys.2021.106936', '10.2200/s01118ed1v01y202107hlt051', '10.1007/978-3-030-86383-8_29', '10.1016/j.neucom.2021.01.148', '10.3390/mi13030355', '10.1016/j.knosys.2022.108550', '10.3390/app12094099', '10.3390/app12063072', '10.1109/mis.2019.2916965', '10.1007/978-981-16-9113-3_1', '10.1007/s00521-022-07561-2', '10.1007/s00521-022-07561-2', '10.1109/taslp.2021.3058616', '10.1109/ccis53392.2021.9754687', '10.1109/iccmc53470.2022.9754070', '10.1145/3477495.3532083', '10.1145/3527631', '10.1109/taslp.2021.3138683', '10.1109/icassp39728.2021.9414980', '10.1109/taslp.2022.3156789', '10.1007/s00799-022-00329-y', '10.1109/access.2021.3068993', '10.1109/ijcnn52387.2021.9533341', '10.1109/ijcnn52387.2021.9533364', '10.1109/taslp.2022.3164219', '10.1007/978-3-031-14771-5_3', '10.1109/ijcnn55064.2022.9892162', '10.1109/tcsvt.2022.3174136'], 'cited': ['10.1162/tacl_a_00023', '10.3115/1219044.1219075', '10.3138/cmlr.63.1.59', '10.18653/v1/d18-1241']}","","/root/snap/zotero-snap/common/Zotero/storage/R9VUID8V/Sun et al. - 2019 - DREAM A Challenge Data Set and Models for Dialogu.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KXGYS8MP","conferencePaper","2019","Sap, Maarten; Le Bras, Ronan; Allaway, Emily; Bhagavatula, Chandra; Lourie, Nicholas; Rashkin, Hannah; Roof, Brendan; Smith, Noah A.; Choi, Yejin","ATOMIC: an atlas of machine commonsense for if-then reasoning","Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence","978-1-57735-809-1","","10.1609/aaai.v33i01.33013027","https://dl.acm.org/doi/10.1609/aaai.v33i01.33013027","We present ATOMIC, an atlas of everyday commonsense reasoning, organized through 877k textual descriptions of inferential knowledge. Compared to existing resources that center around taxonomic knowledge, ATOMIC focuses on inferential knowledge organized as typed if-then relations with variables (e.g., ""if X pays Y a compliment, then Y will likely return the compliment""). We propose nine if-then relation types to distinguish causes vs. effects, agents vs. themes, voluntary vs. involuntary events, and actions vs. mental states. By gen-eratively training on the rich inferential knowledge described in ATOMIC, we show that neural models can acquire simple commonsense capabilities and reason about previously unseen events. Experimental results demonstrate that multitask models that incorporate the hierarchical structure of if-then relation types lead to more accurate inference compared to models trained in isolation, as measured by both automatic and human evaluation.","2019-01-27","2023-10-18 07:48:47","2023-10-30 13:49:25","2023-10-18","3027–3035","","","","","","ATOMIC","AAAI'19/IAAI'19/EAAI'19","","","","AAAI Press","Honolulu, Hawaii, USA","","","","","","ACM Digital Library","","{'citing': ['10.1007/978-3-030-25719-4_66', '10.1527/tjsai.dsi-e', '10.3233/sw-190383', '10.1145/3386308.3386309', '10.1145/3397271.3401173', '10.1101/2020.06.26.174482', '10.1101/2020.06.26.174482', '10.1007/978-3-030-50146-4_31', '10.1007/978-3-030-58558-7_30', '10.1145/3422852.3423484', '10.1145/3340531.3411895', '10.1145/3394171.3413909', '10.1007/978-3-030-62466-8_18', '10.1145/3397271.3401427', '10.1007/978-3-030-78111-8_30', '10.1145/3442381.3449997', '10.1016/j.knosys.2021.107347', '10.1088/1757-899x/1022/1/012038', '10.1631/fitee.2000347', '10.3156/jsoft.33.2_630', '10.1016/j.procs.2021.06.085', '10.1093/logcom/exab005', '10.1145/3453156', '10.1007/978-3-030-77385-4_41', '10.1016/j.knosys.2021.107449', '10.1007/s10462-021-10056-6', '10.1007/978-3-030-88483-3_32', '10.1007/978-3-030-92238-2_6', '10.1007/978-3-030-88483-3_2', '10.1007/978-3-030-91100-3_1', '10.1073/pnas.2105646118', '10.1016/j.neucom.2021.10.121', '10.1007/978-3-030-95481-9_3', '10.1007/s00521-022-06975-2', '10.1145/3485447.3511928', '10.1145/3485447.3512135', '10.1109/taslp.2021.3120601', '10.1145/3510030', '10.1007/978-3-031-06981-9_6', '10.1109/access.2021.3128277', '10.1109/pic53636.2021.9687029', '10.1109/ijcnn52387.2021.9534355', '10.1016/j.ipm.2022.102961', '10.1109/access.2021.3130956', '10.1007/s11063-022-10831-8', '10.1109/access.2021.3063234', '10.1007/978-3-031-11609-4_38', '10.1109/tkde.2020.3014166', '10.1109/icetci55101.2022.9832371', '10.1109/icetci55101.2022.9832250', '10.1109/cisai54367.2021.00222', '10.1109/cscwd49262.2021.9437862', '10.1109/icassp43922.2022.9746464', '10.1145/3477495.3532080', '10.1109/slt48900.2021.9383453', '10.1109/taslp.2022.3164218', '10.1007/978-3-031-15931-2_3', '10.1016/j.knosys.2022.109861', '10.1016/j.knosys.2022.109488', '10.1109/icme52920.2022.9859679', '10.4018/ijswis.309421', '10.1007/978-3-031-16014-1_1', '10.1007/978-3-031-17120-8_11', '10.1007/s10115-022-01744-y', '10.1007/978-3-031-17105-5_7', '10.1145/3511808.3557275', '10.1145/3511808.3557564', '10.1007/978-3-031-10983-6_44', '10.1007/978-3-031-10983-6_45', '10.1145/3514197.3549675', '10.1145/3536221.3558175', '10.1049/cvi2.12154', '10.1109/icpr56361.2022.9956241', '10.1002/aaai.12033'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/8EX79J9W/Sap et al. - 2019 - ATOMIC an atlas of machine commonsense for if-the.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PCWJ7ZDK","journalArticle","","Gashteovski, Kiril; Wanner, Sebastian; Hertling, Sven; Broscheit, Samuel; Gemulla, Rainer","OPIEC: An Open Information Extraction Corpus","","","","not found","","Open information extraction (OIE) systems extract relations and their arguments from natural language text in an unsupervised manner. The resulting extractions are a valuable resource for downstream tasks such as knowledge base construction, open question answering, or event schema induction. In this paper, we release, describe, and analyze an OIE corpus called OPIEC, which was extracted from the text of English Wikipedia. OPIEC complements the available OIE resources: It is the largest OIE corpus publicly available to date (over 340M triples) and contains valuable metadata such as provenance information, conﬁdence scores, linguistic annotations, and semantic annotations including spatial and temporal information. We analyze the OPIEC corpus by comparing its content with knowledge bases such as DBpedia or YAGO, which are also based on Wikipedia. We found that most of the facts between entities present in OPIEC cannot be found in DBpedia and/or YAGO, that OIE facts often diﬀer in the level of speciﬁcity compared to knowledge base facts, and that OIE open relations are generally highly polysemous. We believe that the OPIEC corpus is a valuable resource for future research on automated knowledge base construction.","","2023-10-18 07:50:15","2025-01-15 08:51:37","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/LZDPNA9P/Gashteovski et al. - OPIEC An Open Information Extraction Corpus.pdf","","","⚠️ Invalid DOI; ⛔ No DOI found","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BV4QR6QI","conferencePaper","2020","Safavi, Tara; Koutra, Danai","CoDEx: A Comprehensive Knowledge Graph Completion Benchmark","Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","","","10.18653/v1/2020.emnlp-main.669","https://aclanthology.org/2020.emnlp-main.669","We present CoDEx, a set of knowledge graph completion datasets extracted from Wikidata and Wikipedia that improve upon existing knowledge graph completion benchmarks in scope and level of difficulty. In terms of scope, CoDEx comprises three knowledge graphs varying in size and structure, multilingual descriptions of entities and relations, and tens of thousands of hard negative triples that are plausible but verified to be false. To characterize CoDEx, we contribute thorough empirical analyses and benchmarking experiments. First, we analyze each CoDEx dataset in terms of logical relation patterns. Next, we report baseline link prediction and triple classification results on CoDEx for five extensively tuned embedding models. Finally, we differentiate CoDEx from the popular FB15K-237 knowledge graph completion dataset by showing that CoDEx covers more diverse and interpretable content, and is a more difficult link prediction benchmark. Data, code, and pretrained models are available at https://bit.ly/2EPbrJs.","2020-11","2023-10-18 07:50:29","2023-10-30 13:49:23","2023-10-18 07:50:29","8328–8350","","","","","","CoDEx","","","","","Association for Computational Linguistics","Online","","","","","","ACLWeb","","{'citing': ['10.1145/3442381.3449856', '10.1007/978-3-030-79463-7_21', '10.1007/978-3-030-77385-4_37', '10.1007/978-3-030-88361-4_30', '10.1145/3488560.3502183', '10.1145/3485447.3511927', '10.1007/978-3-031-06981-9_5', '10.1109/access.2022.3191666', '10.1145/3511808.3557115'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/SUTI2LLY/Safavi and Koutra - 2020 - CoDEx A Comprehensive Knowledge Graph Completion .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2020","","","","","","","","","","","","","","",""
"VCYKG539","conferencePaper","2015","Toutanova, Kristina; Chen, Danqi; Pantel, Patrick; Poon, Hoifung; Choudhury, Pallavi; Gamon, Michael","Representing Text for Joint Embedding of Text and Knowledge Bases","Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/D15-1174","https://aclanthology.org/D15-1174","","2015-09","2023-10-18 07:51:06","2023-10-30 13:49:21","2023-10-18 07:51:06","1499–1509","","","","","","","","","","","Association for Computational Linguistics","Lisbon, Portugal","","","","","","ACLWeb","","{'citing': ['10.1007/978-3-031-00123-9_8', '10.1016/j.knosys.2022.108843', '10.1109/jiot.2021.3092360', '10.1109/bdai52447.2021.9515213', '10.1109/cvpr.2019.00203', '10.1109/dsc50466.2020.00023', '10.1145/3511095.3531284', '10.1016/j.knosys.2022.109459', '10.1145/3510030', '10.1109/access.2019.2963367', '10.1109/access.2020.2981212', '10.1109/iscid.2018.00045', '10.1109/access.2019.2950230', '10.1109/tkde.2020.2970044', '10.1109/access.2018.2875066', '10.1109/ijcnn52387.2021.9533477', '10.1109/ijcnn52387.2021.9534404', '10.1109/tkde.2019.2893920', '10.1109/access.2019.2901544', '10.1109/ict-dm52643.2021.9664081', '10.1145/3477495.3532679', '10.1109/access.2020.2995074', '10.1109/iccia55271.2022.9828440', '10.1109/icicn52636.2021.9673867', '10.1109/access.2020.3044343', '10.1109/kse50997.2020.9287591', '10.1109/iros.2018.8593634', '10.1109/iske54062.2021.9755334', '10.1109/access.2021.3055529', '10.1109/jiot.2020.3039750', '10.1109/icaibd55127.2022.9820227', '10.1109/mis.2021.3095055', '10.1016/j.knosys.2022.109310', '10.3390/app12126168', '10.1145/3477495.3531669', '10.1145/3477495.3531757', '10.1145/3477495.3531996', '10.1360/ssi-2021-0111', '10.1109/icnlp52887.2021.00019', '10.1109/ijcnn.2019.8852431', '10.1109/bigdata52589.2021.9671344', '10.1109/icdmw.2018.00146', '10.1109/icde53745.2022.00088', '10.1145/3487553.3524238', '10.23919/splitech55088.2022.9854264', '10.1007/s00521-022-07796-z', '10.1016/j.ipm.2022.103076', '10.1016/j.knosys.2022.109889', '10.1109/access.2022.3206037', '10.1007/s10618-022-00854-z', '10.1145/3511808.3557115', '10.1145/3511808.3557355', '10.1007/s10115-022-01764-8', '10.1145/3503161.3547981', '10.1007/978-3-031-10983-6_19', '10.1007/978-3-031-10983-6_47', '10.1007/978-3-031-10983-6_52', '10.1109/icpr56361.2022.9956220', '10.1109/kse56063.2022.9953802', '10.1145/3570733.3570735', '10.1007/978-3-031-20865-2_5', '10.1016/j.inffus.2022.11.025', '10.1109/ijcnn55064.2022.9891938', '10.1109/ijcnn55064.2022.9892443', '10.1109/ijcnn55064.2022.9892213', '10.1007/s10489-022-04147-2', '10.1109/tkde.2021.3060755', '10.1109/ccet55412.2022.9906358', '10.1007/978-3-031-22137-8_10', '10.1007/978-981-19-8234-7_21', '10.1016/b978-0-323-89931-4.00005-5', '10.1109/bigdata47090.2019.9005462', '10.1007/s41109-019-0133-4', '10.1145/3038912.3052708', '10.1145/3097983.3098105', '10.1145/3178876.3186024', '10.1145/3219819.3220017', '10.1145/3241741', '10.1145/3289600.3291030', '10.1145/3292500.3332296', '10.1145/3308558.3313573', '10.1145/3308558.3313597', '10.1145/3308558.3313620', '10.1007/s00521-019-04181-1', '10.1007/s10618-019-00653-z', '10.1186/s12859-018-2316-x', '10.1007/978-3-030-04284-4_5', '10.1007/978-3-030-15712-8_20', '10.1007/978-3-030-21348-0_16', '10.1007/978-3-030-30493-5_52', '10.1007/978-3-319-25789-1_1', '10.1371/journal.pone.0193094', '10.1007/978-3-319-45814-4_16', '10.1007/978-3-319-46523-4_7', '10.1007/978-3-319-50496-4_60', '10.1007/978-3-319-57454-7_11', '10.1007/978-3-319-93803-5_35', '10.1007/978-3-319-96890-2_31', '10.1527/tjsai.d-g96', '10.3156/jsoft.29.2_55', '10.3233/sw-180318', '10.3233/sw-190361', '10.1109/tkde.2016.2622705', '10.1109/bigdata.2017.8258048', '10.1145/3209978.3210190', '10.1145/3195106.3195111', '10.1007/978-3-030-30793-6_20', '10.1007/978-3-030-30793-6_25', '10.1007/978-3-030-30793-6_35', '10.1007/978-3-030-33676-9_30', '10.1007/s10844-019-00592-7', '10.1145/3336191.3371874', '10.1007/978-3-030-00671-6_2', '10.3233/sw-190368', '10.1007/978-3-030-21348-0_3', '10.1007/s00521-019-04630-x', '10.22430/22565337.1483', '10.1007/978-3-030-32233-5_14', '10.1145/3159652.3159709', '10.1145/3366423.3380089', '10.1145/3366423.3380155', '10.1145/3366423.3380257', '10.1587/transinf.2019dap0007', '10.1007/s00521-020-04940-5', '10.1007/978-981-15-5573-2_2', '10.1007/978-981-15-7670-6_22', '10.14778/3229863.3229876', '10.1007/978-3-030-62419-4_36', '10.1145/3424672', '10.1016/j.websem.2019.01.004', '10.1587/transinf.2019edp7229', '10.2139/ssrn.3331039', '10.1007/s00521-020-05654-4', '10.1016/j.knosys.2020.106421', '10.1016/j.neucom.2020.12.040', '10.1016/j.knosys.2020.105910', '10.1007/s11280-021-00911-5', '10.1145/3442381.3449883', '10.1145/3442381.3449974', '10.1145/3442381.3450043', '10.1007/978-981-16-0479-9_4', '10.1007/978-3-030-79463-7_21', '10.1007/978-3-030-69377-0_17', '10.1007/978-3-030-77385-4_22', '10.3389/fnbot.2021.674428', '10.1007/s00521-021-06252-8', '10.1007/s10489-021-02672-0', '10.2200/s01067ed1v01y202012dtm064', '10.1007/s00521-021-06221-1', '10.1007/s10845-021-01749-4', '10.1088/1742-6596/1848/1/012073', '10.2200/s01078ed2v01y202002hlt049', '10.1016/j.websem.2021.100656', '10.1007/978-3-030-86365-4_15', '10.1007/978-3-030-88361-4_16', '10.1007/978-3-030-82136-4_39', '10.1007/978-3-030-86520-7_18', '10.1111/cogs.13029', '10.1007/s11063-021-10586-8', '10.1007/s00521-021-06460-2', '10.1049/cvi2.12066', '10.1016/j.knosys.2021.108038', '10.1145/3459637.3482224', '10.1007/s10489-021-02947-6', '10.3233/sw-212892', '10.1155/2022/1615596', '10.1145/3488560.3498410', '10.1145/3488560.3498437', '10.1111/cogs.13085', '10.1016/j.knosys.2022.108235', '10.1016/j.csl.2021.101340', '10.1007/978-3-030-95384-3_3'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/8ZLGI4N5/Toutanova et al. - 2015 - Representing Text for Joint Embedding of Text and .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2015","","","","","","","","","","","","","","",""
"YKS39A9Z","conferencePaper","2020","Yu, Dian; Sun, Kai; Cardie, Claire; Yu, Dong","Dialogue-Based Relation Extraction","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/2020.acl-main.444","https://aclanthology.org/2020.acl-main.444","We present the first human-annotated dialogue-based relation extraction (RE) dataset DialogRE, aiming to support the prediction of relation(s) between two arguments that appear in a dialogue. We further offer DialogRE as a platform for studying cross-sentence RE as most facts span multiple sentences. We argue that speaker-related information plays a critical role in the proposed task, based on an analysis of similarities and differences between dialogue-based and traditional RE tasks. Considering the timeliness of communication in a dialogue, we design a new metric to evaluate the performance of RE methods in a conversational setting and investigate the performance of several representative RE methods on DialogRE. Experimental results demonstrate that a speaker-aware extension on the best-performing model leads to gains in both the standard and conversational evaluation settings. DialogRE is available at https://dataset.org/dialogre/.","2020-07","2023-10-18 07:53:14","2023-10-30 13:49:20","2023-10-18 07:53:14","4927–4940","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","ACLWeb","","{'citing': ['10.1145/3404835.3463070', '10.1016/j.neucom.2021.05.082', '10.1007/978-3-030-88480-2_21', '10.1145/3485447.3511921', '10.1145/3485447.3511998', '10.1109/icassp43922.2022.9747486', '10.1109/taslp.2021.3082295', '10.1016/j.knosys.2022.109146', '10.1145/3477495.3531746', '10.1109/itaic54216.2022.9836511', '10.1016/j.knosys.2022.109471'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/QK3GU6QB/Yu et al. - 2020 - Dialogue-Based Relation Extraction.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2020","","","","","","","","","","","","","","",""
"84SEMG2F","conferencePaper","2020","Park, Jae Sung; Bhagavatula, Chandra; Mottaghi, Roozbeh; Farhadi, Ali; Choi, Yejin","VisualCOMET: Reasoning About the Dynamic Context of a Still Image","Computer Vision – ECCV 2020","978-3-030-58558-7","","10.1007/978-3-030-58558-7_30","","Even from a single frame of a still image, people can reason about the dynamic story of the image before, after, and beyond the frame. For example, given an image of a man struggling to stay afloat in water, we can reason that the man fell into the water sometime in the past, the intent of that man at the moment is to stay alive, and he will need help in the near future or else he will get washed away. We propose  VisualCOMET, (Visual Commonsense Reasoning in Time.) the novel framework of visual commonsense reasoning tasks to predict events that might have happened before, events that might happen next, and the intents of the people at present. To support research toward visual commonsense reasoning, we introduce the first large-scale repository of Visual Commonsense Graphs that consists of over 1.4 million textual descriptions of visual commonsense inferences carefully annotated over a diverse set of 59,000 images, each paired with short video summaries of before and after. In addition, we provide person-grounding (i.e., co-reference links) between people appearing in the image and people mentioned in the textual commonsense descriptions, allowing for tighter integration between images and text. We establish strong baseline performances on this task and demonstrate that integration between visual and textual commonsense reasoning is the key and wins over non-integrative alternatives.","2020","2023-10-18 07:53:58","2023-10-30 13:49:18","","508-524","","","","","","VisualCOMET","Lecture Notes in Computer Science","","","","Springer International Publishing","Cham","en","","","","","Springer Link","","{'citing': ['10.1109/cvpr46437.2021.00683', '10.1109/icme52920.2022.9859679', '10.1109/cvpr52688.2022.01593', '10.1007/978-3-031-19836-6_17', '10.1007/978-3-031-20059-5_32'], 'cited': ['10.1007/978-3-319-10578-9_45', '10.1007/978-3-319-46493-0_17', '10.1007/s11263-016-0966-6', '10.1109/cvpr.2009.5206848', '10.1109/cvpr.2014.416', '10.1109/cvpr.2015.7298935', '10.1109/cvpr.2015.7299087', '10.1109/cvpr.2016.110', '10.1109/cvpr.2016.9', '10.1109/cvpr.2016.90', '10.1109/cvpr.2017.121', '10.1109/cvpr.2017.215', '10.1109/cvpr.2017.388', '10.1109/cvpr.2019.00036', '10.1109/cvpr.2019.00331', '10.1109/cvpr.2019.00688', '10.1109/iccv.2015.292', '10.1109/iccv.2015.303', '10.1109/iccv.2015.494', '10.1109/iccv.2015.511', '10.1109/iccv.2017.322', '10.1109/iccv.2017.361', '10.1109/iccv.2019.00770', '10.1609/aaai.v33i01.33013027', '10.1609/aaai.v34i07.7005', '10.18653/v1/d19-1514', '10.18653/v1/p18-1238', '10.18653/v1/p19-1470', '10.21236/ada612444', '10.3115/1073083.1073135', '10.3115/v1/d14-1086']}","","/root/snap/zotero-snap/common/Zotero/storage/X2V7RYVI/Park et al. - 2020 - VisualCOMET Reasoning About the Dynamic Context o.pdf","","","","Vedaldi, Andrea; Bischof, Horst; Brox, Thomas; Frahm, Jan-Michael","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UK5NJYQK","journalArticle","","Jat, Sharmistha; Khandelwal, Siddhesh; Talukdar, Partha","Improving Distantly Supervised Relation Extraction using Word and Entity Based Attention","","","","not found","","","","2023-10-19 15:09:40","2025-01-15 08:51:37","","","","","","","","","","","","","","","en","","","","","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/A6HP5M7N/Jat et al. - Improving Distantly Supervised Relation Extraction.pdf","","","⚠️ Invalid DOI; ⛔ No DOI found","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DLZIYXJF","conferencePaper","2020","Jin, Zhijing; Guo, Qipeng; Qiu, Xipeng; Zhang, Zheng","GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation","Proceedings of the 28th International Conference on Computational Linguistics","","","10.18653/v1/2020.coling-main.217","https://aclanthology.org/2020.coling-main.217","Data collection for the knowledge graph-to-text generation is expensive. As a result, research on unsupervised models has emerged as an active field recently. However, most unsupervised models have to use non-parallel versions of existing small supervised datasets, which largely constrain their potential. In this paper, we propose a large-scale, general-domain dataset, GenWiki. Our unsupervised dataset has 1.3M text and graph examples, respectively. With a human-annotated test set, we provide this new benchmark dataset for future research on unsupervised text generation from knowledge graphs.","2020-12","2023-10-23 19:51:56","2023-10-23 19:51:56","2023-10-23 19:51:56","2398–2409","","","","","","GenWiki","","","","","International Committee on Computational Linguistics","Barcelona, Spain (Online)","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/3JTJ76QD/Jin et al. - 2020 - GenWiki A Dataset of 1.3 Million Content-Sharing .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","COLING 2020","","","","","","","","","","","","","","",""
"HFM92QR7","conferencePaper","2020",", Tong Zhu 0002; , Haitao Wang 0019; , Junjie Yu; , Xiabing Zhou; , Wenliang Chen; , Wei Zhang 0027; , Min Zhang 0005","Towards Accurate and Consistent Evaluation: A Dataset for Distantly-Supervised Relation Extraction.","","","","10.18653/V1/2020.COLING-MAIN.566","https://dblp.org/rec/journals/corr/abs-2010-16275","nan","2020","2024-07-23 11:48:58","2024-07-23 11:48:58","","6436-6447","","","nan","","","","","","","","nan","","","open","","DBLP","1935032","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","COLING","","","","","","","","","","","","","","",""
"FU76XJ4V","conferencePaper","2016","Dong, Li; Lapata, Mirella","Language to Logical Form with Neural Attention","Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/P16-1004","https://aclanthology.org/P16-1004/","","2016-08","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:55:17","33–43","","","","","","DUIE","","","","","Association for Computational Linguistics","Berlin, Germany","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/L3TQ6H8X/Dong and Lapata - 2016 - Language to Logical Form with Neural Attention.pdf","","FILTER_STEP","","Erk, Katrin; Smith, Noah A.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2016","","","","","","","","","","","","","","",""
"EFJY4L6K","conferencePaper","2020","Zhang, Hongming; Chen, Muhao; Wang, Haoyu; Song, Yangqiu; Roth, Dan","Analogous Process Structure Induction for Sub-event Sequence Prediction","Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","","","10.18653/v1/2020.emnlp-main.119","https://aclanthology.org/2020.emnlp-main.119/","Computational and cognitive studies of event understanding suggest that identifying, comprehending, and predicting events depend on having structured representations of a sequence of events and on conceptualizing (abstracting) its components into (soft) event categories. Thus, knowledge about a known process such as “buying a car” can be used in the context of a new but analogous process such as “buying a house”. Nevertheless, most event understanding work in NLP is still at the ground level and does not consider abstraction. In this paper, we propose an Analogous Process Structure Induction (APSI) framework, which leverages analogies among processes and conceptualization of sub-event instances to predict the whole sub-event sequence of previously unseen open-domain processes. As our experiments and analysis indicate, APSI supports the generation of meaningful sub-event sequences for unseen processes and can help predict missing events.","2020-11","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 13:01:35","1541–1550","","","","","","EVENTPROCESSCOMPLET","","","","","Association for Computational Linguistics","Online","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/XNHLCLRC/Zhang et al. - 2020 - Analogous Process Structure Induction for Sub-event Sequence Prediction.pdf","","FILTER_STEP","","Webber, Bonnie; Cohn, Trevor; He, Yulan; Liu, Yang","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2020","","","","","","","","","","","","","","",""
"6PD2LEUH","conferencePaper","2020","Yu, Dian; Sun, Kai; Cardie, Claire; Yu, Dong","Dialogue-Based Relation Extraction","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/2020.acl-main.444","https://aclanthology.org/2020.acl-main.444/","We present the first human-annotated dialogue-based relation extraction (RE) dataset DialogRE, aiming to support the prediction of relation(s) between two arguments that appear in a dialogue. We further offer DialogRE as a platform for studying cross-sentence RE as most facts span multiple sentences. We argue that speaker-related information plays a critical role in the proposed task, based on an analysis of similarities and differences between dialogue-based and traditional RE tasks. Considering the timeliness of communication in a dialogue, we design a new metric to evaluate the performance of RE methods in a conversational setting and investigate the performance of several representative RE methods on DialogRE. Experimental results demonstrate that a speaker-aware extension on the best-performing model leads to gains in both the standard and conversational evaluation settings. DialogRE is available at https://dataset.org/dialogre/.","2020-07","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-25 11:40:25","4927–4940","","","","","","DIALOGRE","","","","","Association for Computational Linguistics","Online","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/CKPZU7VU/Yu et al. - 2020 - Dialogue-Based Relation Extraction.pdf","","EXAMPLE; FILTER_STEP","","Jurafsky, Dan; Chai, Joyce; Schluter, Natalie; Tetreault, Joel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2020","","","","","","","","","","","","","","",""
"ESMRNLQM","journalArticle","2015","Derczynski, Leon; Maynard, Diana; Rizzo, Giuseppe; van Erp, Marieke; Gorrell, Genevieve; Troncy, Raphaël; Petrak, Johann; Bontcheva, Kalina","Analysis of named entity recognition and linking for tweets","Information Processing & Management","","0306-4573","10.1016/j.ipm.2014.10.006","https://www.sciencedirect.com/science/article/pii/S0306457314001034","Applying natural language processing for mining and intelligent information access to tweets (a form of microblog) is a challenging, emerging research area. Unlike carefully authored news text and other longer content, tweets pose a number of new challenges, due to their short, noisy, context-dependent, and dynamic nature. Information extraction from tweets is typically performed in a pipeline, comprising consecutive stages of language identification, tokenisation, part-of-speech tagging, named entity recognition and entity disambiguation (e.g. with respect to DBpedia). In this work, we describe a new Twitter entity disambiguation dataset, and conduct an empirical analysis of named entity recognition and disambiguation, investigating how robust a number of state-of-the-art systems are on such noisy texts, what the main sources of error are, and which problems should be further investigated to improve the state of the art.","2015-03-01","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:32:02","32-49","","2","51","","Information Processing & Management","DER","","","","","","","","","","","","ScienceDirect","","","","/root/snap/zotero-snap/common/Zotero/storage/TQS4PMI9/Derczynski et al. - 2015 - Analysis of named entity recognition and linking for tweets.pdf","","FILTER_STEP","Named entity recognition; Information extraction; Entity disambiguation; Microblogs; Twitter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GTBPCKNV","journalArticle","2013","Herrero-Zazo, María; Segura-Bedmar, Isabel; Martínez, Paloma; Declerck, Thierry","The DDI corpus: An annotated corpus with pharmacological substances and drug–drug interactions","Journal of Biomedical Informatics","","1532-0464","10.1016/j.jbi.2013.07.011","https://www.sciencedirect.com/science/article/pii/S1532046413001123","The management of drug–drug interactions (DDIs) is a critical issue resulting from the overwhelming amount of information available on them. Natural Language Processing (NLP) techniques can provide an interesting way to reduce the time spent by healthcare professionals on reviewing biomedical literature. However, NLP techniques rely mostly on the availability of the annotated corpora. While there are several annotated corpora with biological entities and their relationships, there is a lack of corpora annotated with pharmacological substances and DDIs. Moreover, other works in this field have focused in pharmacokinetic (PK) DDIs only, but not in pharmacodynamic (PD) DDIs. To address this problem, we have created a manually annotated corpus consisting of 792 texts selected from the DrugBank database and other 233 Medline abstracts. This fined-grained corpus has been annotated with a total of 18,502 pharmacological substances and 5028 DDIs, including both PK as well as PD interactions. The quality and consistency of the annotation process has been ensured through the creation of annotation guidelines and has been evaluated by the measurement of the inter-annotator agreement between two annotators. The agreement was almost perfect (Kappa up to 0.96 and generally over 0.80), except for the DDIs in the MedLine database (0.55–0.72). The DDI corpus has been used in the SemEval 2013 DDIExtraction challenge as a gold standard for the evaluation of information extraction techniques applied to the recognition of pharmacological substances and the detection of DDIs from biomedical texts. DDIExtraction 2013 has attracted wide attention with a total of 14 teams from 7 different countries. For the task of recognition and classification of pharmacological names, the best system achieved an F1 of 71.5%, while, for the detection and classification of DDIs, the best result was F1 of 65.1%. These results show that the corpus has enough quality to be used for training and testing NLP techniques applied to the field of Pharmacovigilance. The DDI corpus and the annotation guidelines are free for use for academic research and are available at http://labda.inf.uc3m.es/ddicorpus.","2013-10-01","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:54:22","914-920","","5","46","","Journal of Biomedical Informatics","DDI","","","","","","","","","","","","ScienceDirect","","","","","","FILTER_STEP","Information extraction; Biomedical corpora; Drug interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XFMHYACB","conferencePaper","2003","Tjong Kim Sang, Erik F.; De Meulder, Fien","Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition","Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003","","","10.3115/1119176.1119195","https://aclanthology.org/W03-0419","We describe the CoNLL-2003 shared task: language-independent named entity recog- nition. We give background information on the data sets (English and German) and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their perfor- mance.","2003","2025-02-06 08:47:21","2025-02-06 08:47:21","2023-02-28 16:29:37","142–147","","","","","","CONLL03","","","","","ACL","","","False","","https://paperswithcode.com/paper/introduction-to-the-conll-2003-shared-task","http://lcg-www.uia.ac.be/conll2003/ner/","ACLWeb","","{'citing': ['10.1109/iceet48479.2020.9048203', '10.1109/access.2020.2984582', '10.1109/icmla.2019.00298', '10.1109/tbdata.2020.2998770', '10.1007/978-981-15-4828-4_14', '10.1109/icawst.2018.8517195', '10.1371/journal.pone.0270904', '10.1109/icmla51294.2020.00094', '10.1109/icphys.2019.8780184', '10.1109/gucon.2018.8674901', '10.1007/978-3-031-10525-8_3', '10.1109/icsc50631.2021.00007', '10.1109/bibm52615.2021.9669766', '10.1016/j.eswa.2020.113765', '10.1109/tpami.2020.3046683', '10.1109/ebbt.2019.8741631', '10.1371/journal.pone.0267812', '10.5715/jnlp.29.294', '10.1109/bibm47256.2019.8983247', '10.1109/cic48465.2019.00031', '10.1007/s10489-022-03511-6', '10.1109/icassp43922.2022.9746913', '10.1109/iaeac50856.2021.9390956', '10.1109/icassp39728.2021.9414304', '10.1049/cit2.12107', '10.1109/infrkm.2018.8464820', '10.1200/cci.21.00136', '10.1109/asonam49781.2020.9381292', '10.1109/slt48900.2021.9383493', '10.1109/ubmk.2019.8907039', '10.1109/asyu52992.2021.9598971', '10.1109/bigdata52589.2021.9671435', '10.1109/slt.2018.8639043', '10.3390/app12136391', '10.1001/jamanetworkopen.2022.27109', '10.1016/j.neucom.2022.09.081', '10.1016/j.neucom.2022.09.081', '10.1039/d2sc04322j', '10.3233/sw-223177', '10.1162/tacl_a_00500', '10.1016/j.ipm.2022.103065', '10.1101/2022.09.22.22280246', '10.1007/978-3-031-17601-2_28', '10.1007/978-3-031-16270-1_12', '10.1145/3301275.3302276', '10.1109/fuzz-ieee55066.2022.9882595', '10.1007/978-3-031-16078-3_49', '10.3390/info13080367', '10.1162/tacl_a_00501', '10.1007/s10618-022-00854-z', '10.1016/j.eswa.2022.119274', '10.1080/13658816.2022.2133125', '10.1109/icacte55855.2022.9943631', '10.12677/csa.2022.1211257', '10.21203/rs.3.rs-2169841/v1', '10.1007/978-3-031-21689-3_38', '10.1109/icpr56361.2022.9956120', '10.21203/rs.3.rs-2163664/v1', '10.1007/s11280-019-00736-3', '10.1186/s13326-019-0211-7', '10.1007/978-3-030-43823-4_41', '10.1007/s42044-018-0014-5', '10.1007/978-3-319-99495-6_19', '10.1007/978-981-15-0751-9_14', '10.1007/978-3-030-00671-6_12', '10.1007/s10916-020-1542-8', '10.1080/14754835.2019.1671173', '10.1631/fitee.1800743', '10.1002/9781119419686.biblio', '10.1145/3368555.3384467', '10.14778/1920841.1920916', '10.14778/2536222.2536237', '10.1007/978-3-030-36708-4_25', '10.1007/978-981-15-1081-6_18', '10.1007/978-3-030-03596-9_35', '10.1007/978-3-319-75477-2_30', '10.1145/3159652.3159695', '10.1007/978-3-030-03192-3_20', '10.2200/s00999ed3v01y202003hlt046', '10.1145/2499955.2499958', '10.1007/11562214_78', '10.1145/1328964.1328989', '10.1145/3366424.3383527', '10.1145/3329710', '10.1145/3331184.3331646', '10.1007/978-3-030-44584-3_37', '10.1145/3297280.3297379', '10.1145/3357384.3358024', '10.1145/3357384.3358109', '10.1101/786921', '10.1145/3308560.3317704', '10.1007/978-3-030-52683-2_1', '10.1162/coli_a_00376', '10.1007/s40998-020-00352-2', '10.1162/tacl_a_00316', '10.1093/bioinformatics/btaa531', '10.1007/978-981-15-5573-2_7', '10.1002/asi.24399', '10.1111/jbfa.12378', '10.1145/2047296.2047298', '10.1145/1967293.1967296', '10.1145/2483691.2483695', '10.1007/s00521-020-05351-2', '10.1007/978-3-030-58323-1_11', '10.1007/978-3-030-58323-1_29', '10.1007/978-3-030-54956-5_7', '10.1080/13658816.2018.1458986', '10.1145/1322391.1322393', '10.1162/tacl_a_00334', '10.1145/3394486.3403149', '10.4018/ijghpc.2020070101', '10.1145/1089815.1089817', '10.1145/2414425.2414428', '10.1051/itmconf/20171204002', '10.1145/3281354.3281363', '10.1145/3368089.3417067', '10.1016/j.websem.2015.12.004', '10.1007/978-3-030-62327-2_23', '10.1007/978-3-030-63007-2_61', '10.1007/978-3-030-63031-7_10', '10.1007/978-3-030-64452-9_3', '10.1007/978-3-030-65218-0_16', '10.1007/978-3-319-59834-5_8', '10.2139/ssrn.2940564', '10.2200/s00994ed1v01y202002hlt045', '10.1016/j.eswa.2011.05.004', '10.1016/j.ins.2008.05.002', '10.1016/j.ipm.2014.04.005', '10.1016/j.patcog.2008.02.010', '10.1016/j.artint.2012.03.006', '10.1016/j.artint.2012.04.005', '10.1016/j.future.2018.03.035', '10.1016/j.jbi.2011.10.007', '10.1016/j.knosys.2020.105842', '10.1016/b978-0-12-809633-8.20463-9', '10.5715/jnlp.27.499', '10.1016/j.datak.2020.101796', '10.1016/j.ipm.2012.05.006', '10.1016/j.jbi.2017.05.009', '10.1016/j.jbi.2004.08.008', '10.1016/j.knosys.2013.02.008', '10.1016/j.artint.2012.10.002', '10.1016/j.csl.2007.12.001', '10.1016/j.datak.2006.06.014', '10.1016/j.drudis.2013.10.006', '10.1016/j.engappai.2016.01.011', '10.1016/j.ipm.2014.10.006', '10.1016/j.neucom.2015.07.046', '10.1016/j.sbspro.2011.10.596', '10.3390/ijgi10030155', '10.1007/s10462-021-09983-1', '10.1002/asi.24032', '10.1016/j.neucom.2021.05.103', '10.1007/s10664-020-09918-4', '10.2196/preprints.31223', '10.1007/978-3-030-72610-2_2', '10.1038/s41598-021-82338-6', '10.1145/3459930.3469533', '10.1002/9781119268567.biblio', '10.1007/s11302-018-9614-7', '10.1007/s11390-017-1762-7', '10.1007/s12204-018-1954-5', '10.1007/s13042-014-0268-7', '10.1007/s13042-014-0275-8', '10.1002/9781444324044.refs', '10.1002/asi.24282', '10.1017/atsip.2019.12', '10.1017/s1351324908004968', '10.1038/sdata.2018.258', '10.1075/term.21.2.04gai', '10.1080/18756891.2012.747661', '10.1093/bioinformatics/bts125', '10.1007/978-94-024-0881-2_31', '10.1007/978-94-024-0881-2_32', '10.1007/978-981-10-8438-6_19', '10.1007/978-981-13-1135-2_4', '10.1111/coin.12214', '10.1007/11683568_8', '10.1007/11893318_27', '10.1145/2328967.2328972', '10.1145/2736277.2741626', '10.1145/2736277.2741633', '10.1145/2740908.2743039', '10.1145/2948649.2948651', '10.1145/2963100', '10.1145/2993901.2993907', '10.1145/3018661.3018724', '10.1145/3038912.3052600', '10.1145/3077136.3080668', '10.1145/3106668.3106672', '10.1145/3148011.3148021', '10.1145/3148011.3148024', '10.1145/3148011.3154478', '10.1145/3205977.3205984', '10.1145/3238797', '10.1145/3273931', '10.1007/978-1-4471-2978-3_1', '10.1177/1464884917716699', '10.1002/9781118617151.ch37', '10.1007/s00500-012-0885-6', '10.1007/s00500-017-2963-2', '10.1007/s10032-011-0155-7', '10.1007/s10115-012-0502-0', '10.1007/s10115-018-1265-z', '10.1007/s10462-019-09688-6', '10.1007/s10506-018-9225-1', '10.1007/s10515-011-0099-7', '10.1007/s10579-013-9255-y', '10.1007/s10579-019-09461-9', '10.1007/s10579-019-09471-7', '10.1007/s10590-017-9208-0', '10.1007/s10664-016-9430-z', '10.1007/s10994-013-5411-2', '10.1007/s11168-010-9071-0', '10.1186/1471-2105-14-281', '10.1186/1758-2946-7-s1-s4', '10.1186/1758-2946-7-s1-s8', '10.1186/s12911-019-0865-1', '10.1186/s12938-018-0573-6', '10.1186/s42400-018-0019-2', '10.1007/978-3-030-01129-1_10', '10.1007/978-3-030-03146-6_116', '10.1007/978-3-030-04179-3_8', '10.1007/978-3-030-14596-5_1', '10.1007/978-3-030-17083-7_2', '10.1007/978-3-030-18305-9_46', '10.1007/978-3-030-22312-0_8', '10.1007/978-3-030-22999-3_65', '10.1007/978-3-030-26072-9_25', '10.1007/978-3-030-29894-4_13', '10.1007/978-3-030-29908-8_26', '10.1007/978-3-030-30241-2_29', '10.1007/978-3-030-30639-7_2', '10.1007/978-3-030-31624-2_7', '10.1007/978-3-030-32236-6_14', '10.1007/978-3-319-06569-4_19', '10.1007/978-3-319-07064-3_26', '10.1007/978-3-319-08958-4_16', '10.1007/978-3-319-08976-8_2', '10.1007/978-3-319-12655-5_6', '10.1007/978-3-319-13647-9_6', '10.1007/978-3-319-14120-6_16', '10.1007/978-3-319-15563-0_3', '10.1007/978-3-319-24033-6_7', '10.1007/978-3-319-27000-5_23', '10.1007/978-3-319-27433-1_15', '10.1007/978-3-319-29009-6_1', '10.1007/978-3-319-45510-5_20', '10.1007/978-3-319-46565-4_2', '10.1007/978-3-319-48674-1_54', '10.1007/978-3-319-50478-0_11', '10.1007/978-3-319-50496-4_22', '10.1007/978-3-319-52920-2_18', '10.1007/978-3-319-56288-9_71', '10.1007/978-3-319-59888-8_23', '10.1007/978-3-319-68723-0_9', '10.1007/978-3-319-68786-5_18', '10.1007/978-3-319-71078-5_12', '10.1007/978-3-319-76348-4_11', '10.1007/978-3-319-90165-7_6', '10.1007/978-3-319-91452-7_53', '10.1007/978-3-319-93417-4_8', '10.1007/978-3-319-93782-3_20', '10.1007/978-3-319-99722-3_32', '10.1587/transinf.2017kbl0001', '10.1007/978-3-540-24581-0_78', '10.1007/978-3-540-24630-5_19', '10.1007/978-3-540-77018-3_18', '10.1007/978-3-540-78246-9_65', '10.1007/978-3-540-89704-0_29', '10.21923/jesd.448251', '10.2200/s00491ed1v01y201303dtm034', '10.2200/s00509ed1v01y201305hlt023', '10.1007/978-3-642-00958-7_50', '10.2200/s00676ed1v01y201509dtm042', '10.2200/s00809ed2v01y201710hlt038', '10.2200/s00866ed1v01y201807dtm049', '10.2200/s00920ed2v01y201904hlt042', '10.1007/978-3-642-04125-9_27', '10.1007/978-3-642-04930-9_66', '10.1007/978-3-642-13840-9_16', '10.1007/978-3-642-13881-2_27', '10.1007/978-3-642-15246-7_8', '10.1007/978-3-642-15998-5_12', '10.1007/978-3-642-22327-3_5', '10.1007/978-3-642-23538-2_26', '10.1007/978-3-642-23708-9_3', '10.1007/978-3-642-23780-5_36', '10.1007/978-3-642-23808-6_18', '10.1007/978-3-642-27172-4_52', '10.1007/978-3-642-28249-2_6', '10.1007/978-3-642-28604-9_26', '10.1007/978-3-642-32790-2_28', '10.1007/978-3-642-37247-6_25', '10.1007/978-3-642-37247-6_27', '10.1007/978-3-642-37453-1_31', '10.1007/978-3-642-39200-9_39', '10.1007/978-3-642-40585-3_10', '10.1007/978-3-642-40585-3_20', '10.1007/978-3-642-41464-0_10', '10.1007/978-3-642-41464-0_16', '10.1007/978-3-642-41644-6_3', '10.1007/978-3-642-45185-0_50', '10.1007/978-3-642-45358-8_7', '10.29252/jsdp.14.3.127', '10.3103/s0005105517030049', '10.3233/ao-190215', '10.3233/ds-190021', '10.3233/sw-170253', '10.3233/sw-170282', '10.3233/sw-170286', '10.3897/bdj.7.e29626', '10.1109/hsi.2016.7529634', '10.1109/ialp.2015.7451557', '10.1109/icaict.2013.6722801', '10.1109/icassp.2011.5947449', '10.1109/icassp.2012.6289004', '10.1109/iccnc.2015.7069416', '10.1109/iccp.2013.6646077', '10.1109/icices.2014.7033948', '10.1109/icpr.2010.477', '10.1109/ictai.2010.54', '10.1109/ijcnn.2017.7966181', '10.1109/isise.2012.107', '10.1109/mercon.2016.7480111', '10.1109/mipro.2014.6859768', '10.1109/mis.2009.32', '10.1109/rivf.2012.6169818', '10.1109/scis-isis.2012.6505254', '10.1109/skg.2012.2', '10.1109/smap.2014.27', '10.1109/sose.2014.30', '10.1109/tkde.2011.178', '10.1109/tsc.2015.2474861', '10.1109/tvcg.2017.2744158', '10.1109/wict.2013.7113096', '10.1109/wi-iat.2010.314', '10.1109/ams.2013.33', '10.1109/asonam.2012.97', '10.1109/asru.2011.6163967', '10.1109/ceec.2012.6375385', '10.1109/civts.2014.7009471', '10.1109/cloudcom-asia.2013.102', '10.1109/compsac.2016.109', '10.1109/eit.2016.7535297', '10.1109/etcm.2017.8247537', '10.1109/fruct.2016.7584769', '10.1109/hicss.2015.190', '10.5715/jnlp.24.655', '10.1145/3377325.3377503', '10.1111/tgis.12579', '10.1007/s11192-019-03274-x', '10.1007/s10664-019-09788-5', '10.1145/3178876.3185997', '10.3233/ida-184238', '10.1145/3453892.3461321', '10.1016/j.ipm.2020.102473', '10.1145/3437963.3441777', '10.1016/j.procs.2021.06.082', '10.2478/popets-2021-0019', '10.1016/j.neucom.2020.10.010', '10.2196/24020', '10.1007/978-3-030-72113-8_28', '10.1007/978-3-030-77442-4_51', '10.1007/s11042-021-11253-9', '10.1007/s10579-020-09516-2', '10.1007/978-3-030-80599-9_7', '10.1186/s13634-021-00736-4', '10.1007/978-3-030-73050-5_34', '10.1145/3442381.3449995', '10.1162/coli_a_00397', '10.1162/tacl_a_00386', '10.1007/s00521-020-05268-w', '10.1021/acs.jcim.9b00470', '10.1007/978-3-030-87839-9_3', '10.1145/3404835.3463071', '10.1007/978-3-030-83527-9_19', '10.1016/j.eswa.2021.114855', '10.1007/978-3-030-86331-9_48', '10.1145/3404835.3462873', '10.1145/3404835.3463113', '10.3103/s1066530720020027', '10.1007/978-3-030-84186-7_24', '10.1145/3442381.3449870', '10.5715/jnlp.28.847', '10.1016/j.artmed.2021.102153', '10.1162/tacl_a_00404', '10.1007/978-3-030-86549-8_36', '10.1186/s12859-021-04247-9', '10.1145/3442442.3451894', '10.1007/s00799-021-00319-6', '10.1162/tacl_a_00425', '10.1162/tacl_a_00416', '10.1007/s41060-021-00285-x', '10.1016/j.procs.2021.08.030', '10.1162/tacl_a_00429', '10.1162/tacl_a_00438', '10.1145/3474124.3474160', '10.1007/978-3-030-91669-5_21', '10.1145/3297280.3297378', '10.1007/978-3-030-88304-1_28', '10.1145/3487057', '10.1007/978-3-030-91699-2_42', '10.1016/j.psep.2021.11.004', '10.2196/preprints.34400', '10.48084/etasr.4300', '10.1162/tacl_a_00448', '10.1021/acs.jcim.1c01199', '10.2196/preprints.36119', '10.1017/s1351324921000486', '10.1108/ijwis-05-2013-0016', '10.1007/s41060-022-00310-7', '10.1007/s11063-021-10737-x', '10.1007/s41666-021-00111-w', '10.2196/36119', '10.54856/jiswa.201912084', '10.1145/3487664.3487677', '10.1017/s1351324922000080', '10.1007/s00521-022-07164-x', '10.1145/3498324', '10.1007/s11192-022-04332-7', '10.1101/2022.04.14.488416', '10.1017/s1351324922000122', '10.1145/3485447.3512242', '10.1016/j.neucom.2022.04.027', '10.1145/3523150.3523176', '10.1162/tacl_a_00459', '10.2196/preprints.37816', '10.1109/ast52587.2021.00017', '10.1109/icctec.2017.00113', '10.1109/sp46214.2022.9833641', '10.1109/icassp43922.2022.9747433', '10.1109/icbats54253.2022.9759051', '10.1109/csci51800.2020.00099', '10.1109/hpca51647.2021.00018', '10.1109/escience.2019.00021', '10.1109/icoice48418.2019.9035170', '10.1109/tkde.2020.2981314', '10.1109/tkde.2020.2981329', '10.1109/rivf.2019.8713710', '10.1109/ivmem.2019.00016', '10.1109/iac3t.2018.8674025', '10.1109/ic-aiai.2018.8674438', '10.1109/ispras.2018.00015', '10.1109/bigcomp.2019.8679473', '10.1109/icosc.2019.8665500', '10.1109/istel.2018.8661067', '10.1109/ijcnn52387.2021.9534328', '10.1145/3531146.3533233', '10.1007/978-3-658-35969-0_3', '10.1109/dicta.2018.8615844', '10.1109/icmla.2018.00104', '10.1109/icmla.2018.00149', '10.1109/snams.2018.8554623', '10.1109/icbaie52039.2021.9389994'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/2HWPSQAW/Tjong Kim Sang and De Meulder - 2003 - Introduction to the CoNLL-2003 Shared Task Langua.pdf","","EXAMPLE; FILTER_STEP; DOMAIN:?; GRANULARITY:?; TASK:Ner; LANG:Multi; LANG:German; DATATYPEPROP:?; NBTYPEREL:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:?","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CoNLL-HLT 2003","","","","","","","","","","","","","","",""
"F4FSESAG","conferencePaper","2012","Speer, Robyn; Havasi, Catherine","Representing General Relational Knowledge in ConceptNet 5","Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC`12)","","","","https://aclanthology.org/L12-1639/","ConceptNet is a knowledge representation project, providing a large semantic graph that describes general human knowledge and how it is expressed in natural language. This paper presents the latest iteration, ConceptNet 5, including its fundamental design decisions, ways to use it, and evaluations of its coverage and accuracy.","2012-05","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-28 18:25:08","3679–3686","","","","","","CONCEPTNET","","","","","European Language Resources Association (ELRA)","Istanbul, Turkey","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/XXG8EEP4/Speer and Havasi - 2012 - Representing General Relational Knowledge in ConceptNet 5.pdf","","EXAMPLE; FILTER_STEP","","Calzolari, Nicoletta; Choukri, Khalid; Declerck, Thierry; Doğan, Mehmet Uğur; Maegaard, Bente; Mariani, Joseph; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LREC 2012","","","","","","","","","","","","","","",""
"XJT2EYHL","conferencePaper","2020","Mori, Yusuke; Yamane, Hiroaki; Mukuta, Yusuke; Harada, Tatsuya","Finding and Generating a Missing Part for Story Completion","Proceedings of the 4th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature","","","","https://aclanthology.org/2020.latechclfl-1.19/","Creating a story is difficult. Professional writers often experience a writer`s block. Thus, providing automatic support to writers is crucial but also challenging. Recently, in the field of generating and understanding stories, story completion (SC) has been proposed as a method for generating missing parts of an incomplete story. Despite this method`s usefulness in providing creative support, its applicability is currently limited because it requires the user to have prior knowledge of the missing part of a story. Writers do not always know which part of their writing is flawed. To overcome this problem, we propose a novel approach called “missing position prediction (MPP).” Given an incomplete story, we aim to predict the position of the missing part. We also propose a novel method for MPP and SC. We first conduct an experiment focusing on MPP, and our analysis shows that highly accurate predictions can be obtained when the missing part of a story is the beginning or the end. This suggests that if a story has a specific beginning or end, they play significant roles. We conduct an experiment on SC using MPP, and our proposed method demonstrates promising results.","2020-12","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 13:06:09","156–166","","","","","","COUNTERFACTUALSTORY/ABDUCTIVECSREASONING","","","","","International Committee on Computational Linguistics","Online","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/JG34HSJQ/Mori et al. - 2020 - Finding and Generating a Missing Part for Story Completion.pdf","","FILTER_STEP","","DeGaetano, Stefania; Kazantseva, Anna; Reiter, Nils; Szpakowicz, Stan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LaTeCHCLfL 2020","","","","","","","","","","","","","","",""
"KBZ4TVJ3","webpage","","","Cognitive Computation Group","","","","","https://cogcomp.seas.upenn.edu/page/resource_view/43","","","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-24 16:29:43","","","","","","","Conll04","","","","","","","","","","","","","","","","","","EXAMPLE; FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YAI887U3","conferencePaper","2021",", Yuan YAO; , Jiaju Du; , Yankai Lin; , Peng Li; , Zhiyuan Liu; , Jie zhou; , Maosong Sun","CodRED: A Cross-Document Relation Extraction Dataset for Acquiring Knowledge in the Wild","","","","10.18653/v1/2021.emnlp-main.366","https://aclanthology.org/2021.emnlp-main.366","Existing relation extraction (RE) methods typically focus on extracting relational facts between entity pairs within single sentences or documents. However, a large quantity of relational facts in knowledge bases can only be inferred across documents in practice. In this work, we present the problem of cross-document RE, making an initial step towards knowledge acquisition in the wild. To facilitate the research, we construct the first human-annotated cross-document RE dataset CodRED. Compared to existing RE datasets, CodRED presents two key challenges: Given two entities, (1) it requires finding the relevant documents that can provide clues for identifying their relations; (2) it requires reasoning over multiple documents to extract the relational facts. We conduct comprehensive experiments to show that CodRED is challenging to existing RE methods including strong BERT-based models.","2021-11-01","2025-02-06 08:47:21","2025-02-06 08:47:21","","NA","","","NA","","","CodRED","","","","","ACL","","","True","","https://paperswithcode.com/paper/codred-a-cross-document-relation-extraction","https://github.com/thunlp/CodRED","","","","","/root/snap/zotero-snap/common/Zotero/storage/JWR7ZL56/ et al. - 2021 - CodRED A Cross-Document Relation Extraction Datas.pdf","","DONE; TASK:Relextract; GRANULARITY:Document; GRANULARITY:Sentences; TASK:Ner; LANG:English; SYNTHGENERATION_BIN:?; NBTYPEREL:10²; SELECTIONMETHOD:Automatic; DOMAIN:Encyclo; SOURCE:Wikidata; SOURCE:Wikipedia; SELECTIONMETHOD:Manual; NBTRIPLES:10³; NBDOC:10⁶; DATATYPEPROP:None; OBJECTPROPERTIES_BIN:1; NBSENT:10⁵; NBTYPEENTITY:NSP; DOMAIN:general; Task:Retrieval; Task:reasoning; NBENTITY:NSP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2021 11","","","","","","","","","","","","","","",""
"XAHU5DF8","journalArticle","2016","Kringelum, Jens; Kjaerulff, Sonny Kim; Brunak, Søren; Lund, Ole; Oprea, Tudor I.; Taboureau, Olivier","ChemProt-3.0: a global chemical biology diseases mapping","Database: The Journal of Biological Databases and Curation","","1758-0463","10.1093/database/bav123","","ChemProt is a publicly available compilation of chemical-protein-disease annotation resources that enables the study of systems pharmacology for a small molecule across multiple layers of complexity from molecular to clinical levels. In this third version, ChemProt has been updated to more than 1.7 million compounds with 7.8 million bioactivity measurements for 19,504 proteins. Here, we report the implementation of global pharmacological heatmap, supporting a user-friendly navigation of chemogenomics space. This facilitates the visualization and selection of chemicals that share similar structural properties. In addition, the user has the possibility to search by compound, target, pathway, disease and clinical effect. Genetic variations associated to target proteins were integrated, making it possible to plan pharmacogenetic studies and to suggest human response variability to drug. Finally, Quantitative Structure-Activity Relationship models for 850 proteins having sufficient data were implemented, enabling secondary pharmacological profiling predictions from molecular structure. Database URL: http://potentia.cbs.dtu.dk/ChemProt/.","2016","2025-02-06 08:47:21","2025-02-06 08:47:21","","bav123","","","2016","","Database (Oxford)","ChemProt-3.0","","","","","","","eng","","","","","PubMed","","PMID: 26876982 PMCID: PMC4752971","","/root/snap/zotero-snap/common/Zotero/storage/HJ3RQM8Z/Kringelum et al. - 2016 - ChemProt-3.0 a global chemical biology diseases mapping.pdf; ","http://www.ncbi.nlm.nih.gov/pubmed/26876982","EXAMPLE; FILTER_STEP","Proteins; Internet; Humans; Caffeine; Databases, Chemical; Databases, Factual; Databases, Protein; Disease; Genetic Variation; Ligands; Molecular Structure; Pharmacogenetics; Phenotype; Quantitative Structure-Activity Relationship; Software; User-Computer Interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y27L52DQ","conferencePaper","2023","Li, Peng; Sun, Tianxiang; Tang, Qiong; Yan, Hang; Wu, Yuanbin; Huang, Xuanjing; Qiu, Xipeng","CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2023.acl-long.855","https://aclanthology.org/2023.acl-long.855/","Large language models (LLMs) pre-trained on massive corpora have demonstrated impressive few-shot learning ability on many NLP tasks. A common practice is to recast the task into a text-to-text format such that generative LLMs of natural language (NL-LLMs) like GPT-3 can be prompted to solve it. However, it is nontrivial to perform information extraction (IE) tasks with NL-LLMs since the output of the IE task is usually structured and therefore is hard to be converted into plain text. In this paper, we propose to recast the structured output in the form of code instead of natural language and utilize generative LLMs of code (Code-LLMs) such as Codex to perform IE tasks, in particular, named entity recognition and relation extraction. In contrast to NL-LLMs, we show that Code-LLMs can be well-aligned with these IE tasks by designing code-style prompts and formulating these IE tasks as code generation tasks. Experiment results on seven benchmarks show that our method consistently outperforms fine-tuning moderate-size pre-trained models specially designed for IE tasks (e.g., UIE) and prompting NL-LLMs under few-shot settings. We further conduct a series of in-depth analyses to demonstrate the merits of leveraging Code-LLMs for IE tasks.","2023-07","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:27:42","15339–15353","","","","","","CodeIE","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/IMTBA39D/Li et al. - 2023 - CodeIE Large Code Generation Models are Better Few-Shot Information Extractors.pdf","","FILTER_STEP","","Rogers, Anna; Boyd-Graber, Jordan; Okazaki, Naoaki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2023","","","","","","","","","","","","","","",""
"MHJFRELQ","conferencePaper","2016","Bethard, Steven; Savova, Guergana; Chen, Wei-Te; Derczynski, Leon; Pustejovsky, James; Verhagen, Marc","SemEval-2016 Task 12: Clinical TempEval","Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)","","","10.18653/v1/S16-1165","https://aclanthology.org/S16-1165/","","2016-06","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:56:58","1052–1062","","","","","","CLINICALTEMPEVAL","","","","","Association for Computational Linguistics","San Diego, California","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/8UAAJ4YP/Bethard et al. - 2016 - SemEval-2016 Task 12 Clinical TempEval.pdf","","EXAMPLE; FILTER_STEP","","Bethard, Steven; Carpuat, Marine; Cer, Daniel; Jurgens, David; Nakov, Preslav; Zesch, Torsten","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SemEval 2016","","","","","","","","","","","","","","",""
"BT4HMHWH","journalArticle","2020","Satyapanich, Taneeya; Ferraro, Francis; Finin, Tim","CASIE: Extracting Cybersecurity Event Information from Text","Proceedings of the AAAI Conference on Artificial Intelligence","","2374-3468","10.1609/aaai.v34i05.6401","https://ojs.aaai.org/index.php/AAAI/article/view/6401","We present CASIE, a system that extracts information about cybersecurity events from text and populates a semantic model, with the ultimate goal of integration into a knowledge graph of cybersecurity data. It was trained on a new corpus of 1,000 English news articles from 2017–2019 that are labeled with rich, event-based annotations and that covers both cyberattack and vulnerability-related events. Our model defines five event subtypes along with their semantic roles and 20 event-relevant argument types (e.g., file, device, software, money). CASIE uses different deep neural networks approaches with attention and can incorporate rich linguistic features and word embeddings. We have conducted experiments on each component in the event detection pipeline and the results show that each subsystem performs well.","2020-04-03","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:01:25","8749-8757","","05","34","","","CASIE","","","","","","","en","Copyright (c) 2020 Association for the Advancement of Artificial Intelligence","","","","ojs.aaai.org","","Number: 05","","/root/snap/zotero-snap/common/Zotero/storage/S9F3UPFA/Satyapanich et al. - 2020 - CASIE Extracting Cybersecurity Event Information from Text.pdf","","EXAMPLE; FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NGFCIPWS","conferencePaper","2020",", Chris van der Lee; , Chris Emmery; , Sander Wubben; , Emiel Krahmer","The CACAPO Dataset: A Multilingual, Multi-Domain Dataset for Neural Pipeline and End-to-End Data-to-Text Generation","","","","not found","https://aclanthology.org/2020.inlg-1.10","This paper describes the CACAPO dataset, built for training both neural pipeline and end-to-end data-to-text language generation systems. The dataset is multilingual (Dutch and English), and contains almost 10,000 sentences from human-written news texts in the sports, weather, stocks, and incidents domain, together with aligned attribute-value paired data. The dataset is unique in that the linguistic variation and indirect ways of expressing data in these texts reflect the challenges of real world NLG tasks.","2020-12-01","2025-02-06 08:47:21","2025-02-06 08:47:21","","NA","","","NA","","","CACAPO","","","","","ACL","","","TRUE","","https://paperswithcode.com/paper/the-cacapo-dataset-a-multilingual-multi","https://github.com/TallChris91/CACAPO-Dataset","","","","","","","SAT_oldTag:CHECKED0923; SAT_granularity:sentence; SAT_lang:multi; SAT_task:TextGeneration; SAT_domain:multi; SAT_method_selection:Human; SAT_domain:finance; SAT_lang:english; SAT_All_checked:True; SAT_lang:dutch; SAT_domain:sport; SAT_domain:weather; SAT_method_selection:MultiHuman; SAT_focus:indirectRephrasing; SAT_nbSent:10000; SAT_task:Data-to-text","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","INLG (ACL) 2020 12","","","","","","","","","","","","","","",""
"MKTW3P8V","journalArticle","2016","Li, Jiao; Sun, Yueping; Johnson, Robin J.; Sciaky, Daniela; Wei, Chih-Hsuan; Leaman, Robert; Davis, Allan Peter; Mattingly, Carolyn J.; Wiegers, Thomas C.; Lu, Zhiyong","BioCreative V CDR task corpus: a resource for chemical disease relation extraction","Database: The Journal of Biological Databases and Curation","","1758-0463","10.1093/database/baw068","https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4860626/","Community-run, formal evaluations and manually annotated text corpora are critically important for advancing biomedical text-mining research. Recently in BioCreative V, a new challenge was organized for the tasks of disease named entity recognition (DNER) and chemical-induced disease (CID) relation extraction. Given the nature of both tasks, a test collection is required to contain both disease/chemical annotations and relation annotations in the same set of articles. Despite previous efforts in biomedical corpus construction, none was found to be sufficient for the task. Thus, we developed our own corpus called BC5CDR during the challenge by inviting a team of Medical Subject Headings (MeSH) indexers for disease/chemical entity annotation and Comparative Toxicogenomics Database (CTD) curators for CID relation annotation. To ensure high annotation quality and productivity, detailed annotation guidelines and automatic annotation tools were provided. The resulting BC5CDR corpus consists of 1500 PubMed articles with 4409 annotated chemicals, 5818 diseases and 3116 chemical-disease interactions. Each entity annotation includes both the mention text spans and normalized concept identifiers, using MeSH as the controlled vocabulary. To ensure accuracy, the entities were first captured independently by two annotators followed by a consensus annotation: The average inter-annotator agreement (IAA) scores were 87.49% and 96.05% for the disease and chemicals, respectively, in the test set according to the Jaccard similarity coefficient. Our corpus was successfully used for the BioCreative V challenge tasks and should serve as a valuable resource for the text-mining research community., Database URL: http://www.biocreative.org/tasks/biocreative-v/track-3-cdr/","2016-05-08","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-24 16:23:46","baw068","","","2016","","Database (Oxford)","BioCreative V CDR task corpus","","","CDR","","","","","","","","","PubMed Central","","PMID: 27161011 PMCID: PMC4860626","","/root/snap/zotero-snap/common/Zotero/storage/7P2WU3SV/Li et al. - 2016 - BioCreative V CDR task corpus a resource for chemical disease relation extraction.pdf; ","https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4860626/","EXAMPLE; FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BZSHA9DN","conferencePaper","1990","Hemphill, Charles T.; Godfrey, John J.; Doddington, George R.","The ATIS Spoken Language Systems Pilot Corpus","Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, Pennsylvania, June 24-27,1990","","","","https://aclanthology.org/H90-1021/","","1990","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 11:10:15","","","","","","","ATIS","","","","","","","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/S2EIWLND/Hemphill et al. - 1990 - The ATIS Spoken Language Systems Pilot Corpus.pdf","","FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","HLT 1990","","","","","","","","","","","","","","",""
"HXHXY8LI","preprint","2019","Sap, Maarten; LeBras, Ronan; Allaway, Emily; Bhagavatula, Chandra; Lourie, Nicholas; Rashkin, Hannah; Roof, Brendan; Smith, Noah A.; Choi, Yejin","ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning","","","","10.48550/arXiv.1811.00146","http://arxiv.org/abs/1811.00146","We present ATOMIC, an atlas of everyday commonsense reasoning, organized through 877k textual descriptions of inferential knowledge. Compared to existing resources that center around taxonomic knowledge, ATOMIC focuses on inferential knowledge organized as typed if-then relations with variables (e.g., ""if X pays Y a compliment, then Y will likely return the compliment""). We propose nine if-then relation types to distinguish causes vs. effects, agents vs. themes, voluntary vs. involuntary events, and actions vs. mental states. By generatively training on the rich inferential knowledge described in ATOMIC, we show that neural models can acquire simple commonsense capabilities and reason about previously unseen events. Experimental results demonstrate that multitask models that incorporate the hierarchical structure of if-then relation types lead to more accurate inference compared to models trained in isolation, as measured by both automatic and human evaluation.","2019-02-07","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 13:14:50","","","","","","","ATOMIC","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1811.00146 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/XKQLNU9I/Sap et al. - 2019 - ATOMIC An Atlas of Machine Commonsense for If-Then Reasoning.pdf; /root/snap/zotero-snap/common/Zotero/storage/T5WCAQAN/1811.html","","FILTER_STEP","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:1811.00146","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B4Q7KZVV","dataset","2002","Graff, David","The AQUAINT Corpus of English News Text","","","","10.35111/PCBV-JQ63","https://catalog.ldc.upenn.edu/LDC2002T31","<h3>Introduction</h3> The AQUAINT Corpus, Linguistic Data Consortium (LDC) catalog number LDC2002T31 and ISBN 1-58563-240-6 consists of newswire text data in English, drawn from three sources: the Xinhua News Service (People's Republic of China), the New York Times News Service, and the Associated Press Worldstream News Service. It was prepared by the LDC for the AQUAINT Project, and will be used in official benchmark evaluations conducted by National Institute of Standards and Technology (NIST). <h3>Data</h3> <p>The data files contain roughly 375 million words correlating to about 3GB of data. The text data are separated into directories by source (apw, nyt, xie); within each source, data files are subdivided by year, and within each year, there is one file per date of collection. Each file is named to reflect the source and date, and contains a stream of SGML-tagged text data presenting the series of news stories reported on the given date as a concatenation of DOC elements (i.e. blocks of text bounded by and tags). </p><p>All data files are published in compressed form, using the GNU ""gzip"" utility; as such, all files have a "".gz"" extension, and will have null file name extension when uncompressed in the usual way (i.e. just the base file name, consisting of ""YYYYMMDD_SRC""). </p><p>While all the data files are covered by a single DTD, it is not the case that they all have a single pattern of markup. Rather, all files share a core markup structure, with minor variations in the peripheral regions of each DOC element, and the DTD has been written to accommodate the variations. </p><h3>Updates</h3> <p>19980614_NYT.gz was left off in the conversion from CD to DVD. An update was issued on 09/13/2012. All copies ordered after this date will be complete. Contact <a rel=""nofollow"">ldc@ldc.upenn.edu</a> for more information.</p>  </br>  Portions © 1998-2000 New York Times, © 1998-2000 The Associated Press, © 1996-2000 Xinhua News Agency, © 2002 Trustees of the University of Pennsylvania","2002-09-26","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-28 18:29:47","","","","","","","AQUAINT","","","","","Linguistic Data Consortium","","","","","","","DOI.org (Datacite)","","Artwork Size: 2202009 KB Pages: 2202009 KB","","","","EXAMPLE; FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CVKVRQQR","journalArticle","2005","Bunescu, Razvan; Ge, Ruifang; Kate, Rohit J.; Marcotte, Edward M.; Mooney, Raymond J.; Ramani, Arun K.; Wong, Yuk Wah","Comparative experiments on learning information extractors for proteins and their interactions","Artificial Intelligence in Medicine","","09333657","10.1016/j.artmed.2004.07.016","https://linkinghub.elsevier.com/retrieve/pii/S0933365704001319","Objective: Automatically extracting information from biomedical text holds the promise of easily consolidating large amounts of biological knowledge in computer-accessible form. This strategy is particularly attractive for extracting data relevant to genes of the human genome from the 11 million abstracts in Medline. However, extraction efforts have been frustrated by the lack of conventions for describing human genes and proteins. We have developed and evaluated a variety of learned information extraction systems for identifying human protein names in Medline abstracts and subsequently extracting information on interactions between the proteins.","2005-02","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:53:05","139-155","","2","33","","Artificial Intelligence in Medicine","AIMED","","","","","","","en","https://www.elsevier.com/tdm/userlicense/1.0/","","","","DOI.org (Crossref)","","","","/root/snap/zotero-snap/common/Zotero/storage/ZBCLVXLW/Bunescu et al. - 2005 - Comparative experiments on learning information extractors for proteins and their interactions.pdf","","FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZJEHJ2FX","journalArticle","2012","Gurulingappa, Harsha; Rajput, Abdul Mateen; Roberts, Angus; Fluck, Juliane; Hofmann-Apitius, Martin; Toldo, Luca","Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports","Journal of Biomedical Informatics","","1532-0480","10.1016/j.jbi.2012.04.008","","A significant amount of information about drug-related safety issues such as adverse effects are published in medical case reports that can only be explored by human readers due to their unstructured nature. The work presented here aims at generating a systematically annotated corpus that can support the development and validation of methods for the automatic extraction of drug-related adverse effects from medical case reports. The documents are systematically double annotated in various rounds to ensure consistent annotations. The annotated documents are finally harmonized to generate representative consensus annotations. In order to demonstrate an example use case scenario, the corpus was employed to train and validate models for the classification of informative against the non-informative sentences. A Maximum Entropy classifier trained with simple features and evaluated by 10-fold cross-validation resulted in the F₁ score of 0.70 indicating a potential useful application of the corpus.","2012-10","2025-02-06 08:47:21","2025-02-06 08:47:21","","885-892","","5","45","","J Biomed Inform","ADE","","","","","","","eng","","","","","PubMed","","PMID: 22554702","","","http://www.ncbi.nlm.nih.gov/pubmed/22554702","EXAMPLE; FILTER_STEP","Semantics; Artificial Intelligence; Data Mining; Humans; PubMed; Databases, Factual; Documentation; Drug-Related Side Effects and Adverse Reactions; Reproducibility of Results","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R4KWRAMK","journalArticle","2020","Peng, Haiyun; Xu, Lu; Bing, Lidong; Huang, Fei; Lu, Wei; Si, Luo","Knowing What, How and Why: A Near Complete Solution for Aspect-Based Sentiment Analysis","Proceedings of the AAAI Conference on Artificial Intelligence","","2374-3468","10.1609/aaai.v34i05.6383","https://ojs.aaai.org/index.php/AAAI/article/view/6383","Target-based sentiment analysis or aspect-based sentiment analysis (ABSA) refers to addressing various sentiment analysis tasks at a fine-grained level, which includes but is not limited to aspect extraction, aspect sentiment classification, and opinion extraction. There exist many solvers of the above individual subtasks or a combination of two subtasks, and they can work together to tell a complete story, i.e. the discussed aspect, the sentiment on it, and the cause of the sentiment. However, no previous ABSA research tried to provide a complete solution in one shot. In this paper, we introduce a new subtask under ABSA, named aspect sentiment triplet extraction (ASTE). Particularly, a solver of this task needs to extract triplets (What, How, Why) from the inputs, which show WHAT the targeted aspects are, HOW their sentiment polarities are and WHY they have such polarities (i.e. opinion reasons). For instance, one triplet from “Waiters are very friendly and the pasta is simply average” could be (‘Waiters’, positive, ‘friendly’). We propose a two-stage framework to address this task. The first stage predicts what, how and why in a unified model, and then the second stage pairs up the predicted what (how) and why from the first stage to output triplets. In the experiments, our framework has set a benchmark performance in this novel triplet extraction task. Meanwhile, it outperforms a few strong baselines adapted from state-of-the-art related methods.","2020-04-03","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:03:14","8600-8607","","05","34","","","ASTE","","","","","","","en","Copyright (c) 2020 Association for the Advancement of Artificial Intelligence","","","","ojs.aaai.org","","Number: 05","","/root/snap/zotero-snap/common/Zotero/storage/AFLXLYD3/Peng et al. - 2020 - Knowing What, How and Why A Near Complete Solution for Aspect-Based Sentiment Analysis.pdf","","EXAMPLE; FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4SF67DAJ","dataset","2006","Walker, Christopher; Strassel, Stephanie; Medero, Julie; Maeda, Kazuaki","ACE 2005 Multilingual Training Corpus","","","","10.35111/MWXC-VH88","https://catalog.ldc.upenn.edu/LDC2006T06","<h3>Introduction</h3><br>  <p>ACE 2005 Multilingual Training Corpus was developed by the Linguistic Data Consortium (LDC) and contains approximately 1,800 files of mixed genre text in English, Arabic, and Chinese annotated for entities, relations, and events. This represents the complete set of training data in those languages for the 2005 Automatic Content Extraction (ACE) technology evaluation. The genres include newswire, broadcast news, broadcast conversation, weblog, discussion forums, and coversational telephone speech. The data was annotated by LDC with support from the ACE Program and additional assistance from LDC.</p><br>  <p>The objective of the ACE program was to develop automatic content extraction technology to support automatic processing of human language in text form.</p><br>  <p>In November 2005, sites were evaluated on system performance in five primary areas: the recognition of entities, values, temporal expressions, relations, and events. Entity, relation, and event mention detection were also offered as diagnostic tasks. All tasks with the exception of event tasks were performed for three languages, English, Chinese, and Arabic. Events tasks were evaluated in English and Chinese only. This release comprises the official training data for these evaluation tasks.</p><br>  <p>For more information about linguistic resources for the ACE Program, including annotation guidelines, task definitions and other documentation, see LDC's <a href=""https://www.ldc.upenn.edu/collaborations/past-projects/ace"" rel=""nofollow"">ACE website</a>.</p><br>  <h3>Data</h3><br>  <p>Below is information about the amount of data in this release and its annotation status. Further information such as breakdown of genres and formats can be found in the associated README file.</p><br>  <ul><br>  <ul><br>  <li>1P: data subject to first pass (complete) annotation</li><br>  <li>DUAL: data also subject to dual first pass (complete) annotation</li><br>  <li>ADJ: data also subject to discrepancy resolution/adjudication</li><br>  <li>NORM: data also subject to TIMEX2 normalization</li><br>  </ul><br>  </ul><br>  <p>&nbsp;</p><br>  <table border=""1"" width=""50%""><br>  <tbody><br>  <tr><br>  <td colspan=""8""><strong>English</strong></td><br>  </tr><br>  <tr><br>  <td colspan=""4"">words</td><br>  <td colspan=""4"">files</td><br>  </tr><br>  <tr><br>  <td>1P</td><br>  <td>DUAL</td><br>  <td>ADJ</td><br>  <td>NORM</td><br>  <td>1P</td><br>  <td>DUAL</td><br>  <td>ADJ</td><br>  <td>NORM</td><br>  </tr><br>  <tr><br>  <td>303833</td><br>  <td>297185</td><br>  <td>216545</td><br>  <td>259889</td><br>  <td>666</td><br>  <td>650</td><br>  <td>535</td><br>  <td>599</td><br>  </tr><br>  </tbody><br>  </table><br>  <p>&nbsp;</p><br>  <table border=""1"" width=""35%""><br>  <tbody><br>  <tr><br>  <td colspan=""6""><strong>Chinese</strong> Note: Chinese data expressed in terms of characters. We assume a correspondence of roughly 1.5 characters/word.</td><br>  </tr><br>  <tr><br>  <td colspan=""3"">chars</td><br>  <td colspan=""3"">files</td><br>  </tr><br>  <tr><br>  <td>1P</td><br>  <td>DUAL</td><br>  <td>ADJ</td><br>  <td>1P</td><br>  <td>DUAL</td><br>  <td>ADJ</td><br>  </tr><br>  <tr><br>  <td>334121</td><br>  <td>325834</td><br>  <td>307991</td><br>  <td>687</td><br>  <td>671</td><br>  <td>633</td><br>  </tr><br>  </tbody><br>  </table><br>  <p>&nbsp;</p><br>  <table border=""1"" width=""35%""><br>  <tbody><br>  <tr><br>  <td colspan=""6""><strong>Arabic</strong></td><br>  </tr><br>  <tr><br>  <td colspan=""3"">words</td><br>  <td colspan=""3"">files</td><br>  </tr><br>  <tr><br>  <td>1P</td><br>  <td>DUAL</td><br>  <td>ADJ</td><br>  <td>1P</td><br>  <td>DUAL</td><br>  <td>ADJ</td><br>  </tr><br>  <tr><br>  <td>112233</td><br>  <td>103504</td><br>  <td>100114</td><br>  <td>433</td><br>  <td>409</td><br>  <td>403</td><br>  </tr><br>  </tbody><br>  </table><br>  <p>&nbsp;</p><br>  <h3>Samples</h3><br>  <p>For examples of the data in this publication, please review the following samples:</p><br>  <ul><br>  <li><a href=""desc/addenda/LDC2006T06.ara.xml"">Arabic (XML)</a></li><br>  <li><a href=""desc/addenda/LDC2006T06.eng.xml"">English (XML)</a></li><br>  <li><a href=""desc/addenda/LDC2006T06.cmn.xml"">Chinese (XML)</a></li><br>  </ul><br>  <h3>Updates</h3><br>  <p>None at this time.</p></br>  Portions © 2000-2003 Agence France Presse, © 2003 The Associated Press, © 2003 New York Times, © 2000-2001, 2003 Xinhua News Agency, © 2003 Cable News Network LP, LLLP, © 2000-2001 SPH AsiaOne Ltd, © 2000-2001 China Broadcasting System, © 2000-2001 China National Radio, © 2000-2001 China Television System, © 2000-2001 China Central TV, © 2000-2001 Al Hayat, © 2000-2001 An-Nahar, © 2000-2001 Nile TV, © 2005, 2006 Trustees of the University of Pennsylvania","2006-02-15","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-24 16:47:13","","","","","","","ACE2005","","","","","Linguistic Data Consortium","","","","","","","DOI.org (Datacite)","","Artwork Size: 1572864 KB Pages: 1572864 KB","","","","EXAMPLE; FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R4N3YK5L","conferencePaper","2004","Doddington, George; Mitchell, Alexis; Przybocki, Mark; Ramshaw, Lance; Strassel, Stephanie; Weischedel, Ralph","The Automatic Content Extraction (ACE) Program Tasks, Data, and Evaluation","Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC’04)","","","10.35111/mwxc-vh88","http://www.lrec-conf.org/proceedings/lrec2004/pdf/5.pdf","The objective of the ACE program is to develop technology to automatically infer from human language data the entities being mentioned, the relations among these entities that are directly expressed, and the events in which these entities participate. Data sources include audio and image data in addition to pure text, and Arabic and Chinese in addition to English. The effort involves defining the research tasks in detail, collecting and annotating data needed for training, development, and evaluation, and supporting the research with evaluation tools and research workshops. This program began with a pilot study in 1999. The next evaluation is scheduled for September 2004.","2004","2025-02-06 08:47:21","2025-02-06 08:47:21","","","","","Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC’04)","","","ACE2004","","","","","ELRA","","en","False","","","","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/YYIQPWZM/Doddington et al. - The Automatic Content Extraction (ACE) Program Tas.pdf","","EXAMPLE; FILTER_STEP; DOMAIN:?; TASK:Relextract; GRANULARITY:Document; TASK:Ner; LANG:Multi; LANG:Arabic; LANG:Chinese; LANG:English; DATATYPEPROP:?; SYNTHGENERATION_BIN:?; NBDOC:?; NBENTITY:?; SOURCE:?; NBSENT:10⁴; SELECTIONMETHOD:Manual; NBTRIPLES:10⁴; NBTYPEENTITY:10⁰; NBTYPEREL:10⁰","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LREC","","","","","","","","","","","","","","",""
"PRNDZVTH","conferencePaper","2023",", Leonhard Hennig; , Philippe Thomas 0002; , Sebastian Möller 0001","MultiTACRED: A Multilingual Version of the TAC Relation Extraction Dataset.","","","","10.18653/V1/2023.ACL-LONG.210","https://dblp.org/rec/conf/acl/Hennig0023","nan","2023","2025-02-05 17:33:42","2025-02-05 17:33:42","","3785-3801","","","nan","","","","","","","","nan","","","open","","https://paperswithcode.com/paper/multitacred-a-multilingual-version-of-the-tac","731860","","","","","","","DOMAIN:?; GRANULARITY:?; LANG:?; DATATYPEPROP:?; NBTYPEREL:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:?; MANUALANNOTATION:?; TASK:Relationextraction; TASK:Machinetranslation; TASK:Relation; TASK:Transferlearning; TASK:Translation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL","","","","","","","","","","","","","","",""
"T6P37DVZ","conferencePaper","2024",", Youmi Ma; , An Wang; , Naoaki Okazaki","Building a Japanese Document-Level Relation Extraction Dataset Assisted by Cross-Lingual Transfer.","","","","10.48550/ARXIV.2404.16506","https://dblp.org/rec/conf/coling/MaWO24","nan","2024","2025-02-05 17:33:42","2025-02-05 17:33:42","","2567-2579","","","nan","","","","","","","","nan","","","open","","https://paperswithcode.com/paper/building-a-japanese-document-level-relation","263689","","","","","","","DOMAIN:?; GRANULARITY:?; LANG:?; DATATYPEPROP:?; NBTYPEREL:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:?; MANUALANNOTATION:?; TASK:Relationextraction; TASK:Relation; TASK:Attribute; TASK:Cross-Lingualtransfer; TASK:Document-Levelrelationextraction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LREC/COLING","","","","","","","","","","","","","","",""
"SVX6HQPH","conferencePaper","2024",", Fahmida Alam; , Md. Asiful Islam; , Robert Vacareanu; , Mihai Surdeanu","Towards Realistic Few-Shot Relation Extraction: A New Meta Dataset and Evaluation.","","","","10.48550/ARXIV.2404.04445","https://dblp.org/rec/conf/coling/AlamIVS24","nan","2024","2025-02-05 17:33:42","2025-02-05 17:33:42","","16592-16606","","","nan","","","","","","","","nan","","","open","","https://paperswithcode.com/paper/towards-realistic-few-shot-relation-1","https://github.com/clulab/releases/tree/master/lrec2024-realistic-fewshot-meta-dataset15","","","","","/root/snap/zotero-snap/common/Zotero/storage/29IEKM6S/et al. - 2024 - Towards Realistic Few-Shot Relation Extraction A New Meta Dataset and Evaluation..pdf","","DOMAIN:?; GRANULARITY:?; LANG:?; DATATYPEPROP:?; NBTYPEREL:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:?; MANUALANNOTATION:?; TASK:Relationextraction; TASK:Relation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LREC/COLING","","","","","","","","","","","","","","",""
"RFPG8TA9","conferencePaper","2023",", Peipei Liu,Hong Li,Zhiyu Wang,Yimo Ren,Jie Liu,Fei Lv,Hongsong Zhu,Limin Sun","CEntRE: A paragraph-level Chinese dataset for Relation Extraction among Enterprises","International Joint Conference on Neural Networks (IJCNN)","","","https://doi.org/10.1109/ijcnn54540.2023.10191251","https://doi.org/10.1109/ijcnn54540.2023.10191251","nan","2023-06-18","2025-02-05 17:33:42","2025-02-05 17:33:42","","1-8","","","","","","","","","","","IEEE","","","TRUE","","https://paperswithcode.com/paper/centre-a-paragraph-level-chinese-dataset-for","https://openalex.org/W4385482650","","","{'citing': [], 'cited': ['10.18653/v1/p18-1047', '10.18653/v1/d18-1514', '10.18653/v1/p16-1087', '10.18653/v1/p16-1105', '10.18653/v1/2020.coling-main.138', '10.18653/v1/d19-1649', '10.18653/v1/p19-1279', '10.18653/v1/2021.acl-long.487', '10.3115/1690219.1690287', '10.18653/v1/2021.naacl-main.5', '10.18653/v1/p17-1113', '10.1609/aaai.v34i05.6374', '10.18653/v1/2020.acl-main.128', '10.18653/v1/2020.acl-main.136', '10.1145/3297280.3297378', '10.18653/v1/n16-1065', '10.18653/v1/d15-1206', '10.1609/aaai.v34i05.6495', '10.18653/v1/2021.emnlp-main.433', '10.18653/v1/2021.acl-long.248', '10.1609/aaai.v33i01.33016300', '10.18653/v1/2020.emnlp-main.516']}","","/root/snap/zotero-snap/common/Zotero/storage/3M5YTRZD/2023 - CEntRE A paragraph-level Chinese dataset for Relation Extraction among Enterprises.pdf","","DOMAIN:?; GRANULARITY:?; LANG:?; DATATYPEPROP:?; NBTYPEREL:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:?; MANUALANNOTATION:?; TASK:Relationextraction; TASK:Relation; TASK:Attribute","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IJCNN","","","","","","","","","","","","","","",""
"IHU5LESX","conferencePaper","2023",", Hongbo Wang,Weimin Xiong,Yifan Song,Dawei Zhu,Yu Xia,Sujian Li","DocRED-FE: A Document-Level Fine-Grained Entity and Relation Extraction Dataset","International Conference on Acoustics, Speech, and Signal Processing (ICASSP)","","","https://doi.org/10.1109/icassp49357.2023.10095786","https://doi.org/10.1109/icassp49357.2023.10095786","nan","2023-05-05","2025-02-05 17:33:42","2025-02-05 17:33:42","","1-5","","","","","","","","","","","IEEE","","","TRUE","","https://paperswithcode.com/paper/docred-fe-a-document-level-fine-grained","https://openalex.org/W4372342761","","","{'citing': [], 'cited': ['10.1177/001316446002000104', '10.18653/v1/d18-1514', '10.18653/v1/d18-1360', '10.18653/v1/2020.emnlp-main.301', '10.1016/j.eswa.2018.07.032', '10.1609/aaai.v35i16.17665', '10.18653/v1/2021.eacl-main.319', '10.18653/v1/2021.findings-emnlp.204', '10.18653/v1/p19-1074', '10.18653/v1/d17-1004', '10.18653/v1/2021.naacl-main.5', '10.1016/j.ipm.2021.102563', '10.18653/v1/2020.acl-main.703', '10.1609/aaai.v26i1.8122', '10.18653/v1/2021.acl-long.248', '10.18653/v1/2020.emnlp-main.127', '10.18653/v1/2020.emnlp-main.132']}","","/root/snap/zotero-snap/common/Zotero/storage/IRNFTHMB/2023 - DocRED-FE A Document-Level Fine-Grained Entity and Relation Extraction Dataset.pdf","","DOMAIN:?; GRANULARITY:?; LANG:?; DATATYPEPROP:?; NBTYPEREL:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:?; MANUALANNOTATION:?; TASK:Relationclassification; TASK:Relationextraction; TASK:Relation; TASK:Jointentityandrelationextraction; TASK:Sentence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICASSP","","","","","","","","","","","","","","",""
"QVQNATVF","conferencePaper","2023",", Simerjot Kaur,Charese Smiley,A.K. Gupta,Joy Prakash Sain,Dongsheng Wang,Suchetha Siddagangappa,Toyin Aguda,Sameena Shah","REFinD: Relation Extraction Financial Dataset","SIGIR","","","https://doi.org/10.1145/3539618.3591911","https://doi.org/10.1145/3539618.3591911","nan","2023-07-18","2025-02-05 17:33:42","2025-02-05 17:33:42","","3054-3063","","","","","","","","","","","ACM","","","TRUE","","https://paperswithcode.com/paper/refind-relation-extraction-financial-dataset","https://github.com/kwanhui/finrelextract","","","{'citing': [], 'cited': ['10.7717/peerj-cs.1400', '10.18653/v1/p18-1144', '10.1007/978-3-642-53917-6_21', '10.1016/j.ins.2019.09.006', '10.1109/tcsvt.2021.3121062', '10.18653/v1/p16-1200', '10.18653/v1/p16-2025', '10.18653/v1/p16-2034', '10.1162/neco.1997.9.8.1735', '10.1109/tcsvt.2023.3254530', '10.1145/3554727', '10.1109/tkde.2020.2970044', '10.18653/v1/p19-1430', '10.1109/tip.2022.3147032', '10.1109/icassp.2013.6638947', '10.18653/v1/d17-1145', '10.1016/j.inffus.2023.101862', '10.1109/iccv.2019.00473', '10.3115/v1/p14-1054', '10.3390/electronics12102320', '10.18653/v1/p17-1078', '10.18653/v1/p17-2040', '10.18653/v1/d15-1203', '10.18653/v1/d15-1166', '10.18653/v1/d15-1141', '10.3115/v1/p15-1150', '10.1109/iccv.2017.236']}","","/root/snap/zotero-snap/common/Zotero/storage/95MN7M88/2023 - REFinD Relation Extraction Financial Dataset.pdf","","DOMAIN:?; GRANULARITY:?; LANG:?; DATATYPEPROP:?; NBTYPEREL:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:?; MANUALANNOTATION:?; TASK:Relationextraction; TASK:Relation; TASK:Generalknowledge; TASK:Informationretrieval; TASK:Naturallanguageinference; TASK:Questionanswering; TASK:Retrieval","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SIGIR '23: Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","","","","","","","","","","","",""
"X5W3YYE8","preprint","2016","Lebret, Remi; Grangier, David; Auli, Michael","Neural Text Generation from Structured Data with Application to the Biography Domain","","","","10.48550/arXiv.1603.07771","http://arxiv.org/abs/1603.07771","This paper introduces a neural model for concept-to-text generation that scales to large, rich domains. It generates biographical sentences from fact tables on a new dataset of biographies from Wikipedia. This set is an order of magnitude larger than existing resources with over 700k samples and a 400k vocabulary. Our model builds on conditional neural language models for text generation. To deal with the large vocabulary, we extend these models to mix a ﬁxed vocabulary with copy actions that transfer sample-speciﬁc words from the input database to the generated output sentence. To deal with structured data, we allow the model to embed words differently depending on the data ﬁelds in which they occur. Our neural model significantly outperforms a Templated Kneser-Ney language model by nearly 15 BLEU.","2016-09-23","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-22 17:58:07","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1603.07771 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/SCEXL4GT/Lebret et al. - 2016 - Neural Text Generation from Structured Data with Application to the Biography Domain.pdf","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:1603.07771","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PNCIV4S5","webpage","","","LREC 2014 Proceedings","","","","","http://www.lrec-conf.org/proceedings/lrec2014/summaries/1023.html","","","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 10:22:13","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GQJSED3H","webpage","","","https://arxiv.org/pdf/2111.06467","","","","","https://arxiv.org/pdf/2111.06467","","","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-22 17:57:41","","","","","","","","","","","","","","","","","","","","","","","/root/snap/zotero-snap/common/Zotero/storage/8I33V4BM/2111.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKFYPA2P","conferencePaper","2022",", Tushar Abhishek; , Shivprasad Sagare; , Bhavyajeet Singh; , Anubhav Sharma; , Manish Gupta; , Vasudeva Varma","XAlign: Cross-lingual Fact-to-Text Alignment and Generation for Low-Resource Languages","Proceedings of the Web Conference 2022","","","10.1145/3487553.3524265","https://arxiv.org/abs/2202.00291v2","Multiple critical scenarios (like Wikipedia text generation given English Infoboxes) need automated generation of descriptive text in low resource (LR) languages from English fact triples. Previous work has focused on English fact-to-text (F2T) generation. To the best of our knowledge, there has been no previous attempt on cross-lingual alignment or generation for LR languages. Building an effective cross-lingual F2T (XF2T) system requires alignment between English structured facts and LR sentences. We propose two unsupervised methods for cross-lingual alignment. We contribute XALIGN, an XF2T dataset with 0.45M pairs across 8 languages, of which 5402 pairs have been manually annotated. We also train strong baseline XF2T generation models on the XAlign dataset.","2022-02-01","2025-02-06 08:47:23","2025-02-06 08:47:23","","","","","","","","XAlign","","","","","ACM","","","True","","https://paperswithcode.com/paper/xalign-cross-lingual-fact-to-text-alignment","https://github.com/tushar117/XAlign","","","{'citing': [], 'cited': ['10.18653/v1/2020.acl-main.224', '10.18653/v1/2020.acl-main.747', '10.18653/v1/2020.emnlp-main.630', '10.18653/v1/2021.naacl-main.278', '10.18653/v1/2021.naacl-main.41', '10.18653/v1/d16-1128', '10.18653/v1/n18-1139', '10.18653/v1/w17-3518']}","","/root/snap/zotero-snap/common/Zotero/storage/5KQLPWIG/ et al. - 2022 - XAlign Cross-lingual Fact-to-Text Alignment and G.pdf","","DOMAIN:?; GRANULARITY:?; TASK:?; LANG:Multi; DATATYPEPROP:?; NBTYPEREL:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:1; NBDOC:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; NBENTITY:10⁴; SOURCE:Wikidata","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WWW '22","","","","","","","","","","","","","","",""
"DXR33A8X","conferencePaper","2019",", Mostafa Abdou; , Cezar Sas; , Rahul Aralikatte; , Isabelle Augenstein; , Anders Søgaard","X-WikiRE: A Large, Multilingual Resource for Relation Extraction as Machine Comprehension","Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019)","","","10.18653/v1/d19-6130","https://arxiv.org/abs/1908.05111v2","Although the vast majority of knowledge bases KBs are heavily biased towards English, Wikipedias do cover very different topics in different languages. Exploiting this, we introduce a new multilingual dataset (X-WikiRE), framing relation extraction as a multilingual machine reading problem. We show that by leveraging this resource it is possible to robustly transfer models cross-lingually and that multilingual support significantly improves (zero-shot) relation extraction, enabling the population of low-resourced KBs from their well-populated counterparts.","2019-08-14","2025-02-06 08:47:23","2025-02-06 08:47:23","","","","","","","","X-WikiRE","","","","","ACL","","","True","","https://paperswithcode.com/paper/x-wikire-a-large-multilingual-resource-for","https://github.com/mhany90/Multi-WikiRE","","","","","/root/snap/zotero-snap/common/Zotero/storage/LT9K3XU6/ et al. - 2019 - X-WikiRE A Large, Multilingual Resource for Relat.pdf","","DOMAIN:?; GRANULARITY:?; TASK:Relextract; TASK:Nlu; LANG:Multi; LANG:English; LANG:German; TASK:Slotfilling; DATATYPEPROP:?; NBTYPEREL:10²; SYNTHGENERATION_BIN:1; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:Wikidata; SOURCE:Wikipedia; SELECTIONMETHOD:Manual; LANG:French; LANG:Spanish","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","DeepLo","","","","","","","","","","","","","","",""
"U9SAKS3Q","conferencePaper","2020",", Jeniya Tabassum; , Sydney Lee; , Wei Xu; , Alan Ritter","WNUT-2020 Task 1 Overview: Extracting Entities and Relations from Wet Lab Protocols","Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020)","","","10.18653/v1/2020.wnut-1.33","https://arxiv.org/abs/2010.14576v3","This paper presents the results of the wet lab information extraction task at WNUT 2020. This task consisted of two sub tasks: (1) a Named Entity Recognition (NER) task with 13 participants and (2) a Relation Extraction (RE) task with 2 participants. We outline the task, data annotation process, corpus statistics, and provide a high-level overview of the participating systems for each sub task.","2020-10-27","2025-02-06 08:47:23","2025-02-06 08:47:23","","NA","","","NA","","","WNUT-2020","","","","","ACL","","","True","","https://paperswithcode.com/paper/wnut-2020-task-1-overview-extracting-entities","https://github.com/jeniyat/WNUT_2020_NER","","","{'citing': ['10.1101/2021.04.26.21256038', '10.3389/frma.2021.689803', '10.1109/gcce53005.2021.9621966', '10.1109/bigdata52589.2021.9671781', '10.1155/2022/1222692'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/KW7BC2T6/ et al. - 2020 - WNUT-2020 Task 1 Overview Extracting Entities and.pdf","","LANG:?; TASK:Relextract; GRANULARITY:Document; TASK:Ner; DATATYPEPROP:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBTYPEREL:10¹; SOURCE:?; NBTRIPLES:10⁵; NBSENT:10⁴; NBTYPEENTITY:10¹; NBENTITY:10⁶; DOMAIN:Bio; NBDOC:10²","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WNUT","","","","","","","","","","","","","","",""
"KSZFZWCK","preprint","2018","Dettmers, Tim; Minervini, Pasquale; Stenetorp, Pontus; Riedel, Sebastian","Convolutional 2D Knowledge Graph Embeddings","","","","10.48550/arXiv.1707.01476","http://arxiv.org/abs/1707.01476","Link prediction for knowledge graphs is the task of predicting missing relationships between entities. Previous work on link prediction has focused on shallow, fast models which can scale to large knowledge graphs. However, these models learn less expressive features than deep, multi-layer models -- which potentially limits performance. In this work, we introduce ConvE, a multi-layer convolutional network model for link prediction, and report state-of-the-art results for several established datasets. We also show that the model is highly parameter efficient, yielding the same performance as DistMult and R-GCN with 8x and 17x fewer parameters. Analysis of our model suggests that it is particularly effective at modelling nodes with high indegree -- which are common in highly-connected, complex knowledge graphs such as Freebase and YAGO3. In addition, it has been noted that the WN18 and FB15k datasets suffer from test set leakage, due to inverse relations from the training set being present in the test set -- however, the extent of this issue has so far not been quantified. We find this problem to be severe: a simple rule-based model can achieve state-of-the-art results on both WN18 and FB15k. To ensure that models are evaluated on datasets where simply exploiting inverse relations cannot yield competitive results, we investigate and validate several commonly used datasets -- deriving robust variants where necessary. We then perform experiments on these robust datasets for our own and several previously proposed models and find that ConvE achieves state-of-the-art Mean Reciprocal Rank across most datasets.","2018-07-04","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 11:14:07","","","","","","","WN18RR","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1707.01476 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/6AINZ75A/Dettmers et al. - 2018 - Convolutional 2D Knowledge Graph Embeddings.pdf; /root/snap/zotero-snap/common/Zotero/storage/QNNQ3855/1707.html","","FILTER_STEP","Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1707.01476","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UKVATMN5","conferencePaper","2020",", Mingda Chen; , Sam Wiseman; , Kevin Gimpel","WikiTableT: A Large-Scale Data-to-Text Dataset for Generating Wikipedia Article Sections","Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021","","","10.18653/v1/2021.findings-acl.17","https://arxiv.org/abs/2012.14919v2","Datasets for data-to-text generation typically focus either on multi-domain, single-sentence generation or on single-domain, long-form generation. In this work, we cast generating Wikipedia sections as a data-to-text generation task and create a large-scale dataset, WikiTableT, that pairs Wikipedia sections with their corresponding tabular data and various metadata. WikiTableT contains millions of instances, covering a broad range of topics, as well as a variety of flavors of generation tasks with different levels of flexibility. We benchmark several training and decoding strategies on WikiTableT. Our qualitative analysis shows that the best approaches can generate fluent and high quality texts but they struggle with coherence and factuality, showing the potential for our dataset to inspire future work on long-form generation.","2020-12-29","2025-02-06 08:47:23","2025-02-06 08:47:23","","","","","","","","WikiTableT","","","","","ACL","","","True","","https://paperswithcode.com/paper/generating-wikipedia-article-sections-from","https://github.com/mingdachen/WikiTableT","","","","","/root/snap/zotero-snap/common/Zotero/storage/HDBVEE2Y/ et al. - 2020 - WikiTableT A Large-Scale Data-to-Text Dataset for.pdf","","LANG:?; GRANULARITY:Document; GRANULARITY:Sentences; TASK:Ner; TASK:Entitylinking; DATATYPEPROP:?; NBTYPEREL:?; SYNTHGENERATION_BIN:?; SELECTIONMETHOD:Automatic; NBDOC:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; DOMAIN:Encyclo; SOURCE:Wikidata; SOURCE:Wikipedia; NBENTITY:10⁶","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL-IJCNLP","","","","","","","","","","","","","","",""
"WCYHZN9C","journalArticle","2018","Welbl, Johannes; Stenetorp, Pontus; Riedel, Sebastian","Constructing Datasets for Multi-hop Reading Comprehension Across Documents","Transactions of the Association for Computational Linguistics","","","10.1162/tacl_a_00021","https://aclanthology.org/Q18-1021/","Most Reading Comprehension methods limit themselves to queries which can be answered using a single sentence, paragraph, or document. Enabling models to combine disjoint pieces of textual evidence would extend the scope of machine comprehension methods, but currently no resources exist to train and test this capability. We propose a novel task to encourage the development of models for text understanding across multiple documents and to investigate the limits of existing methods. In our task, a model learns to seek and combine evidence — effectively performing multihop, alias multi-step, inference. We devise a methodology to produce datasets for this task, given a collection of query-answer pairs and thematically linked documents. Two datasets from different domains are induced, and we identify potential pitfalls and devise circumvention strategies. We evaluate two previously proposed competitive models and find that one can integrate information across documents. However, both models struggle to select relevant information; and providing documents guaranteed to be relevant greatly improves their performance. While the models outperform several strong baselines, their best accuracy reaches 54.5% on an annotated test set, compared to human performance at 85.0%, leaving ample room for improvement.","2018","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 10:09:03","287–302","","","6","","","WIKIHOP","","","","","","","","","","","","ACLWeb","","Place: Cambridge, MA Publisher: MIT Press","","/root/snap/zotero-snap/common/Zotero/storage/4ICNG45Z/Welbl et al. - 2018 - Constructing Datasets for Multi-hop Reading Comprehension Across Documents.pdf","","FILTER_STEP","","Lee, Lillian; Johnson, Mark; Toutanova, Kristina; Roark, Brian","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZXR5EQHX","conferencePaper","2021",", Luyu Wang; , Yujia Li; , Ozlem Aslan; , Oriol Vinyals","WikiGraphs: A Wikipedia Text - Knowledge Graph Paired Dataset","Proceedings of the Fifteenth Workshop on Graph-Based Methods for Natural Language Processing (TextGraphs-15)","","","10.18653/v1/11.textgraphs-1.7","https://arxiv.org/abs/2107.09556v1","We present a new dataset of Wikipedia articles each paired with a knowledge graph, to facilitate the research in conditional text generation, graph generation and graph representation learning. Existing graph-text paired datasets typically contain small graphs and short text (1 or few sentences), thus limiting the capabilities of the models that can be learned on the data. Our new dataset WikiGraphs is collected by pairing each Wikipedia article from the established WikiText-103 benchmark (Merity et al., 2016) with a subgraph from the Freebase knowledge graph (Bollacker et al., 2008). This makes it easy to benchmark against other state-of-the-art text generative models that are capable of generating long paragraphs of coherent text. Both the graphs and the text data are of significantly larger scale compared to prior graph-text paired datasets. We present baseline graph neural network and transformer model results on our dataset for 3 tasks: graph -> text generation, graph -> text retrieval and text -> graph retrieval. We show that better conditioning on the graph provides gains in generation and retrieval quality but there is still large room for improvement.","2021-07-20","2025-02-06 08:47:23","2025-02-06 08:47:23","","","","","","","","WikiGraphs","","","","","ACL","","","True","","https://paperswithcode.com/paper/wikigraphs-a-wikipedia-text-knowledge-graph","https://github.com/google-deepmind/deepmind-research/tree/master/wikigraphs","","","","","/root/snap/zotero-snap/common/Zotero/storage/QQHHFPT6/ et al. - 2021 - WikiGraphs A Wikipedia Text - Knowledge Graph Pai.pdf","","DOMAIN:?; GRANULARITY:?; LANG:?; TASK:?; DATATYPEPROP:?; NBTYPEREL:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:Wikipedia; NBDOC:10⁴; SOURCE:Freebase","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","TextGraph","","","","","","","","","","","","","","",""
"HN5XL8KR","conferencePaper","2022","Chen, Xiang; Zhang, Ningyu; Xie, Xin; Deng, Shumin; Yao, Yunzhi; Tan, Chuanqi; Huang, Fei; Si, Luo; Chen, Huajun","KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction","Proceedings of the ACM Web Conference 2022","","","10.1145/3485447.3511998","http://arxiv.org/abs/2104.07650","Recently, prompt-tuning has achieved promising results for specific few-shot classification tasks. The core idea of prompt-tuning is to insert text pieces (i.e., templates) into the input and transform a classification task into a masked language modeling problem. However, for relation extraction, determining an appropriate prompt template requires domain expertise, and it is cumbersome and timeconsuming to obtain a suitable label word. Furthermore, there exists abundant semantic and prior knowledge among the relation labels that cannot be ignored. To this end, we focus on incorporating knowledge among relation labels into prompt-tuning for relation extraction and propose a Knowledge-aware Prompt-tuning approach with synergistic optimization (KnowPrompt). Specifically, we inject latent knowledge contained in relation labels into prompt construction with learnable virtual type words and answer words. Then, we synergistically optimize their representation with structured constraints. Extensive experimental results on five datasets with standard and low-resource settings demonstrate the effectiveness of our approach. Our code and datasets are available in GitHub1 for reproducibility.","2022-04-25","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-24 17:06:32","2778-2788","","","","","","WIKI-ZSL","","","","","","","en","","","","","arXiv.org","","arXiv:2104.07650 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/Q5UC5SAK/Chen et al. - 2022 - KnowPrompt Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction.pdf","","EXAMPLE; FILTER_STEP","Computer Science - Computation and Language; Computer Science - Artificial Intelligence; Computer Science - Machine Learning; Computer Science - Information Retrieval","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PB5CQQGM","conferencePaper","2018","Kulkarni, Chaitanya; Xu, Wei; Ritter, Alan; Machiraju, Raghu","An Annotated Corpus for Machine Reading of Instructions in Wet Lab Protocols","Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)","","","10.18653/v1/N18-2016","https://aclanthology.org/N18-2016/","We describe an effort to annotate a corpus of natural language instructions consisting of 622 wet lab protocols to facilitate automatic or semi-automatic conversion of protocols into a machine-readable format and benefit biological research. Experimental results demonstrate the utility of our corpus for developing machine learning approaches to shallow semantic parsing of instructional texts. We make our annotated Wet Lab Protocol Corpus available to the research community.","2018-06","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 13:16:18","97–106","","","","","","WLPC","","","","","Association for Computational Linguistics","New Orleans, Louisiana","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/X2UKZTME/Kulkarni et al. - 2018 - An Annotated Corpus for Machine Reading of Instructions in Wet Lab Protocols.pdf","","FILTER_STEP","","Walker, Marilyn; Ji, Heng; Stent, Amanda","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL-HLT 2018","","","","","","","","","","","","","","",""
"QJTD2UTR","journalArticle","","Strobl, Michael; Trabelsi, Amine; Zaiane, Osmar","WEXEA: Wikipedia EXhaustive Entity Annotation","","","","","","Building predictive models for information extraction from text, such as named entity recognition or the extraction of semantic relationships between named entities in text, requires a large corpus of annotated text. Wikipedia is often used as a corpus for these tasks where the annotation is a named entity linked by a hyperlink to its article. However, editors on Wikipedia are only expected to link these mentions in order to help the reader to understand the content, but are discouraged from adding links that do not add any beneﬁt for understanding an article. Therefore, many mentions of popular entities (such as countries or popular events in history), or previously linked articles, as well as the article’s entity itself, are not linked. In this paper, we discuss WEXEA, a Wikipedia EXhaustive Entity Annotation system, to create a text corpus based on Wikipedia with exhaustive annotations of entity mentions, i.e. linking all mentions of entities to their corresponding articles. This results in a huge potential for additional annotations that can be used for downstream NLP tasks, such as Relation Extraction. We show that our annotations are useful for creating distantly supervised datasets for this task. Furthermore, we publish all code necessary to derive a corpus from a raw Wikipedia dump, so that it can be reproduced by everyone.","","2025-02-06 08:47:23","2025-02-06 08:47:23","","","","","","","","WEXEA","","","","","","","en","","","","","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/WMG243UB/Strobl et al. - WEXEA Wikipedia EXhaustive Entity Annotation.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8AEQ8EHL","conferencePaper","2019","Trisedya, Bayu Distiawan; Weikum, Gerhard; Qi, Jianzhong; Zhang, Rui","Neural Relation Extraction for Knowledge Base Enrichment","Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/P19-1023","https://aclanthology.org/P19-1023/","We study relation extraction for knowledge base (KB) enrichment. Specifically, we aim to extract entities and their relationships from sentences in the form of triples and map the elements of the extracted triples to an existing KB in an end-to-end manner. Previous studies focus on the extraction itself and rely on Named Entity Disambiguation (NED) to map triples into the KB space. This way, NED errors may cause extraction errors that affect the overall precision and recall. To address this problem, we propose an end-to-end relation extraction model for KB enrichment based on a neural encoder-decoder model. We collect high-quality training data by distant supervision with co-reference resolution and paraphrase detection. We propose an n-gram based attention model that captures multi-word entity names in a sentence. Our model employs jointly learned word and entity embeddings to support named entity disambiguation. Finally, our model uses a modified beam search and a triple classifier to help generate high-quality triples. Our model outperforms state-of-the-art baselines by 15.51% and 8.38% in terms of F1 score on two real-world datasets.","2019-07","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 10:38:03","229–240","","","","","","WIKI-NRE/GEO-NRE","","","","","Association for Computational Linguistics","Florence, Italy","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/9IWVV59R/Trisedya et al. - 2019 - Neural Relation Extraction for Knowledge Base Enrichment.pdf","","FILTER_STEP","","Korhonen, Anna; Traum, David; Màrquez, Lluís","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2019","","","","","","","","","","","","","","",""
"CPR5K44C","conferencePaper","2011","Hoffmann, Raphael; Zhang, Congle; Ling, Xiao; Zettlemoyer, Luke; Weld, Daniel S.","Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations","Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies","","","","https://aclanthology.org/P11-1055/","","2011-06","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-25 11:36:23","541–550","","","","","","WIKI-KBP","","","","","Association for Computational Linguistics","Portland, Oregon, USA","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/CBN3EGCD/Hoffmann et al. - 2011 - Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations.pdf","","EXAMPLE; FILTER_STEP","","Lin, Dekang; Matsumoto, Yuji; Mihalcea, Rada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL-HLT 2011","","","","","","","","","","","","","","",""
"9IUZ3LLI","conferencePaper","2021","Li, Sha; Ji, Heng; Han, Jiawei","Document-Level Event Argument Extraction by Conditional Generation","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2021.naacl-main.69","https://aclanthology.org/2021.naacl-main.69/","Event extraction has long been treated as a sentence-level task in the IE community. We argue that this setting does not match human informative seeking behavior and leads to incomplete and uninformative extraction results. We propose a document-level neural event argument extraction model by formulating the task as conditional generation following event templates. We also compile a new document-level event extraction benchmark dataset WikiEvents which includes complete event and coreference annotation. On the task of argument extraction, we achieve an absolute gain of 7.6% F1 and 5.7% F1 over the next best model on the RAMS and WikiEvents dataset respectively. On the more challenging task of informative argument extraction, which requires implicit coreference reasoning, we achieve a 9.3% F1 gain over the best baseline. To demonstrate the portability of our model, we also create the first end-to-end zero-shot event extraction framework and achieve 97% of fully supervised model`s trigger extraction performance and 82% of the argument extraction performance given only access to 10 out of the 33 types on ACE.","2021-06","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 10:50:34","894–908","","","","","","WIKI-EVENTS","","","","","Association for Computational Linguistics","Online","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/I9YSC7V5/Li et al. - 2021 - Document-Level Event Argument Extraction by Conditional Generation.pdf","","FILTER_STEP","","Toutanova, Kristina; Rumshisky, Anna; Zettlemoyer, Luke; Hakkani-Tur, Dilek; Beltagy, Iz; Bethard, Steven; Cotterell, Ryan; Chakraborty, Tanmoy; Zhou, Yichao","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL-HLT 2021","","","","","","","","","","","","","","",""
"M974FVFX","conferencePaper","2021","Ormándi, Róbert; Saleh, Mohammad; Winter, Erin; Rao, Vinay","WebRED: Effective Pretraining And Finetuning For Relation Extraction On The Web","Findings of the Association for Computational Linguistics: EACL 2023","","","10.18653/v1/2023.findings-eacl.195","https://www.semanticscholar.org/paper/WebRED%3A-Effective-Pretraining-And-Finetuning-For-On-Orm%C3%A1ndi-Saleh/085c4ca05bfb9e02ea9e534d931d5ce6f35811a6","Relation extraction is used to populate knowledge bases that are important to many applications. Prior datasets used to train relation extraction models either suffer from noisy labels due to distant supervision, are limited to certain domains or are too small to train highcapacity models. This constrains downstream applications of relation extraction. We therefore introduce: WebRED (Web Relation Extraction Dataset), a strongly-supervised human annotated dataset for extracting relationships from a variety of text found on the World Wide Web, consisting of ∼110K examples. We also describe the methods we used to collect ∼200M examples as pre-training data for this task. We show that combining pre-training on a large weakly supervised dataset with finetuning on a small strongly-supervised dataset leads to better relation extraction performance. We provide baselines for this new dataset and present a case for the importance of human annotation in improving the performance of relation extraction from text found on the web.","2021-02-18","2025-02-06 08:47:23","2025-02-06 08:47:23","2023-06-01 12:13:40","","","","","","","WebRED","","","","","ACL","","","True","","","https://github.com/ google-research-datasets/WebRED.","Semantic Scholar","","","","/root/snap/zotero-snap/common/Zotero/storage/TW2WESEC/Ormándi et al. - 2021 - WebRED Effective Pretraining And Finetuning For R.pdf; ","https://www.semanticscholar.org/paper/WebRED%3A-Effective-Pretraining-And-Finetuning-For-On-Orm%C3%A1ndi-Saleh/085c4ca05bfb9e02ea9e534d931d5ce6f35811a6","DOMAIN:?; LANG:?; TASK:Relextract; GRANULARITY:Document; TASK:Ner; TASK:Coref; DATATYPEPROP:?; SYNTHGENERATION_BIN:?; NBTYPEREL:10²; SELECTIONMETHOD:Automatic; NBTYPEREL:10¹; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:Wikidata; NBDOC:10⁵; SOURCE:Web; NBDOC:10⁸","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EACL 2023","","","","","","","","","","","","","","",""
"Z36NGECF","conferencePaper","2022","Amaral, Gabriel; Rodrigues, Odinaldo; Simperl, Elena","WDV: A Broad Data Verbalisation Dataset Built from Wikidata","The Semantic Web – ISWC 2022","978-3-031-19433-7","","10.1007/978-3-031-19433-7_32","","Data verbalisation is a task of great importance in the current field of natural language processing, as there is a clear benefit in the transformation of our abundant structured and semi-structured data into human-readable formats. Verbalising Knowledge Graph (KG) data focuses on converting interconnected triple-based claims, formed of subject, predicate, and object, into text. Although KG verbalisation datasets exist for some KGs, there are still limitations in their applicability to many scenarios. This is especially true for Wikidata, where available datasets either loosely couple claim sets with textual information or heavily focus on predicates around biographies, cities, and countries. To address these gaps, we propose WDV, a large KG claim verbalisation dataset built from Wikidata, with a tight coupling between triples and text, covering a wide variety of entities and predicates. We also evaluate the quality of our verbalisations through a reusable workflow for measuring human-centred fluency and adequacy scores. Our data (https://doi.org/10.6084/m9.figshare.17159045.v1) and code (https://github.com/gabrielmaia7/WDV) are openly available in the hopes of furthering research towards KG verbalisation.","2022","2025-02-06 08:47:23","2025-02-06 08:47:23","","556-574","","","","","","WDV","Lecture Notes in Computer Science","","","","Springer","Cham","en","True","","https://paperswithcode.com/paper/wdv-a-broad-data-verbalisation-dataset-built","https://github.com/gabrielmaia7/wdv","Springer Link","","{'citing': [], 'cited': ['10.1007/978-3-319-11964-9_4', '10.1007/978-3-319-18818-8_20', '10.1016/j.csl.2020.101151', '10.1016/j.websem.2018.07.002', '10.1080/13674676.2018.1486394', '10.1080/19312450709336664', '10.1145/1743384.1743478', '10.1145/2872427.2874809', '10.1145/3159652.3159661', '10.1145/3479531', '10.1145/3484828', '10.1162/coli_a_00322', '10.1177/2053168015604648', '10.18653/v1/2020.acl-main.224', '10.18653/v1/2020.coling-main.218', '10.18653/v1/2020.emnlp-main.628', '10.18653/v1/2021.findings-emnlp.90', '10.18653/v1/2021.nlp4convai-1.20', '10.18653/v1/d15-1312', '10.18653/v1/d17-1004', '10.18653/v1/d17-1238', '10.18653/v1/d18-1081', '10.18653/v1/p17-1017', '10.18653/v1/p18-1151', '10.18653/v1/w15-4007', '10.2307/2529310', '10.24963/ijcai.2020/419', '10.24963/ijcai.2020/711', '10.3115/1073083.1073135', '10.3115/1690219.1690287', '10.5281/zenodo.3828935']}","","","","SAT_oldTag:CHECKED0923; SAT_granularity:sentence; SAT_task:DataAugmentation; SAT_source:Wikidata; SAT_focus:verbalization; SAT_method_selection:Human; SAT_nbtypes_relations:439; SAT_nbDoc:7.6K; SAT_nbTriples:7.6K; SAT_nbtypes_entity:20; SAT_method_selection:Tight; SAT_method_selection:MultiHuman; SAT_task:Data-to-text","","Sattler, Ulrike; Hogan, Aidan; Keet, Maria; Presutti, Valentina; Almeida, João Paulo A.; Takeda, Hideaki; Monnin, Pierre; Pirrò, Giuseppe; d’Amato, Claudia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C83QBQJX","conferencePaper","2017","Joshi, Mandar; Choi, Eunsol; Weld, Daniel; Zettlemoyer, Luke","TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension","Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/P17-1147","https://aclanthology.org/P17-1147/","We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that TriviaQA is a challenging testbed that is worth significant future study.","2017-07","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-25 11:34:42","1601–1611","","","","","","TRIVIAQA","","","","","Association for Computational Linguistics","Vancouver, Canada","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/MMP9D9EB/Joshi et al. - 2017 - TriviaQA A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension.pdf","","EXAMPLE; FILTER_STEP","","Barzilay, Regina; Kan, Min-Yen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2017","","","","","","","","","","","","","","",""
"3NWI4L6Y","conferencePaper","2023","Whitehouse, Chenxi; Vania, Clara; Aji, Alham Fikri; Christodoulopoulos, Christos; Pierleoni, A.","WebIE: Faithful and Robust Information Extraction on the Web","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2023.acl-long.428","https://www.semanticscholar.org/paper/WebIE%3A-Faithful-and-Robust-Information-Extraction-Whitehouse-Vania/49848674fd5e498a340e5632c151789ef76ae523","Extracting structured and grounded fact triples from raw text is a fundamental task in Information Extraction (IE). Existing IE datasets are typically collected from Wikipedia articles, using hyperlinks to link entities to the Wikidata knowledge base. However, models trained only on Wikipedia have limitations when applied to web domains, which often contain noisy text or text that does not have any factual information. We present WebIE, the first large-scale, entity-linked closed IE dataset consisting of 1.6M sentences automatically collected from the English Common Crawl corpus. WebIE also includes negative examples, i.e. sentences without fact triples, to better reflect the data on the web. We annotate ~25K triples from WebIE through crowdsourcing and introduce mWebIE, a translation of the annotated set in four other languages: French, Spanish, Portuguese, and Hindi. We evaluate the in-domain, out-of-domain, and zero-shot cross-lingual performance of generative IE models and find models trained on WebIE show better generalisability. We also propose three training strategies that use entity linking as an auxiliary task. Our experiments show that adding Entity-Linking objectives improves the faithfulness of our generative IE models.","2023-05-23","2025-02-06 08:47:23","2025-02-06 08:47:23","2023-06-01 12:19:58","","","","","","","WebIE","","","","","ACL","","","True","","","https://github.com/amazon-science/WebIE","Semantic Scholar","","","","/root/snap/zotero-snap/common/Zotero/storage/CBA44K47/Whitehouse et al. - 2023 - WebIE Faithful and Robust Information Extraction .pdf; ","https://www.semanticscholar.org/paper/WebIE%3A-Faithful-and-Robust-Information-Extraction-Whitehouse-Vania/49848674fd5e498a340e5632c151789ef76ae523","DOMAIN:?; GRANULARITY:?; TASK:Ner; LANG:Multi; DATATYPEPROP:?; NBTYPEREL:?; SYNTHGENERATION_BIN:?; SELECTIONMETHOD:Automatic; NBDOC:?; NBENTITY:?; SOURCE:Wikidata; SELECTIONMETHOD:Manual; NBTRIPLES:10⁶; NBTYPEENTITY:10²; SOURCE:Web; NBSENT:10⁶; SOURCE:C4","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Annual Meeting of ACL","","","","","","","","","","","","","","",""
"28DIAMI7","conferencePaper","2018","Elsahar, Hady; Vougiouklis, Pavlos; Remaci, Arslen; Gravier, Christophe; Hare, Jonathon; Simperl, Elena; Laforest, Frederique","T-REx: A Large Scale Alignment of Natural Language with Knowledge Base Triples","LREC2018","","","not found","https://aclanthology.org/L18-1544","Alignments between natural language and Knowledge Base (KB) triples are an essential prerequisite for training machine learning approaches employed in a variety of Natural Language Processing problems. These include Relation Extraction, KB Population, Question Answering and Natural Language Generation from KB triples. Available datasets that provide those alignments are plagued by signiﬁcant shortcomings – they are of limited size, they exhibit a restricted predicate coverage, and/or they are of unreported quality. To alleviate these shortcomings, we present T-REx, a dataset of large scale alignments between Wikipedia abstracts and Wikidata triples. T-REx consists of 11 million triples aligned with 3.09 million Wikipedia abstracts (6.2 million sentences). T-REx is two orders of magnitude larger than the largest available alignments dataset and covers 2.5 times more predicates. Additionally, we stress the quality of this language resource thanks to an extensive crowdsourcing evaluation. T-REx is publicly available at https://w3id.org/t-rex.","2018","2025-02-06 08:47:23","2025-02-06 08:47:23","","","","","","","","TREX","","","","","European Language Resources Association (ELRA)","","en","True","","https://paperswithcode.com/paper/t-rex-a-large-scale-alignment-of-natural","https://github.com/hadyelsahar/RE-NLG-Dataset","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/6W9826UD/Elsahar et al. - 2018 - T-REx A Large Scale Alignment of Natural Language.pdf","","EXAMPLE; DONE; TASK:Relclassif; TASK:Relextract; GRANULARITY:Sentences; TASK:Ner; TASK:Entitylinking; LANG:English; TASK:Coref; DATATYPEPROP:Date; DATATYPEPROP:String; NBTYPEREL:10²; SELECTIONMETHOD:Automatic; DOMAIN:Encyclo; SOURCE:Wikidata; SOURCE:Wikipedia; SOURCE:Dbpedia; NBTRIPLES:10⁶; NBDOC:10⁶; DATATYPEPROP:Number; SYNTHGENERATION_BIN:0; NBTYPEENTITY:NSP; NBSENT:10^6; NBENTITY:NSP","⚠️ Invalid DOI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JSRC8IEG","dataset","2006","Pustejovsky, James; Verhagen, Marc; Sauri, Roser; Littman, Jessica; Gaizauskas, Robert; Katz, Graham; Mani, Inderjeet; Knippen, Robert; Setzer, Andrea","TimeBank 1.2","","","","10.35111/09B1-5N19","https://catalog.ldc.upenn.edu/LDC2006T08","<h3>Introduction</h3><br>  <p>TimeBank 1.2 was developed by Brandeis University and contains 183 English news articles with over 27,000 event and temporal annotations, adding events, times and temporal links between events and times. The annotation follows the TimeML 1.2.1 specification.</p><br>  <h3>Data</h3><br>  <p>TimeML aims to capture and represent temporal information. This is accomplished using four primary tag types: TIMEX3 for temporal expressions, EVENT for temporal events, SIGNAL for temporal signals, and LINK for representing relationships. For a detailed description of TimeML, see the TimeML 1.2.1 Specification and Guidelines included in the corpus package documentation.</p><br>  <p>Here are descriptions for each tag:</p><br>  <p style=""padding-left: 30px;"">TIMEX3 - Captures dates, times, durations, and sets of dates and times.<br />EVENT - Annotates those elements in a text that mark the semantic events described by it.<br />MAKEINSTANCE - Creates tags for events that include information about a particular instance of the event. When an event participates in a relationship, it is actually the event instance that is referenced.<br />SIGNAL - Annotates temporal function words such as ""after,"" ""during,"" and ""when.""</p><br>  <p>The following three tags are link tags. They capture temporal, subordination, and aspectual relationships found in the text. These tags do not consume any actual text, but they do relate the four tag types above to each other.</p><br>  <p style=""padding-left: 30px;"">TLINK - Temporally relates two temporal expressions, two event instances, or a temporal expression and an event instance.<br />SLINK - Captures subordination relationships that involve event modality, evidentiality, and factuality.<br />ALINK - Captures an aspectual connection between two event instances.</p><br>  <p>TimeBank 1.2 contains 183 articles with just over 61,000 non-punctuation tokens. The count for each TimeML tag is listed below:</p><br>  <table><br>  <tbody><br>  <tr><br>  <td>EVENT</td><br>  <td width=""100pt"">7,935</td><br>  </tr><br>  <tr><br>  <td>MAKEINSTANCE</td><br>  <td>7,940</td><br>  </tr><br>  <tr><br>  <td>TIMEX3</td><br>  <td>1,414</td><br>  </tr><br>  <tr><br>  <td>SIGNAL</td><br>  <td>688</td><br>  </tr><br>  <tr><br>  <td>ALINK</td><br>  <td>265</td><br>  </tr><br>  <tr><br>  <td>SLINK</td><br>  <td>2,932</td><br>  </tr><br>  <tr><br>  <td>TLINK</td><br>  <td>6,418</td><br>  </tr><br>  <tr><br>  <td>Total</td><br>  <td>27,592</td><br>  </tr><br>  </tbody><br>  </table><br>  <h3>Samples</h3><br>  <p>For an example of the data in this corpus, please view the following <a href=""desc/addenda/LDC2006T08.tml"">sample (XML)</a>.</p><br>  <h3>Updates</h3><br>  <p>None at this time.</p></br>  Portions © 1998 American Broadcasting Corporation, © 1998 The Associated Press, © 1998 Cable News Network, LP, LLLP, © 1987-1989 Dow Jones &amp; Company, Inc., © 1998 New York Times, © 1998 Public Radio International, © 2002-2006 Brandeis University, © 2006 Trustees of the University of Pennsylvania<br><br>The World is a co-production of Public Radio International and the British Broadcasting Corporation and is produced at WGBH Boston.","2006-04-17","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-02-05 13:56:16","","","","","","","TIMEBANK","","","","","Linguistic Data Consortium","","","","","","","DOI.org (Datacite)","","Artwork Size: 11264 KB Pages: 11264 KB","","","","EXAMPLE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7J8F8LG6","journalArticle","2014","Styler IV, William F.; Bethard, Steven; Finan, Sean; Palmer, Martha; Pradhan, Sameer; de Groen, Piet C; Erickson, Brad; Miller, Timothy; Lin, Chen; Savova, Guergana; Pustejovsky, James","Temporal Annotation in the Clinical Domain","Transactions of the Association for Computational Linguistics","","","10.1162/tacl_a_00172","https://aclanthology.org/Q14-1012/","This article discusses the requirements of a formal specification for the annotation of temporal information in clinical narratives. We discuss the implementation and extension of ISO-TimeML for annotating a corpus of clinical notes, known as the THYME corpus. To reflect the information task and the heavily inference-based reasoning demands in the domain, a new annotation guideline has been developed, “the THYME Guidelines to ISO-TimeML (THYME-TimeML)”. To clarify what relations merit annotation, we distinguish between linguistically-derived and inferentially-derived temporal orderings in the text. We also apply a top performing TempEval 2013 system against this new resource to measure the difficulty of adapting systems to the clinical domain. The corpus is available to the community and has been proposed for use in a SemEval 2015 task.","2014","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 13:13:26","143–154","","","2","","","THYME","","","","","","","","","","","","ACLWeb","","Place: Cambridge, MA Publisher: MIT Press","","/root/snap/zotero-snap/common/Zotero/storage/37LWYKWP/Styler IV et al. - 2014 - Temporal Annotation in the Clinical Domain.pdf","","FILTER_STEP","","Lin, Dekang; Collins, Michael; Lee, Lillian","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EU8Z6ASE","conferencePaper","2022",", Shuyang Cao; , Lu Wang","Time-aware Prompting for Text Generation","Findings of the Association for Computational Linguistics: EMNLP 2022","","","10.18653/v1/2022.findings-emnlp.535","https://arxiv.org/abs/2211.02162v1","In this paper, we study the effects of incorporating timestamps, such as document creation dates, into generation systems. Two types of time-aware prompts are investigated: (1) textual prompts that encode document timestamps in natural language sentences; and (2) linear prompts that convert timestamps into continuous vectors. To explore extrapolation to future data points, we further introduce a new data-to-text generation dataset, TempWikiBio, containing more than 4 millions of chronologically ordered revisions of biographical articles from English Wikipedia, each paired with structured personal profiles. Through data-to-text generation on TempWikiBio, text-to-text generation on the content transfer dataset, and summarization on XSum, we show that linear prompts on encoder and textual prompts improve the generation quality on all datasets. Despite having less performance drop when testing on data drawn from a later time, linear prompts focus more on non-temporal information and are less sensitive to the given timestamps, according to human evaluations and sensitivity analyses. Meanwhile, textual prompts establish the association between the given timestamps and the output dates, yielding more factual temporal information in the output.","2022-11-03","2025-02-06 08:47:23","2025-02-06 08:47:23","","","","","","","","TEMPWIKIBIO","","","","","ACL","","","False","","https://paperswithcode.com/paper/time-aware-prompting-for-text-generation","","","","","","/root/snap/zotero-snap/common/Zotero/storage/65Z8M4BG/ and  - 2022 - Time-aware Prompting for Text Generation.pdf","","SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_task:TextGeneration; SAT_task:SlotFilling; SAT_task:Event; SAT_learning:FewShot; SAT_context:Text; SAT_source:Wikipedia; SAT_context:Table; SAT_focus:FewSHot; SAT_NbEntity:695929; SAT_nbDoc:625000; SAT_method_generation:BART; SAT_task:Data-to-text","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP","","","","","","","","","","","","","","",""
"J66YUJ4K","conferencePaper","2023","Ma, Yubo; Cao, Yixin; Hong, YongChing; Sun, Aixin","Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!","Findings of the Association for Computational Linguistics: EMNLP 2023","","","10.18653/v1/2023.findings-emnlp.710","http://arxiv.org/abs/2303.08559","Large Language Models (LLMs) have made remarkable strides in various tasks. Whether LLMs are competitive few-shot solvers for information extraction (IE) tasks, however, remains an open problem. In this work, we aim to provide a thorough answer to this question. Through extensive experiments on nine datasets across four IE tasks, we demonstrate that current advanced LLMs consistently exhibit inferior performance, higher latency, and increased budget requirements compared to fine-tuned SLMs under most settings. Therefore, we conclude that LLMs are not effective few-shot information extractors in general. Nonetheless, we illustrate that with appropriate prompting strategies, LLMs can effectively complement SLMs and tackle challenging samples that SLMs struggle with. And moreover, we propose an adaptive filter-then-rerank paradigm to combine the strengths of LLMs and SLMs. In this paradigm, SLMs serve as filters and LLMs serve as rerankers. By prompting LLMs to rerank a small portion of difficult samples identified by SLMs, our preliminary system consistently achieves promising improvements (2.4% F1-gain on average) on various IE tasks, with an acceptable time and cost investment.","2023","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 10:25:56","10572-10601","","","","","","TEXTIE","","","","","","","","","","","","arXiv.org","","arXiv:2303.08559 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/G67I3UK7/Ma et al. - 2023 - Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samp.pdf; /root/snap/zotero-snap/common/Zotero/storage/PAN5XHYL/2303.html","","FILTER_STEP","Computer Science - Computation and Language; Computer Science - Artificial Intelligence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TDR8IIJL","conferencePaper","2011","UzZaman, Naushad; Allen, James","Temporal Evaluation","Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies","","","","https://aclanthology.org/P11-2061/","","2011-06","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 13:08:42","351–356","","","","","","TempEval3","","","","","Association for Computational Linguistics","Portland, Oregon, USA","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/HESAMLR3/UzZaman and Allen - 2011 - Temporal Evaluation.pdf","","EXAMPLE; FILTER_STEP","","Lin, Dekang; Matsumoto, Yuji; Mihalcea, Rada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL-HLT 2011","","","","","","","","","","","","","","",""
"H3ICGBCZ","conferencePaper","2021","Agarwal, Oshin; Ge, Heming; Shakeri, Siamak; Al-Rfou, Rami","Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2021.naacl-main.278","https://aclanthology.org/2021.naacl-main.278/","Prior work on Data-To-Text Generation, the task of converting knowledge graph (KG) triples into natural text, focused on domain-specific benchmark datasets. In this paper, however, we verbalize the entire English Wikidata KG, and discuss the unique challenges associated with a broad, open-domain, large-scale verbalization. We further show that verbalizing a comprehensive, encyclopedic KG like Wikidata can be used to integrate structured KGs and natural language corpora. In contrast to the many architectures that have been developed to integrate these two sources, our approach converts the KG into natural text, allowing it to be seamlessly integrated into existing language models. It carries the further advantages of improved factual accuracy and reduced toxicity in the resulting language model. We evaluate this approach by augmenting the retrieval corpus in a retrieval language model and showing significant improvements on the knowledge intensive tasks of open domain QA and the LAMA knowledge probe.","2021-06","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 09:53:49","3554–3565","","","","","","TEKGEN/KELM","","","","","Association for Computational Linguistics","Online","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/97QESBRJ/Agarwal et al. - 2021 - Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training.pdf","","FILTER_STEP","","Toutanova, Kristina; Rumshisky, Anna; Zettlemoyer, Luke; Hakkani-Tur, Dilek; Beltagy, Iz; Bethard, Steven; Cotterell, Ryan; Chakraborty, Tanmoy; Zhou, Yichao","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL-HLT 2021","","","","","","","","","","","","","","",""
"RAF36HHE","conferencePaper","2013","UzZaman, Naushad; Llorens, Hector; Derczynski, Leon; Allen, James; Verhagen, Marc; Pustejovsky, James","SemEval-2013 Task 1: TempEval-3: Evaluating Time Expressions, Events, and Temporal Relations","Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013)","","","","https://aclanthology.org/S13-2001/","","2013-06","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-25 11:24:56","1–9","","","","","","TempEval","","","","","Association for Computational Linguistics","Atlanta, Georgia, USA","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/QQUQWCLB/UzZaman et al. - 2013 - SemEval-2013 Task 1 TempEval-3 Evaluating Time Expressions, Events, and Temporal Relations.pdf","","EXAMPLE; FILTER_STEP","","Manandhar, Suresh; Yuret, Deniz","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SemEval 2013","","","","","","","","","","","","","","",""
"NGYL3MUT","conferencePaper","2019",", Aakanksha Naik; , Luke Breitfeller; , Carolyn Rose","TDDiscourse: A Dataset for Discourse-Level Temporal Ordering of Events","","","","10.18653/v1/w19-5929","https://aclanthology.org/W19-5929","Prior work on temporal relation classification has focused extensively on event pairs in the same or adjacent sentences (local), paying scant attention to discourse-level (global) pairs. This restricts the ability of systems to learn temporal links between global pairs, since reliance on local syntactic features suffices to achieve reasonable performance on existing datasets. However, systems should be capable of incorporating cues from document-level structure to assign temporal relations. In this work, we take a first step towards discourse-level temporal ordering by creating TDDiscourse, the first dataset focusing specifically on temporal links between event pairs which are more than one sentence apart. We create TDDiscourse by augmenting TimeBank-Dense, a corpus of English news articles, manually annotating global pairs that cannot be inferred automatically from existing annotations. Our annotations double the number of temporal links in TimeBank-Dense, while possessing several desirable properties such as focusing on long-distance pairs and not being automatically inferable. We adapt and benchmark the performance of three state-of-the-art models on TDDiscourse and observe that existing systems indeed find discourse-level temporal ordering harder.","2019-09-01","2025-02-06 08:47:23","2025-02-06 08:47:23","","NA","","","NA","","","TDD","","","","","ACL","","","True","","https://paperswithcode.com/paper/tddiscourse-a-dataset-for-discourse-level","https://github.com/aakanksha19/TDDiscourse","","","{'citing': ['10.1007/978-3-031-17120-8_15', '10.1109/ijcnn55064.2022.9892554'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/GMTMLG8Z/ et al. - 2019 - TDDiscourse A Dataset for Discourse-Level Tempora.pdf","","FILTER_STEP; DOMAIN:?; LANG:?; TASK:Relclassif; TASK:Relextract; GRANULARITY:Document; DATATYPEPROP:?; SYNTHGENERATION_BIN:?; SELECTIONMETHOD:Automatic; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:?; SELECTIONMETHOD:Manual; NBTYPEREL:10⁰; NBDOC:10¹","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WS 2019 9","","","","","","","","","","","","","","",""
"JUVRLWIU","conferencePaper","2020","Ning, Qiang; Wu, Hao; Han, Rujun; Peng, Nanyun; Gardner, Matt; Roth, Dan","TORQUE: A Reading Comprehension Dataset of Temporal Ordering Questions","Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","","","10.18653/v1/2020.emnlp-main.88","https://www.aclweb.org/anthology/2020.emnlp-main.88","","2020","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 11:16:16","1158-1172","","","","","","TCR","","","","","Association for Computational Linguistics","Online","en","","","","","DOI.org (Crossref)","","","","/root/snap/zotero-snap/common/Zotero/storage/QDHEB2EA/Ning et al. - 2020 - TORQUE A Reading Comprehension Dataset of Temporal Ordering Questions.pdf","","FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","","","","","","","","","","","","","","",""
"ZP8NP5IN","conferencePaper","2020","Alt, Christoph; Gabryszak, Aleksandra; Hennig, Leonhard","TACRED Revisited: A Thorough Evaluation of the TACRED Relation Extraction Task","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.48550/arXiv.2004.14855","http://arxiv.org/abs/2004.14855","TACRED (Zhang et al., 2017) is one of the largest, most widely used crowdsourced datasets in Relation Extraction (RE). But, even with recent advances in unsupervised pre-training and knowledge enhanced neural RE, models still show a high error rate. In this paper, we investigate the questions: Have we reached a performance ceiling or is there still room for improvement? And how do crowd annotations, dataset, and models contribute to this error rate? To answer these questions, we first validate the most challenging 5K examples in the development and test sets using trained annotators. We find that label errors account for 8% absolute F1 test error, and that more than 50% of the examples need to be relabeled. On the relabeled test set the average F1 score of a large baseline model set improves from 62.1 to 70.1. After validation, we analyze misclassifications on the challenging instances, categorize them into linguistically motivated error groups, and verify the resulting error hypotheses on three state-of-the-art RE models. We show that two groups of ambiguous relations are responsible for most of the remaining errors and that models may adopt shallow heuristics on the dataset when entities are not masked.","2020-04-30","2025-02-06 08:47:23","2025-02-06 08:47:23","2023-03-06 14:47:11","","","","","","","TACREV","","","","","Association for Computational Linguistics","","","False","","https://paperswithcode.com/paper/tacred-revisited-a-thorough-evaluation-of-the","https://github.com/DFKI-NLP/tacrev","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/CZWM7WJ7/Alt et al. - 2020 - TACRED Revisited A Thorough Evaluation of the TAC.pdf; /root/snap/zotero-snap/common/Zotero/storage/CLH3QF7U/2004.html","","EXAMPLE; DOMAIN:?; TASK:Relextract; GRANULARITY:Sentences; LANG:English; DATATYPEPROP:?; NBTYPEREL:?; SYNTHGENERATION_BIN:?; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:?; SELECTIONMETHOD:Manual","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QD6WGVUV","conferencePaper","2017","Zhang, Yuhao; Zhong, Victor; Chen, Danqi; Angeli, Gabor; Manning, Christopher D.","Position-aware Attention and Supervised Data Improve Slot Filling","Proceedings of the 2017 Conference on Empirical Methods in Natural           Language Processing","","","10.18653/v1/d17-1004","http://aclweb.org/anthology/D17-1004","Organized relational knowledge in the form of “knowledge graphs” is important for many applications. However, the ability to populate knowledge bases with facts automatically extracted from documents has improved frustratingly slowly. This paper simultaneously addresses two issues that have held back prior work. We ﬁrst propose an effective new model, which combines an LSTM sequence model with a form of entity position-aware attention that is better suited to relation extraction. Then we build TACRED, a large (119,474 examples) supervised relation extraction dataset, obtained via crowdsourcing and targeted towards TAC KBP relations. The combination of better supervised data and a more appropriate high-capacity model enables much better relation extraction performance. When the model trained on this new dataset replaces the previous relation extraction component of the best TAC KBP 2015 slot ﬁlling system, its F1 score increases markedly from 22.2% to 26.7%.","2017","2025-02-06 08:47:23","2025-02-06 08:47:23","2023-02-28 16:25:47","35-45","","","","","","TACRED","","","","","Association for Computational Linguistics","Copenhagen, Denmark","en","False","","https://paperswithcode.com/paper/position-aware-attention-and-supervised-data","","DOI.org (Crossref)","","{'citing': ['10.1109/icassp39728.2021.9414755', '10.1145/3477495.3531746', '10.1109/access.2018.2890390', '10.1109/slt.2018.8639671', '10.1007/s10462-022-10239-9', '10.1109/inista55318.2022.9894216', '10.1109/taslp.2022.3199655', '10.1016/j.eswa.2022.117678', '10.1016/j.knosys.2022.109471', '10.1093/database/baac070', '10.1162/dint_a_00147', '10.1007/978-3-031-19433-7_32', '10.1007/978-3-031-19433-7_37', '10.1145/3511808.3557251', '10.1145/3511808.3557459', '10.1145/3511808.3557615', '10.3390/info13080364', '10.3390/math10203831', '10.3390/app12199781', '10.1109/tii.2022.3159710', '10.1145/3563766.3564109', '10.1109/tbdata.2022.3144151', '10.1007/978-3-031-18315-7_7', '10.1007/978-3-031-18315-7_6', '10.1007/s10489-022-03731-w', '10.1017/s1351324918000451', '10.1145/3308558.3313573', '10.1007/978-3-030-30490-4_12', '10.1007/978-3-319-91947-8_18', '10.1145/3377713.3377784', '10.2196/preprints.18417', '10.1145/3371158.3371186', '10.1007/978-3-030-32381-3_19', '10.1145/3366423.3380282', '10.2196/18417', '10.1007/s00521-020-05087-z', '10.1007/978-981-15-6168-9_2', '10.1007/s10115-020-01502-y', '10.1007/978-3-030-55130-8_11', '10.1145/3340531.3412011', '10.12677/hjdm.2020.104030', '10.1007/978-3-030-62419-4_11', '10.1007/978-3-030-63031-7_9', '10.1016/j.knosys.2020.106321', '10.1016/j.asoc.2019.105913', '10.1016/j.datak.2019.101764', '10.1007/s10489-021-02596-9', '10.1007/s10489-021-02632-8', '10.1016/j.oregeorev.2021.104200', '10.14778/3407790.3407804', '10.1016/j.aiopen.2021.06.004', '10.1007/978-3-030-80599-9_10', '10.1371/journal.pone.0248299', '10.1007/978-3-030-73216-5_22', '10.1145/3412841.3441977', '10.1016/j.ipm.2021.102636', '10.1007/978-3-030-75768-7_26', '10.1007/978-3-030-75768-7_30', '10.1007/978-3-030-75015-2_15', '10.1016/j.ipm.2021.102563', '10.1007/978-3-030-77867-5_10', '10.1007/978-3-030-82322-1_5', '10.1162/tacl_a_00392', '10.1007/978-3-030-86523-8_35', '10.1007/978-3-030-85896-4_23', '10.1007/s10489-021-02667-x', '10.1007/978-3-658-31938-0_6', '10.1007/978-3-030-84529-2_39', '10.1007/s12559-021-09917-7', '10.1007/978-3-030-87571-8_29', '10.1145/3491056', '10.1007/978-981-16-6471-7_4', '10.52547/jipm.37.1.255', '10.1016/j.jii.2021.100301', '10.1145/3436369.3437431', '10.1016/j.knosys.2021.107565', '10.1145/3503917', '10.1007/978-981-16-8885-0_29', '10.1007/s00521-021-06667-3', '10.1142/s0218194021400222', '10.1145/3503047.3503060', '10.1007/978-981-16-6963-7_85', '10.1007/s10462-022-10148-x', '10.1007/s10115-022-01665-w', '10.1007/978-3-031-01333-1_2', '10.1145/3485447.3511998', '10.1007/s11633-022-1323-6', '10.1007/s00521-022-07223-3', '10.1016/j.eswa.2022.117113', '10.1016/j.eswa.2022.117113', '10.1162/tacl_a_00456', '10.1527/tjsai.37-3_ids-d', '10.1109/icccbda49378.2020.9095628', '10.1109/ijcnn48605.2020.9207515', '10.1109/ijcnn48605.2020.9207706', '10.1109/dsc53577.2021.00017', '10.1109/icassp43922.2022.9747486', '10.1145/3495162', '10.1109/trustcom50675.2020.00083', '10.1109/cis52066.2020.00028', '10.1145/3510030', '10.1007/978-3-031-03948-5_11', '10.1109/cscwd54268.2022.9776127', '10.1109/access.2019.2917302', '10.1007/978-3-031-07472-1_16', '10.1007/s10115-022-01687-4', '10.1109/taslp.2022.3153254', '10.1109/ijcnn52387.2021.9534434', '10.1109/ijcnn52387.2021.9534473', '10.1109/ijcnn52387.2021.9534183', '10.1109/ijcnn52387.2021.9534398', '10.1109/access.2021.3086480', '10.1109/access.2019.2930407', '10.1109/tai.2021.3068697', '10.1109/tetci.2021.3136598', '10.1109/s.a.i.ence50533.2020.9303196', '10.3390/s22134911', '10.1109/icicn52636.2021.9673905', '10.1109/tetci.2020.3040444', '10.1109/bibm47256.2019.8982966', '10.1109/iccst50977.2020.00059', '10.1109/icme51207.2021.9428274', '10.1109/bibm47256.2019.8983057', '10.1109/ictai.2019.00210', '10.1016/j.knosys.2022.109146'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/UTJHUW78/Zhang et al. - 2017 - Position-aware Attention and Supervised Data Impro.pdf","","EXAMPLE; FILTER_STEP; DOMAIN:?; LANG:?; TASK:Relextract; GRANULARITY:Sentences; TASK:Ner; TASK:Entitytyping; TASK:Slotfilling; DATATYPEPROP:?; SYNTHGENERATION_BIN:?; NBTYPEREL:10¹; NBENTITY:?; NBSENT:?; NBTYPEENTITY:?; SOURCE:?; SELECTIONMETHOD:Manual; NBTRIPLES:10⁴; NBDOC:10⁵","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2017 Conference on Empirical Methods in Natural           Language Processing","","","","","","","","","","","","","","",""
"7XA2NU8W","conferencePaper","2017","","TAC KBP 2017 Cold Start Track","","","","not found","https://tac.nist.gov/2017/KBP/ColdStart/index.html","","2017","2025-02-06 08:47:23","2025-02-06 08:47:23","2023-02-27 14:09:40","","","","","","","TAC","","","","","","","","False","","","","","","","","/root/snap/zotero-snap/common/Zotero/storage/9HLDIJ9I/index.html","","SAT_oldTag:CHECKED0923; SAT_granularity:sentence; SAT_method_selection:Human; SAT_All_checked:True; SAT_nbTriples:84000; SAT_nbtypes_relations:41","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NVJGB789","preprint","2022","Yuan, Ann; Ippolito, Daphne; Nikolaev, Vitaly; Callison-Burch, Chris; Coenen, Andy; Gehrmann, Sebastian","SynthBio: A Case Study in Human-AI Collaborative Curation of Text Datasets","","","","10.48550/arXiv.2111.06467","http://arxiv.org/abs/2111.06467","NLP researchers need more, higher-quality text datasets. Human-labeled datasets are expensive to collect, while datasets collected via automatic retrieval from the web such as WikiBio are noisy and can include undesired biases. Moreover, data sourced from the web is often included in datasets used to pretrain models, leading to inadvertent cross-contamination of training and test sets. In this work we introduce a novel method for efficient dataset curation: we use a large language model to provide seed generations to human raters, thereby changing dataset authoring from a writing task to an editing task. We use our method to curate SynthBio - a new evaluation set for WikiBio - composed of structured attribute lists describing fictional individuals, mapped to natural language biographies. We show that our dataset of fictional biographies is less noisy than WikiBio, and also more balanced with respect to gender and nationality.","2022-01-12","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-22 17:57:42","","","","","","","SynthBio","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2111.06467 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/TKXT7ASV/Yuan et al. - 2022 - SynthBio A Case Study in Human-AI Collaborative Curation of Text Datasets.pdf","","","Computer Science - Computation and Language; Computer Science - Artificial Intelligence; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2111.06467","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NRGXQQEP","conferencePaper","2019","Lockard, Colin; Shiralkar, Prashant; Dong, Xin Luna","OpenCeres: When Open Information Extraction Meets the Semi-Structured Web","Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)","","","10.18653/v1/N19-1309","https://aclanthology.org/N19-1309/","Open Information Extraction (OpenIE), the problem of harvesting triples from natural language text whose predicate relations are not aligned to any pre-defined ontology, has been a popular subject of research for the last decade. However, this research has largely ignored the vast quantity of facts available in semi-structured webpages. In this paper, we define the problem of OpenIE from semi-structured websites to extract such facts, and present an approach for solving it. We also introduce a labeled evaluation dataset to motivate research in this area. Given a semi-structured website and a set of seed facts for some relations existing on its pages, we employ a semi-supervised label propagation technique to automatically create training data for the relations present on the site. We then use this training data to learn a classifier for relation extraction. Experimental results of this method on our new benchmark dataset obtained a precision of over 70%. A larger scale extraction experiment on 31 websites in the movie vertical resulted in the extraction of over 2 million triples.","2019-06","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 13:17:08","3047–3056","","","","","","SWDE","","","","","Association for Computational Linguistics","Minneapolis, Minnesota","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/JDCE7HWE/Lockard et al. - 2019 - OpenCeres When Open Information Extraction Meets the Semi-Structured Web.pdf","","FILTER_STEP","","Burstein, Jill; Doran, Christy; Solorio, Thamar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL-HLT 2019","","","","","","","","","","","","","","",""
"3YSAUUEL","journalArticle","2020","Guan, Jian; Huang, Fei; Huang, Minlie; Zhao, Zhihao; Zhu, Xiaoyan","A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation","Transactions of the Association for Computational Linguistics","","2307-387X","","https://transacl.org/ojs/index.php/tacl/article/view/1886","Story generation, namely generating a reasonable story from a leading context, is an important but challenging task. In spite of the success in modeling ﬂuency and local coherence, existing neural language generation models (e.g., GPT-2) still suffer from repetition, logic conﬂicts, and lack of long-range coherence in generated stories. We conjecture that this is because of the difﬁculty of associating relevant commonsense knowledge, understanding the causal relationships, and planning entities and events with proper temporal order. In this paper, we devise a knowledge-enhanced pretraining model for commonsense story generation. We propose to utilize commonsense knowledge from external knowledge bases to generate reasonable stories. To further capture the causal and temporal dependencies between the sentences in a reasonable story, we employ multi-task learning which combines a discriminative objective to distinguish true and fake stories during ﬁne-tuning. Automatic and manual evaluation shows that our model can generate more reasonable stories than state-of-the-art baselines, particularly in terms of logic and global coherence.","2020-04-01","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 12:56:56","93-108","","","8","","","STORYENDINGGEN/CS.STORYGEN","","","","","","","en","Copyright (c) 2020 Association for Computational Linguistics","","","","transacl.org","","","","","","FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZXCPA6S9","preprint","2016","Rajpurkar, Pranav; Zhang, Jian; Lopyrev, Konstantin; Liang, Percy","SQuAD: 100,000+ Questions for Machine Comprehension of Text","","","","10.48550/arXiv.1606.05250","http://arxiv.org/abs/1606.05250","We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at https://stanford-qa.com","2016-10-11","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-25 11:31:37","","","","","","","SQUAD","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1606.05250 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/YCNILR7D/Rajpurkar et al. - 2016 - SQuAD 100,000+ Questions for Machine Comprehension of Text.pdf; /root/snap/zotero-snap/common/Zotero/storage/ZKLGLVEH/1606.html","","EXAMPLE; FILTER_STEP","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:1606.05250","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9M2NQ8U2","preprint","2018","Coucke, Alice; Saade, Alaa; Ball, Adrien; Bluche, Théodore; Caulier, Alexandre; Leroy, David; Doumouro, Clément; Gisselbrecht, Thibault; Caltagirone, Francesco; Lavril, Thibaut; Primet, Maël; Dureau, Joseph","Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces","","","","10.48550/arXiv.1805.10190","http://arxiv.org/abs/1805.10190","This paper presents the machine learning architecture of the Snips Voice Platform, a software solution to perform Spoken Language Understanding on microprocessors typical of IoT devices. The embedded inference is fast and accurate while enforcing privacy by design, as no personal user data is ever collected. Focusing on Automatic Speech Recognition and Natural Language Understanding, we detail our approach to training high-performance Machine Learning models that are small enough to run in real-time on small devices. Additionally, we describe a data generation procedure that provides sufficient, high-quality training data without compromising user privacy.","2018-12-06","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 11:08:37","","","","","","","SNIPS","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1805.10190 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/254WN37U/Coucke et al. - 2018 - Snips Voice Platform an embedded Spoken Language Understanding system for private-by-design voice i.pdf; /root/snap/zotero-snap/common/Zotero/storage/PM7274L6/1805.html","","FILTER_STEP","Computer Science - Computation and Language; Computer Science - Neural and Evolutionary Computing","","","","","","","","","","","","","","","","","","","arXiv:1805.10190","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3YWBXC5B","conferencePaper","2021","Seganti, Alessandro; Firląg, Klaudia; Skowronska, Helena; Satława, Michał; Andruszkiewicz, Piotr","Multilingual Entity and Relation Extraction Dataset and Model","Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume","","","10.18653/v1/2021.eacl-main.166","https://aclanthology.org/2021.eacl-main.166","We present a novel dataset and model for a multilingual setting to approach the task of Joint Entity and Relation Extraction. The SMiLER dataset consists of 1.1 M annotated sentences, representing 36 relations, and 14 languages. To the best of our knowledge, this is currently both the largest and the most comprehensive dataset of this type. We introduce HERBERTa, a pipeline that combines two independent BERT models: one for sequence classiﬁcation, and the other for entity tagging. The model achieves micro F1 81.49 for English on this dataset, which is close to the current SOTA on CoNLL, SpERT.","2021","2025-02-06 08:47:23","2025-02-06 08:47:23","2023-08-22 09:20:04","1946-1955","","","","","","Smiler","","","","","Association for Computational Linguistics","Online","en","True","","","https://github.com/samsungnlp/smiler/","DOI.org (Crossref)","","","","/root/snap/zotero-snap/common/Zotero/storage/CE4DWDGJ/Seganti et al. - 2021 - Multilingual Entity and Relation Extraction Datase.pdf","","FILTER_STEP; DOMAIN:?; TASK:Relextract; GRANULARITY:Sentences; TASK:Ner; LANG:Multi; LANG:Arabic; LANG:English; LANG:German; DATATYPEPROP:?; SYNTHGENERATION_BIN:?; SELECTIONMETHOD:Automatic; NBTYPEREL:10¹; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; SOURCE:Wikipedia; SELECTIONMETHOD:Manual; NBTYPEENTITY:10⁰; SOURCE:Dbpedia; LANG:French; LANG:Spanish; LANG:Dutch; LANG:Russian; LANG:Finish; LANG:Italian; LANG:Polish; LANG:Portuguese; LANG:Sloven","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume","","","","","","","","","","","","","","",""
"KP2UAPFC","conferencePaper","2021","Xie, Chenhao; Liang, Jiaqing; Liu, Jingping; Huang, Chengsong; Huang, Wenhao; Xiao, Yanghua","Revisiting the Negative Data of Distantly Supervised Relation Extraction","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","","10.18653/v1/2021.acl-long.277","https://aclanthology.org/2021.acl-long.277/","Distantly supervision automatically generates plenty of training samples for relation extraction. However, it also incurs two major problems: noisy labels and imbalanced training data. Previous works focus more on reducing wrongly labeled relations (false positives) while few explore the missing relations that are caused by incompleteness of knowledge base (false negatives). Furthermore, the quantity of negative labels overwhelmingly surpasses the positive ones in previous problem formulations. In this paper, we first provide a thorough analysis of the above challenges caused by negative data. Next, we formulate the problem of relation extraction into as a positive unlabeled learning task to alleviate false negative problem. Thirdly, we propose a pipeline approach, dubbed ReRe, that first performs sentence classification with relational labels and then extracts the subjects/objects. Experimental results show that the proposed method consistently outperforms existing approaches and remains excellent performance even learned with a large quantity of false positive samples. Source code is available online at https://github.com/redreamality/RERE-relation-extraction.","2021-08","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 10:24:50","3572–3581","","","","","","SKE21","","","","","Association for Computational Linguistics","Online","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/7BI5T6KS/Xie et al. - 2021 - Revisiting the Negative Data of Distantly Supervised Relation Extraction.pdf","","FILTER_STEP","","Zong, Chengqing; Xia, Fei; Li, Wenjie; Navigli, Roberto","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL-IJCNLP 2021","","","","","","","","","","","","","","",""
"UXIAFLY9","conferencePaper","2016","Pontiki, Maria; Galanis, Dimitris; Papageorgiou, Haris; Androutsopoulos, Ion; Manandhar, Suresh; AL-Smadi, Mohammad; Al-Ayyoub, Mahmoud; Zhao, Yanyan; Qin, Bing; De Clercq, Orphée; Hoste, Véronique; Apidianaki, Marianna; Tannier, Xavier; Loukachevitch, Natalia; Kotelnikov, Evgeniy; Bel, Nuria; Jiménez-Zafra, Salud María; Eryiğit, Gülşen","SemEval-2016 Task 5: Aspect Based Sentiment Analysis","Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)","","","10.18653/v1/S16-1002","https://aclanthology.org/S16-1002/","","2016-06","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 09:58:07","19–30","","","","","","SemEval2016","","","","","Association for Computational Linguistics","San Diego, California","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/D3ZZHZ4D/Pontiki et al. - 2016 - SemEval-2016 Task 5 Aspect Based Sentiment Analysis.pdf","","FILTER_STEP","","Bethard, Steven; Carpuat, Marine; Cer, Daniel; Jurgens, David; Nakov, Preslav; Zesch, Torsten","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SemEval 2016","","","","","","","","","","","","","","",""
"NE9DVMCL","conferencePaper","2020","Han, Xu; Dai, Yi; Gao, Tianyu; Lin, Yankai; Liu, Zhiyuan; Li, Peng; Sun, Maosong; Zhou, Jie","Continual Relation Learning via Episodic Memory Activation and Reconsolidation","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/2020.acl-main.573","https://aclanthology.org/2020.acl-main.573/","Continual relation learning aims to continually train a model on new data to learn incessantly emerging novel relations while avoiding catastrophically forgetting old relations. Some pioneering work has proved that storing a handful of historical relation examples in episodic memory and replaying them in subsequent training is an effective solution for such a challenging problem. However, these memory-based methods usually suffer from overfitting the few memorized examples of old relations, which may gradually cause inevitable confusion among existing relations. Inspired by the mechanism in human long-term memory formation, we introduce episodic memory activation and reconsolidation (EMAR) to continual relation learning. Every time neural models are activated to learn both new and memorized data, EMAR utilizes relation prototypes for memory reconsolidation exercise to keep a stable understanding of old relations. The experimental results show that EMAR could get rid of catastrophically forgetting old relations and outperform the state-of-the-art continual learning models.","2020-07","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 12:51:15","6429–6440","","","","","","SIMPLEQUESTIONS","","","","","Association for Computational Linguistics","Online","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/XYGS9EQY/Han et al. - 2020 - Continual Relation Learning via Episodic Memory Activation and Reconsolidation.pdf","","FILTER_STEP","","Jurafsky, Dan; Chai, Joyce; Schluter, Natalie; Tetreault, Joel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2020","","","","","","","","","","","","","","",""
"AKL9L937","conferencePaper","2015","Pontiki, Maria; Galanis, Dimitris; Papageorgiou, Haris; Manandhar, Suresh; Androutsopoulos, Ion","SemEval-2015 Task 12: Aspect Based Sentiment Analysis","Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015)","","","10.18653/v1/S15-2082","https://aclanthology.org/S15-2082/","","2015-06","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 10:59:25","486–495","","","","","","SemEval2015","","","","","Association for Computational Linguistics","Denver, Colorado","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/CXA2GISP/Pontiki et al. - 2015 - SemEval-2015 Task 12 Aspect Based Sentiment Analysis.pdf","","FILTER_STEP","","Nakov, Preslav; Zesch, Torsten; Cer, Daniel; Jurgens, David","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SemEval 2015","","","","","","","","","","","","","","",""
"3SK32NAY","conferencePaper","2009","Hendrickx, Iris; Kim, Su Nam; Kozareva, Zornitsa; Nakov, Preslav; Ó Séaghdha, Diarmuid; Padó, Sebastian; Pennacchiotti, Marco; Romano, Lorenza; Szpakowicz, Stan","SemEval-2010 task 8: multi-way classification of semantic relations between pairs of nominals","Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions - DEW '09","978-1-932432-31-2","","10.3115/1621969.1621986","http://portal.acm.org/citation.cfm?doid=1621969.1621986","SemEval-2 Task 8 focuses on Multi-way classiﬁcation of semantic relations between pairs of nominals. The task was designed to compare different approaches to semantic relation classiﬁcation and to provide a standard testbed for future research. This paper deﬁnes the task, describes the training and test data and the process of their creation, lists the participating systems (10 teams, 28 runs), and discusses their results.","2009","2025-02-06 08:47:23","2025-02-06 08:47:23","2023-02-28 16:28:16","94","","","","","","SemEval2010","","","","","Association for Computational Linguistics","Boulder, Colorado","en","True","","","https://drive.google.com/file/d/0B_jQiLugGTAkMDQ5ZjZiMTUtMzQ1Yy00YWNmLWJlZDYtOWY1ZDMwY2U4YjFk/view?sort=name&layout=list&num=50","DOI.org (Crossref)","","{'citing': ['10.1186/s13638-020-01720-6', '10.1016/j.oregeorev.2021.104200', '10.1007/978-3-030-80119-9_64', '10.1007/978-981-16-1964-9_8', '10.1007/978-3-030-75762-5_28', '10.1007/s11704-020-9420-6', '10.1016/j.knosys.2021.106888', '10.1007/978-3-030-79725-6_5', '10.1061/(asce)cp.1943-5487.0000977', '10.2196/preprints.27527', '10.1007/s11390-020-9713-0', '10.1007/978-3-030-72240-1_82', '10.1007/978-3-030-81007-8_72', '10.1016/j.ipm.2021.102563', '10.1007/s42521-020-00023-1', '10.1007/978-3-030-80599-9_10', '10.1007/s10489-021-02492-2', '10.1007/s10489-021-02596-9', '10.1016/j.neucom.2021.03.066', '10.1145/3451471.3451506', '10.1016/j.jbi.2021.103820', '10.1007/s12559-021-09917-7', '10.1007/s11431-020-1673-6', '10.1016/j.neucom.2021.12.044', '10.4018/ijitwe.2020070102', '10.1007/978-981-16-8062-5_33', '10.1007/s00799-021-00310-1', '10.1111/exsy.12873', '10.48084/etasr.4300', '10.1016/j.neucom.2021.10.002', '10.1016/j.jbi.2021.103932', '10.1145/3502223.3502229', '10.1017/s135132492100036x', '10.1007/978-981-16-8885-0_29', '10.1007/s00521-021-06667-3', '10.1007/s10115-022-01665-w', '10.1007/978-981-16-9573-5_25', '10.1007/s10115-022-01663-y', '10.1016/j.eswa.2022.117113', '10.1016/j.eswa.2022.117113', '10.1109/icccbda49378.2020.9095628', '10.1109/access.2020.2966303', '10.1109/mlhpc49564.2019.00010', '10.1109/ssci50451.2021.9660108', '10.1109/itaic.2019.8785831', '10.1109/access.2020.3048088', '10.1109/ijcnn48605.2020.9207554', '10.1109/ijcnn48605.2020.9207662', '10.1007/s10489-022-03596-z', '10.1109/access.2019.2948155', '10.1007/s10115-022-01687-4', '10.1109/icosc.2019.8665497', '10.1109/access.2021.3086480', '10.1109/bibm.2018.8621228', '10.1016/j.neucom.2015.12.091', '10.1109/access.2018.2888508', '10.1109/cds52072.2021.00022', '10.1109/tai.2021.3068697', '10.1109/tetci.2021.3136598', '10.1109/access.2019.2932041', '10.1109/ithings-greencom-cpscom-smartdata-cybermatics50389.2020.00094', '10.1109/s.a.i.ence50533.2020.9303196', '10.1109/tetci.2020.3040444', '10.1109/access.2020.3034907', '10.1109/gucon48875.2020.9231227', '10.1109/taslp.2018.2852502', '10.1109/icme51207.2021.9428274', '10.1109/icdm.2019.00204', '10.1109/icdm.2019.00205', '10.1109/iucc/dsci/smartcns.2019.00071', '10.1109/taslp.2021.3082295', '10.1109/iaeac47372.2019.8997966', '10.1109/ictai.2019.00227', '10.1007/s10489-022-03731-w', '10.1109/access.2018.2877934', '10.1109/cis.2019.00032', '10.1109/gncc42960.2018.9018722', '10.1109/taslp.2019.2921726', '10.1109/access.2019.2955977', '10.1109/cset.2019.8904905', '10.1109/iccse51940.2021.9569695', '10.1109/ijcnn.2019.8852408', '10.1109/nics.2018.8606824', '10.1007/s41666-022-00116-z', '10.1007/978-3-031-16075-2_59', '10.1007/s10462-022-10239-9', '10.1007/978-3-031-17288-5_8', '10.1109/inista55318.2022.9894216', '10.1007/978-3-031-16078-3_49', '10.1145/3543174.3547117', '10.1007/978-3-031-19433-7_37', '10.1007/978-3-031-19496-2_8', '10.1016/b978-0-323-89931-4.00005-5', '10.1007/978-3-030-40223-5_2', '10.12677/csa.2022.1210245', '10.1007/s11859-017-1278-6', '10.1007/s12559-016-9425-5', '10.1017/s1351324913000041', '10.1017/s1351324913000065', '10.1017/s1351324913000107', '10.1017/s135132491900024x', '10.1093/bioinformatics/btw486', '10.1007/978-981-10-8438-6_5', '10.1007/978-981-13-3146-6_8', '10.1002/sam.10135', '10.4018/ijdwm.2019100104', '10.1162/coli_a_00301', '10.1007/s00521-016-2603-2', '10.1007/s00521-016-2680-2', '10.1186/s12859-018-2584-5', '10.1186/s12859-019-2808-3', '10.1007/978-3-030-01716-3_12', '10.1007/978-3-030-04015-4_43', '10.1007/978-3-030-14596-5_1', '10.1007/978-3-030-14799-0_12', '10.1007/978-3-030-22744-9_23', '10.1007/978-3-030-23584-0_10', '10.1007/978-3-030-30490-4_4', '10.1007/978-3-030-31964-9_6', '10.1007/978-3-030-32236-6_21', '10.1007/978-3-030-32236-6_29', '10.1007/978-3-030-32236-6_65', '10.1007/978-3-030-32236-6_72', '10.1007/978-3-319-23135-8_13', '10.1371/journal.pone.0221582', '10.1007/978-3-319-45814-4_34', '10.1007/978-3-319-46128-1_28', '10.1007/978-3-319-46349-0_21', '10.1007/978-3-319-47674-2_24', '10.1007/978-3-319-50496-4_60', '10.1007/978-3-319-56535-4_11', '10.1007/978-3-319-59569-6_13', '10.1007/978-3-319-59569-6_49', '10.1007/978-3-319-70096-0_15', '10.1007/978-3-319-73618-1_31', '10.1007/978-3-319-73618-1_38', '10.1007/978-3-319-73618-1_39', '10.1007/978-3-319-73618-1_81', '10.1007/978-3-319-93701-4_15', '10.1007/978-3-319-93803-5_35', '10.1527/tjsai.ai30-l', '10.1527/tjsai.d-g96', '10.2200/s00489ed1v01y201303hlt019', '10.1007/978-3-642-19400-9_23', '10.1007/978-3-642-25261-7_25', '10.1007/978-3-642-28604-9_32', '10.1007/978-3-642-33185-5_2', '10.1007/978-3-642-41154-0_16', '10.1109/iaeac.2017.8054150', '10.1109/iciibms.2015.7439518', '10.1109/icsc.2010.73', '10.1109/ie.2017.18', '10.1109/ie.2017.28', '10.1109/ijcnn.2017.7966407', '10.1109/spc.2013.6735129', '10.1109/taslp.2016.2573050', '10.1109/access.2017.2785229', '10.1145/3041021.3054266', '10.1145/3377713.3377784', '10.1145/3184558.3191546', '10.1145/3357384.3357997', '10.1145/3357384.3358003', '10.1145/3357384.3358003', '10.1145/3357384.3358119', '10.1145/3018896.3036386', '10.1587/nolta.10.28', '10.1007/978-3-030-00665-5_90', '10.1007/978-3-319-70087-8_16', '10.1007/978-3-030-35445-9_50', '10.1007/978-981-15-1925-3_19', '10.1007/978-3-319-93037-4_29', '10.22430/22565337.1483', '10.1145/3159652.3159709', '10.1007/978-3-030-51310-8_15', '10.1145/3402885', '10.1145/3405962.3405985', '10.1145/3340531.3411858', '10.1145/3340531.3412763', '10.1007/978-3-030-32233-5_15', '10.1007/978-3-030-63799-6_5', '10.1007/978-3-030-65218-0_16', '10.1016/j.neucom.2020.08.078', '10.1016/j.neucom.2020.08.078', '10.1016/j.neucom.2020.08.078', '10.1016/j.neucom.2020.08.078', '10.1016/j.engappai.2016.01.027', '10.1016/j.neucom.2015.11.028', '10.1016/j.jbi.2016.11.004', '10.1016/j.procs.2018.04.221', '10.1016/j.procs.2018.10.475', '10.1007/978-3-030-73539-5_1', '10.1007/978-3-030-75768-7_26', '10.2196/27527', '10.1016/j.csl.2021.101265', '10.1007/s00521-020-05087-z'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/F44RU94F/Hendrickx et al. - 2009 - SemEval-2010 task 8 multi-way classification of s.pdf","","EXAMPLE; FILTER_STEP; LANG:?; TASK:Relclassif; GRANULARITY:Sentences; TASK:Ner; DOMAIN:General; DATATYPEPROP:?; SYNTHGENERATION_BIN:?; NBTYPEREL:10¹; NBDOC:?; NBENTITY:?; NBTRIPLES:?; NBTYPEENTITY:?; NBSENT:10⁴; SELECTIONMETHOD:Manual; SOURCE:Web","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","the Workshop","","","","","","","","","","","","","","",""
"YQFXH2PH","conferencePaper","2014","Pontiki, Maria; Galanis, Dimitris; Pavlopoulos, John; Papageorgiou, Harris; Androutsopoulos, Ion; Manandhar, Suresh","SemEval-2014 Task 4: Aspect Based Sentiment Analysis","Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014)","","","10.3115/v1/S14-2004","https://aclanthology.org/S14-2004/","","2014-08","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-01-30 10:58:44","27–35","","","","","","SemEval2014","","","","","Association for Computational Linguistics","Dublin, Ireland","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/BSAQS6WZ/Pontiki et al. - 2014 - SemEval-2014 Task 4 Aspect Based Sentiment Analysis.pdf","","FILTER_STEP","","Nakov, Preslav; Zesch, Torsten","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SemEval 2014","","","","","","","","","","","","","","",""
"PZSGA4Y6","conferencePaper","2018","Gábor, Kata; Buscaldi, Davide; Schumann, Anne-Kathrin; QasemiZadeh, Behrang; Zargayouna, Haïfa; Charnois, Thierry","SemEval-2018 Task 7: Semantic Relation Extraction and Classification in Scientific Papers","Proceedings of the 12th International Workshop on Semantic Evaluation","","","10.18653/v1/S18-1111","https://aclanthology.org/S18-1111/","This paper describes the first task on semantic relation extraction and classification in scientific paper abstracts at SemEval 2018. The challenge focuses on domain-specific semantic relations and includes three different subtasks. The subtasks were designed so as to compare and quantify the effect of different pre-processing steps on the relation classification results. We expect the task to be relevant for a broad range of researchers working on extracting specialized knowledge from domain corpora, for example but not limited to scientific or bio-medical information extraction. The task attracted a total of 32 participants, with 158 submissions across different scenarios.","2018-06","2025-02-06 08:47:23","2025-02-06 08:47:23","2025-02-05 13:53:20","679–688","","","","","","SemEval-2018 Task 7","","","","","Association for Computational Linguistics","New Orleans, Louisiana","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/FHTNUV4V/Gábor et al. - 2018 - SemEval-2018 Task 7 Semantic Relation Extraction and Classification in Scientific Papers.pdf","","EXAMPLE","","Apidianaki, Marianna; Mohammad, Saif M.; May, Jonathan; Shutova, Ekaterina; Bethard, Steven; Carpuat, Marine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SemEval 2018","","","","","","","","","","","","","","",""
"UJ5GUF8X","conferencePaper","2020","Jain, Sarthak; van Zuylen, Madeleine; Hajishirzi, Hannaneh; Beltagy, Iz","SciREX: A Challenge Dataset for Document-Level Information Extraction","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/2020.acl-main.670","https://aclanthology.org/2020.acl-main.670","Extracting information from full documents is an important problem in many domains, but most previous work focus on identifying relationships within a sentence or a paragraph. It is challenging to create a large-scale information extraction (IE) dataset at the document level since it requires an understanding of the whole document to annotate entities and their document-level relationships that usually span beyond sentences or even sections. In this paper, we introduce SciREX, a document level IE dataset that encompasses multiple IE tasks, including salient entity identification and document level N-ary relation identification from scientific articles. We annotate our dataset by integrating automatic and human annotations, leveraging existing scientific knowledge resources. We develop a neural model as a strong baseline that extends previous state-of-the-art IE models to document-level IE. Analyzing the model performance shows a significant gap between human performance and current baselines, inviting the community to use our dataset as a challenge to develop document-level IE models. Our data and code are publicly available at https://github.com/allenai/SciREX .","2020-07","2025-02-06 08:47:21","2025-02-06 08:47:21","2023-02-28 16:23:56","7506–7516","","","","","","SciREX","","","","","Association for Computational Linguistics","Online","","True","","https://paperswithcode.com/paper/scirex-a-challenge-dataset-for-document-level","https: //github.com/allenai/SciREX","ACLWeb","","{'citing': ['10.1145/3340531.3412878', '10.1007/978-3-030-82322-1_5', '10.1007/s00799-021-00306-x', '10.1016/j.jbi.2021.103893', '10.3233/jifs-210982', '10.1007/s12559-021-09917-7', '10.1007/978-3-030-91669-5_35', '10.1007/s11192-022-04332-7', '10.3390/su14052802', '10.1109/jcdl52503.2021.00068', '10.1109/isi53945.2021.9624840', '10.1109/ijcnn52387.2021.9533869', '10.1145/3487553.3524637', '10.1145/3487553.3524654', '10.1007/s40747-022-00806-6', '10.1016/j.neucom.2022.11.064'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/8UW3CTJ6/Jain et al. - 2020 - SciREX A Challenge Dataset for Document-Level Inf.pdf","","FILTER_STEP; LANG:?; TASK:Relextract; GRANULARITY:Document; TASK:Ner; DOMAIN:Science; TASK:Coref; DATATYPEPROP:?; NBTYPEREL:?; SYNTHGENERATION_BIN:?; SELECTIONMETHOD:Automatic; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:?; SELECTIONMETHOD:Manual; NBDOC:10²","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2020","","","","","","","","","","","","","","",""
"FI7LU69R","conferencePaper","2018","Luan, Yi; He, Luheng; Ostendorf, Mari; Hajishirzi, Hannaneh","Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction","Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/D18-1360","https://aclanthology.org/D18-1360/","We introduce a multi-task setup of identifying entities, relations, and coreference clusters in scientific articles. We create SciERC, a dataset that includes annotations for all three tasks and develop a unified framework called SciIE with shared span representations. The multi-task setup reduces cascading errors between tasks and leverages cross-sentence relations through coreference links. Experiments show that our multi-task model outperforms previous models in scientific information extraction without using any domain-specific features. We further show that the framework supports construction of a scientific knowledge graph, which we use to analyze information in scientific literature.","2018-10","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-24 16:29:05","3219–3232","","","","","","SciERC","","","","","Association for Computational Linguistics","Brussels, Belgium","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/LPNITQSZ/Luan et al. - 2018 - Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Con.pdf","","EXAMPLE; FILTER_STEP","","Riloff, Ellen; Chiang, David; Hockenmaier, Julia; Tsujii, Jun'ichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2018","","","","","","","","","","","","","","",""
"ZGGV8QL4","conferencePaper","2021","Stoica, George; Platanios, Emmanouil Antonios; Póczos, Barnabás","Re-TACRED: Addressing Shortcomings of the TACRED Dataset","The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)","","","10.48550/arXiv.2104.08398","http://arxiv.org/abs/2104.08398","TACRED is one of the largest and most widely used sentence-level relation extraction datasets. Proposed models that are evaluated using this dataset consistently set new state-of-the-art performance. However, they still exhibit large error rates despite leveraging external knowledge and unsupervised pretraining on large text corpora. A recent study suggested that this may be due to poor dataset quality. The study observed that over 50% of the most challenging sentences from the development and test sets are incorrectly labeled and account for an average drop of 8% f1-score in model performance. However, this study was limited to a small biased sample of 5k (out of a total of 106k) sentences, substantially restricting the generalizability and broader implications of its findings. In this paper, we address these shortcomings by: (i) performing a comprehensive study over the whole TACRED dataset, (ii) proposing an improved crowdsourcing strategy and deploying it to re-annotate the whole dataset, and (iii) performing a thorough analysis to understand how correcting the TACRED annotations affects previously published results. After verification, we observed that 23.9% of TACRED labels are incorrect. Moreover, evaluating several models on our revised dataset yields an average f1-score improvement of 14.3% and helps uncover significant relationships between the different models (rather than simply offsetting or scaling their scores by a constant factor). Finally, aside from our analysis we also release Re-TACRED, a new completely re-annotated version of the TACRED dataset that can be used to perform reliable evaluation of relation extraction models.","2021-04-16","2025-02-06 08:47:21","2025-02-06 08:47:21","2023-02-27 14:11:26","","","","","","","ReTACRED","","","","","AAAI","","","FALSE","","https://paperswithcode.com/paper/re-tacred-addressing-shortcomings-of-the","https://github.com/gstoica27/Re-TACRED","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/9N75FA2R/Stoica et al. - 2021 - Re-TACRED Addressing Shortcomings of the TACRED D.pdf; /root/snap/zotero-snap/common/Zotero/storage/BGZCWVSU/2104.html","","EXAMPLE; FILTER_STEP; TASK:Relextract; GRANULARITY:Sentences; LANG:English; DOMAIN:Web; DATATYPEPROP:?; SYNTHGENERATION_BIN:?; NBTYPEREL:10¹; NBDOC:?; NBENTITY:?; NBTRIPLES:?; SOURCE:?; DOMAIN:News; NBSENT:10⁴; NBTYPEENTITY:10¹; SELECTIONMETHOD:Manual","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AAAI","","","","","","","","","","","","","","",""
"N3ACIMRI","conferencePaper","2023","Ali, Manzoor; Saleem, Muhammad; Moussallem, Diego; Sherif, Mohamed Ahmed; Ngonga Ngomo, Axel-Cyrille","RELD: A Knowledge Graph of Relation Extraction Datasets","The Semantic Web","978-3-031-33454-2 978-3-031-33455-9","","10.1007/978-3-031-33455-9_20","https://link.springer.com/10.1007/978-3-031-33455-9_20","Relation extraction plays an important role in natural language processing. There is a wide range of available datasets that benchmark existing relation extraction approaches. However, most benchmarking datasets are provided in different formats containing specific annotation rules, thus making it difficult to conduct experiments on different types of relation extraction approaches. We present RELD, an RDF knowledge graph of eight open-licensed and publicly available relation extraction datasets. We modeled the benchmarking datasets into a single ontology that provides a unified format for data access, along with annotations required for training different types of relation extraction systems. Moreover, RELD abides by the Linked Data principles. To the best of our knowledge, RELD is the largest RDF knowledge graph of entities and relations from text, containing ∼1230 million triples describing 1034 relations, 2 million sentences, 3 million abstracts and 4013 documents. RELD contributes to a variety of uses in the natural language processing community, and distinctly provides unified and easy modeling of data for benchmarking relation extraction and named entity recognition models.","2023","2025-02-06 08:47:21","2025-02-06 08:47:21","2023-05-30 18:18:10","337-353","","","13870","","","RELD","","","","","Springer Nature Switzerland","Cham","en","True","","","https://github.com/dice-group/RELD","DOI.org (Crossref)","","","","/root/snap/zotero-snap/common/Zotero/storage/WIYVRWRW/Ali et al. - 2023 - RELD A Knowledge Graph of Relation Extraction Dat.pdf","","DOMAIN:?; LANG:?; TASK:Relextract; GRANULARITY:Document; GRANULARITY:Sentences; TASK:Ner; DATATYPEPROP:?; NBTYPEREL:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBENTITY:?; NBTYPEENTITY:?; SOURCE:?; NBDOC:10³; NBSENT:10⁶; NBDOC:10⁶; NBTRIPLES:10⁹","","Pesquita, Catia; Jimenez-Ruiz, Ernesto; McCusker, Jamie; Faria, Daniel; Dragoni, Mauro; Dimou, Anastasia; Troncy, Raphael; Hertling, Sven","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C2MESRTQ","conferencePaper","2020",", Abdullatif K{\""o}ksal; , Arzucan {\""O}zg{\""u}r","The RELX Dataset and Matching the Multilingual Blanks for Cross-Lingual Relation Classification","","","","10.18653/v1/2020.findings-emnlp.32","https://aclanthology.org/2020.findings-emnlp.32","Relation classification is one of the key topics in information extraction, which can be used to construct knowledge bases or to provide useful information for question answering. Current approaches for relation classification are mainly focused on the English language and require lots of training data with human annotations. Creating and annotating a large amount of training data for low-resource languages is impractical and expensive. To overcome this issue, we propose two cross-lingual relation classification models: a baseline model based on Multilingual BERT and a new multilingual pretraining setup, which significantly improves the baseline with distant supervision. For evaluation, we introduce a new public benchmark dataset for cross-lingual relation classification in English, French, German, Spanish, and Turkish, called RELX. We also provide the RELX-Distant dataset, which includes hundreds of thousands of sentences with relations from Wikipedia and Wikidata collected by distant supervision for these languages. Our code and data are available at: https://github.com/boun-tabi/RELX","2020-11-01","2025-02-06 08:47:21","2025-02-06 08:47:21","","NA","","","NA","","","RELX","","","","","ACL","","","True","","https://paperswithcode.com/paper/the-relx-dataset-and-matching-the-1","https://github.com/boun-tabi/RELX","","","","","","","SAT_model:BERT; SAT_oldTag:CHECKED0923; SAT_task:QA; SAT_granularity:sentence; SAT_task:RC; SAT_lang:multi; SAT_task:NER; SAT_source:Wikidata; SAT_source:Wikipedia; SAT_lang:english; SAT_lang:french; SAT_lang:german; SAT_lang:spanish; SAT_method_selection:Distant; SAT_lang:turkish; SAT_extend: KBP-37; SAT_nbtypes_relations:37; SAT_nbtypes_relations:24; SAT_nbSent:2575582; havecode; SAT_task:Classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings of the Association for Computational Linguistics 2020","","","","","","","","","","","","","","",""
"KRIYUPIH","conferencePaper","2021","Huguet Cabot, Pere-Lluís; Navigli, Roberto","REBEL: Relation Extraction By End-to-end Language generation","Findings of the Association for Computational Linguistics: EMNLP 2021","","","10.18653/v1/2021.findings-emnlp.204","https://aclanthology.org/2021.findings-emnlp.204","Extracting relation triplets from raw text is a crucial task in Information Extraction, enabling multiple applications such as populating or validating knowledge bases, factchecking, and other downstream tasks. However, it usually involves multiple-step pipelines that propagate errors or are limited to a small number of relation types. To overcome these issues, we propose the use of autoregressive seq2seq models. Such models have previously been shown to perform well not only in language generation, but also in NLU tasks such as Entity Linking, thanks to their framing as seq2seq tasks. In this paper, we show how Relation Extraction can be simplified by expressing triplets as a sequence of text and we present REBEL, a seq2seq model based on BART that performs end-to-end relation extraction for more than 200 different relation types. We show our model’s flexibility by fine-tuning it on an array of Relation Extraction and Relation Classification benchmarks, with it attaining state-of-the-art performance in most of them.","2021","2025-02-06 08:47:21","2025-02-06 08:47:21","2023-02-27 14:10:56","2370-2381","","","","","","REBEL","","","","","Association for Computational Linguistics","Punta Cana, Dominican Republic","en","True","","https://paperswithcode.com/paper/rebel-relation-extraction-by-end-to-end","https://github.com/Babelscape/rebel/","DOI.org (Crossref)","","{'citing': ['10.1093/bib/bbac409', '10.1007/978-3-031-19433-7_37', '10.1145/3511808.3557323', '10.1016/j.jksuci.2022.08.038', '10.1093/bib/bbac409', '10.1007/978-3-031-19433-7_37', '10.1145/3511808.3557323', '10.1016/j.jksuci.2022.08.038'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/ZI3Z2A42/Huguet Cabot and Navigli - 2021 - REBEL Relation Extraction By End-to-end Language .pdf","","EXAMPLE; FILTER_STEP; TASK:Relclassif; TASK:Relextract; GRANULARITY:Document; GRANULARITY:Sentences; TASK:Endtoendre; LANG:English; SYNTHGENERATION_BIN:?; DATATYPEPROP:Date; DATATYPEPROP:String; NBTYPEREL:10²; SELECTIONMETHOD:Automatic; NBDOC:?; NBSENT:?; DOMAIN:Encyclo; NBENTITY:10⁴; NBENTITY:10⁵; NBTRIPLES:10⁵; NBTYPEENTITY:10³; SOURCE:Wikidata; SOURCE:Wikipedia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings of the Association for Computational Linguistics: EMNLP 2021","","","","","","","","","","","","","","",""
"BAGZYS7U","conferencePaper","2022","Tan, Qingyu; Xu, Lu; Bing, Lidong; Ng, Hwee Tou; Aljunied, Sharifah Mahani","Revisiting DocRED -- Addressing the False Negative Problem in Relation Extraction","Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","","","10.48550/arxiv.2205.12696","http://arxiv.org/abs/2205.12696","The DocRED dataset is one of the most popular and widely used benchmarks for document-level relation extraction (RE). It adopts a recommend-revise annotation scheme so as to have a large-scale annotated dataset. However, we find that the annotation of DocRED is incomplete, i.e., false negative samples are prevalent. We analyze the causes and effects of the overwhelming false negative problem in the DocRED dataset. To address the shortcoming, we re-annotate 4,053 documents in the DocRED dataset by adding the missed relation triples back to the original DocRED. We name our revised DocRED dataset Re-DocRED. We conduct extensive experiments with state-of-the-art neural models on both datasets, and the experimental results show that the models trained and evaluated on our Re-DocRED achieve performance improvements of around 13 F1 points. Moreover, we conduct a comprehensive analysis to identify the potential areas for further improvement. Our dataset is publicly available at https://github.com/tonytan48/Re-DocRED.","2022-10-25","2025-02-06 08:47:21","2025-02-06 08:47:21","2023-03-22 11:23:39","8472--8487","","","","","","ReDocRED","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates","en","True","","https://paperswithcode.com/paper/revisiting-docred-addressing-the-overlooked","https://github.com/tonytan48/Re-DocRED","arXiv.org","","","","/root/snap/zotero-snap/common/Zotero/storage/6TFAN5RE/Tan et al. - 2022 - Revisiting DocRED -- Addressing the False Negative.pdf","","FILTER_STEP; DOMAIN:?; LANG:?; TASK:Relextract; GRANULARITY:Document; TASK:Coref; DATATYPEPROP:?; SYNTHGENERATION_BIN:?; NBTYPEREL:10²; SELECTIONMETHOD:Automatic; NBDOC:?; NBENTITY:?; NBSENT:?; SOURCE:?; NBTRIPLES:10⁵; SELECTIONMETHOD:Manual; NBTYPEENTITY:10⁰","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4EWW3Z9","conferencePaper","2023","Cabot, Pere-Lluís Huguet; Tedeschi, Simone; Ngomo, Axel-Cyrille Ngonga; Navigli, Roberto","RED$^{\rm FM}$: a Filtered and Multilingual Relation Extraction Dataset","","","","10.18653/v1/2023.acl-long.237","https://aclanthology.org/2023.acl-long.237/","Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English.","2023-06-19","2025-02-06 08:47:21","2025-02-06 08:47:21","2023-07-21 16:01:56","","","","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","REDfm","","","","","ACL","","en","True","","https://paperswithcode.com/paper/red-rm-fm-a-filtered-and-multilingual","https://github.com/babelscape/rebel","arXiv.org","[{""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""64.3"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""80.1"", ""metric"": ""RE Macro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""59.6"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""88.6"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""59.6"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""64.3"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""No"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""ALBERT"", ""metric"": ""Sentence Encoder""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""89.7"", ""metric"": ""NER Macro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""67.6"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""No"", ""metric"": ""Cross Sentence""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""63.3"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""Adverse Drug Events (ADE) Corpus"", ""res"": ""80.1"", ""metric"": ""RE+ Macro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2004"", ""res"": ""63.3"", ""metric"": ""RE Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""89.5"", ""metric"": ""NER Micro F1""}, {""task"": ""Relation Extraction"", ""dataset"": ""ACE 2005"", ""res"": ""67.6"", ""metric"": ""RE+ Micro F1""}, {""task"": ""Zero-shot Relation Triplet Extraction"", ""dataset"": ""Wiki-ZSL"", ""res"": ""6.4"", ""metric"": ""Avg. F1""}, {""task"": ""Zero-shot Relation Triplet Extraction"", ""dataset"": ""FewRel"", ""res"": ""6.37"", ""metric"": ""Avg. F1""}]","","","","","DONE; TASK:Relclassif; TASK:Relextract; GRANULARITY:Sentences; LANG:Multi; LANG:Arabic; LANG:Chinese; LANG:English; LANG:German; LANG:Greek; DOMAIN:General; PTM:Bart; TASK:Entitytyping; DATASET:Rebel; DATATYPEPROP:Date; DATATYPEPROP:String; INPUT:Text; LEARNINGMETHOD:Finetuning; LINEARIZEDGRAPH_BIN:1; NBTYPEREL:10²; SELECTIONMETHOD:Automatic; USENEGATIVEEXAMPLE_BIN:0; NBTYPEREL:10¹; DOMAIN:Encyclo; NBENTITY:10⁴; SOURCE:Wikidata; SOURCE:Wikipedia; NBSENT:10⁴; NBTYPEENTITY:10¹; SELECTIONMETHOD:Manual; LANG:French; LANG:Spanish; LANG:Dutch; LANG:Russian; LANG:Italian; LANG:Polish; LANG:Portuguese; DATATYPEPROP:Number; PTM:Mbart; COSTEVAL_BIN:0; DECODINGMETHOD_BIN:0; LOSSUPDATE_BIN:0; SYNTHGENERATION_BIN:0; NBDATASET:2; LANG:Catalan; LANG:Hindi; LANG:Japanese; LANG:Korean; LANG:Swedish; LANG:Vietnamese; OBJECTPROPERTIES_BIN:0; NBTRIPLES:10⁷","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3B85XR28","preprint","2018","Zhang, Sheng; Liu, Xiaodong; Liu, Jingjing; Gao, Jianfeng; Duh, Kevin; Durme, Benjamin Van","ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension","","","","10.48550/arXiv.1810.12885","http://arxiv.org/abs/1810.12885","We present a large-scale dataset, ReCoRD, for machine reading comprehension requiring commonsense reasoning. Experiments on this dataset demonstrate that the performance of state-of-the-art MRC systems fall far behind human performance. ReCoRD represents a challenge for future research to bridge the gap between human and machine commonsense reading comprehension. ReCoRD is available at http://nlp.jhu.edu/record.","2018-10-30","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 11:11:40","","","","","","","ReCoRD","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1810.12885 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/43BFCSP9/Zhang et al. - 2018 - ReCoRD Bridging the Gap between Human and Machine Commonsense Reading Comprehension.pdf; /root/snap/zotero-snap/common/Zotero/storage/TTGKVBNY/1810.html","","FILTER_STEP","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:1810.12885","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NDMT3IYA","journalArticle","","Roder, Michael; Usbeck, Ricardo; Hellmann, Sebastian; Gerber, Daniel; Both, Andreas","N3 - A Collection of Datasets for Named Entity Recognition and Disambiguation in the NLP Interchange Format","","","","","","Extracting Linked Data following the Semantic Web principle from unstructured sources has become a key challenge for scientiﬁc research. Named Entity Recognition and Disambiguation are two basic operations in this extraction process. One step towards the realization of the Semantic Web vision and the development of highly accurate tools is the availability of data for validating the quality of processes for Named Entity Recognition and Disambiguation as well as for algorithm tuning. This article presents three novel, manually curated and annotated corpora (N3). All of them are based on a free license and stored in the NLP Interchange Format to leverage the Linked Data character of our datasets.","","2025-02-06 08:47:21","2025-02-06 08:47:21","","","","","","","","R128","","","","","","","en","","","","","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/Z5PJZWMG/Roder et al. - N3 - A Collection of Datasets for Named Entity Recognition and Disambiguation in the NLP Interchange.pdf","","FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FV4NNM37","conferencePaper","2019","Dasigi, Pradeep; Liu, Nelson F.; Marasović, Ana; Smith, Noah A.; Gardner, Matt","Quoref: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","10.18653/v1/D19-1606","https://aclanthology.org/D19-1606/","Machine comprehension of texts longer than a single sentence often requires coreference resolution. However, most current reading comprehension benchmarks do not contain complex coreferential phenomena and hence fail to evaluate the ability of models to resolve coreference. We present a new crowdsourced dataset containing more than 24K span-selection questions that require resolving coreference among entities in over 4.7K English paragraphs from Wikipedia. Obtaining questions focused on such phenomena is challenging, because it is hard to avoid lexical cues that shortcut complex reasoning. We deal with this issue by using a strong baseline model as an adversary in the crowdsourcing loop, which helps crowdworkers avoid writing questions with exploitable surface cues. We show that state-of-the-art reading comprehension models perform significantly worse than humans on this benchmark—the best model performance is 70.5 F1, while the estimated human performance is 93.4 F1.","2019-11","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 13:19:00","5925–5932","","","","","","Quoref","","","","","Association for Computational Linguistics","Hong Kong, China","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/CV6QW9U8/Dasigi et al. - 2019 - Quoref A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning.pdf","","FILTER_STEP","","Inui, Kentaro; Jiang, Jing; Ng, Vincent; Wan, Xiaojun","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP-IJCNLP 2019","","","","","","","","","","","","","","",""
"4HDCXM3Y","conferencePaper","2013","Xu, Ying; Kim, Mi-Young; Quinn, Kevin; Goebel, Randy; Barbosa, Denilson","Open Information Extraction with Tree Kernels","Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","","https://aclanthology.org/N13-1107/","","2013-06","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 11:04:46","868–877","","","","","","PENN","","","","","Association for Computational Linguistics","Atlanta, Georgia","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/ET76Q2DE/Xu et al. - 2013 - Open Information Extraction with Tree Kernels.pdf","","FILTER_STEP","","Vanderwende, Lucy; Daumé III, Hal; Kirchhoff, Katrin","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL-HLT 2013","","","","","","","","","","","","","","",""
"33UIXYF3","conferencePaper","2008","Prasad, Rashmi; Dinesh, Nikhil; Lee, Alan; Miltsakaki, Eleni; Robaldo, Livio; Joshi, Aravind; Webber, Bonnie","The Penn Discourse TreeBank 2.0.","Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC`08)","","","","https://aclanthology.org/L08-1093/","We present the second version of the Penn Discourse Treebank, PDTB-2.0, describing its lexically-grounded annotations of discourse relations and their two abstract object arguments over the 1 million word Wall Street Journal corpus. We describe all aspects of the annotation, including (a) the argument structure of discourse relations, (b) the sense annotation of the relations, and (c) the attribution of discourse relations and each of their arguments. We list the differences between PDTB-1.0 and PDTB-2.0. We present representative statistics for several aspects of the annotation in the corpus.","2008-05","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:44:11","","","","","","","PDTB2","","","","","European Language Resources Association (ELRA)","Marrakech, Morocco","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/89CVQA8S/Prasad et al. - 2008 - The Penn Discourse TreeBank 2.0..pdf","","FILTER_STEP","","Calzolari, Nicoletta; Choukri, Khalid; Maegaard, Bente; Mariani, Joseph; Odijk, Jan; Piperidis, Stelios; Tapias, Daniel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LREC 2008","","","","","","","","","","","","","","",""
"8YJ42MRT","conferencePaper","2020","Kim, Najoung; Feng, Song; Gunasekara, Chulaka; Lastras, Luis","Implicit Discourse Relation Classification: We Need to Talk about Evaluation","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/2020.acl-main.480","https://aclanthology.org/2020.acl-main.480/","Implicit relation classification on Penn Discourse TreeBank (PDTB) 2.0 is a common benchmark task for evaluating the understanding of discourse relations. However, the lack of consistency in preprocessing and evaluation poses challenges to fair comparison of results in the literature. In this work, we highlight these inconsistencies and propose an improved evaluation protocol. Paired with this protocol, we report strong baseline results from pretrained sentence encoders, which set the new state-of-the-art for PDTB 2.0. Furthermore, this work is the first to explore fine-grained relation classification on PDTB 3.0. We expect our work to serve as a point of comparison for future work, and also as an initiative to discuss models of larger context and possible data augmentations for downstream transferability.","2020-07","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:44:16","5404–5414","","","","","","PDTB3","","","","","Association for Computational Linguistics","Online","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/EUAAZSDK/Kim et al. - 2020 - Implicit Discourse Relation Classification We Need to Talk about Evaluation.pdf","","FILTER_STEP","","Jurafsky, Dan; Chai, Joyce; Schluter, Natalie; Tetreault, Joel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2020","","","","","","","","","","","","","","",""
"DZM9GF5U","conferencePaper","2018","Choi, Eunsol; Levy, Omer; Choi, Yejin; Zettlemoyer, Luke","Ultra-Fine Entity Typing","Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/P18-1009","https://aclanthology.org/P18-1009/","We introduce a new entity typing task: given a sentence with an entity mention, the goal is to predict a set of free-form phrases (e.g. skyscraper, songwriter, or criminal) that describe appropriate types for the target entity. This formulation allows us to use a new type of distant supervision at large scale: head words, which indicate the type of the noun phrases they appear in. We show that these ultra-fine types can be crowd-sourced, and introduce new evaluation sets that are much more diverse and fine-grained than existing benchmarks. We present a model that can predict ultra-fine types, and is trained using a multitask objective that pools our new head-word supervision with prior supervision from entity linking. Experimental results demonstrate that our model is effective in predicting entity types at varying granularity; it achieves state of the art performance on an existing fine-grained entity typing benchmark, and sets baselines for our newly-introduced datasets.","2018-07","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 11:13:14","87–96","","","","","","OPENENTITY","","","","","Association for Computational Linguistics","Melbourne, Australia","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/WADCF6Y2/Choi et al. - 2018 - Ultra-Fine Entity Typing.pdf","","FILTER_STEP","","Gurevych, Iryna; Miyao, Yusuke","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2018","","","","","","","","","","","","","","",""
"KHUWEF5C","conferencePaper","2013","Pradhan, Sameer; Moschitti, Alessandro; Xue, Nianwen; Ng, Hwee Tou; Björkelund, Anders; Uryupina, Olga; Zhang, Yuchen; Zhong, Zhi","Towards Robust Linguistic Analysis using OntoNotes","Proceedings of the Seventeenth Conference on Computational Natural Language Learning","","","","https://aclanthology.org/W13-3516/","","2013-08","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 11:02:42","143–152","","","","","","ONTONOTES","","","","","Association for Computational Linguistics","Sofia, Bulgaria","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/6YBLT8C9/Pradhan et al. - 2013 - Towards Robust Linguistic Analysis using OntoNotes.pdf","","FILTER_STEP","","Hockenmaier, Julia; Riedel, Sebastian","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CoNLL 2013","","","","","","","","","","","","","","",""
"CYWT9ML9","conferencePaper","2011","Hoffmann, Raphael; Zhang, Congle; Ling, Xiao; Zettlemoyer, Luke; Weld, Daniel S.","Knowledge-based weak supervision for information extraction of overlapping relations","Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1","978-1-932432-87-9","","","","Information extraction (IE) holds the promise of generating a large-scale knowledge base from the Web's natural language text. Knowledge-based weak supervision, using structured data to heuristically label a training corpus, works towards this goal by enabling the automated learning of a potentially unbounded number of relation extractors. Recently, researchers have developed multi-instance learning algorithms to combat the noisy training data that can come from heuristic labeling, but their models assume relations are disjoint --- for example they cannot extract the pair Founded(Jobs, Apple) and CEO-of(Jobs, Apple).This paper presents a novel approach for multi-instance learning with overlapping relations that combines a sentence-level extraction model with a simple, corpus-level component for aggregating the individual facts. We apply our model to learn extractors for NY Times text using weak supervision from Free-base. Experiments show that the approach runs quickly and yields surprising gains in accuracy, at both the aggregate and sentence level.","2011-06-19","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-24","541–550","","","","","","NYT11","HLT '11","","","","Association for Computational Linguistics","USA","","","","","","ACM Digital Library","","","","/root/snap/zotero-snap/common/Zotero/storage/QPX5DGIN/Hoffmann et al. - 2011 - Knowledge-based weak supervision for information extraction of overlapping relations.pdf","","EXAMPLE; FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PBYDTMR9","preprint","2019","Gashteovski, Kiril; Wanner, Sebastian; Hertling, Sven; Broscheit, Samuel; Gemulla, Rainer","OPIEC: An Open Information Extraction Corpus","","","","10.48550/arXiv.1904.12324","http://arxiv.org/abs/1904.12324","Open information extraction (OIE) systems extract relations and their arguments from natural language text in an unsupervised manner. The resulting extractions are a valuable resource for downstream tasks such as knowledge base construction, open question answering, or event schema induction. In this paper, we release, describe, and analyze an OIE corpus called OPIEC, which was extracted from the text of English Wikipedia. OPIEC complements the available OIE resources: It is the largest OIE corpus publicly available to date (over 340M triples) and contains valuable metadata such as provenance information, confidence scores, linguistic annotations, and semantic annotations including spatial and temporal information. We analyze the OPIEC corpus by comparing its content with knowledge bases such as DBpedia or YAGO, which are also based on Wikipedia. We found that most of the facts between entities present in OPIEC cannot be found in DBpedia and/or YAGO, that OIE facts often differ in the level of specificity compared to knowledge base facts, and that OIE open relations are generally highly polysemous. We believe that the OPIEC corpus is a valuable resource for future research on automated knowledge base construction.","2019-04-28","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 11:01:58","","","","","","","OPIEC","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1904.12324 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/Z47LYABD/Gashteovski et al. - 2019 - OPIEC An Open Information Extraction Corpus.pdf; /root/snap/zotero-snap/common/Zotero/storage/S6TVG9IW/1904.html","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:1904.12324","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QU9MWEEA","conferencePaper","2015","Nuzzolese, Andrea Giovanni; Gentile, Anna Lisa; Presutti, Valentina; Gangemi, Aldo; Garigliotti, Darío; Navigli, Roberto","Open Knowledge Extraction Challenge","Semantic Web Evaluation Challenges","978-3-319-25518-7","","10.1007/978-3-319-25518-7_1","","The Open Knowledge Extraction (OKE) challenge is aimed at promoting research in the automatic extraction of structured content from textual data and its representation and publication as Linked Data. We designed two extraction tasks: (1) Entity Recognition, Linking and Typing and (2) Class Induction and entity typing. The challenge saw the participations of four systems: CETUS-FOX and FRED participating to both tasks, Adel participating to Task 1 and OAK@Sheffield participating to Task 2. In this paper we describe the OKE challenge, the tasks, the datasets used for training and evaluating the systems, the evaluation method, and obtained results.","2015","2025-02-06 08:47:21","2025-02-06 08:47:21","","3-15","","","","","","OKE","","","","","Springer International Publishing","Cham","en","","","","","Springer Link","","","","","","FILTER_STEP","","Gandon, Fabien; Cabrio, Elena; Stankovic, Milan; Zimmermann, Antoine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A728IDTB","conferencePaper","2010","Riedel, Sebastian; Yao, Limin; McCallum, Andrew","Modeling relations and their mentions without labeled text","Proceedings of the 2010th European Conference on Machine Learning and Knowledge Discovery in Databases - Volume Part III","978-3-642-15938-1","","10.1007/978-3-642-15939-8_10","https://doi.org/10.1007/978-3-642-15939-8_10","Several recent works on relation extraction have been applying the distant supervision paradigm: instead of relying on annotated text to learn how to predict relations, they employ existing knowledge bases (KBs) as source of supervision. Crucially, these approaches are trained based on the assumption that each sentence which mentions the two related entities is an expression of the given relation. Here we argue that this leads to noisy patterns that hurt precision, in particular if the knowledge base is not directly related to the text we are working with. We present a novel approach to distant supervision that can alleviate this problem based on the following two ideas: First, we use a factor graph to explicitly model the decision whether two entities are related, and the decision whether this relation is mentioned in a given sentence; second, we apply constraint-driven semi-supervision to train this model without any knowledge about which sentences express the relations in our training KB. We apply our approach to extract relations from the New York Times corpus and use Freebase as knowledge base. When compared to a state-of-the-art approach for relation extraction under distant supervision, we achieve 31% error reduction.","2010-09-20","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-24","148–163","","","","","","NYT10","ECMLPKDD'10","","","","Springer-Verlag","Berlin, Heidelberg","","","","","","ACM Digital Library","","","","/root/snap/zotero-snap/common/Zotero/storage/FYWKDD9G/Riedel et al. - 2010 - Modeling relations and their mentions without labeled text.pdf","","EXAMPLE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YGF9BIIN","conferencePaper","2018","Zeng, Xiangrong; Zeng, Daojian; He, Shizhu; Liu, Kang; Zhao, Jun","Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism","Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/P18-1047","http://aclweb.org/anthology/P18-1047","The relational facts in sentences are often complicated. Different relational triplets may have overlaps in a sentence. We divided the sentences into three types according to triplet overlap degree, including Normal, EntityPairOverlap and SingleEntiyOverlap. Existing methods mainly focus on Normal class and fail to extract relational triplets precisely. In this paper, we propose an end-to-end model based on sequence-to-sequence learning with copy mechanism, which can jointly extract relational facts from sentences of any of these classes. We adopt two different strategies in decoding process: employing only one united decoder or applying multiple separated decoders. We test our models in two public datasets and our model outperform the baseline method signiﬁcantly.","2018","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:41:36","506-514","","","","","","NYT-MULTI","","","","","Association for Computational Linguistics","Melbourne, Australia","en","","","","","DOI.org (Crossref)","","","","/root/snap/zotero-snap/common/Zotero/storage/T4S7W7PG/Zeng et al. - 2018 - Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism.pdf","","FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","","","","","","","","","","","","",""
"7NWYKB3L","journalArticle","2016","Marcheggiani, Diego; Titov, Ivan","Discrete-State Variational Autoencoders for Joint Discovery and Factorization of Relations","Transactions of the Association for Computational Linguistics","","2307-387X","10.1162/tacl_a_00095","https://doi.org/10.1162/tacl_a_00095","We present a method for unsupervised open-domain relation discovery. In contrast to previous (mostly generative and agglomerative clustering) approaches, our model relies on rich contextual features and makes minimal independence assumptions. The model is composed of two parts: a feature-rich relation extractor, which predicts a semantic relation between two entities, and a factorization model, which reconstructs arguments (i.e., the entities) relying on the predicted relation. The two components are estimated jointly so as to minimize errors in recovering arguments. We study factorization models inspired by previous work in relation factorization and selectional preference modeling. Our models substantially outperform the generative and agglomerative-clustering counterparts and achieve state-of-the-art performance.","2016-06-01","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-28 18:20:31","231-244","","","4","","Transactions of the Association for Computational Linguistics","NYT-FB","","","","","","","","","","","","Silverchair","","","","/root/snap/zotero-snap/common/Zotero/storage/ECTAIGLG/Marcheggiani and Titov - 2016 - Discrete-State Variational Autoencoders for Joint Discovery and Factorization of Relations.pdf","","EXAMPLE; FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K5H7FSF8","conferencePaper","2020",", Tong Zhu 0002; , Haitao Wang 0019; , Junjie Yu; , Xiabing Zhou; , Wenliang Chen; , Wei Zhang 0027; , Min Zhang 0005","Towards Accurate and Consistent Evaluation: A Dataset for Distantly-Supervised Relation Extraction.","","","","10.18653/V1/2020.COLING-MAIN.566","https://dblp.org/rec/journals/corr/abs-2010-16275","nan","2020","2025-02-06 08:47:21","2025-02-06 08:47:21","","6436-6447","","","nan","","","NYT-H","","","","","nan","","","open","","DBLP","1935032","","","","","/root/snap/zotero-snap/common/Zotero/storage/834VUHWY/et al. - 2020 - Towards Accurate and Consistent Evaluation A Dataset for Distantly-Supervised Relation Extraction..pdf","","FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","COLING","","","","","","","","","","","","","","",""
"68YTVV4S","conferencePaper","2021",", Natalia Loukachevitch; , Ekaterina Artemova; , Tatiana Batura; , Pavel Braslavski; , Ilia Denisov; , Vladimir Ivanov; , Suresh Manandhar; , Alexander Pugachev; , Elena Tutubalina","NEREL: A Russian Dataset with Nested Named Entities, Relations and Events","","","","10.26615/978-954-452-072-4_100","https://arxiv.org/abs/2108.13112v2","In this paper, we present NEREL, a Russian dataset for named entity recognition and relation extraction. NEREL is significantly larger than existing Russian datasets: to date it contains 56K annotated named entities and 39K annotated relations. Its important difference from previous datasets is annotation of nested named entities, as well as relations within nested entities and at the discourse level. NEREL can facilitate development of novel models that can extract relations between nested named entities, as well as relations on both sentence and document levels. NEREL also contains the annotation of events involving named entities and their roles in the events. The NEREL collection is available via https://github.com/nerel-ds/NEREL.","2021-08-30","2025-02-06 08:47:21","2025-02-06 08:47:21","","NA","","","NA","","","NEREL","","","","","Incoma Ltd","","","True","","https://paperswithcode.com/paper/nerel-a-russian-dataset-with-nested-named","https://github.com/nerel-ds/NEREL","","","","","/root/snap/zotero-snap/common/Zotero/storage/4C4ELBI4/ et al. - 2021 - NEREL A Russian Dataset with Nested Named Entitie.pdf","","DOMAIN:?; TASK:Relextract; GRANULARITY:Document; TASK:Ner; DATATYPEPROP:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBTYPEREL:10¹; NBDOC:?; NBSENT:?; NBENTITY:10⁴; NBTYPEENTITY:10¹; NBTRIPLES:10⁴; LANG:Russian; SOURCE:Wikinews","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","RANLP 2021 9","","","","","","","","","","","","","","",""
"P8CS7PME","journalArticle","2019","Kwiatkowski, Tom; Palomaki, Jennimaria; Redfield, Olivia; Collins, Michael; Parikh, Ankur; Alberti, Chris; Epstein, Danielle; Polosukhin, Illia; Devlin, Jacob; Lee, Kenton; Toutanova, Kristina; Jones, Llion; Kelcey, Matthew; Chang, Ming-Wei; Dai, Andrew M.; Uszkoreit, Jakob; Le, Quoc; Petrov, Slav","Natural Questions: A Benchmark for Question Answering Research","Transactions of the Association for Computational Linguistics","","","10.1162/tacl_a_00276","https://aclanthology.org/Q19-1026/","We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature.","2019","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-25 11:30:38","452–466","","","7","","","NATURALQA","","","","","","","","","","","","ACLWeb","","Place: Cambridge, MA Publisher: MIT Press","","/root/snap/zotero-snap/common/Zotero/storage/7ASUQUIF/Kwiatkowski et al. - 2019 - Natural Questions A Benchmark for Question Answering Research.pdf","","EXCLUDED; EXAMPLE; FILTER_STEP","","Lee, Lillian; Johnson, Mark; Roark, Brian; Nenkova, Ani","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PGE6SYT3","conferencePaper","2020","Eric, Mihail; Goel, Rahul; Paul, Shachi; Sethi, Abhishek; Agarwal, Sanchit; Gao, Shuyang; Kumar, Adarsh; Goyal, Anuj; Ku, Peter; Hakkani-Tur, Dilek","MultiWOZ 2.1: A Consolidated Multi-Domain Dialogue Dataset with State Corrections and State Tracking Baselines","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.53/","MultiWOZ 2.0 (Budzianowski et al., 2018) is a recently released multi-domain dialogue dataset spanning 7 distinct domains and containing over 10,000 dialogues. Though immensely useful and one of the largest resources of its kind to-date, MultiWOZ 2.0 has a few shortcomings. Firstly, there are substantial noise in the dialogue state annotations and dialogue utterances which negatively impact the performance of state-tracking models. Secondly, follow-up work (Lee et al., 2019) has augmented the original dataset with user dialogue acts. This leads to multiple co-existent versions of the same dataset with minor modifications. In this work we tackle the aforementioned issues by introducing MultiWOZ 2.1. To fix the noisy state annotations, we use crowdsourced workers to re-annotate state and utterances based on the original utterances in the dataset. This correction process results in changes to over 32% of state annotations across 40% of the dialogue turns. In addition, we fix 146 dialogue utterances by canonicalizing slot values in the utterances to the values in the dataset ontology. To address the second problem, we combined the contributions of the follow-up works into MultiWOZ 2.1. Hence, our dataset also includes user dialogue acts as well as multiple slot descriptions per dialogue state slot. We then benchmark a number of state-of-the-art dialogue state tracking models on the MultiWOZ 2.1 dataset and show the joint state tracking performance on the corrected state annotations. We are publicly releasing MultiWOZ 2.1 to the community, hoping that this dataset resource will allow for more effective models across various dialogue subproblems to be built in the future.","2020-05","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:20:25","422–428","","","","","","MultiWOZ","","","","","European Language Resources Association","Marseille, France","eng","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/BMPEJZ96/Eric et al. - 2020 - MultiWOZ 2.1 A Consolidated Multi-Domain Dialogue Dataset with State Corrections and State Tracking.pdf","","FILTER_STEP","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LREC 2020","","","","","","","","","","","","","","",""
"HHDWWTJU","conferencePaper","2023","Bassignana, Elisa; Ginter, Filip; Pyysalo, Sampo; van der Goot, Rob; Plank, Barbara","Multi-CrossRE A Multi-Lingual Multi-Domain Dataset for Relation Extraction","Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa)","","","not found","https://aclanthology.org/2023.nodalida-1.9","Most research in Relation Extraction (RE) involves the English language, mainly due to the lack of multi-lingual resources. We propose Multi-CrossRE, the broadest multi-lingual dataset for RE, including 26 languages in addition to English, and covering six text domains. Multi-CrossRE is a machine translated version of CrossRE (Bassignana and Plank, 2022), with a sub-portion including more than 200 sentences in seven diverse languages checked by native speakers. We run a baseline model over the 26 new datasets and–as sanity check–over the 26 back-translations to English. Results on the back-translated data are consistent with the ones on the original English CrossRE, indicating high quality of the translation and the resulting dataset.","2023-05","2025-02-06 08:47:21","2025-02-06 08:47:21","2023-10-09 16:10:11","80–85","","","","","","MultiCrossRE","","","","","University of Tartu Library","Tórshavn, Faroe Islands","","True","","","https://github.com/mainlp/CrossRE","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/9WH2JN2B/Bassignana et al. - 2023 - Multi-CrossRE A Multi-Lingual Multi-Domain Dataset.pdf","","GRANULARITY:?; TASK:Relextract; TASK:Ner; LANG:Multi; DOMAIN:Science; DATATYPEPROP:?; NBTYPEREL:?; SYNTHGENERATION_BIN:1; NBDOC:?; NBENTITY:?; NBTYPEENTITY:?; SOURCE:Wikipedia; DOMAIN:News; SELECTIONMETHOD:Manual; SOURCE:Dbpedia; NBTRIPLES:10⁶; DOMAIN:Litterature; DOMAIN:Politic; NBSENT:10³","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NoDaLiDa 2023","","","","","","","","","","","","","","",""
"BALBHQE6","journalArticle","2017","Peng, Nanyun; Poon, Hoifung; Quirk, Chris; Toutanova, Kristina; Yih, Wen-tau","Cross-Sentence N-ary Relation Extraction with Graph LSTMs","Transactions of the Association for Computational Linguistics","","","10.1162/tacl_a_00049","https://aclanthology.org/Q17-1008/","Past work in relation extraction has focused on binary relations in single sentences. Recent NLP inroads in high-value domains have sparked interest in the more general setting of extracting n-ary relations that span multiple sentences. In this paper, we explore a general relation extraction framework based on graph long short-term memory networks (graph LSTMs) that can be easily extended to cross-sentence n-ary relation extraction. The graph formulation provides a unified way of exploring different LSTM approaches and incorporating various intra-sentential and inter-sentential dependencies, such as sequential, syntactic, and discourse relations. A robust contextual representation is learned for the entities, which serves as input to the relation classifier. This simplifies handling of relations with arbitrary arity, and enables multi-task learning with related relations. We evaluate this framework in two important precision medicine settings, demonstrating its effectiveness with both conventional supervised learning and distant supervision. Cross-sentence extraction produced larger knowledge bases. and multi-task learning significantly improved extraction accuracy. A thorough analysis of various LSTM approaches yielded useful insight the impact of linguistic analysis on extraction accuracy.","2017","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:57:51","101–115","","","5","","","N-ARY","","","","","","","","","","","","ACLWeb","","Place: Cambridge, MA Publisher: MIT Press","","/root/snap/zotero-snap/common/Zotero/storage/ILWSSQX3/Peng et al. - 2017 - Cross-Sentence N-ary Relation Extraction with Graph LSTMs.pdf","","EXAMPLE; FILTER_STEP","","Lee, Lillian; Johnson, Mark; Toutanova, Kristina","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LD9IHYZX","dataset","","","Datasets","","","","","https://www.jmlr.org/papers/volume1/heckerman00a/html/node12.html","","","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:34:54","","","","","","","MSNBC","","","","","","","","","","","","","","","","","","FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LK6XAFMZ","conferencePaper","2021","Zheng, Changmeng; Wu, Zhiwei; Feng, Junhao; Fu, Ze; Cai, Yi","MNRE: A Challenge Multimodal Dataset for Neural Relation Extraction with Visual Evidence in Social Media Posts","2021 IEEE International Conference on Multimedia and Expo (ICME)","978-1-6654-3864-3","","10.1109/icme51207.2021.9428274","https://ieeexplore.ieee.org/document/9428274/","","2021-07-05","2025-02-06 08:47:21","2025-02-06 08:47:21","2023-05-11 14:17:37","1-6","","","","","","MNRE","","","","","IEEE","Shenzhen, China","","True","","","https://github.com/thecharm/MNRE","DOI.org (Crossref)","","{'citing': ['10.1145/3477495.3531992', '10.1109/icme52920.2022.9859972', '10.3390/app12199691'], 'cited': ['10.1007/s00500-020-04742-w', '10.1109/cvpr.2017.670', '10.18653/v1/d15-1203', '10.18653/v1/d15-1205', '10.18653/v1/d17-1004', '10.18653/v1/d17-1115', '10.18653/v1/d18-1514', '10.18653/v1/p18-1185', '10.18653/v1/p18-1208', '10.18653/v1/p19-1074', '10.18653/v1/p19-1279', '10.3115/1220175.1220279', '10.3115/1621969.1621986', '10.3115/v1/w15-1506']}","","","","FILTER_STEP; DOMAIN:?; GRANULARITY:?; LANG:?; TASK:Relextract; TASK:Ner; DATATYPEPROP:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBTYPEREL:10¹; NBDOC:?; NBTYPEENTITY:?; NBENTITY:10⁴; NBTRIPLES:10⁴; NBSENT:10³; SOURCE:Twitter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021 IEEE International Conference on Multimedia and Expo (ICME)","","","","","","","","","","","","","","",""
"8GGZQZTA","conferencePaper","2021","Zheng, Changmeng; Feng, Junhao; Fu, Ze; Cai, Yi; Li, Qing; Wang, Tao","Multimodal Relation Extraction with Efficient Graph Alignment","Proceedings of the 29th ACM International Conference on Multimedia","978-1-4503-8651-7","","10.1145/3474085.3476968","https://dl.acm.org/doi/10.1145/3474085.3476968","Relation extraction (RE) is a fundamental process in constructing knowledge graphs. However, previous methods on relation extraction suffer sharp performance decline in short and noisy social media texts due to a lack of contexts. Fortunately, the related visual contents (objects and their relations) in social media posts can supplement the missing semantics and help to extract relations precisely. We introduce the multimodal relation extraction (MRE), a task that identifies textual relations with visual clues. To tackle this problem, we present a large-scale dataset which contains 15000+ sentences with 23 pre-defined relation categories. Considering that the visual relations among objects are corresponding to textual relations, we develop a dual graph alignment method to capture this correlation for better performance. Experimental results demonstrate that visual contents help to identify relations more precisely against the text-only baselines. Besides, our alignment method can find the correlations between vision and language, resulting in better performance. Our dataset and code are available at https://github.com/thecharm/Mega.","2021-10-17","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:19:42","5298-5306","","","","","","MNRE","","","","","ACM","Virtual Event China","en","","","","","DOI.org (Crossref)","","","","/root/snap/zotero-snap/common/Zotero/storage/PIN8KCAJ/Zheng et al. - 2021 - Multimodal Relation Extraction with Efficient Graph Alignment.pdf","","FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","MM '21: ACM Multimedia Conference","","","","","","","","","","","","","","",""
"3XPCSE2B","dataset","2024","zhangyz","nlpir2020/MIE-ACL-2020","","","","","https://github.com/nlpir2020/MIE-ACL-2020","code&data for MIE: A Medical Information Extractor towards Medical Dialogues, ACL 2020","2024-12-12","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:10:17","","","","","","","MIE","","","","","","","","","","","","GitHub","","original-date: 2020-04-29T09:01:43Z","","","","FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6UDHMIX6","conferencePaper","2022","Lai, Viet Dac; Veyseh, Amir Pouran Ben; Nguyen, Minh Van; Dernoncourt, Franck; Nguyen, Thien Huu","MECI: A Multilingual Dataset for Event Causality Identification","Proceedings of the 29th International Conference on Computational Linguistics","","","","https://aclanthology.org/2022.coling-1.206/","Event Causality Identification (ECI) is the task of detecting causal relations between events mentioned in the text. Although this task has been extensively studied for English materials, it is under-explored for many other languages. A major reason for this issue is the lack of multilingual datasets that provide consistent annotations for event causality relations in multiple non-English languages. To address this issue, we introduce a new multilingual dataset for ECI, called MECI. The dataset employs consistent annotation guidelines for five typologically different languages, i.e., English, Danish, Spanish, Turkish, and Urdu. Our dataset thus enable a new research direction on cross-lingual transfer learning for ECI. Our extensive experiments demonstrate high quality for MECI that can provide ample research challenges and directions for future research. We will publicly release MECI to promote research on multilingual ECI.","2022-10","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:23:35","2346–2356","","","","","","MECI","","","","","International Committee on Computational Linguistics","Gyeongju, Republic of Korea","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/8AVFA472/Lai et al. - 2022 - MECI A Multilingual Dataset for Event Causality Identification.pdf","","FILTER_STEP","","Calzolari, Nicoletta; Huang, Chu-Ren; Kim, Hansaem; Pustejovsky, James; Wanner, Leo; Choi, Key-Sun; Ryu, Pum-Mo; Chen, Hsin-Hsi; Donatelli, Lucia; Ji, Heng; Kurohashi, Sadao; Paggio, Patrizia; Xue, Nianwen; Kim, Seokhwan; Hahm, Younggyun; He, Zhong; Lee, Tony Kyungil; Santus, Enrico; Bond, Francis; Na, Seung-Hoon","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","COLING 2022","","","","","","","","","","","","","","",""
"JWX4EBJB","journalArticle","2018","Li, Zhongyang; Ding, Xiao; Liu, Ting","Constructing Narrative Event Evolutionary Graph for Script Event Prediction","","","","","https://www.ijcai.org/proceedings/2018/584","Electronic proceedings of IJCAI 2018","2018","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 12:59:42","4201-4207","","","","","","mcnc","","","","","","","","","","","","www.ijcai.org","","","","","","FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VNF8XKJA","conferencePaper","2022",", Xiaozhi Wang; , Yulin Chen; , Ning Ding; , Hao Peng; , Zimu Wang; , Yankai Lin; , Xu Han; , Lei Hou; , Juanzi Li; , Zhiyuan Liu; , Peng Li; , Jie zhou","MAVEN-ERE: A Unified Large-scale Dataset for Event Coreference, Temporal, Causal, and Subevent Relation Extraction","Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","","","not found","https://arxiv.org/abs/2211.07342v1","The diverse relationships among real-world events, including coreference, temporal, causal, and subevent relations, are fundamental to understanding natural languages. However, two drawbacks of existing datasets limit event relation extraction (ERE) tasks: (1) Small scale. Due to the annotation complexity, the data scale of existing datasets is limited, which cannot well train and evaluate data-hungry models. (2) Absence of unified annotation. Different types of event relations naturally interact with each other, but existing datasets only cover limited relation types at once, which prevents models from taking full advantage of relation interactions. To address these issues, we construct a unified large-scale human-annotated ERE dataset MAVEN-ERE with improved annotation schemes. It contains 103,193 event coreference chains, 1,216,217 temporal relations, 57,992 causal relations, and 15,841 subevent relations, which is larger than existing datasets of all the ERE tasks by at least an order of magnitude. Experiments show that ERE on MAVEN-ERE is quite challenging, and considering relation interactions with joint learning can improve performances. The dataset and source codes can be obtained from https://github.com/THU-KEG/MAVEN-ERE.","2022-11-14","2025-02-06 08:47:21","2025-02-06 08:47:21","","926--941","","","","","","MAVEN-ERE","","","","","Association for Computational Linguistics","","","True","","https://paperswithcode.com/paper/maven-ere-a-unified-large-scale-dataset-for","https://github.com/THU-KEG/MAVEN-ERE","","","","","/root/snap/zotero-snap/common/Zotero/storage/39ZQWSKL/ et al. - 2022 - MAVEN-ERE A Unified Large-scale Dataset for Event.pdf","","EXAMPLE; FILTER_STEP; DOMAIN:?; LANG:?; TASK:Relextract; GRANULARITY:Document; TASK:Coref; DATATYPEPROP:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBTYPEREL:10¹; NBTRIPLES:?; SOURCE:?; NBENTITY:10⁴; NBSENT:10⁴; NBTYPEENTITY:10¹; NBTYPEENTITY:10⁰; NBDOC:10³","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP","","","","","","","","","","","","","","",""
"3EGC5YCI","conferencePaper","2019","Han, Rujun; Ning, Qiang; Peng, Nanyun","Joint Event and Temporal Relation Extraction with Shared Representations and Structured Prediction","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","10.18653/v1/D19-1041","https://aclanthology.org/D19-1041/","We propose a joint event and temporal relation extraction model with shared representation learning and structured prediction. The proposed method has two advantages over existing work. First, it improves event representation by allowing the event and relation modules to share the same contextualized embeddings and neural representation learner. Second, it avoids error propagation in the conventional pipeline systems by leveraging structured inference and learning methods to assign both the event labels and the temporal relation labels jointly. Experiments show that the proposed method can improve both event extraction and temporal relation extraction over state-of-the-art systems, with the end-to-end F1 improved by 10% and 6.8% on two benchmark datasets respectively.","2019-11","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-25 11:26:10","434–444","","","","","","MATRES","","","","","Association for Computational Linguistics","Hong Kong, China","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/C5XREMLW/Han et al. - 2019 - Joint Event and Temporal Relation Extraction with Shared Representations and Structured Prediction.pdf","","EXAMPLE; FILTER_STEP","","Inui, Kentaro; Jiang, Jing; Ng, Vincent; Wan, Xiaojun","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP-IJCNLP 2019","","","","","","","","","","","","","","",""
"PG4ICMYH","conferencePaper","2019","Wang, Hong; Xiong, Wenhan; Yu, Mo; Guo, Xiaoxiao; Chang, Shiyu; Wang, William Yang","Sentence Embedding Alignment for Lifelong Relation Extraction","Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)","","","10.18653/v1/N19-1086","https://aclanthology.org/N19-1086/","Conventional approaches to relation extraction usually require a fixed set of pre-defined relations. Such requirement is hard to meet in many real applications, especially when new data and relations are emerging incessantly and it is computationally expensive to store all data and re-train the whole model every time new data and relations come in. We formulate such challenging problem as lifelong relation extraction and investigate memory-efficient incremental learning methods without catastrophically forgetting knowledge learned from previous tasks. We first investigate a modified version of the stochastic gradient methods with a replay memory, which surprisingly outperforms recent state-of-the-art lifelong learning methods. We further propose to improve this approach to alleviate the forgetting problem by anchoring the sentence embedding space. Specifically, we utilize an explicit alignment model to mitigate the sentence embedding distortion of learned model when training on new data and new relations. Experiment results on multiple benchmarks show that our proposed method significantly outperforms the state-of-the-art lifelong learning approaches.","2019-06","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:12:31","796–806","","","","","","LIFELONGSIMPLEQUESTIONS","","","","","Association for Computational Linguistics","Minneapolis, Minnesota","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/Z8AP4P2X/Wang et al. - 2019 - Sentence Embedding Alignment for Lifelong Relation Extraction.pdf","","EXAMPLE; FILTER_STEP","","Burstein, Jill; Doran, Christy; Solorio, Thamar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL-HLT 2019","","","","","","","","","","","","","","",""
"FYYLSCHQ","conferencePaper","2012","Hoffart, Johannes; Seufert, Stephan; Nguyen, Dat Ba; Theobald, Martin; Weikum, Gerhard","KORE: keyphrase overlap relatedness for entity disambiguation","Proceedings of the 21st ACM international conference on Information and knowledge management","978-1-4503-1156-4","","10.1145/2396761.2396832","https://doi.org/10.1145/2396761.2396832","Measuring the semantic relatedness between two entities is the basis for numerous tasks in IR, NLP, and Web-based knowledge extraction. This paper focuses on disambiguating names in a Web or text document by jointly mapping all names onto semantically related entities registered in a knowledge base. To this end, we have developed a novel notion of semantic relatedness between two entities represented as sets of weighted (multi-word) keyphrases, with consideration of partially overlapping phrases. This measure improves the quality of prior link-based models, and also eliminates the need for (usually Wikipedia-centric) explicit interlinkage between entities. Thus, our method is more versatile and can cope with long-tail and newly emerging entities that have few or no links associated with them. For efficiency, we have developed approximation techniques based on min-hash sketches and locality-sensitive hashing. Our experiments on semantic relatedness and on named entity disambiguation demonstrate the superiority of our method compared to state-of-the-art baselines.","2012-10-29","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30","545–554","","","","","","KORE","CIKM '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XFZYUTR4","conferencePaper","2019","Mesquita, Filipe; Cannaviccio, Matteo; Schmidek, Jordan; Mirza, Paramita; Barbosa, Denilson","KnowledgeNet: A Benchmark Dataset for Knowledge Base Population","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","10.18653/v1/d19-1069","https://www.aclweb.org/anthology/D19-1069","","2019","2025-02-06 08:47:21","2025-02-06 08:47:21","2023-02-27 15:22:13","749-758","","","","","","KnowledgeNet","","","","","Association for Computational Linguistics","Hong Kong, China","en","True","","https://paperswithcode.com/paper/knowledgenet-a-benchmark-dataset-for","https://github.com/diffbot/knowledge-net","DOI.org (Crossref)","","{'citing': ['10.14778/3384345.3384352', '10.1007/s10115-020-01502-y', '10.1145/3340531.3412164', '10.1007/978-3-030-62419-4_11', '10.1016/j.websem.2021.100638', '10.1007/978-3-030-75015-2_15', '10.1007/978-3-030-86549-8_33', '10.1111/lnc3.12438', '10.1007/s11280-021-00972-6', '10.3233/sw-212865', '10.1007/978-3-031-11609-4_35', '10.3390/s22155765', '10.1007/978-3-031-19433-7_47', '10.3390/info13110510', '10.1109/access.2022.3208666'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/KFMWGIK8/Mesquita et al. - 2019 - KnowledgeNet A Benchmark Dataset for Knowledge Ba.pdf","","SAT_granularity:Cross-sentence; SAT_oldTag:CHECKED0923; SAT_task:RE; SAT_task:RC; SAT_task:CorefReso; SAT_task:EntityLinking; SAT_task:NER; SAT_source:Wikidata; SAT_method_selection:Human; SAT_source:Wikipedia; SAT_All_checked:True; SAT_source:DBpedia; SAT_negativeExamples:True; SAT_nbSent:9000; SAT_nbtypes_relations:15; SAT_nbTriples:13000; SAT_extend:T-REX; SAT_method_selection:MultiHuman; SAT_method_generation:Pipeline; SAT_rel_type:qualified; SAT_task:GraphGeneration; FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","","","","","","","","","","","","",""
"E7JFTFEM","conferencePaper","2020",", Fabio Petroni; , Aleksandra Piktus; , Angela Fan; , Patrick Lewis; , Majid Yazdani; , Nicola De Cao; , James Thorne; , Yacine Jernite; , Vladimir Karpukhin; , Jean Maillard; , Vassilis Plachouras; , Tim Rocktäschel; , Sebastian Riedel","KILT: a Benchmark for Knowledge Intensive Language Tasks","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2021.naacl-main.200","https://arxiv.org/abs/2009.02252v4","Challenging problems such as open-domain question answering, fact checking, slot filling and entity linking require access to large, external knowledge sources. While some models do well on individual tasks, developing general models is difficult as each task might require computationally expensive indexing of custom knowledge sources, in addition to dedicated infrastructure. To catalyze research on models that condition on specific information in large textual resources, we present a benchmark for knowledge-intensive language tasks (KILT). All tasks in KILT are grounded in the same snapshot of Wikipedia, reducing engineering turnaround through the re-use of components, as well as accelerating research into task-agnostic memory architectures. We test both task-specific and general baselines, evaluating downstream performance in addition to the ability of the models to provide provenance. We find that a shared dense vector index coupled with a seq2seq model is a strong baseline, outperforming more tailor-made approaches for fact checking, open-domain question answering and dialogue, and yielding competitive results on entity linking and slot filling, by generating disambiguated text. KILT data and code are available at https://github.com/facebookresearch/KILT.","2020-09-04","2025-02-06 08:47:21","2025-02-06 08:47:21","","NA","","","NA","","","KILT","","","","","ACL","","","True","","https://paperswithcode.com/paper/kilt-a-benchmark-for-knowledge-intensive","https://github.com/facebookresearch/KILT","","","{'citing': ['10.7238/artnodes.v0i28.385735', '10.1186/s40537-021-00492-0', '10.1162/tacl_a_00407', '10.1007/978-3-030-88361-4_19', '10.1162/tacl_a_00446', '10.3233/sw-212865', '10.1162/tacl_a_00460', '10.1145/3477314.3506999', '10.1162/tacl_a_00475', '10.1109/access.2022.3190408', '10.1145/3477495.3531712', '10.1007/978-3-031-14756-2_9', '10.1007/978-3-031-17189-5_19', '10.1145/3543829.3543830', '10.1145/3511808.3557388', '10.1016/b978-0-323-89931-4.00005-5'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/6HRTWJR4/ et al. - 2020 - KILT a Benchmark for Knowledge Intensive Language.pdf","","FILTER_STEP; DOMAIN:?; GRANULARITY:?; LANG:?; TASK:Entitylinking; TASK:Slotfilling; DATATYPEPROP:?; NBTYPEREL:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBDOC:?; NBENTITY:?; NBSENT:?; NBTRIPLES:?; NBTYPEENTITY:?; SOURCE:Wikipedia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL","","","","","","","","","","","","","","",""
"4SEHF4QB","conferencePaper","2016",", Andrej {\v{Z}}ukov-Gregori{\v{c}}; , Zhiyuan Luo; , Bartal Veyhe","IBC-C: A Dataset for Armed Conflict Analysis","","","","10.18653/v1/p16-2061","https://aclanthology.org/P16-2061","NA","2016-08-01","2025-02-06 08:47:21","2025-02-06 08:47:21","","NA","","","NA","","","IBC-C","","","","","ACL","","","False","","https://paperswithcode.com/paper/ibc-c-a-dataset-for-armed-conflict-analysis","NA","","","","","/root/snap/zotero-snap/common/Zotero/storage/YPU85RDB/ et al. - 2016 - IBC-C A Dataset for Armed Conflict Analysis.pdf","","LANG:?; TASK:Relextract; GRANULARITY:Document; GRANULARITY:Sentences; TASK:Ner; TASK:Slotfilling; DATATYPEPROP:?; NBTYPEREL:?; SELECTIONMETHOD:?; SYNTHGENERATION_BIN:?; NBENTITY:?; NBTRIPLES:?; SOURCE:?; NBSENT:10⁴; NBDOC:10⁴; NBTYPEENTITY:10⁰; DOMAIN:Military","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACL 2016 8","","","","","","","","","","","","","","",""
"98VZCCEJ","conferencePaper","2022",", Tobias Deußer; , Syed Musharraf Ali; , Lars Hillebrand; , Desiana Nurchalifah; , Basil Jacob; , Christian Bauckhage; , Rafet Sifa","KPI-EDGAR: A Novel Dataset and Accompanying Metric for Relation Extraction from Financial Documents","2022 21st IEEE International Conference on Machine Learning and Applications","","","10.1109/icmla55696.2022.00254","https://arxiv.org/abs/2210.09163v1","We introduce KPI-EDGAR, a novel dataset for Joint Named Entity Recognition and Relation Extraction building on financial reports uploaded to the Electronic Data Gathering, Analysis, and Retrieval (EDGAR) system, where the main objective is to extract Key Performance Indicators (KPIs) from financial documents and link them to their numerical values and other attributes. We further provide four accompanying baselines for benchmarking potential future research. Additionally, we propose a new way of measuring the success of said extraction process by incorporating a word-level weighting scheme into the conventional F1 score to better model the inherently fuzzy borders of the entity pairs of a relation in this domain.","2022-10-17","2025-02-06 08:47:21","2025-02-06 08:47:21","","","","","","","","KPI-EDGAR","","","","","IEEE","","","Registration","","https://paperswithcode.com/paper/kpi-edgar-a-novel-dataset-and-accompanying","https://www.sec.gov/edgar","","","","","/root/snap/zotero-snap/common/Zotero/storage/ZBJD2HDW/ et al. - 2022 - KPI-EDGAR A Novel Dataset and Accompanying Metric.pdf","","LANG:?; TASK:Relextract; GRANULARITY:Document; GRANULARITY:Sentences; TASK:Ner; TASK:Endtoendre; DATATYPEPROP:?; NBTYPEREL:?; SYNTHGENERATION_BIN:?; NBTYPEENTITY:?; SOURCE:?; SELECTIONMETHOD:Manual; NBDOC:10⁴; NBSENT:10³; NBTRIPLES:10³; DOMAIN:Finance; NBENTITY:10³","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICMLA","","","","","","","","","","","","","","",""
"48SV79EL","journalArticle","","Glavasˇ, Goran; ˇSnajder, Jan; Kordjamshidi, Parisa; Moens, Marie-Francine","HiEve: A Corpus for Extracting Event Hierarchies from News Stories","","","","","","In news stories, event mentions denote real-world events of different spatial and temporal granularity. Narratives in news stories typically describe some real-world event of coarse spatial and temporal granularity along with its subevents. In this work, we present HiEve, a corpus for recognizing relations of spatiotemporal containment between events. In HiEve, the narratives are represented as hierarchies of events based on relations of spatiotemporal containment (i.e., superevent–subevent relations). We describe the process of manual annotation of HiEve. Furthermore, we build a supervised classiﬁer for recognizing spatiotemporal containment between events to serve as a baseline for future research. Preliminary experimental results are encouraging, with classiﬁer performance reaching 58% F1-score, only 11% less than the inter-annotator agreement.","","2025-02-06 08:47:21","2025-02-06 08:47:21","","","","","","","","HIEVE","","","","","","","en","","","","","Zotero","","","","/root/snap/zotero-snap/common/Zotero/storage/8BF8QHW8/Glavasˇ et al. - HiEve A Corpus for Extracting Event Hierarchies from News Stories.pdf","","EXAMPLE; FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MDJHAFMZ","conferencePaper","2021","Cheng, Qiao; Liu, Juntao; Qu, Xiaoye; Zhao, Jin; Liang, Jiaqing; Wang, Zhefeng; Huai, Baoxing; Yuan, Nicholas Jing; Xiao, Yanghua","HacRED: A Large-Scale Relation Extraction Dataset Toward Hard Cases in Practical Applications","Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021","","","10.18653/v1/2021.findings-acl.249","https://aclanthology.org/2021.findings-acl.249","","2021-08","2025-02-06 08:47:21","2025-02-06 08:47:21","2023-03-22 11:25:40","2819–2831","","","","","","HacRED","","","","","Association for Computational Linguistics","Online","","True","","https://paperswithcode.com/paper/hacred-a-large-scale-relation-extraction","https://github. com/qiaojiim/HacRED","ACLWeb","","{'citing': ['10.3390/app12031599'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/II4IGQGB/Cheng et al. - 2021 - HacRED A Large-Scale Relation Extraction Dataset .pdf","","FILTER_STEP; DOMAIN:?; TASK:Relclassif; GRANULARITY:Document; TASK:Ner; TASK:Entitylinking; LANG:Chinese; DATATYPEPROP:?; SYNTHGENERATION_BIN:?; NBTYPEREL:10¹; NBENTITY:?; NBSENT:?; NBTYPEENTITY:?; SOURCE:Wikipedia; SELECTIONMETHOD:Manual; NBTRIPLES:10⁴; SOURCE:Dbpedia; NBDOC:10³","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings 2021","","","","","","","","","","","","","","",""
"4L5A696M","conferencePaper","2020",", Zhijing Jin; , Qipeng Guo; , Xipeng Qiu; , Zheng Zhang","GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation","","","","10.18653/v1/2020.coling-main.217","https://aclanthology.org/2020.coling-main.217/","Data collection for the knowledge graph-to-text generation is expensive. As a result, research on unsupervised models has emerged as an active field recently. However, most unsupervised models have to use non-parallel versions of existing small supervised datasets, which largely constrain their potential. In this paper, we propose a large-scale, general-domain dataset, GenWiki. Our unsupervised dataset has 1.3M text and graph examples, respectively. With a human-annotated test set, we provide this new benchmark dataset for future research on unsupervised text generation from knowledge graphs.","2020-12-01","2025-02-06 08:47:21","2025-02-06 08:47:21","","NA","","","NA","","","GenWiki","","","","","ACL","","","True","","https://paperswithcode.com/paper/genwiki-a-dataset-of-1-3-million-content","https://github.com/zhijing-jin/genwiki","","","{'citing': ['10.1109/access.2022.3146405'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/WPU9Z7X9/ et al. - 2020 - GenWiki A Dataset of 1.3 Million Content-Sharing .pdf","","DOMAIN:?; LANG:?; GRANULARITY:Sentences; TASK:Ner; DATATYPEPROP:?; SYNTHGENERATION_BIN:?; NBTYPEREL:10²; SELECTIONMETHOD:Automatic; NBDOC:?; NBSENT:?; NBTYPEENTITY:?; SOURCE:Wikipedia; SOURCE:Dbpedia; NBTRIPLES:10⁶; NBENTITY:10⁶","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SFMC685A","dataset","2024","","google-research-datasets/relation-extraction-corpus","","","","","https://github.com/google-research-datasets/relation-extraction-corpus","Automatically exported from code.google.com/p/relation-extraction-corpus","2024-03-23","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 09:56:38","","","","","","","GoogleRE","","","","","Google Research Datasets","","","","","","","GitHub","","original-date: 2015-12-14T23:01:15Z","","","","EXAMPLE; FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5P6Q4EDP","conferencePaper","2018","Wang, Alex; Singh, Amanpreet; Michael, Julian; Hill, Felix; Levy, Omer; Bowman, Samuel","GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding","Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP","","","10.18653/v1/W18-5446","https://aclanthology.org/W18-5446/","Human ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions.","2018-11","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:11:40","353–355","","","","","","GLUE","","","","","Association for Computational Linguistics","Brussels, Belgium","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/G99NEPT7/Wang et al. - 2018 - GLUE A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding.pdf","","FILTER_STEP","","Linzen, Tal; Chrupała, Grzegorz; Alishahi, Afra","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2018","","","","","","","","","","","","","","",""
"4XSJ47Q2","conferencePaper","2019","Wu, Ye; Luo, Ruibang; Leung, Henry C. M.; Ting, Hing-Fung; Lam, Tak-Wah","RENET: A Deep Learning Approach for Extracting Gene-Disease Associations from Literature","Research in Computational Molecular Biology","978-3-030-17083-7","","10.1007/978-3-030-17083-7_17","","Over one million new biomedical articles are published every year. Efficient and accurate text-mining tools are urgently needed to automatically extract knowledge from these articles to support research and genetic testing. In particular, the extraction of gene-disease associations is mostly studied. However, existing text-mining tools for extracting gene-disease associations have limited capacity, as each sentence is considered separately. Our experiments show that the best existing tools, such as BeFree and DTMiner, achieve a precision of 48% and recall rate of 78% at most. In this study, we designed and implemented a deep learning approach, named RENET, which considers the correlation between the sentences in an article to extract gene-disease associations. Our method has significantly improved the precision and recall rate to 85.2% and 81.8%, respectively. The source code of RENET is available at https://bitbucket.org/alexwuhkucs/gda-extraction/src/master/.","2019","2025-02-06 08:47:21","2025-02-06 08:47:21","","272-284","","","","","","GDA","","","","","Springer International Publishing","Cham","en","","","","","Springer Link","","","","","","EXAMPLE; FILTER_STEP","","Cowen, Lenore J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z36S3J39","journalArticle","2015","Ling, Xiao; Singh, Sameer; Weld, Daniel S.","Design Challenges for Entity Linking","Transactions of the Association for Computational Linguistics","","","10.1162/tacl_a_00141","https://aclanthology.org/Q15-1023/","Recent research on entity linking (EL) has introduced a plethora of promising techniques, ranging from deep neural networks to joint inference. But despite numerous papers there is surprisingly little understanding of the state of the art in EL. We attack this confusion by analyzing differences between several versions of the EL problem and presenting a simple yet effective, modular, unsupervised system, called Vinculum, for entity linking. We conduct an extensive evaluation on nine data sets, comparing Vinculum with two state-of-the-art systems, and elucidate key aspects of the system that include mention extraction, candidate generation, entity type prediction, entity coreference, and coherence.","2015","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:07:19","315–328","","","3","","","FIGER","","","","","","","","","","","","ACLWeb","","Place: Cambridge, MA Publisher: MIT Press","","/root/snap/zotero-snap/common/Zotero/storage/LEJZ2X7U/Ling et al. - 2015 - Design Challenges for Entity Linking.pdf","","FILTER_STEP","","Collins, Michael; Lee, Lillian","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2YF686Q4","conferencePaper","2019","Gao, Tianyu; Han, Xu; Zhu, Hao; Liu, Zhiyuan; Li, Peng; Sun, Maosong; Zhou, Jie","FewRel 2.0: Towards More Challenging Few-Shot Relation Classification","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","10.18653/v1/d19-1649","https://aclanthology.org/D19-1649","We present FewRel 2.0, a more challenging task to investigate two aspects of few-shot relation classification models: (1) Can they adapt to a new domain with only a handful of instances? (2) Can they detect none-of-the-above (NOTA) relations? To construct FewRel 2.0, we build upon the FewRel dataset by adding a new test set in a quite different domain, and a NOTA relation choice. With the new dataset and extensive experimental analysis, we found (1) that the state-of-the-art few-shot relation classification models struggle on these two aspects, and (2) that the commonly-used techniques for domain adaptation and NOTA detection still cannot handle the two challenges well. Our research calls for more attention and further efforts to these two real-world issues. All details and resources about the dataset and baselines are released at https://github.com/thunlp/fewrel.","2019-11","2025-02-06 08:47:21","2025-02-06 08:47:21","2023-02-28 16:25:14","6250–6255","","","","","","FewRel2","","","","","Association for Computational Linguistics","Hong Kong, China","","True","","https://paperswithcode.com/paper/fewrel-20-towards-more-challenging-few-shot","https://github.com/thunlp/fewrel","ACLWeb","","{'citing': ['10.1145/3340531.3411858', '10.1145/3340531.3412153', '10.1007/978-3-030-67661-2_37', '10.2196/25670', '10.2196/preprints.25670', '10.1016/j.ipm.2021.102596', '10.1162/tacl_a_00392', '10.1145/3447548.3467438', '10.1007/s12559-021-09917-7', '10.1007/978-3-030-82136-4_9', '10.1007/978-3-030-84186-7_13', '10.1016/j.jii.2021.100301', '10.1007/978-3-030-88480-2_56', '10.1145/3459637.3482268', '10.1145/3459637.3482280', '10.1016/j.ipm.2021.102863', '10.1007/s00521-021-06667-3', '10.1016/j.neucom.2022.04.067', '10.1109/ssci50451.2021.9660108', '10.1007/978-3-030-93119-3_8', '10.1016/j.csl.2022.101432', '10.1007/s13042-022-01604-9', '10.1145/3510030', '10.1007/s10489-022-03596-z', '10.1109/taslp.2022.3153254', '10.1117/12.2631869', '10.1109/s.a.i.ence50533.2020.9303192', '10.1109/icccs52626.2021.9449297', '10.1109/iv51561.2020.00051', '10.1109/cvprw56347.2022.00447', '10.3390/electronics11152423', '10.1145/3511808.3557323', '10.1145/3511808.3557422', '10.1109/taffc.2022.3205358', '10.3390/math10224378'], 'cited': []}","","/root/snap/zotero-snap/common/Zotero/storage/VPMYDN3Q/Gao et al. - 2019 - FewRel 2.0 Towards More Challenging Few-Shot Rela.pdf","","EXAMPLE; DONE; TASK:Relclassif; TASK:Relextract; GRANULARITY:Sentences; DOMAIN:Biomedical; LANG:English; DOMAIN:General; SELECTIONMETHOD:Automatic; NBTYPEREL:10¹; SOURCE:Wikidata; SOURCE:Wikipedia; SELECTIONMETHOD:Manual; SOURCE:Pubmed; NBSENT:10³; NBTRIPLES:10³; SOURCE:Umls; SYNTHGENERATION_BIN:0; DATATYPEPROP:None; NBTYPEENTITY:NSP; NBDATASET:2; NBENTITY:NSP; TASK:NER; NBMODEL:6","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP-IJCNLP 2019","","","","","","","","","","","","","","",""
"2ESEFFZP","conferencePaper","2002","Ohta, Tomoko; Tateisi, Yuka; Kim, Jin-Dong","The GENIA corpus: an annotated research abstract corpus in molecular biology domain","Proceedings of the second international conference on Human Language Technology Research","","","","","With the information overload in genome-related field, there is an increasing need for natural language processing technology to extract information from literature and various attempts of information extraction using NLP has been being made. We are developing the necessary resources including domain ontology and annotated corpus from research abstracts in MEDLINE database (GENIA corpus). We are building the ontology and the corpus simultaneously, using each other. In this paper we report on our new corpus, its ontological basis, annotation scheme, and statistics of annotated objects. We also describe the tools used for corpus annotation and management.","2002-03-24","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-28","82–86","","","","","","GENIA","HLT '02","","","","Morgan Kaufmann Publishers Inc.","San Francisco, CA, USA","","","","","","ACM Digital Library","","","","/root/snap/zotero-snap/common/Zotero/storage/9JKL4QR6/Ohta et al. - 2002 - The GENIA corpus an annotated research abstract corpus in molecular biology domain.pdf","","EXAMPLE; FILTER_STEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4V7UNCPW","preprint","2018","Jat, Sharmistha; Khandelwal, Siddhesh; Talukdar, Partha","Improving Distantly Supervised Relation Extraction using Word and Entity Based Attention","","","","10.48550/arXiv.1804.06987","http://arxiv.org/abs/1804.06987","Relation extraction is the problem of classifying the relationship between two entities in a given sentence. Distant Supervision (DS) is a popular technique for developing relation extractors starting with limited supervision. We note that most of the sentences in the distant supervision relation extraction setting are very long and may benefit from word attention for better sentence representation. Our contributions in this paper are threefold. Firstly, we propose two novel word attention models for distantly- supervised relation extraction: (1) a Bi-directional Gated Recurrent Unit (Bi-GRU) based word attention model (BGWA), (2) an entity-centric attention model (EA), and (3) a combination model which combines multiple complementary models using weighted voting method for improved relation extraction. Secondly, we introduce GDS, a new distant supervision dataset for relation extraction. GDS removes test data noise present in all previous distant- supervision benchmark datasets, making credible automatic evaluation possible. Thirdly, through extensive experiments on multiple real-world datasets, we demonstrate the effectiveness of the proposed methods.","2018-04-19","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-28 18:32:50","","","","","","","GDS","","","","","arXiv","","","","","","","arXiv.org","","arXiv:1804.06987 [cs]","","/root/snap/zotero-snap/common/Zotero/storage/XTFPHLVH/Jat et al. - 2018 - Improving Distantly Supervised Relation Extraction using Word and Entity Based Attention.pdf; /root/snap/zotero-snap/common/Zotero/storage/8D2J56WH/1804.html","","EXAMPLE; FILTER_STEP","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:1804.06987","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2V5MEIFJ","conferencePaper","2018","Thorne, James; Vlachos, Andreas; Christodoulopoulos, Christos; Mittal, Arpit","FEVER: a Large-scale Dataset for Fact Extraction and VERification","Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)","","","10.18653/v1/N18-1074","https://aclanthology.org/N18-1074/","In this paper we introduce a new publicly available dataset for verification against textual sources, FEVER: Fact Extraction and VERification. It consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from. The claims are classified as Supported, Refuted or NotEnoughInfo by annotators achieving 0.6841 in Fleiss kappa. For the first two classes, the annotators also recorded the sentence(s) forming the necessary evidence for their judgment. To characterize the challenge of the dataset presented, we develop a pipeline approach and compare it to suitably designed oracles. The best accuracy we achieve on labeling a claim accompanied by the correct evidence is 31.87%, while if we ignore the evidence we achieve 50.91%. Thus we believe that FEVER is a challenging testbed that will help stimulate progress on claim verification against textual sources.","2018-06","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 10:10:59","809–819","","","","","","FEVER","","","","","Association for Computational Linguistics","New Orleans, Louisiana","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/VCKR767Z/Thorne et al. - 2018 - FEVER a Large-scale Dataset for Fact Extraction and VERification.pdf","","FILTER_STEP","","Walker, Marilyn; Ji, Heng; Stent, Amanda","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NAACL-HLT 2018","","","","","","","","","","","","","","",""
"NNCVM49D","conferencePaper","2015","Toutanova, Kristina; Chen, Danqi; Pantel, Patrick; Poon, Hoifung; Choudhury, Pallavi; Gamon, Michael","Representing Text for Joint Embedding of Text and Knowledge Bases","Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/D15-1174","https://aclanthology.org/D15-1174/","","2015-09","2025-02-06 08:47:21","2025-02-06 08:47:21","2025-01-30 11:14:37","1499–1509","","","","","","FB15K-237","","","","","Association for Computational Linguistics","Lisbon, Portugal","","","","","","ACLWeb","","","","/root/snap/zotero-snap/common/Zotero/storage/8BQTS7RM/Toutanova et al. - 2015 - Representing Text for Joint Embedding of Text and Knowledge Bases.pdf","","FILTER_STEP","","Màrquez, Lluís; Callison-Burch, Chris; Su, Jian","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EMNLP 2015","","","","","","","","","","","","","","",""